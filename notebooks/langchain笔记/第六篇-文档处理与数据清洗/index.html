<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第六篇 文档处理与数据清洗：从非结构化到结构化# 在RAG（检索增强生成）系统中，文档处理质量（ETL）直接决定了最终效果的上限。“Garbage In, Garbage Out” 是绝对真理。无论你的模型多么强大，如果喂给它的数据是破碎、混乱或含有噪声的，检索效果一定很差。
本篇不仅介绍工具的使用，更侧重于生产级文档处理方法论，对比 LangChain 和 LlamaIndex 的最佳实践，并涵盖最新的 PDF 解析技术（如 MinerU, LlamaParse）。
学习路径# graph LR A[ETL核心方法论] --> B[Loading<br/>多模态加载] B --> C[Chunking<br/>智能切分] C --> D[Metadata<br/>元数据增强] D --> E[实战<br/>复杂PDF处理] style A fill:#e1f5e1 style B fill:#fff4e1 style D fill:#ffe1e1 style E fill:#e1f5fe Part 1: ETL 核心方法论# 在构建 LLM 应用时，我们遵循标准的 ETL (Extract, Transform, Load) 流程，但在向量数据库语境下，通常描述为：
Load (加载): 将各种非结构化数据（PDF, HTML, MarkDown）统一为标准 Document 对象。 Split (切分): 将长文档切分为适合 Embedding 模型窗口（如 512/1024 tokens）的 Chunks。 Embed (向量化): 将文本块转化为向量。 Store (存储): 存入向量数据库。 关键数据结构对比：
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第六篇 文档处理与数据清洗"><meta property="og:description" content="第六篇 文档处理与数据清洗：从非结构化到结构化# 在RAG（检索增强生成）系统中，文档处理质量（ETL）直接决定了最终效果的上限。“Garbage In, Garbage Out” 是绝对真理。无论你的模型多么强大，如果喂给它的数据是破碎、混乱或含有噪声的，检索效果一定很差。
本篇不仅介绍工具的使用，更侧重于生产级文档处理方法论，对比 LangChain 和 LlamaIndex 的最佳实践，并涵盖最新的 PDF 解析技术（如 MinerU, LlamaParse）。
学习路径# graph LR A[ETL核心方法论] --> B[Loading<br/>多模态加载] B --> C[Chunking<br/>智能切分] C --> D[Metadata<br/>元数据增强] D --> E[实战<br/>复杂PDF处理] style A fill:#e1f5e1 style B fill:#fff4e1 style D fill:#ffe1e1 style E fill:#e1f5fe Part 1: ETL 核心方法论# 在构建 LLM 应用时，我们遵循标准的 ETL (Extract, Transform, Load) 流程，但在向量数据库语境下，通常描述为：
Load (加载): 将各种非结构化数据（PDF, HTML, MarkDown）统一为标准 Document 对象。 Split (切分): 将长文档切分为适合 Embedding 模型窗口（如 512/1024 tokens）的 Chunks。 Embed (向量化): 将文本块转化为向量。 Store (存储): 存入向量数据库。 关键数据结构对比："><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第六篇 文档处理与数据清洗"><meta itemprop=description content="第六篇 文档处理与数据清洗：从非结构化到结构化# 在RAG（检索增强生成）系统中，文档处理质量（ETL）直接决定了最终效果的上限。“Garbage In, Garbage Out” 是绝对真理。无论你的模型多么强大，如果喂给它的数据是破碎、混乱或含有噪声的，检索效果一定很差。
本篇不仅介绍工具的使用，更侧重于生产级文档处理方法论，对比 LangChain 和 LlamaIndex 的最佳实践，并涵盖最新的 PDF 解析技术（如 MinerU, LlamaParse）。
学习路径# graph LR A[ETL核心方法论] --> B[Loading<br/>多模态加载] B --> C[Chunking<br/>智能切分] C --> D[Metadata<br/>元数据增强] D --> E[实战<br/>复杂PDF处理] style A fill:#e1f5e1 style B fill:#fff4e1 style D fill:#ffe1e1 style E fill:#e1f5fe Part 1: ETL 核心方法论# 在构建 LLM 应用时，我们遵循标准的 ETL (Extract, Transform, Load) 流程，但在向量数据库语境下，通常描述为：
Load (加载): 将各种非结构化数据（PDF, HTML, MarkDown）统一为标准 Document 对象。 Split (切分): 将长文档切分为适合 Embedding 模型窗口（如 512/1024 tokens）的 Chunks。 Embed (向量化): 将文本块转化为向量。 Store (存储): 存入向量数据库。 关键数据结构对比："><meta itemprop=wordCount content="873"><title>第六篇 文档处理与数据清洗 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle checked>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/ class=active>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第六篇 文档处理与数据清洗</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#学习路径>学习路径</a></li><li><a href=#part-1-etl-核心方法论>Part 1: ETL 核心方法论</a></li><li><a href=#part-2-数据加载-loading>Part 2: 数据加载 (Loading)</a><ul><li><a href=#21-langchain-加载方案>2.1 LangChain 加载方案</a><ul><li><a href=#211-网页加载-webbaseloader>2.1.1 网页加载 (WebBaseLoader)</a></li><li><a href=#212-目录加载-directoryloader>2.1.2 目录加载 (DirectoryLoader)</a></li></ul></li><li><a href=#22-llamaindex-加载方案>2.2 LlamaIndex 加载方案</a><ul><li><a href=#221-simpledirectoryreader-全能王>2.2.1 SimpleDirectoryReader (全能王)</a></li><li><a href=#222-llamahub-加载器生态>2.2.2 LlamaHub (加载器生态)</a></li></ul></li></ul></li><li><a href=#part-3-智能切分-chunking>Part 3: 智能切分 (Chunking)</a><ul><li><a href=#langchain-vs-llamaindex-切分器对比>LangChain vs LlamaIndex 切分器对比</a></li><li><a href=#31-langchain-递归字符切分>3.1 LangChain: 递归字符切分</a></li><li><a href=#32-llamaindex-句子窗口切分>3.2 LlamaIndex: 句子窗口切分</a></li><li><a href=#33-高级策略分层切分-hierarchical-chunking>3.3 高级策略：分层切分 (Hierarchical Chunking)</a></li></ul></li><li><a href=#part-4-元数据提取-metadata-extraction>Part 4: 元数据提取 (Metadata Extraction)</a><ul><li><a href=#41-使用-llm-提取元数据>4.1 使用 LLM 提取元数据</a></li><li><a href=#42-llamaindex-自动化-pipeline>4.2 LlamaIndex 自动化 Pipeline</a></li></ul></li><li><a href=#part-5-复杂文档实战-pdf--tables>Part 5: 复杂文档实战 (PDF & Tables)</a><ul><li><a href=#51-解决方案对比矩阵>5.1 解决方案对比矩阵</a></li><li><a href=#52-llamaparse-实战-推荐>5.2 LlamaParse 实战 (推荐)</a></li><li><a href=#53-mineru-实战-学术公式场景>5.3 MinerU 实战 (学术/公式场景)</a></li><li><a href=#54-图片与图表处理-multimodal-rag>5.4 图片与图表处理 (Multimodal RAG)</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第六篇-文档处理与数据清洗从非结构化到结构化>第六篇 文档处理与数据清洗：从非结构化到结构化<a class=anchor href=#%e7%ac%ac%e5%85%ad%e7%af%87-%e6%96%87%e6%a1%a3%e5%a4%84%e7%90%86%e4%b8%8e%e6%95%b0%e6%8d%ae%e6%b8%85%e6%b4%97%e4%bb%8e%e9%9d%9e%e7%bb%93%e6%9e%84%e5%8c%96%e5%88%b0%e7%bb%93%e6%9e%84%e5%8c%96>#</a></h1><p>在RAG（检索增强生成）系统中，<strong>文档处理质量（ETL）直接决定了最终效果的上限</strong>。&ldquo;Garbage In, Garbage Out&rdquo; 是绝对真理。无论你的模型多么强大，如果喂给它的数据是破碎、混乱或含有噪声的，检索效果一定很差。</p><p>本篇不仅介绍工具的使用，更侧重于<strong>生产级文档处理方法论</strong>，对比 LangChain 和 LlamaIndex 的最佳实践，并涵盖最新的 PDF 解析技术（如 MinerU, LlamaParse）。</p><hr><h2 id=学习路径>学习路径<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84>#</a></h2><pre class=mermaid>graph LR
    A[ETL核心方法论] --&gt; B[Loading&lt;br/&gt;多模态加载]
    B --&gt; C[Chunking&lt;br/&gt;智能切分]
    C --&gt; D[Metadata&lt;br/&gt;元数据增强]
    D --&gt; E[实战&lt;br/&gt;复杂PDF处理]

    style A fill:#e1f5e1
    style B fill:#fff4e1
    style D fill:#ffe1e1
    style E fill:#e1f5fe</pre><script src=/mermaid.min.js></script><script>mermaid.initialize({flowchart:{useMaxWidth:!0},theme:"default"})</script><hr><h2 id=part-1-etl-核心方法论>Part 1: ETL 核心方法论<a class=anchor href=#part-1-etl-%e6%a0%b8%e5%bf%83%e6%96%b9%e6%b3%95%e8%ae%ba>#</a></h2><p>在构建 LLM 应用时，我们遵循标准的 <strong>ETL (Extract, Transform, Load)</strong> 流程，但在向量数据库语境下，通常描述为：</p><ol><li><strong>Load (加载)</strong>: 将各种非结构化数据（PDF, HTML, MarkDown）统一为标准 <code>Document</code> 对象。</li><li><strong>Split (切分)</strong>: 将长文档切分为适合 Embedding 模型窗口（如 512/1024 tokens）的 <code>Chunks</code>。</li><li><strong>Embed (向量化)</strong>: 将文本块转化为向量。</li><li><strong>Store (存储)</strong>: 存入向量数据库。</li></ol><p><strong>关键数据结构对比</strong>：</p><table><thead><tr><th>概念</th><th>LangChain</th><th>LlamaIndex</th><th>说明</th></tr></thead><tbody><tr><td><strong>原始文档</strong></td><td><code>Document</code></td><td><code>Document</code></td><td>包含 <code>page_content</code> (text) 和 <code>metadata</code></td></tr><tr><td><strong>切分单元</strong></td><td><code>Document</code> (chunk)</td><td><code>Node</code></td><td>LlamaIndex 的 Node 结构更丰富，包含关系信息</td></tr><tr><td><strong>加载器</strong></td><td><code>BaseLoader</code></td><td><code>BaseReader</code></td><td>接口命名不同，功能类似</td></tr></tbody></table><hr><h2 id=part-2-数据加载-loading>Part 2: 数据加载 (Loading)<a class=anchor href=#part-2-%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd-loading>#</a></h2><h3 id=21-langchain-加载方案>2.1 LangChain 加载方案<a class=anchor href=#21-langchain-%e5%8a%a0%e8%bd%bd%e6%96%b9%e6%a1%88>#</a></h3><p>LangChain 的加载器生态非常丰富，适合处理异构数据源。</p><h4 id=211-网页加载-webbaseloader>2.1.1 网页加载 (WebBaseLoader)<a class=anchor href=#211-%e7%bd%91%e9%a1%b5%e5%8a%a0%e8%bd%bd-webbaseloader>#</a></h4><p>最常用的网页加载器，基于 <code>BeautifulSoup</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_community.document_loaders</span> <span class=kn>import</span> <span class=n>WebBaseLoader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 加载单个网页</span>
</span></span><span class=line><span class=cl><span class=n>loader</span> <span class=o>=</span> <span class=n>WebBaseLoader</span><span class=p>(</span><span class=s2>&#34;https://python.langchain.com/docs/get_started/introduction&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>docs</span> <span class=o>=</span> <span class=n>loader</span><span class=o>.</span><span class=n>load</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loaded </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>docs</span><span class=p>)</span><span class=si>}</span><span class=s2> docs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Content preview: </span><span class=si>{</span><span class=n>docs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>page_content</span><span class=p>[:</span><span class=mi>200</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Metadata: </span><span class=si>{</span><span class=n>docs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>metadata</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 并行加载多个网页</span>
</span></span><span class=line><span class=cl><span class=n>loader_multi</span> <span class=o>=</span> <span class=n>WebBaseLoader</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;https://www.google.com&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;https://www.baidu.com&#34;</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>loader_multi</span><span class=o>.</span><span class=n>requests_per_second</span> <span class=o>=</span> <span class=mi>2</span>  <span class=c1># 限流</span>
</span></span><span class=line><span class=cl><span class=n>docs_multi</span> <span class=o>=</span> <span class=n>loader_multi</span><span class=o>.</span><span class=n>aload</span><span class=p>()</span> <span class=c1># 异步加载</span></span></span></code></pre></div><h4 id=212-目录加载-directoryloader>2.1.2 目录加载 (DirectoryLoader)<a class=anchor href=#212-%e7%9b%ae%e5%bd%95%e5%8a%a0%e8%bd%bd-directoryloader>#</a></h4><p>适合加载本地知识库文件夹。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_community.document_loaders</span> <span class=kn>import</span> <span class=n>DirectoryLoader</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_community.document_loaders</span> <span class=kn>import</span> <span class=n>TextLoader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载指定目录下所有的 .md 文件</span>
</span></span><span class=line><span class=cl><span class=n>loader</span> <span class=o>=</span> <span class=n>DirectoryLoader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;./knowledge_base&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>glob</span><span class=o>=</span><span class=s2>&#34;**/*.md&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>loader_cls</span><span class=o>=</span><span class=n>TextLoader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>show_progress</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>docs</span> <span class=o>=</span> <span class=n>loader</span><span class=o>.</span><span class=n>load</span><span class=p>()</span></span></span></code></pre></div><h3 id=22-llamaindex-加载方案>2.2 LlamaIndex 加载方案<a class=anchor href=#22-llamaindex-%e5%8a%a0%e8%bd%bd%e6%96%b9%e6%a1%88>#</a></h3><p>LlamaIndex 的 <code>SimpleDirectoryReader</code> 是目前最强大的全能加载器，一行代码即可处理 PDF, Word, Excel, 图片等多种格式。</p><h4 id=221-simpledirectoryreader-全能王>2.2.1 SimpleDirectoryReader (全能王)<a class=anchor href=#221-simpledirectoryreader-%e5%85%a8%e8%83%bd%e7%8e%8b>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.core</span> <span class=kn>import</span> <span class=n>SimpleDirectoryReader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 基础用法：加载目录</span>
</span></span><span class=line><span class=cl><span class=n>reader</span> <span class=o>=</span> <span class=n>SimpleDirectoryReader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>input_dir</span><span class=o>=</span><span class=s2>&#34;./data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>recursive</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>         <span class=c1># 递归子目录</span>
</span></span><span class=line><span class=cl>    <span class=n>required_exts</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;.pdf&#34;</span><span class=p>,</span> <span class=s2>&#34;.docx&#34;</span><span class=p>],</span> <span class=c1># 指定后缀</span>
</span></span><span class=line><span class=cl>    <span class=n>filename_as_id</span><span class=o>=</span><span class=kc>True</span>     <span class=c1># 使用文件名做ID</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>documents</span> <span class=o>=</span> <span class=n>reader</span><span class=o>.</span><span class=n>load_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Loaded </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span><span class=si>}</span><span class=s2> docs&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 自定义特定的加载器 (例如对 .pdf 使用特殊的解析逻辑)</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.readers.file</span> <span class=kn>import</span> <span class=n>PDFReader</span>
</span></span><span class=line><span class=cl><span class=n>file_extractor</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;.pdf&#34;</span><span class=p>:</span> <span class=n>PDFReader</span><span class=p>()}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>reader_custom</span> <span class=o>=</span> <span class=n>SimpleDirectoryReader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;./data&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>file_extractor</span><span class=o>=</span><span class=n>file_extractor</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h4 id=222-llamahub-加载器生态>2.2.2 LlamaHub (加载器生态)<a class=anchor href=#222-llamahub-%e5%8a%a0%e8%bd%bd%e5%99%a8%e7%94%9f%e6%80%81>#</a></h4><p>LlamaIndex 拥有世界上最大的数据加载器社区 <strong>LlamaHub</strong>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 例如：加载 Notion 数据</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.readers.notion</span> <span class=kn>import</span> <span class=n>NotionPageReader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 需要先在 Notion 申请 Integration Token</span>
</span></span><span class=line><span class=cl><span class=n>reader</span> <span class=o>=</span> <span class=n>NotionPageReader</span><span class=p>(</span><span class=n>integration_token</span><span class=o>=</span><span class=s2>&#34;secret_xxx&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>documents</span> <span class=o>=</span> <span class=n>reader</span><span class=o>.</span><span class=n>load_data</span><span class=p>(</span><span class=n>page_ids</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;page_id_1&#34;</span><span class=p>,</span> <span class=s2>&#34;page_id_2&#34;</span><span class=p>])</span></span></span></code></pre></div><hr><h2 id=part-3-智能切分-chunking>Part 3: 智能切分 (Chunking)<a class=anchor href=#part-3-%e6%99%ba%e8%83%bd%e5%88%87%e5%88%86-chunking>#</a></h2><p>切分策略直接影响检索的准确性。切分太碎会丢失上下文，切分太大则包含噪声。</p><h3 id=langchain-vs-llamaindex-切分器对比>LangChain vs LlamaIndex 切分器对比<a class=anchor href=#langchain-vs-llamaindex-%e5%88%87%e5%88%86%e5%99%a8%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>特性</th><th>LangChain: <code>RecursiveCharacterTextSplitter</code></th><th>LlamaIndex: <code>SentenceSplitter</code></th></tr></thead><tbody><tr><td><strong>默认行为</strong></td><td>递归尝试分隔符 <code>["\n\n", "\n", " ", ""]</code></td><td>优先按句子完整性切分，窗口滑动</td></tr><tr><td><strong>优势</strong></td><td>通用性强，适合代码、Markdown</td><td>语义保留更好，适合纯文本</td></tr><tr><td><strong>元数据</strong></td><td>需手动维护</td><td>自动保留前后文关系 (Relationships)</td></tr></tbody></table><h3 id=31-langchain-递归字符切分>3.1 LangChain: 递归字符切分<a class=anchor href=#31-langchain-%e9%80%92%e5%bd%92%e5%ad%97%e7%ac%a6%e5%88%87%e5%88%86>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_text_splitters</span> <span class=kn>import</span> <span class=n>RecursiveCharacterTextSplitter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>text_splitter</span> <span class=o>=</span> <span class=n>RecursiveCharacterTextSplitter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>chunk_size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>      <span class=c1># 块大小</span>
</span></span><span class=line><span class=cl>    <span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>200</span><span class=p>,</span>    <span class=c1># 重叠部分，防止上下文丢失</span>
</span></span><span class=line><span class=cl>    <span class=n>separators</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;</span><span class=se>\n\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=s2>&#34;</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>,</span> <span class=s2>&#34; &#34;</span><span class=p>,</span> <span class=s2>&#34;&#34;</span><span class=p>]</span> <span class=c1># 优先级从左到右</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>splits</span> <span class=o>=</span> <span class=n>text_splitter</span><span class=o>.</span><span class=n>split_documents</span><span class=p>(</span><span class=n>docs</span><span class=p>)</span></span></span></code></pre></div><h3 id=32-llamaindex-句子窗口切分>3.2 LlamaIndex: 句子窗口切分<a class=anchor href=#32-llamaindex-%e5%8f%a5%e5%ad%90%e7%aa%97%e5%8f%a3%e5%88%87%e5%88%86>#</a></h3><p>LlamaIndex 的切分器通常称为 <code>NodeParser</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.core.node_parser</span> <span class=kn>import</span> <span class=n>SentenceSplitter</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 默认分块器</span>
</span></span><span class=line><span class=cl><span class=n>splitter</span> <span class=o>=</span> <span class=n>SentenceSplitter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>chunk_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>20</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nodes</span> <span class=o>=</span> <span class=n>splitter</span><span class=o>.</span><span class=n>get_nodes_from_documents</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看生成的 Node</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;生成了 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>nodes</span><span class=p>)</span><span class=si>}</span><span class=s2> 个节点&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>nodes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>get_content</span><span class=p>())</span> <span class=c1># 内容</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>nodes</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>relationships</span><span class=p>)</span> <span class=c1># 关系（上一块、下一块的ID）</span></span></span></code></pre></div><h3 id=33-高级策略分层切分-hierarchical-chunking>3.3 高级策略：分层切分 (Hierarchical Chunking)<a class=anchor href=#33-%e9%ab%98%e7%ba%a7%e7%ad%96%e7%95%a5%e5%88%86%e5%b1%82%e5%88%87%e5%88%86-hierarchical-chunking>#</a></h3><p>对于长文档，<strong>父子索引 (Parent-Child Indexing)</strong> 是一种非常有效的策略：</p><ul><li><strong>父块</strong>: 大块（如 2048 tokens），用于给 LLM 生成答案，保留完整上下文。</li><li><strong>子块</strong>: 小块（如 256 tokens），用于向量检索，提高精准度。</li></ul><p><strong>LlamaIndex 实现</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.core.node_parser</span> <span class=kn>import</span> <span class=n>HierarchicalNodeParser</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>node_parser</span> <span class=o>=</span> <span class=n>HierarchicalNodeParser</span><span class=o>.</span><span class=n>from_defaults</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>chunk_sizes</span><span class=o>=</span><span class=p>[</span><span class=mi>2048</span><span class=p>,</span> <span class=mi>512</span><span class=p>,</span> <span class=mi>128</span><span class=p>]</span> <span class=c1># 三层切分</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>nodes</span> <span class=o>=</span> <span class=n>node_parser</span><span class=o>.</span><span class=n>get_nodes_from_documents</span><span class=p>(</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 检索时，如果命中 128 的块，可以自动回溯到 2048 的父块内容</span></span></span></code></pre></div><hr><h2 id=part-4-元数据提取-metadata-extraction>Part 4: 元数据提取 (Metadata Extraction)<a class=anchor href=#part-4-%e5%85%83%e6%95%b0%e6%8d%ae%e6%8f%90%e5%8f%96-metadata-extraction>#</a></h2><p>单纯靠文本内容检索往往不够，我们需要<strong>结构化元数据</strong>（如标题、作者、摘要、关键词）来进行过滤（Pre-filtering）。</p><h3 id=41-使用-llm-提取元数据>4.1 使用 LLM 提取元数据<a class=anchor href=#41-%e4%bd%bf%e7%94%a8-llm-%e6%8f%90%e5%8f%96%e5%85%83%e6%95%b0%e6%8d%ae>#</a></h3><p>这是目前最灵活的方法。我们可以定义一个 Pydantic 模型，利用 LLM 的 Function Calling 能力提取元数据。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_core.pydantic_v1</span> <span class=kn>import</span> <span class=n>BaseModel</span><span class=p>,</span> <span class=n>Field</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>langchain_openai</span> <span class=kn>import</span> <span class=n>ChatOpenAI</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 定义元数据结构</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DocumentMetadata</span><span class=p>(</span><span class=n>BaseModel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>title</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;The title of the document&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>summary</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;A one-sentence summary&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>tags</span><span class=p>:</span> <span class=nb>list</span><span class=p>[</span><span class=nb>str</span><span class=p>]</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Keywords for categorization&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>sentiment</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=n>Field</span><span class=p>(</span><span class=o>...</span><span class=p>,</span> <span class=n>description</span><span class=o>=</span><span class=s2>&#34;Sentiment: positive, negative, or neutral&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 配置 LLM</span>
</span></span><span class=line><span class=cl><span class=n>llm</span> <span class=o>=</span> <span class=n>ChatOpenAI</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4&#34;</span><span class=p>,</span> <span class=n>temperature</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>structured_llm</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>with_structured_output</span><span class=p>(</span><span class=n>DocumentMetadata</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 提取函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_metadata</span><span class=p>(</span><span class=n>text_chunk</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>structured_llm</span><span class=o>.</span><span class=n>invoke</span><span class=p>(</span><span class=n>text_chunk</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试</span>
</span></span><span class=line><span class=cl><span class=n>sample_text</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>LlamaIndex v0.10 发布了！这次更新带来了重大的架构变革，
</span></span></span><span class=line><span class=cl><span class=s2>将库拆分为 llama-index-core 和各种插件包。用户现在可以按需安装依赖，
</span></span></span><span class=line><span class=cl><span class=s2>大大减小了包体积。社区对此反应热烈。
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>metadata</span> <span class=o>=</span> <span class=n>extract_metadata</span><span class=p>(</span><span class=n>sample_text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>metadata</span><span class=o>.</span><span class=n>json</span><span class=p>(</span><span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=c1># 输出:</span>
</span></span><span class=line><span class=cl><span class=c1># {</span>
</span></span><span class=line><span class=cl><span class=c1>#   &#34;title&#34;: &#34;LlamaIndex v0.10 Release&#34;,</span>
</span></span><span class=line><span class=cl><span class=c1>#   &#34;summary&#34;: &#34;LlamaIndex v0.10 introduces architectural changes splitting the core library from plugins for optimized dependency management.&#34;,</span>
</span></span><span class=line><span class=cl><span class=c1>#   &#34;tags&#34;: [&#34;LlamaIndex&#34;, &#34;Release&#34;, &#34;Python&#34;, &#34;Architecture&#34;],</span>
</span></span><span class=line><span class=cl><span class=c1>#   &#34;sentiment&#34;: &#34;positive&#34;</span>
</span></span><span class=line><span class=cl><span class=c1># }</span></span></span></code></pre></div><h3 id=42-llamaindex-自动化-pipeline>4.2 LlamaIndex 自动化 Pipeline<a class=anchor href=#42-llamaindex-%e8%87%aa%e5%8a%a8%e5%8c%96-pipeline>#</a></h3><p>LlamaIndex 提供了 <code>IngestionPipeline</code> 来串联提取过程。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.core.ingestion</span> <span class=kn>import</span> <span class=n>IngestionPipeline</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.core.extractors</span> <span class=kn>import</span> <span class=n>TitleExtractor</span><span class=p>,</span> <span class=n>SummaryExtractor</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>pipeline</span> <span class=o>=</span> <span class=n>IngestionPipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>transformations</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=n>SentenceSplitter</span><span class=p>(</span><span class=n>chunk_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>chunk_overlap</span><span class=o>=</span><span class=mi>200</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>TitleExtractor</span><span class=p>(</span><span class=n>nodes</span><span class=o>=</span><span class=mi>5</span><span class=p>),</span>    <span class=c1>#利用前5个节点生成标题</span>
</span></span><span class=line><span class=cl>        <span class=n>SummaryExtractor</span><span class=p>(</span><span class=n>summaries</span><span class=o>=</span><span class=p>[</span><span class=s2>&#34;prev&#34;</span><span class=p>,</span> <span class=s2>&#34;self&#34;</span><span class=p>,</span> <span class=s2>&#34;next&#34;</span><span class=p>]),</span> <span class=c1># 生成摘要</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>nodes</span> <span class=o>=</span> <span class=n>pipeline</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>documents</span><span class=o>=</span><span class=n>documents</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># nodes[0].metadata 现在会自动包含 &#39;document_title&#39;, &#39;section_summary&#39; 等字段</span></span></span></code></pre></div><hr><h2 id=part-5-复杂文档实战-pdf--tables>Part 5: 复杂文档实战 (PDF & Tables)<a class=anchor href=#part-5-%e5%a4%8d%e6%9d%82%e6%96%87%e6%a1%a3%e5%ae%9e%e6%88%98-pdf--tables>#</a></h2><p>真实世界的文档（尤其是 PDF）充满了挑战：多栏布局、表格、公式、图片。简单的 <code>PyPDF</code> 往往无法胜任。</p><h3 id=51-解决方案对比矩阵>5.1 解决方案对比矩阵<a class=anchor href=#51-%e8%a7%a3%e5%86%b3%e6%96%b9%e6%a1%88%e5%af%b9%e6%af%94%e7%9f%a9%e9%98%b5>#</a></h3><table><thead><tr><th>方案</th><th>核心技术</th><th>优势</th><th>劣势</th><th>推荐场景</th></tr></thead><tbody><tr><td><strong>LlamaParse</strong></td><td>LLM Vision</td><td>SOTA 表格/布局识别，Markdown 输出</td><td>付费，云端处理</td><td>复杂表格、图文混排商业文档</td></tr><tr><td><strong>MinerU</strong></td><td>Deep Learning</td><td>开源免费，公式识别极强 (LaTeX)</td><td>需 GPU，部署较重</td><td>学术论文、课本、公式密集型</td></tr><tr><td><strong>PyMuPDF</strong></td><td>Rule-based</td><td>极快，免费</td><td>复杂布局/表格无法处理</td><td>纯文本 PDF，简单发票</td></tr><tr><td><strong>Unstructured</strong></td><td>Hybrid</td><td>格式支持最全</td><td>速度较慢，依赖系统库多</td><td>格式杂乱的文档堆</td></tr></tbody></table><h3 id=52-llamaparse-实战-推荐>5.2 LlamaParse 实战 (推荐)<a class=anchor href=#52-llamaparse-%e5%ae%9e%e6%88%98-%e6%8e%a8%e8%8d%90>#</a></h3><p>LlamaParse 是专为 RAG 设计的解析器，它直接将 PDF 转换为 Markdown，完美保留标题层级和表格结构。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># pip install llama-parse</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_parse</span> <span class=kn>import</span> <span class=n>LlamaParse</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>llama_index.core</span> <span class=kn>import</span> <span class=n>SimpleDirectoryReader</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 配置 API Key (https://cloud.llamaindex.ai/)</span>
</span></span><span class=line><span class=cl><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=p>[</span><span class=s2>&#34;LLAMA_CLOUD_API_KEY&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=s2>&#34;llx-...&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 配置解析器</span>
</span></span><span class=line><span class=cl><span class=n>parser</span> <span class=o>=</span> <span class=n>LlamaParse</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>result_type</span><span class=o>=</span><span class=s2>&#34;markdown&#34;</span><span class=p>,</span>  <span class=c1># 输出 Markdown</span>
</span></span><span class=line><span class=cl>    <span class=n>verbose</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>language</span><span class=o>=</span><span class=s2>&#34;zh&#34;</span><span class=p>,</span>           <span class=c1># 支持中文</span>
</span></span><span class=line><span class=cl>    <span class=n>gpt4o_mode</span><span class=o>=</span><span class=kc>True</span>          <span class=c1># 开启高级多模态识别 (消耗更多 credit)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 结合 SimpleDirectoryReader 使用</span>
</span></span><span class=line><span class=cl><span class=n>file_extractor</span> <span class=o>=</span> <span class=p>{</span><span class=s2>&#34;.pdf&#34;</span><span class=p>:</span> <span class=n>parser</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=n>reader</span> <span class=o>=</span> <span class=n>SimpleDirectoryReader</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;./complex_docs&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>file_extractor</span><span class=o>=</span><span class=n>file_extractor</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>documents</span> <span class=o>=</span> <span class=n>reader</span><span class=o>.</span><span class=n>load_data</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 检查结果</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>documents</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>text</span><span class=p>[:</span><span class=mi>500</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=c1># 你会发现表格被转换为了 Markdown Table 格式：</span>
</span></span><span class=line><span class=cl><span class=c1># | 季度 | 营收 | 利润 |</span>
</span></span><span class=line><span class=cl><span class=c1># |-----|------|-----|</span>
</span></span><span class=line><span class=cl><span class=c1># | Q1  | 100  | 20  |</span></span></span></code></pre></div><h3 id=53-mineru-实战-学术公式场景>5.3 MinerU 实战 (学术/公式场景)<a class=anchor href=#53-mineru-%e5%ae%9e%e6%88%98-%e5%ad%a6%e6%9c%af%e5%85%ac%e5%bc%8f%e5%9c%ba%e6%99%af>#</a></h3><p>如果你处理的是包含大量数学公式的论文，MinerU (Magic-PDF) 是目前开源界的 SOTA。</p><p><em>注：MinerU 需要独立部署，以下为 Python 调用示例。</em></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 假设已在本地安装 magic-pdf</span>
</span></span><span class=line><span class=cl><span class=c1># pip install magic-pdf[full]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># MinerU 通常通过命令行使用，但也可以封装为 Python 函数</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_pdf_with_mineru</span><span class=p>(</span><span class=n>pdf_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>dirname</span><span class=p>(</span><span class=n>pdf_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 调用 CLI (实际生产环境建议使用 API 服务模式)</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>system</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;magic-pdf -p </span><span class=si>{</span><span class=n>pdf_path</span><span class=si>}</span><span class=s2> -o </span><span class=si>{</span><span class=n>output_dir</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># MinerU 会生成 .md 文件</span>
</span></span><span class=line><span class=cl>    <span class=n>md_path</span> <span class=o>=</span> <span class=n>pdf_path</span><span class=o>.</span><span class=n>replace</span><span class=p>(</span><span class=s2>&#34;.pdf&#34;</span><span class=p>,</span> <span class=s2>&#34;.md&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>exists</span><span class=p>(</span><span class=n>md_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>md_path</span><span class=p>,</span> <span class=s2>&#34;r&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 读取后的 Markdown 内容可以直接喂给 LangChain/LlamaIndex</span>
</span></span><span class=line><span class=cl><span class=n>markdown_content</span> <span class=o>=</span> <span class=n>process_process_pdf_with_mineru</span><span class=p>(</span><span class=s2>&#34;./paper.pdf&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=54-图片与图表处理-multimodal-rag>5.4 图片与图表处理 (Multimodal RAG)<a class=anchor href=#54-%e5%9b%be%e7%89%87%e4%b8%8e%e5%9b%be%e8%a1%a8%e5%a4%84%e7%90%86-multimodal-rag>#</a></h3><p>对于 PDF 中的图片，通常有两种策略：</p><ol><li><strong>OCR 转文本</strong>: 使用 GPT-4o-vision 描述图片内容，存为文本。</li><li><strong>多模态索引</strong>: 将图片直接作为 Embedding 存入（如 CLIP Embedding），支持文搜图。</li></ol><p><strong>策略 1 代码示例 (使用 GPT-4o 生成图片描述)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 这是一个概念性示例</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_image</span><span class=p>(</span><span class=n>image_bytes</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>langchain_openai</span> <span class=kn>import</span> <span class=n>ChatOpenAI</span>
</span></span><span class=line><span class=cl>    <span class=kn>from</span> <span class=nn>langchain_core.messages</span> <span class=kn>import</span> <span class=n>HumanMessage</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>chat</span> <span class=o>=</span> <span class=n>ChatOpenAI</span><span class=p>(</span><span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>msg</span> <span class=o>=</span> <span class=n>HumanMessage</span><span class=p>(</span><span class=n>content</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;请详细描述这张图片中的图表数据或关键信息。&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span> <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>chat</span><span class=o>.</span><span class=n>invoke</span><span class=p>([</span><span class=n>msg</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>content</span></span></span></code></pre></div><h2 id=总结>总结<a class=anchor href=#%e6%80%bb%e7%bb%93>#</a></h2><p>文档处理是 RAG 系统中最 &ldquo;脏&rdquo; 但最 &ldquo;重要&rdquo; 的环节。</p><ul><li><strong>Loading</strong>: 首选 <strong>LlamaIndex SimpleDirectoryReader</strong>，简单强大。</li><li><strong>Parsing</strong>: 复杂 PDF 首选 <strong>LlamaParse</strong> (商业) 或 <strong>MinerU</strong> (开源)。</li><li><strong>Chunking</strong>: 文本用 <strong>SentenceSplitter</strong>，代码用 <strong>RecursiveCharacterTextSplitter</strong>。</li><li><strong>Metadata</strong>: 务必提取 <strong>标题</strong> 和 <strong>摘要</strong>，这对检索排序至关重要。</li></ul><p>做好 ETL，你的 RAG 系统就已经成功了一半。</p></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第五篇 RAG高级篇(LlamaIndex篇)</span>
</a></span><span><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/ class="flex align-center"><span>第七篇 Deep Agents</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#学习路径>学习路径</a></li><li><a href=#part-1-etl-核心方法论>Part 1: ETL 核心方法论</a></li><li><a href=#part-2-数据加载-loading>Part 2: 数据加载 (Loading)</a><ul><li><a href=#21-langchain-加载方案>2.1 LangChain 加载方案</a><ul><li><a href=#211-网页加载-webbaseloader>2.1.1 网页加载 (WebBaseLoader)</a></li><li><a href=#212-目录加载-directoryloader>2.1.2 目录加载 (DirectoryLoader)</a></li></ul></li><li><a href=#22-llamaindex-加载方案>2.2 LlamaIndex 加载方案</a><ul><li><a href=#221-simpledirectoryreader-全能王>2.2.1 SimpleDirectoryReader (全能王)</a></li><li><a href=#222-llamahub-加载器生态>2.2.2 LlamaHub (加载器生态)</a></li></ul></li></ul></li><li><a href=#part-3-智能切分-chunking>Part 3: 智能切分 (Chunking)</a><ul><li><a href=#langchain-vs-llamaindex-切分器对比>LangChain vs LlamaIndex 切分器对比</a></li><li><a href=#31-langchain-递归字符切分>3.1 LangChain: 递归字符切分</a></li><li><a href=#32-llamaindex-句子窗口切分>3.2 LlamaIndex: 句子窗口切分</a></li><li><a href=#33-高级策略分层切分-hierarchical-chunking>3.3 高级策略：分层切分 (Hierarchical Chunking)</a></li></ul></li><li><a href=#part-4-元数据提取-metadata-extraction>Part 4: 元数据提取 (Metadata Extraction)</a><ul><li><a href=#41-使用-llm-提取元数据>4.1 使用 LLM 提取元数据</a></li><li><a href=#42-llamaindex-自动化-pipeline>4.2 LlamaIndex 自动化 Pipeline</a></li></ul></li><li><a href=#part-5-复杂文档实战-pdf--tables>Part 5: 复杂文档实战 (PDF & Tables)</a><ul><li><a href=#51-解决方案对比矩阵>5.1 解决方案对比矩阵</a></li><li><a href=#52-llamaparse-实战-推荐>5.2 LlamaParse 实战 (推荐)</a></li><li><a href=#53-mineru-实战-学术公式场景>5.3 MinerU 实战 (学术/公式场景)</a></li><li><a href=#54-图片与图表处理-multimodal-rag>5.4 图片与图表处理 (Multimodal RAG)</a></li></ul></li><li><a href=#总结>总结</a></li></ul></nav></div></aside></main></body></html>