<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第11章 广义线性模型 (Generalized Linear Models)# “The purpose of models is not to fit the data but to sharpen the questions.” — Samuel Karlin
11.1 引言：从线性回归到GLM# 在前面的章节中,我们已经学习了线性回归和逻辑回归两个重要模型：
线性回归：假设 $y \sim \mathcal{N}(\boldsymbol{w}^T\boldsymbol{x}, \sigma^2)$，用于预测连续值 逻辑回归：假设 $y \sim \text{Bernoulli}(\sigma(\boldsymbol{w}^T\boldsymbol{x}))$，用于二分类 这两个看似不同的模型，实际上可以统一在广义线性模型 (Generalized Linear Model, GLM) 的框架下。GLM 通过引入指数族分布和链接函数，为处理各种类型的响应变量（连续、离散、计数等）提供了统一的理论框架。
核心思想：GLM 不直接建模 $E[y|\boldsymbol{x}]$，而是对其进行某种变换后再与线性预测器 $\boldsymbol{w}^T\boldsymbol{x}$ 建立关系。
11.1.1 为什么需要GLM？# 传统线性回归的局限性：
响应变量类型受限：只能处理服从正态分布的连续变量 异方差问题：方差与均值相关时，模型假设被违背 取值范围限制：无法保证预测值在合理范围内（如概率 $\in [0,1]$，计数 $\in \mathbb{N}$） GLM 通过以下方式解决这些问题：
允许响应变量服从指数族分布 通过链接函数将均值映射到实数域 方差可以是均值的函数 11.2 指数族分布# 11.2.1 指数族的通用形式# 如果随机变量 $y$ 的概率密度（或质量）函数可以写成以下形式，则称 $y$ 服从指数族分布：
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第11章 广义线性模型(GLM)"><meta property="og:description" content="第11章 广义线性模型 (Generalized Linear Models)# “The purpose of models is not to fit the data but to sharpen the questions.” — Samuel Karlin
11.1 引言：从线性回归到GLM# 在前面的章节中,我们已经学习了线性回归和逻辑回归两个重要模型：
线性回归：假设 $y \sim \mathcal{N}(\boldsymbol{w}^T\boldsymbol{x}, \sigma^2)$，用于预测连续值 逻辑回归：假设 $y \sim \text{Bernoulli}(\sigma(\boldsymbol{w}^T\boldsymbol{x}))$，用于二分类 这两个看似不同的模型，实际上可以统一在广义线性模型 (Generalized Linear Model, GLM) 的框架下。GLM 通过引入指数族分布和链接函数，为处理各种类型的响应变量（连续、离散、计数等）提供了统一的理论框架。
核心思想：GLM 不直接建模 $E[y|\boldsymbol{x}]$，而是对其进行某种变换后再与线性预测器 $\boldsymbol{w}^T\boldsymbol{x}$ 建立关系。
11.1.1 为什么需要GLM？# 传统线性回归的局限性：
响应变量类型受限：只能处理服从正态分布的连续变量 异方差问题：方差与均值相关时，模型假设被违背 取值范围限制：无法保证预测值在合理范围内（如概率 $\in [0,1]$，计数 $\in \mathbb{N}$） GLM 通过以下方式解决这些问题：
允许响应变量服从指数族分布 通过链接函数将均值映射到实数域 方差可以是均值的函数 11.2 指数族分布# 11.2.1 指数族的通用形式# 如果随机变量 $y$ 的概率密度（或质量）函数可以写成以下形式，则称 $y$ 服从指数族分布："><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第11章 广义线性模型(GLM)"><meta itemprop=description content="第11章 广义线性模型 (Generalized Linear Models)# “The purpose of models is not to fit the data but to sharpen the questions.” — Samuel Karlin
11.1 引言：从线性回归到GLM# 在前面的章节中,我们已经学习了线性回归和逻辑回归两个重要模型：
线性回归：假设 $y \sim \mathcal{N}(\boldsymbol{w}^T\boldsymbol{x}, \sigma^2)$，用于预测连续值 逻辑回归：假设 $y \sim \text{Bernoulli}(\sigma(\boldsymbol{w}^T\boldsymbol{x}))$，用于二分类 这两个看似不同的模型，实际上可以统一在广义线性模型 (Generalized Linear Model, GLM) 的框架下。GLM 通过引入指数族分布和链接函数，为处理各种类型的响应变量（连续、离散、计数等）提供了统一的理论框架。
核心思想：GLM 不直接建模 $E[y|\boldsymbol{x}]$，而是对其进行某种变换后再与线性预测器 $\boldsymbol{w}^T\boldsymbol{x}$ 建立关系。
11.1.1 为什么需要GLM？# 传统线性回归的局限性：
响应变量类型受限：只能处理服从正态分布的连续变量 异方差问题：方差与均值相关时，模型假设被违背 取值范围限制：无法保证预测值在合理范围内（如概率 $\in [0,1]$，计数 $\in \mathbb{N}$） GLM 通过以下方式解决这些问题：
允许响应变量服从指数族分布 通过链接函数将均值映射到实数域 方差可以是均值的函数 11.2 指数族分布# 11.2.1 指数族的通用形式# 如果随机变量 $y$ 的概率密度（或质量）函数可以写成以下形式，则称 $y$ 服从指数族分布："><meta itemprop=wordCount content="2201"><title>第11章 广义线性模型(GLM) | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle checked>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/ class=active>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第11章 广义线性模型(GLM)</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#111-引言从线性回归到glm>11.1 引言：从线性回归到GLM</a><ul><li><a href=#1111-为什么需要glm>11.1.1 为什么需要GLM？</a></li></ul></li><li><a href=#112-指数族分布>11.2 指数族分布</a><ul><li><a href=#1121-指数族的通用形式>11.2.1 指数族的通用形式</a></li><li><a href=#1122-指数族的核心性质>11.2.2 指数族的核心性质</a></li><li><a href=#1123-常见分布属于指数族>11.2.3 常见分布属于指数族</a><ul><li><a href=#1-高斯分布>(1) 高斯分布</a></li><li><a href=#2-伯努利分布>(2) 伯努利分布</a></li><li><a href=#3-泊松分布>(3) 泊松分布</a></li></ul></li></ul></li><li><a href=#113-glm的三要素>11.3 GLM的三要素</a><ul><li><a href=#1131-随机成分-random-component>11.3.1 随机成分 (Random Component)</a></li><li><a href=#1132-系统成分-systematic-component>11.3.2 系统成分 (Systematic Component)</a></li><li><a href=#1133-链接函数-link-function>11.3.3 链接函数 (Link Function)</a><ul><li><a href=#常见链接函数>常见链接函数</a></li></ul></li></ul></li><li><a href=#114-glm的参数估计>11.4 GLM的参数估计</a><ul><li><a href=#1141-极大似然估计>11.4.1 极大似然估计</a></li><li><a href=#1142-梯度计算>11.4.2 梯度计算</a></li><li><a href=#1143-迭代加权最小二乘-irls>11.4.3 迭代加权最小二乘 (IRLS)</a></li></ul></li><li><a href=#115-案例分析统一框架下的三大模型>11.5 案例分析：统一框架下的三大模型</a><ul><li><a href=#1151-线性回归>11.5.1 线性回归</a></li><li><a href=#1152-逻辑回归>11.5.2 逻辑回归</a></li><li><a href=#1153-泊松回归>11.5.3 泊松回归</a></li><li><a href=#1154-统一框架的威力>11.5.4 统一框架的威力</a></li></ul></li><li><a href=#116-模型诊断与评估>11.6 模型诊断与评估</a><ul><li><a href=#1161-偏差-deviance>11.6.1 偏差 (Deviance)</a></li><li><a href=#1162-pearson-残差>11.6.2 Pearson 残差</a></li><li><a href=#1163-aic-与-bic>11.6.3 AIC 与 BIC</a></li></ul></li><li><a href=#117-glm的扩展>11.7 GLM的扩展</a><ul><li><a href=#1171-准似然-quasi-likelihood>11.7.1 准似然 (Quasi-likelihood)</a></li><li><a href=#1172-零膨胀模型-zero-inflated-models>11.7.2 零膨胀模型 (Zero-Inflated Models)</a></li><li><a href=#1173-广义加性模型-gam>11.7.3 广义加性模型 (GAM)</a></li></ul></li><li><a href=#118-实践案例保险索赔建模>11.8 实践案例：保险索赔建模</a><ul><li><a href=#1181-问题背景>11.8.1 问题背景</a></li><li><a href=#1182-模型选择>11.8.2 模型选择</a></li><li><a href=#1183-模型拟合>11.8.3 模型拟合</a></li><li><a href=#1184-模型诊断>11.8.4 模型诊断</a></li></ul></li><li><a href=#119-理论深化glm与指数族的深层联系>11.9 理论深化：GLM与指数族的深层联系</a><ul><li><a href=#1191-充分统计量与信息几何>11.9.1 充分统计量与信息几何</a></li><li><a href=#1192-fisher-信息矩阵>11.9.2 Fisher 信息矩阵</a></li><li><a href=#1193-glm的渐近性质>11.9.3 GLM的渐近性质</a></li></ul></li><li><a href=#1110-总结与展望>11.10 总结与展望</a><ul><li><a href=#11101-核心要点回顾>11.10.1 核心要点回顾</a></li><li><a href=#11102-glm与其他模型的关系>11.10.2 GLM与其他模型的关系</a></li><li><a href=#11103-进一步学习方向>11.10.3 进一步学习方向</a></li><li><a href=#11104-哲学思考>11.10.4 哲学思考</a></li></ul></li><li><a href=#参考文献>参考文献</a></li><li><a href=#附录python实现示例>附录：Python实现示例</a><ul><li><a href=#a1-使用-statsmodels-拟合glm>A.1 使用 statsmodels 拟合GLM</a></li><li><a href=#a2-手动实现irls算法>A.2 手动实现IRLS算法</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第11章-广义线性模型-generalized-linear-models>第11章 广义线性模型 (Generalized Linear Models)<a class=anchor href=#%e7%ac%ac11%e7%ab%a0-%e5%b9%bf%e4%b9%89%e7%ba%bf%e6%80%a7%e6%a8%a1%e5%9e%8b-generalized-linear-models>#</a></h1><blockquote class=book-hint><p>&ldquo;The purpose of models is not to fit the data but to sharpen the questions.&rdquo;
— Samuel Karlin</p></blockquote><hr><h2 id=111-引言从线性回归到glm>11.1 引言：从线性回归到GLM<a class=anchor href=#111-%e5%bc%95%e8%a8%80%e4%bb%8e%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92%e5%88%b0glm>#</a></h2><p>在前面的章节中,我们已经学习了<strong>线性回归</strong>和<strong>逻辑回归</strong>两个重要模型：</p><ul><li><strong>线性回归</strong>：假设 $y \sim \mathcal{N}(\boldsymbol{w}^T\boldsymbol{x}, \sigma^2)$，用于预测连续值</li><li><strong>逻辑回归</strong>：假设 $y \sim \text{Bernoulli}(\sigma(\boldsymbol{w}^T\boldsymbol{x}))$，用于二分类</li></ul><p>这两个看似不同的模型，实际上可以统一在<strong>广义线性模型 (Generalized Linear Model, GLM)</strong> 的框架下。GLM 通过引入<strong>指数族分布</strong>和<strong>链接函数</strong>，为处理各种类型的响应变量（连续、离散、计数等）提供了统一的理论框架。</p><blockquote class=book-hint><p><strong>核心思想</strong>：GLM 不直接建模 $E[y|\boldsymbol{x}]$，而是对其进行某种变换后再与线性预测器 $\boldsymbol{w}^T\boldsymbol{x}$ 建立关系。</p></blockquote><h3 id=1111-为什么需要glm>11.1.1 为什么需要GLM？<a class=anchor href=#1111-%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81glm>#</a></h3><p>传统线性回归的局限性：</p><ol><li><strong>响应变量类型受限</strong>：只能处理服从正态分布的连续变量</li><li><strong>异方差问题</strong>：方差与均值相关时，模型假设被违背</li><li><strong>取值范围限制</strong>：无法保证预测值在合理范围内（如概率 $\in [0,1]$，计数 $\in \mathbb{N}$）</li></ol><p>GLM 通过以下方式解决这些问题：</p><ul><li>允许响应变量服从<strong>指数族分布</strong></li><li>通过<strong>链接函数</strong>将均值映射到实数域</li><li>方差可以是均值的函数</li></ul><hr><h2 id=112-指数族分布>11.2 指数族分布<a class=anchor href=#112-%e6%8c%87%e6%95%b0%e6%97%8f%e5%88%86%e5%b8%83>#</a></h2><h3 id=1121-指数族的通用形式>11.2.1 指数族的通用形式<a class=anchor href=#1121-%e6%8c%87%e6%95%b0%e6%97%8f%e7%9a%84%e9%80%9a%e7%94%a8%e5%bd%a2%e5%bc%8f>#</a></h3><p>如果随机变量 $y$ 的概率密度（或质量）函数可以写成以下形式，则称 $y$ 服从<strong>指数族分布</strong>：</p><p>$$
p(y|\eta) = h(y) \exp\left(\eta T(y) - A(\eta)\right)
$$</p><p>其中：</p><ul><li>$\eta$ 称为<strong>自然参数 (natural parameter)</strong> 或<strong>典范参数 (canonical parameter)</strong></li><li>$T(y)$ 称为<strong>充分统计量 (sufficient statistic)</strong>，通常 $T(y) = y$</li><li>$A(\eta)$ 称为<strong>对数配分函数 (log partition function)</strong>，用于归一化</li><li>$h(y)$ 称为<strong>基础测度 (base measure)</strong></li></ul><blockquote class=book-hint><p><strong>重要性质</strong>：对数配分函数 $A(\eta)$ 是凸函数，其导数和二阶导数分别给出分布的均值和方差。</p></blockquote><h3 id=1122-指数族的核心性质>11.2.2 指数族的核心性质<a class=anchor href=#1122-%e6%8c%87%e6%95%b0%e6%97%8f%e7%9a%84%e6%a0%b8%e5%bf%83%e6%80%a7%e8%b4%a8>#</a></h3><p>通过对概率密度函数积分，可以推导出：</p><p>$$
\int h(y) \exp\left(\eta T(y) - A(\eta)\right) dy = 1
$$</p><p>对 $\eta$ 求导：</p><p>$$
\frac{\partial}{\partial \eta} \int h(y) \exp\left(\eta T(y) - A(\eta)\right) dy = 0
$$</p><p>$$
\int h(y) \left(T(y) - A&rsquo;(\eta)\right) \exp\left(\eta T(y) - A(\eta)\right) dy = 0
$$</p><p>$$
\mathbb{E}[T(y)] = A&rsquo;(\eta)
$$</p><blockquote class=book-hint><p><strong>性质1</strong>：均值由对数配分函数的一阶导数给出：$\mu = \mathbb{E}[y] = A&rsquo;(\eta)$</p></blockquote><p>继续对 $\eta$ 求二阶导数：</p><p>$$
\frac{\partial^2 A(\eta)}{\partial \eta^2} = \text{Var}(T(y))
$$</p><blockquote class=book-hint><p><strong>性质2</strong>：方差由对数配分函数的二阶导数给出：$\text{Var}(y) = A&rsquo;&rsquo;(\eta)$</p></blockquote><p>这两个性质在 GLM 的推导中起着核心作用。</p><h3 id=1123-常见分布属于指数族>11.2.3 常见分布属于指数族<a class=anchor href=#1123-%e5%b8%b8%e8%a7%81%e5%88%86%e5%b8%83%e5%b1%9e%e4%ba%8e%e6%8c%87%e6%95%b0%e6%97%8f>#</a></h3><h4 id=1-高斯分布>(1) 高斯分布<a class=anchor href=#1-%e9%ab%98%e6%96%af%e5%88%86%e5%b8%83>#</a></h4><p>$$
p(y|\mu, \sigma^2) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{(y-\mu)^2}{2\sigma^2}\right)
$$</p><p>展开：</p><p>$$
= \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{y^2}{2\sigma^2} + \frac{\mu y}{\sigma^2} - \frac{\mu^2}{2\sigma^2}\right)
$$</p><p>对比指数族形式（假设 $\sigma^2$ 已知）：</p><p>$$
\begin{cases}
\eta = \frac{\mu}{\sigma^2} \
T(y) = y \
A(\eta) = \frac{\mu^2}{2\sigma^2} = \frac{\sigma^2 \eta^2}{2} \
h(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\left(-\frac{y^2}{2\sigma^2}\right)
\end{cases}
$$</p><p>验证性质：</p><p>$$
\mathbb{E}[y] = A&rsquo;(\eta) = \sigma^2 \eta = \mu \quad \checkmark
$$</p><p>$$
\text{Var}(y) = A&rsquo;&rsquo;(\eta) = \sigma^2 \quad \checkmark
$$</p><h4 id=2-伯努利分布>(2) 伯努利分布<a class=anchor href=#2-%e4%bc%af%e5%8a%aa%e5%88%a9%e5%88%86%e5%b8%83>#</a></h4><p>$$
p(y|\phi) = \phi^y (1-\phi)^{1-y}, \quad y \in {0, 1}
$$</p><p>取对数并重排：</p><p>$$
\log p(y|\phi) = y \log \phi + (1-y) \log(1-\phi)
$$</p><p>$$
= y \log \frac{\phi}{1-\phi} + \log(1-\phi)
$$</p><p>$$
= y \eta - \log(1 + e^\eta)
$$</p><p>其中 $\eta = \log \frac{\phi}{1-\phi}$ 是 <strong>logit 函数</strong>，反解得 $\phi = \frac{1}{1+e^{-\eta}} = \sigma(\eta)$。</p><p>对比指数族形式：</p><p>$$
\begin{cases}
\eta = \log \frac{\phi}{1-\phi} \
T(y) = y \
A(\eta) = \log(1 + e^\eta) \
h(y) = 1
\end{cases}
$$</p><p>验证性质：</p><p>$$
\mathbb{E}[y] = A&rsquo;(\eta) = \frac{e^\eta}{1+e^\eta} = \sigma(\eta) = \phi \quad \checkmark
$$</p><p>$$
\text{Var}(y) = A&rsquo;&rsquo;(\eta) = \frac{e^\eta}{(1+e^\eta)^2} = \phi(1-\phi) \quad \checkmark
$$</p><h4 id=3-泊松分布>(3) 泊松分布<a class=anchor href=#3-%e6%b3%8a%e6%9d%be%e5%88%86%e5%b8%83>#</a></h4><p>$$
p(y|\lambda) = \frac{\lambda^y e^{-\lambda}}{y!}, \quad y \in {0, 1, 2, \ldots}
$$</p><p>取对数：</p><p>$$
\log p(y|\lambda) = y \log \lambda - \lambda - \log(y!)
$$</p><p>对比指数族形式：</p><p>$$
\begin{cases}
\eta = \log \lambda \
T(y) = y \
A(\eta) = e^\eta = \lambda \
h(y) = \frac{1}{y!}
\end{cases}
$$</p><p>验证性质：</p><p>$$
\mathbb{E}[y] = A&rsquo;(\eta) = e^\eta = \lambda \quad \checkmark
$$</p><p>$$
\text{Var}(y) = A&rsquo;&rsquo;(\eta) = e^\eta = \lambda \quad \checkmark
$$</p><blockquote class=book-hint><p><strong>小结</strong>：高斯、伯努利、泊松分布都可以写成指数族形式，这为 GLM 提供了理论基础。</p></blockquote><hr><h2 id=113-glm的三要素>11.3 GLM的三要素<a class=anchor href=#113-glm%e7%9a%84%e4%b8%89%e8%a6%81%e7%b4%a0>#</a></h2><p>广义线性模型由以下三个要素定义：</p><h3 id=1131-随机成分-random-component>11.3.1 随机成分 (Random Component)<a class=anchor href=#1131-%e9%9a%8f%e6%9c%ba%e6%88%90%e5%88%86-random-component>#</a></h3><p>响应变量 $y$ 服从<strong>指数族分布</strong>：</p><p>$$
p(y|\theta, \phi) = \exp\left(\frac{y\theta - b(\theta)}{a(\phi)} + c(y, \phi)\right)
$$</p><p>其中：</p><ul><li>$\theta$ 是自然参数</li><li>$\phi$ 是离散参数（dispersion parameter），通常已知</li><li>$a(\phi) = \phi / w$，$w$ 是权重</li></ul><blockquote class=book-hint><p>注意：这里的参数化形式与 11.2.1 略有不同，但本质相同。</p></blockquote><h3 id=1132-系统成分-systematic-component>11.3.2 系统成分 (Systematic Component)<a class=anchor href=#1132-%e7%b3%bb%e7%bb%9f%e6%88%90%e5%88%86-systematic-component>#</a></h3><p>线性预测器：</p><p>$$
\eta = \boldsymbol{w}^T \boldsymbol{x} = w_0 + w_1 x_1 + \cdots + w_d x_d
$$</p><p>这是特征的线性组合，保持了线性模型的简单性。</p><h3 id=1133-链接函数-link-function>11.3.3 链接函数 (Link Function)<a class=anchor href=#1133-%e9%93%be%e6%8e%a5%e5%87%bd%e6%95%b0-link-function>#</a></h3><p>链接函数 $g(\cdot)$ 将期望 $\mu = \mathbb{E}[y]$ 与线性预测器 $\eta$ 联系起来：</p><p>$$
g(\mu) = \eta = \boldsymbol{w}^T \boldsymbol{x}
$$</p><p>等价地，反链接函数 $g^{-1}$ 为：</p><p>$$
\mu = g^{-1}(\eta) = g^{-1}(\boldsymbol{w}^T \boldsymbol{x})
$$</p><blockquote class=book-hint><p><strong>典范链接函数</strong>：当 $g(\mu) = \theta$（自然参数），称为<strong>典范链接 (canonical link)</strong>。此时 $\eta = \theta$，数学性质最优美。</p></blockquote><h4 id=常见链接函数>常见链接函数<a class=anchor href=#%e5%b8%b8%e8%a7%81%e9%93%be%e6%8e%a5%e5%87%bd%e6%95%b0>#</a></h4><table><thead><tr><th>分布</th><th>均值 $\mu$</th><th>典范链接 $g(\mu)$</th><th>反链接 $g^{-1}(\eta)$</th><th>应用场景</th></tr></thead><tbody><tr><td>高斯分布</td><td>$\mu$</td><td>$\mu$ (恒等)</td><td>$\eta$</td><td>线性回归</td></tr><tr><td>伯努利分布</td><td>$\phi$</td><td>$\log\frac{\phi}{1-\phi}$</td><td>$\frac{1}{1+e^{-\eta}}$</td><td>逻辑回归</td></tr><tr><td>泊松分布</td><td>$\lambda$</td><td>$\log \lambda$</td><td>$e^\eta$</td><td>计数回归</td></tr><tr><td>伽马分布</td><td>$\mu$</td><td>$\mu^{-1}$</td><td>$\eta^{-1}$</td><td>持续时间建模</td></tr></tbody></table><hr><h2 id=114-glm的参数估计>11.4 GLM的参数估计<a class=anchor href=#114-glm%e7%9a%84%e5%8f%82%e6%95%b0%e4%bc%b0%e8%ae%a1>#</a></h2><h3 id=1141-极大似然估计>11.4.1 极大似然估计<a class=anchor href=#1141-%e6%9e%81%e5%a4%a7%e4%bc%bc%e7%84%b6%e4%bc%b0%e8%ae%a1>#</a></h3><p>给定训练集 $\mathcal{D} = {(\boldsymbol{x}<em>i, y_i)}</em>{i=1}^n$，似然函数为：</p><p>$$
L(\boldsymbol{w}) = \prod_{i=1}^n p(y_i | \boldsymbol{x}_i, \boldsymbol{w})
$$</p><p>对数似然：</p><p>$$
\ell(\boldsymbol{w}) = \sum_{i=1}^n \log p(y_i | \boldsymbol{x}_i, \boldsymbol{w})
$$</p><p>对于指数族分布：</p><p>$$
\ell(\boldsymbol{w}) = \sum_{i=1}^n \left[\frac{y_i \theta_i - b(\theta_i)}{a(\phi)} + c(y_i, \phi)\right]
$$</p><p>其中 $\theta_i = g(\mu_i)$，$\mu_i = g^{-1}(\boldsymbol{w}^T \boldsymbol{x}_i)$。</p><h3 id=1142-梯度计算>11.4.2 梯度计算<a class=anchor href=#1142-%e6%a2%af%e5%ba%a6%e8%ae%a1%e7%ae%97>#</a></h3><p>对 $w_j$ 求偏导：</p><p>$$
\frac{\partial \ell}{\partial w_j} = \sum_{i=1}^n \frac{\partial \ell_i}{\partial \theta_i} \frac{\partial \theta_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \eta_i} \frac{\partial \eta_i}{\partial w_j}
$$</p><p>利用指数族性质：</p><p>$$
\frac{\partial \ell_i}{\partial \theta_i} = \frac{y_i - b&rsquo;(\theta_i)}{a(\phi)} = \frac{y_i - \mu_i}{a(\phi)}
$$</p><p>因为 $\mu_i = b&rsquo;(\theta_i)$（指数族性质）。</p><p>对于典范链接，$\theta_i = \eta_i = \boldsymbol{w}^T \boldsymbol{x}_i$，则：</p><p>$$
\frac{\partial \theta_i}{\partial \mu_i} \frac{\partial \mu_i}{\partial \eta_i} = 1
$$</p><p>$$
\frac{\partial \eta_i}{\partial w_j} = x_{ij}
$$</p><p>因此梯度简化为：</p><p>$$
\frac{\partial \ell}{\partial w_j} = \frac{1}{a(\phi)} \sum_{i=1}^n (y_i - \mu_i) x_{ij}
$$</p><blockquote class=book-hint><p><strong>关键观察</strong>：梯度形式与线性回归完全一致！这是典范链接的优美之处。</p></blockquote><h3 id=1143-迭代加权最小二乘-irls>11.4.3 迭代加权最小二乘 (IRLS)<a class=anchor href=#1143-%e8%bf%ad%e4%bb%a3%e5%8a%a0%e6%9d%83%e6%9c%80%e5%b0%8f%e4%ba%8c%e4%b9%98-irls>#</a></h3><p>对于非典范链接或更一般的情况，使用 <strong>Fisher Scoring</strong> 或 <strong>Newton-Raphson</strong> 迭代求解。</p><p>定义<strong>工作响应变量 (working response)</strong>：</p><p>$$
z_i = \eta_i + (y_i - \mu_i) \frac{\partial \eta_i}{\partial \mu_i}
$$</p><p>其中 $\frac{\partial \eta_i}{\partial \mu_i} = \frac{1}{g&rsquo;(\mu_i)}$ 是链接函数的导数的倒数。</p><p>定义<strong>迭代权重 (iterative weights)</strong>：</p><p>$$
w_i = \frac{1}{\text{Var}(y_i)} \left(\frac{\partial \mu_i}{\partial \eta_i}\right)^2 = \frac{(g&rsquo;(\mu_i))^2}{\text{Var}(y_i)}
$$</p><p><strong>IRLS 算法</strong>：</p><ol><li>初始化 $\boldsymbol{w}^{(0)}$，计算 $\eta_i^{(0)} = \boldsymbol{w}^{(0)T} \boldsymbol{x}_i$</li><li>重复直到收敛：<ul><li>计算 $\mu_i = g^{-1}(\eta_i)$</li><li>计算工作响应 $z_i$ 和权重 $w_i$</li><li>加权最小二乘更新：
$$
\boldsymbol{w}^{(t+1)} = (\boldsymbol{X}^T \boldsymbol{W} \boldsymbol{X})^{-1} \boldsymbol{X}^T \boldsymbol{W} \boldsymbol{z}
$$
其中 $\boldsymbol{W} = \text{diag}(w_1, \ldots, w_n)$</li></ul></li></ol><blockquote class=book-hint><p><strong>物理意义</strong>：IRLS 在每次迭代中对样本重新加权，使得方差较大的样本权重降低，提高估计的效率。</p></blockquote><hr><h2 id=115-案例分析统一框架下的三大模型>11.5 案例分析：统一框架下的三大模型<a class=anchor href=#115-%e6%a1%88%e4%be%8b%e5%88%86%e6%9e%90%e7%bb%9f%e4%b8%80%e6%a1%86%e6%9e%b6%e4%b8%8b%e7%9a%84%e4%b8%89%e5%a4%a7%e6%a8%a1%e5%9e%8b>#</a></h2><h3 id=1151-线性回归>11.5.1 线性回归<a class=anchor href=#1151-%e7%ba%bf%e6%80%a7%e5%9b%9e%e5%bd%92>#</a></h3><p><strong>设定</strong>：</p><ul><li>分布：$y \sim \mathcal{N}(\mu, \sigma^2)$</li><li>链接函数：恒等链接 $g(\mu) = \mu$</li><li>线性预测器：$\eta = \boldsymbol{w}^T \boldsymbol{x}$</li></ul><p>因此：</p><p>$$
\mu = \boldsymbol{w}^T \boldsymbol{x}
$$</p><p>负对数似然：</p><p>$$
-\ell(\boldsymbol{w}) = \frac{1}{2\sigma^2} \sum_{i=1}^n (y_i - \boldsymbol{w}^T \boldsymbol{x}_i)^2 + \text{const}
$$</p><p>这正是最小二乘法！</p><blockquote class=book-hint><p><strong>GLM 视角</strong>：线性回归是 GLM 在高斯分布 + 恒等链接下的特例。</p></blockquote><h3 id=1152-逻辑回归>11.5.2 逻辑回归<a class=anchor href=#1152-%e9%80%bb%e8%be%91%e5%9b%9e%e5%bd%92>#</a></h3><p><strong>设定</strong>：</p><ul><li>分布：$y \sim \text{Bernoulli}(\phi)$</li><li>链接函数：logit 链接 $g(\phi) = \log \frac{\phi}{1-\phi}$</li><li>线性预测器：$\eta = \boldsymbol{w}^T \boldsymbol{x}$</li></ul><p>因此：</p><p>$$
\phi = \frac{1}{1 + e^{-\boldsymbol{w}^T \boldsymbol{x}}}
$$</p><p>对数似然：</p><p>$$
\ell(\boldsymbol{w}) = \sum_{i=1}^n \left[y_i \boldsymbol{w}^T \boldsymbol{x}_i - \log(1 + e^{\boldsymbol{w}^T \boldsymbol{x}_i})\right]
$$</p><blockquote class=book-hint><p><strong>GLM 视角</strong>：逻辑回归是 GLM 在伯努利分布 + logit 链接下的特例。</p></blockquote><h3 id=1153-泊松回归>11.5.3 泊松回归<a class=anchor href=#1153-%e6%b3%8a%e6%9d%be%e5%9b%9e%e5%bd%92>#</a></h3><p><strong>设定</strong>：</p><ul><li>分布：$y \sim \text{Poisson}(\lambda)$，用于建模计数数据</li><li>链接函数：对数链接 $g(\lambda) = \log \lambda$</li><li>线性预测器：$\eta = \boldsymbol{w}^T \boldsymbol{x}$</li></ul><p>因此：</p><p>$$
\lambda = e^{\boldsymbol{w}^T \boldsymbol{x}}
$$</p><p>对数似然：</p><p>$$
\ell(\boldsymbol{w}) = \sum_{i=1}^n \left[y_i \boldsymbol{w}^T \boldsymbol{x}_i - e^{\boldsymbol{w}^T \boldsymbol{x}_i} - \log(y_i!)\right]
$$</p><p>梯度：</p><p>$$
\frac{\partial \ell}{\partial \boldsymbol{w}} = \sum_{i=1}^n (y_i - \lambda_i) \boldsymbol{x}_i
$$</p><p><strong>应用场景</strong>：</p><ul><li>网站访问次数预测</li><li>交通事故数量建模</li><li>基因表达计数分析</li></ul><blockquote class=book-hint><p><strong>GLM 视角</strong>：泊松回归是 GLM 在泊松分布 + 对数链接下的特例。</p></blockquote><h3 id=1154-统一框架的威力>11.5.4 统一框架的威力<a class=anchor href=#1154-%e7%bb%9f%e4%b8%80%e6%a1%86%e6%9e%b6%e7%9a%84%e5%a8%81%e5%8a%9b>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-svg data-lang=svg><span class=line><span class=cl><span class=nt>&lt;svg</span> <span class=na>viewBox=</span><span class=s>&#34;0 0 800 400&#34;</span> <span class=na>xmlns=</span><span class=s>&#34;http://www.w3.org/2000/svg&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 标题 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;30&#34;</span> <span class=na>font-size=</span><span class=s>&#34;20&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>GLM统一框架<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- GLM核心 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;300&#34;</span> <span class=na>y=</span><span class=s>&#34;60&#34;</span> <span class=na>width=</span><span class=s>&#34;200&#34;</span> <span class=na>height=</span><span class=s>&#34;80&#34;</span> <span class=na>fill=</span><span class=s>&#34;#E8F4F8&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4A90E2&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;90&#34;</span> <span class=na>font-size=</span><span class=s>&#34;16&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>广义线性模型<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;110&#34;</span> <span class=na>font-size=</span><span class=s>&#34;12&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>指数族分布<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;125&#34;</span> <span class=na>font-size=</span><span class=s>&#34;12&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>链接函数 g(μ)<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 线性回归 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;50&#34;</span> <span class=na>y=</span><span class=s>&#34;200&#34;</span> <span class=na>width=</span><span class=s>&#34;180&#34;</span> <span class=na>height=</span><span class=s>&#34;150&#34;</span> <span class=na>fill=</span><span class=s>&#34;#F0F8FF&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4682B4&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;140&#34;</span> <span class=na>y=</span><span class=s>&#34;225&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>线性回归<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;140&#34;</span> <span class=na>y=</span><span class=s>&#34;245&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>分布: 高斯<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;140&#34;</span> <span class=na>y=</span><span class=s>&#34;265&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>链接: g(μ) = μ<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;140&#34;</span> <span class=na>y=</span><span class=s>&#34;285&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>应用: 连续值预测<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;140&#34;</span> <span class=na>y=</span><span class=s>&#34;310&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>房价预测<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;140&#34;</span> <span class=na>y=</span><span class=s>&#34;330&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>股票收益<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 逻辑回归 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;310&#34;</span> <span class=na>y=</span><span class=s>&#34;200&#34;</span> <span class=na>width=</span><span class=s>&#34;180&#34;</span> <span class=na>height=</span><span class=s>&#34;150&#34;</span> <span class=na>fill=</span><span class=s>&#34;#FFF8F0&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#E2A14A&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;225&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>逻辑回归<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;245&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>分布: 伯努利<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;265&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>链接: g(φ) = logit(φ)<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;285&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>应用: 二分类<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;310&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>垃圾邮件检测<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;330&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>疾病诊断<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 泊松回归 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;570&#34;</span> <span class=na>y=</span><span class=s>&#34;200&#34;</span> <span class=na>width=</span><span class=s>&#34;180&#34;</span> <span class=na>height=</span><span class=s>&#34;150&#34;</span> <span class=na>fill=</span><span class=s>&#34;#F0FFF0&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4AE27A&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;660&#34;</span> <span class=na>y=</span><span class=s>&#34;225&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>泊松回归<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;660&#34;</span> <span class=na>y=</span><span class=s>&#34;245&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>分布: 泊松<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;660&#34;</span> <span class=na>y=</span><span class=s>&#34;265&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>链接: g(λ) = log(λ)<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;660&#34;</span> <span class=na>y=</span><span class=s>&#34;285&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>应用: 计数预测<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;660&#34;</span> <span class=na>y=</span><span class=s>&#34;310&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>网站访问量<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;660&#34;</span> <span class=na>y=</span><span class=s>&#34;330&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>事故数量<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 连接线 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 350 140 L 140 200&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4682B4&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>fill=</span><span class=s>&#34;none&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrowblue)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 400 140 L 400 200&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#E2A14A&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>fill=</span><span class=s>&#34;none&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arroworange)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 450 140 L 660 200&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4AE27A&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>fill=</span><span class=s>&#34;none&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrowgreen)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 箭头定义 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;defs&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;marker</span> <span class=na>id=</span><span class=s>&#34;arrowblue&#34;</span> <span class=na>markerWidth=</span><span class=s>&#34;10&#34;</span> <span class=na>markerHeight=</span><span class=s>&#34;10&#34;</span> <span class=na>refX=</span><span class=s>&#34;9&#34;</span> <span class=na>refY=</span><span class=s>&#34;3&#34;</span> <span class=na>orient=</span><span class=s>&#34;auto&#34;</span> <span class=na>markerUnits=</span><span class=s>&#34;strokeWidth&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M0,0 L0,6 L9,3 z&#34;</span> <span class=na>fill=</span><span class=s>&#34;#4682B4&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/marker&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;marker</span> <span class=na>id=</span><span class=s>&#34;arroworange&#34;</span> <span class=na>markerWidth=</span><span class=s>&#34;10&#34;</span> <span class=na>markerHeight=</span><span class=s>&#34;10&#34;</span> <span class=na>refX=</span><span class=s>&#34;9&#34;</span> <span class=na>refY=</span><span class=s>&#34;3&#34;</span> <span class=na>orient=</span><span class=s>&#34;auto&#34;</span> <span class=na>markerUnits=</span><span class=s>&#34;strokeWidth&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M0,0 L0,6 L9,3 z&#34;</span> <span class=na>fill=</span><span class=s>&#34;#E2A14A&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/marker&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;marker</span> <span class=na>id=</span><span class=s>&#34;arrowgreen&#34;</span> <span class=na>markerWidth=</span><span class=s>&#34;10&#34;</span> <span class=na>markerHeight=</span><span class=s>&#34;10&#34;</span> <span class=na>refX=</span><span class=s>&#34;9&#34;</span> <span class=na>refY=</span><span class=s>&#34;3&#34;</span> <span class=na>orient=</span><span class=s>&#34;auto&#34;</span> <span class=na>markerUnits=</span><span class=s>&#34;strokeWidth&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M0,0 L0,6 L9,3 z&#34;</span> <span class=na>fill=</span><span class=s>&#34;#4AE27A&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/marker&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/defs&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/svg&gt;</span></span></span></code></pre></div><hr><h2 id=116-模型诊断与评估>11.6 模型诊断与评估<a class=anchor href=#116-%e6%a8%a1%e5%9e%8b%e8%af%8a%e6%96%ad%e4%b8%8e%e8%af%84%e4%bc%b0>#</a></h2><h3 id=1161-偏差-deviance>11.6.1 偏差 (Deviance)<a class=anchor href=#1161-%e5%81%8f%e5%b7%ae-deviance>#</a></h3><p>偏差是衡量模型拟合优度的统计量：</p><p>$$
D = 2[\ell(\text{saturated}) - \ell(\text{fitted})]
$$</p><p>其中：</p><ul><li>$\ell(\text{saturated})$：饱和模型的对数似然（每个观测有独立参数）</li><li>$\ell(\text{fitted})$：拟合模型的对数似然</li></ul><p>对于高斯分布：</p><p>$$
D = \sum_{i=1}^n (y_i - \hat{\mu}_i)^2
$$</p><p>对于伯努利分布：</p><p>$$
D = 2\sum_{i=1}^n \left[y_i \log\frac{y_i}{\hat{\mu}_i} + (1-y_i)\log\frac{1-y_i}{1-\hat{\mu}_i}\right]
$$</p><p>（约定：当 $y_i = 0$ 时，$y_i \log \frac{y_i}{\hat{\mu}_i} = 0$；当 $y_i = 1$ 时，$(1-y_i)\log\frac{1-y_i}{1-\hat{\mu}_i} = 0$）</p><blockquote class=book-hint><p><strong>性质</strong>：偏差越小，模型拟合越好。在嵌套模型中，偏差差值近似服从 $\chi^2$ 分布。</p></blockquote><h3 id=1162-pearson-残差>11.6.2 Pearson 残差<a class=anchor href=#1162-pearson-%e6%ae%8b%e5%b7%ae>#</a></h3><p>标准化残差：</p><p>$$
r_i^P = \frac{y_i - \hat{\mu}_i}{\sqrt{\text{Var}(\hat{\mu}_i)}}
$$</p><p>用于检测异常值和模型假设。</p><h3 id=1163-aic-与-bic>11.6.3 AIC 与 BIC<a class=anchor href=#1163-aic-%e4%b8%8e-bic>#</a></h3><p><strong>Akaike 信息准则</strong>：</p><p>$$
\text{AIC} = -2\ell(\hat{\boldsymbol{w}}) + 2p
$$</p><p><strong>Bayesian 信息准则</strong>：</p><p>$$
\text{BIC} = -2\ell(\hat{\boldsymbol{w}}) + p \log n
$$</p><p>其中 $p$ 是参数个数，$n$ 是样本数。</p><blockquote class=book-hint><p><strong>模型选择</strong>：AIC/BIC 越小越好，平衡拟合优度与模型复杂度。</p></blockquote><hr><h2 id=117-glm的扩展>11.7 GLM的扩展<a class=anchor href=#117-glm%e7%9a%84%e6%89%a9%e5%b1%95>#</a></h2><h3 id=1171-准似然-quasi-likelihood>11.7.1 准似然 (Quasi-likelihood)<a class=anchor href=#1171-%e5%87%86%e4%bc%bc%e7%84%b6-quasi-likelihood>#</a></h3><p>当分布族未知但均值-方差关系已知时，可使用<strong>准似然方法</strong>：</p><p>$$
Q(\mu; y) = \int_y^\mu \frac{y - t}{V(t)} dt
$$</p><p>其中 $V(\mu)$ 是方差函数。</p><p>优点：</p><ul><li>无需完全指定分布</li><li>只需均值和方差关系</li><li>对分布误设定具有鲁棒性</li></ul><h3 id=1172-零膨胀模型-zero-inflated-models>11.7.2 零膨胀模型 (Zero-Inflated Models)<a class=anchor href=#1172-%e9%9b%b6%e8%86%a8%e8%83%80%e6%a8%a1%e5%9e%8b-zero-inflated-models>#</a></h3><p>对于计数数据中零值过多的情况（如保险索赔次数），使用零膨胀泊松或零膨胀负二项模型：</p><p>$$
P(Y = y) = \begin{cases}
\pi + (1-\pi)e^{-\lambda}, & y = 0 \
(1-\pi)\frac{\lambda^y e^{-\lambda}}{y!}, & y > 0
\end{cases}
$$</p><p>其中 $\pi$ 是结构零的概率。</p><h3 id=1173-广义加性模型-gam>11.7.3 广义加性模型 (GAM)<a class=anchor href=#1173-%e5%b9%bf%e4%b9%89%e5%8a%a0%e6%80%a7%e6%a8%a1%e5%9e%8b-gam>#</a></h3><p>将线性预测器扩展为光滑函数的和：</p><p>$$
g(\mu) = \beta_0 + f_1(x_1) + f_2(x_2) + \cdots + f_p(x_p)
$$</p><p>其中 $f_j$ 是光滑函数（如样条），可捕捉非线性关系。</p><hr><h2 id=118-实践案例保险索赔建模>11.8 实践案例：保险索赔建模<a class=anchor href=#118-%e5%ae%9e%e8%b7%b5%e6%a1%88%e4%be%8b%e4%bf%9d%e9%99%a9%e7%b4%a2%e8%b5%94%e5%bb%ba%e6%a8%a1>#</a></h2><h3 id=1181-问题背景>11.8.1 问题背景<a class=anchor href=#1181-%e9%97%ae%e9%a2%98%e8%83%8c%e6%99%af>#</a></h3><p>某保险公司希望根据投保人特征（年龄、性别、车型等）预测年度索赔次数。</p><p><strong>数据特点</strong>：</p><ul><li>响应变量：索赔次数（非负整数）</li><li>特征：年龄、性别、驾龄、车型、地区</li><li>挑战：零值较多（大部分人无索赔）</li></ul><h3 id=1182-模型选择>11.8.2 模型选择<a class=anchor href=#1182-%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9>#</a></h3><p>使用<strong>泊松回归</strong>：</p><p>$$
Y_i \sim \text{Poisson}(\lambda_i)
$$</p><p>$$
\log \lambda_i = w_0 + w_1 \cdot \text{age}_i + w_2 \cdot \text{gender}_i + \cdots
$$</p><h3 id=1183-模型拟合>11.8.3 模型拟合<a class=anchor href=#1183-%e6%a8%a1%e5%9e%8b%e6%8b%9f%e5%90%88>#</a></h3><p>伪代码示例：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>statsmodels.api</span> <span class=k>as</span> <span class=nn>sm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 拟合泊松回归</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>sm</span><span class=o>.</span><span class=n>GLM</span><span class=p>(</span><span class=n>y</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>family</span><span class=o>=</span><span class=n>sm</span><span class=o>.</span><span class=n>families</span><span class=o>.</span><span class=n>Poisson</span><span class=p>(</span><span class=n>link</span><span class=o>=</span><span class=n>sm</span><span class=o>.</span><span class=n>families</span><span class=o>.</span><span class=n>links</span><span class=o>.</span><span class=n>Log</span><span class=p>()))</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看系数</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>summary</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预测</span>
</span></span><span class=line><span class=cl><span class=n>lambda_pred</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span></span></span></code></pre></div><h3 id=1184-模型诊断>11.8.4 模型诊断<a class=anchor href=#1184-%e6%a8%a1%e5%9e%8b%e8%af%8a%e6%96%ad>#</a></h3><p>检查偏差残差分布：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>residuals</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>resid_deviance</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>hist</span><span class=p>(</span><span class=n>residuals</span><span class=p>,</span> <span class=n>bins</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>xlabel</span><span class=p>(</span><span class=s1>&#39;Deviance Residuals&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>plt</span><span class=o>.</span><span class=n>ylabel</span><span class=p>(</span><span class=s1>&#39;Frequency&#39;</span><span class=p>)</span></span></span></code></pre></div><p>如果发现<strong>过离散 (overdispersion)</strong>（方差 > 均值），可改用负二项回归。</p><hr><h2 id=119-理论深化glm与指数族的深层联系>11.9 理论深化：GLM与指数族的深层联系<a class=anchor href=#119-%e7%90%86%e8%ae%ba%e6%b7%b1%e5%8c%96glm%e4%b8%8e%e6%8c%87%e6%95%b0%e6%97%8f%e7%9a%84%e6%b7%b1%e5%b1%82%e8%81%94%e7%b3%bb>#</a></h2><h3 id=1191-充分统计量与信息几何>11.9.1 充分统计量与信息几何<a class=anchor href=#1191-%e5%85%85%e5%88%86%e7%bb%9f%e8%ae%a1%e9%87%8f%e4%b8%8e%e4%bf%a1%e6%81%af%e5%87%a0%e4%bd%95>#</a></h3><p>在指数族分布中，充分统计量 $T(y)$ 包含了关于参数 $\eta$ 的所有信息。从信息几何角度，$\eta$ 和 $\mathbb{E}[T(y)]$ 构成<strong>对偶坐标系</strong>。</p><p>对数配分函数 $A(\eta)$ 是 <strong>Legendre 变换</strong>的核心：</p><p>$$
A^*(\mu) = \sup_\eta {\eta \mu - A(\eta)}
$$</p><p>这在统计物理和信息论中有深刻应用。</p><h3 id=1192-fisher-信息矩阵>11.9.2 Fisher 信息矩阵<a class=anchor href=#1192-fisher-%e4%bf%a1%e6%81%af%e7%9f%a9%e9%98%b5>#</a></h3><p>对于 GLM，Fisher 信息矩阵为：</p><p>$$
\mathcal{I}(\boldsymbol{w}) = \boldsymbol{X}^T \boldsymbol{W} \boldsymbol{X}
$$</p><p>其中 $\boldsymbol{W} = \text{diag}(w_1, \ldots, w_n)$，</p><p>$$
w_i = \frac{1}{a(\phi) \cdot \text{Var}(y_i)} \left(\frac{\partial \mu_i}{\partial \eta_i}\right)^2
$$</p><p>当 $a(\phi) = 1$ 时（如伯努利、泊松分布），这与 IRLS 算法中的权重定义一致。</p><blockquote class=book-hint><p><strong>Cramér-Rao 下界</strong>：参数估计的方差下界为 $\mathcal{I}^{-1}(\boldsymbol{w})$，在正则条件下 MLE 是渐近有效的。</p></blockquote><h3 id=1193-glm的渐近性质>11.9.3 GLM的渐近性质<a class=anchor href=#1193-glm%e7%9a%84%e6%b8%90%e8%bf%91%e6%80%a7%e8%b4%a8>#</a></h3><p>在正则条件下：</p><p>$$
\sqrt{n}(\hat{\boldsymbol{w}} - \boldsymbol{w}_0) \xrightarrow{d} \mathcal{N}(0, \mathcal{I}^{-1}(\boldsymbol{w}_0))
$$</p><p>这为构造置信区间和假设检验提供了理论基础。</p><hr><h2 id=1110-总结与展望>11.10 总结与展望<a class=anchor href=#1110-%e6%80%bb%e7%bb%93%e4%b8%8e%e5%b1%95%e6%9c%9b>#</a></h2><h3 id=11101-核心要点回顾>11.10.1 核心要点回顾<a class=anchor href=#11101-%e6%a0%b8%e5%bf%83%e8%a6%81%e7%82%b9%e5%9b%9e%e9%a1%be>#</a></h3><blockquote class=book-hint><p><strong>GLM的三大支柱</strong>：</p><ol><li><strong>指数族分布</strong>：统一处理各种响应变量类型</li><li><strong>链接函数</strong>：灵活建模均值与线性预测器的关系</li><li><strong>极大似然估计</strong>：提供一致、渐近正态的参数估计</li></ol></blockquote><p>GLM 将线性回归、逻辑回归、泊松回归等模型统一在同一理论框架下，具有以下优势：</p><ul><li><strong>理论优美</strong>：基于指数族分布的深刻性质</li><li><strong>计算高效</strong>：IRLS 算法快速收敛</li><li><strong>解释性强</strong>：保留线性模型的可解释性</li><li><strong>扩展性好</strong>：可轻松扩展到新的分布族</li></ul><h3 id=11102-glm与其他模型的关系>11.10.2 GLM与其他模型的关系<a class=anchor href=#11102-glm%e4%b8%8e%e5%85%b6%e4%bb%96%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%85%b3%e7%b3%bb>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-svg data-lang=svg><span class=line><span class=cl><span class=nt>&lt;svg</span> <span class=na>viewBox=</span><span class=s>&#34;0 0 800 500&#34;</span> <span class=na>xmlns=</span><span class=s>&#34;http://www.w3.org/2000/svg&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 标题 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;30&#34;</span> <span class=na>font-size=</span><span class=s>&#34;20&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>GLM在统计学习中的位置<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 线性模型 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;50&#34;</span> <span class=na>y=</span><span class=s>&#34;80&#34;</span> <span class=na>width=</span><span class=s>&#34;200&#34;</span> <span class=na>height=</span><span class=s>&#34;80&#34;</span> <span class=na>fill=</span><span class=s>&#34;#E8F4F8&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4A90E2&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;150&#34;</span> <span class=na>y=</span><span class=s>&#34;110&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>线性模型<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;150&#34;</span> <span class=na>y=</span><span class=s>&#34;130&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>最简单<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;150&#34;</span> <span class=na>y=</span><span class=s>&#34;145&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>解释性强<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- GLM --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;300&#34;</span> <span class=na>y=</span><span class=s>&#34;80&#34;</span> <span class=na>width=</span><span class=s>&#34;200&#34;</span> <span class=na>height=</span><span class=s>&#34;80&#34;</span> <span class=na>fill=</span><span class=s>&#34;#FFF8F0&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#E2A14A&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;110&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>GLM<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;130&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>指数族+链接函数<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;145&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>平衡性能与解释<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- GAM --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;550&#34;</span> <span class=na>y=</span><span class=s>&#34;80&#34;</span> <span class=na>width=</span><span class=s>&#34;200&#34;</span> <span class=na>height=</span><span class=s>&#34;80&#34;</span> <span class=na>fill=</span><span class=s>&#34;#F0FFF0&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#4AE27A&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;650&#34;</span> <span class=na>y=</span><span class=s>&#34;110&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>GAM<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;650&#34;</span> <span class=na>y=</span><span class=s>&#34;130&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>光滑函数<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;650&#34;</span> <span class=na>y=</span><span class=s>&#34;145&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>捕捉非线性<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 深度学习 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;rect</span> <span class=na>x=</span><span class=s>&#34;300&#34;</span> <span class=na>y=</span><span class=s>&#34;220&#34;</span> <span class=na>width=</span><span class=s>&#34;200&#34;</span> <span class=na>height=</span><span class=s>&#34;80&#34;</span> <span class=na>fill=</span><span class=s>&#34;#FFF0F5&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#E24A90&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;250&#34;</span> <span class=na>font-size=</span><span class=s>&#34;14&#34;</span> <span class=na>font-weight=</span><span class=s>&#34;bold&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>深度学习<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;270&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>高度非线性<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;285&#34;</span> <span class=na>font-size=</span><span class=s>&#34;11&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>黑箱模型<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 箭头和标注 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 250 120 L 300 120&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#666&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrow1)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;275&#34;</span> <span class=na>y=</span><span class=s>&#34;110&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>扩展<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 500 120 L 550 120&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#666&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrow1)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;525&#34;</span> <span class=na>y=</span><span class=s>&#34;110&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>进一步<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 400 160 L 400 220&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#666&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrow1)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;440&#34;</span> <span class=na>y=</span><span class=s>&#34;195&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>灵活性增加<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 坐标轴 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 100 380 L 700 380&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#333&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrow2)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;720&#34;</span> <span class=na>y=</span><span class=s>&#34;385&#34;</span> <span class=na>font-size=</span><span class=s>&#34;12&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>模型复杂度<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M 100 380 L 100 330&#34;</span> <span class=na>stroke=</span><span class=s>&#34;#333&#34;</span> <span class=na>stroke-width=</span><span class=s>&#34;2&#34;</span> <span class=na>marker-end=</span><span class=s>&#34;url(#arrow2)&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;70&#34;</span> <span class=na>y=</span><span class=s>&#34;320&#34;</span> <span class=na>font-size=</span><span class=s>&#34;12&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>解释性<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 位置标记 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;circle</span> <span class=na>cx=</span><span class=s>&#34;150&#34;</span> <span class=na>cy=</span><span class=s>&#34;370&#34;</span> <span class=na>r=</span><span class=s>&#34;6&#34;</span> <span class=na>fill=</span><span class=s>&#34;#4A90E2&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;150&#34;</span> <span class=na>y=</span><span class=s>&#34;395&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>线性<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;circle</span> <span class=na>cx=</span><span class=s>&#34;400&#34;</span> <span class=na>cy=</span><span class=s>&#34;355&#34;</span> <span class=na>r=</span><span class=s>&#34;6&#34;</span> <span class=na>fill=</span><span class=s>&#34;#E2A14A&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;400&#34;</span> <span class=na>y=</span><span class=s>&#34;410&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>GLM<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;circle</span> <span class=na>cx=</span><span class=s>&#34;550&#34;</span> <span class=na>cy=</span><span class=s>&#34;345&#34;</span> <span class=na>r=</span><span class=s>&#34;6&#34;</span> <span class=na>fill=</span><span class=s>&#34;#4AE27A&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;550&#34;</span> <span class=na>y=</span><span class=s>&#34;425&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>GAM<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;circle</span> <span class=na>cx=</span><span class=s>&#34;650&#34;</span> <span class=na>cy=</span><span class=s>&#34;340&#34;</span> <span class=na>r=</span><span class=s>&#34;6&#34;</span> <span class=na>fill=</span><span class=s>&#34;#E24A90&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;text</span> <span class=na>x=</span><span class=s>&#34;650&#34;</span> <span class=na>y=</span><span class=s>&#34;440&#34;</span> <span class=na>font-size=</span><span class=s>&#34;10&#34;</span> <span class=na>text-anchor=</span><span class=s>&#34;middle&#34;</span><span class=nt>&gt;</span>深度学习<span class=nt>&lt;/text&gt;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>  <span class=c>&lt;!-- 箭头标记定义 --&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;defs&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;marker</span> <span class=na>id=</span><span class=s>&#34;arrow1&#34;</span> <span class=na>markerWidth=</span><span class=s>&#34;10&#34;</span> <span class=na>markerHeight=</span><span class=s>&#34;10&#34;</span> <span class=na>refX=</span><span class=s>&#34;9&#34;</span> <span class=na>refY=</span><span class=s>&#34;3&#34;</span> <span class=na>orient=</span><span class=s>&#34;auto&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M0,0 L0,6 L9,3 z&#34;</span> <span class=na>fill=</span><span class=s>&#34;#666&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/marker&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;marker</span> <span class=na>id=</span><span class=s>&#34;arrow2&#34;</span> <span class=na>markerWidth=</span><span class=s>&#34;10&#34;</span> <span class=na>markerHeight=</span><span class=s>&#34;10&#34;</span> <span class=na>refX=</span><span class=s>&#34;9&#34;</span> <span class=na>refY=</span><span class=s>&#34;3&#34;</span> <span class=na>orient=</span><span class=s>&#34;auto&#34;</span><span class=nt>&gt;</span>
</span></span><span class=line><span class=cl>      <span class=nt>&lt;path</span> <span class=na>d=</span><span class=s>&#34;M0,0 L0,6 L9,3 z&#34;</span> <span class=na>fill=</span><span class=s>&#34;#333&#34;</span><span class=nt>/&gt;</span>
</span></span><span class=line><span class=cl>    <span class=nt>&lt;/marker&gt;</span>
</span></span><span class=line><span class=cl>  <span class=nt>&lt;/defs&gt;</span>
</span></span><span class=line><span class=cl><span class=nt>&lt;/svg&gt;</span></span></span></code></pre></div><h3 id=11103-进一步学习方向>11.10.3 进一步学习方向<a class=anchor href=#11103-%e8%bf%9b%e4%b8%80%e6%ad%a5%e5%ad%a6%e4%b9%a0%e6%96%b9%e5%90%91>#</a></h3><ol><li><strong>广义估计方程 (GEE)</strong>：处理相关数据（纵向数据、聚类数据）</li><li><strong>混合效应模型 (GLMM)</strong>：引入随机效应，建模层级结构</li><li><strong>贝叶斯GLM</strong>：通过先验分布进行正则化和不确定性量化</li><li><strong>分位数回归</strong>：建模条件分位数而非条件均值</li><li><strong>生存分析</strong>：Cox 比例风险模型可视为特殊的 GLM</li></ol><h3 id=11104-哲学思考>11.10.4 哲学思考<a class=anchor href=#11104-%e5%93%b2%e5%ad%a6%e6%80%9d%e8%80%83>#</a></h3><blockquote class=book-hint><p>&ldquo;所有模型都是错的，但有些是有用的。&rdquo; — George Box</p></blockquote><p>GLM 不是万能的，但它提供了一个<strong>坚实的起点</strong>：</p><ul><li>当数据符合指数族假设时，GLM 提供最优解</li><li>当假设被违背时，GLM 仍提供合理的近似</li><li>GLM 的简洁性使其成为更复杂模型的基准</li></ul><p>在机器学习追求黑箱性能的时代，GLM 提醒我们：<strong>可解释性和理论基础依然重要</strong>。</p><hr><h2 id=参考文献>参考文献<a class=anchor href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae>#</a></h2><ol><li>McCullagh, P., & Nelder, J. A. (1989). <em>Generalized Linear Models</em> (2nd ed.). Chapman and Hall.</li><li>Dobson, A. J., & Barnett, A. G. (2018). <em>An Introduction to Generalized Linear Models</em> (4th ed.). CRC Press.</li><li>Wood, S. N. (2017). <em>Generalized Additive Models: An Introduction with R</em> (2nd ed.). Chapman and Hall/CRC.</li><li>Hastie, T., & Tibshirani, R. (1990). <em>Generalized Additive Models</em>. Chapman and Hall.</li><li>Murphy, K. P. (2022). <em>Probabilistic Machine Learning: An Introduction</em>. MIT Press.</li></ol><hr><h2 id=附录python实现示例>附录：Python实现示例<a class=anchor href=#%e9%99%84%e5%bd%95python%e5%ae%9e%e7%8e%b0%e7%a4%ba%e4%be%8b>#</a></h2><h3 id=a1-使用-statsmodels-拟合glm>A.1 使用 statsmodels 拟合GLM<a class=anchor href=#a1-%e4%bd%bf%e7%94%a8-statsmodels-%e6%8b%9f%e5%90%88glm>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>statsmodels.api</span> <span class=k>as</span> <span class=nn>sm</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>statsmodels.formula.api</span> <span class=kn>import</span> <span class=n>glm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成模拟数据</span>
</span></span><span class=line><span class=cl><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=mi>42</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>n</span> <span class=o>=</span> <span class=mi>1000</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>n</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>sm</span><span class=o>.</span><span class=n>add_constant</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>  <span class=c1># 添加截距项</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 泊松回归</span>
</span></span><span class=line><span class=cl><span class=n>lambda_true</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>X</span> <span class=o>@</span> <span class=p>[</span><span class=mf>0.5</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>y_count</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>poisson</span><span class=p>(</span><span class=n>lambda_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 拟合模型</span>
</span></span><span class=line><span class=cl><span class=n>poisson_model</span> <span class=o>=</span> <span class=n>sm</span><span class=o>.</span><span class=n>GLM</span><span class=p>(</span><span class=n>y_count</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>family</span><span class=o>=</span><span class=n>sm</span><span class=o>.</span><span class=n>families</span><span class=o>.</span><span class=n>Poisson</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>poisson_result</span> <span class=o>=</span> <span class=n>poisson_model</span><span class=o>.</span><span class=n>fit</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>poisson_result</span><span class=o>.</span><span class=n>summary</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 逻辑回归</span>
</span></span><span class=line><span class=cl><span class=n>prob_true</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>X</span> <span class=o>@</span> <span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>]))</span>
</span></span><span class=line><span class=cl><span class=n>y_binary</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>binomial</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>prob_true</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>logit_model</span> <span class=o>=</span> <span class=n>sm</span><span class=o>.</span><span class=n>GLM</span><span class=p>(</span><span class=n>y_binary</span><span class=p>,</span> <span class=n>X</span><span class=p>,</span> <span class=n>family</span><span class=o>=</span><span class=n>sm</span><span class=o>.</span><span class=n>families</span><span class=o>.</span><span class=n>Binomial</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=n>logit_result</span> <span class=o>=</span> <span class=n>logit_model</span><span class=o>.</span><span class=n>fit</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>logit_result</span><span class=o>.</span><span class=n>summary</span><span class=p>())</span></span></span></code></pre></div><h3 id=a2-手动实现irls算法>A.2 手动实现IRLS算法<a class=anchor href=#a2-%e6%89%8b%e5%8a%a8%e5%ae%9e%e7%8e%b0irls%e7%ae%97%e6%b3%95>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>irls_glm</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>family</span><span class=o>=</span><span class=s1>&#39;gaussian&#39;</span><span class=p>,</span> <span class=n>max_iter</span><span class=o>=</span><span class=mi>25</span><span class=p>,</span> <span class=n>tol</span><span class=o>=</span><span class=mf>1e-8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    IRLS算法实现GLM
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    family: &#39;gaussian&#39;, &#39;binomial&#39;, &#39;poisson&#39;
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>n</span><span class=p>,</span> <span class=n>p</span> <span class=o>=</span> <span class=n>X</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>w</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>p</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>max_iter</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 线性预测</span>
</span></span><span class=line><span class=cl>        <span class=n>eta</span> <span class=o>=</span> <span class=n>X</span> <span class=o>@</span> <span class=n>w</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 均值函数（反链接）和导数</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>family</span> <span class=o>==</span> <span class=s1>&#39;gaussian&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mu</span> <span class=o>=</span> <span class=n>eta</span>  <span class=c1># g^(-1)(eta) = eta</span>
</span></span><span class=line><span class=cl>            <span class=n>mu_prime</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>eta</span><span class=p>)</span>  <span class=c1># dμ/dη = 1</span>
</span></span><span class=line><span class=cl>            <span class=n>var</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>ones_like</span><span class=p>(</span><span class=n>eta</span><span class=p>)</span>  <span class=c1># Var(y) = σ²（假设为1）</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>family</span> <span class=o>==</span> <span class=s1>&#39;binomial&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mu</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>/</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=o>-</span><span class=n>eta</span><span class=p>))</span>  <span class=c1># g^(-1)(eta) = sigmoid(eta)</span>
</span></span><span class=line><span class=cl>            <span class=n>mu_prime</span> <span class=o>=</span> <span class=n>mu</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>mu</span><span class=p>)</span>  <span class=c1># dμ/dη = μ(1-μ)</span>
</span></span><span class=line><span class=cl>            <span class=n>var</span> <span class=o>=</span> <span class=n>mu</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>mu</span><span class=p>)</span>  <span class=c1># Var(y) = μ(1-μ)</span>
</span></span><span class=line><span class=cl>        <span class=k>elif</span> <span class=n>family</span> <span class=o>==</span> <span class=s1>&#39;poisson&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>mu</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>exp</span><span class=p>(</span><span class=n>eta</span><span class=p>)</span>  <span class=c1># g^(-1)(eta) = exp(eta)</span>
</span></span><span class=line><span class=cl>            <span class=n>mu_prime</span> <span class=o>=</span> <span class=n>mu</span>  <span class=c1># dμ/dη = μ</span>
</span></span><span class=line><span class=cl>            <span class=n>var</span> <span class=o>=</span> <span class=n>mu</span>  <span class=c1># Var(y) = μ</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 工作响应和权重</span>
</span></span><span class=line><span class=cl>        <span class=n>z</span> <span class=o>=</span> <span class=n>eta</span> <span class=o>+</span> <span class=p>(</span><span class=n>y</span> <span class=o>-</span> <span class=n>mu</span><span class=p>)</span> <span class=o>/</span> <span class=n>mu_prime</span>  <span class=c1># 工作响应变量</span>
</span></span><span class=line><span class=cl>        <span class=n>weights</span> <span class=o>=</span> <span class=n>mu_prime</span><span class=o>**</span><span class=mi>2</span> <span class=o>/</span> <span class=n>var</span>  <span class=c1># w_i = (dμ/dη)² / Var(y)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 加权最小二乘</span>
</span></span><span class=line><span class=cl>        <span class=n>W</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>diag</span><span class=p>(</span><span class=n>weights</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>w_new</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>solve</span><span class=p>(</span><span class=n>X</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>W</span> <span class=o>@</span> <span class=n>X</span><span class=p>,</span> <span class=n>X</span><span class=o>.</span><span class=n>T</span> <span class=o>@</span> <span class=n>W</span> <span class=o>@</span> <span class=n>z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 检查收敛</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>np</span><span class=o>.</span><span class=n>linalg</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>w_new</span> <span class=o>-</span> <span class=n>w</span><span class=p>)</span> <span class=o>&lt;</span> <span class=n>tol</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Converged in </span><span class=si>{</span><span class=n>iteration</span> <span class=o>+</span> <span class=mi>1</span><span class=si>}</span><span class=s2> iterations&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>w</span> <span class=o>=</span> <span class=n>w_new</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>w</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试</span>
</span></span><span class=line><span class=cl><span class=n>w_estimated</span> <span class=o>=</span> <span class=n>irls_glm</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y_count</span><span class=p>,</span> <span class=n>family</span><span class=o>=</span><span class=s1>&#39;poisson&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;Estimated coefficients:&#34;</span><span class=p>,</span> <span class=n>w_estimated</span><span class=p>)</span></span></span></code></pre></div><hr><blockquote class=book-hint><p><strong>本章完</strong>
下一章将探讨<strong>支持向量机 (SVM)</strong>，从几何角度理解最大间隔分类器。</p></blockquote><hr><p><strong>练习题</strong></p><ol><li>证明伽马分布 $\text{Gamma}(\alpha, \beta)$ 属于指数族，并写出其自然参数。</li><li>推导泊松回归的 Fisher 信息矩阵。</li><li>在逻辑回归中，为什么不使用恒等链接而使用 logit 链接？</li><li>实现一个支持正则化（L1/L2）的 GLM 类。</li><li>对比零膨胀泊松模型和负二项模型在处理计数数据时的优劣。</li></ol></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第10章 逻辑回归与最大熵模型</span>
</a></span><span><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/ class="flex align-center"><span>第13章 概率图模型 表示</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#111-引言从线性回归到glm>11.1 引言：从线性回归到GLM</a><ul><li><a href=#1111-为什么需要glm>11.1.1 为什么需要GLM？</a></li></ul></li><li><a href=#112-指数族分布>11.2 指数族分布</a><ul><li><a href=#1121-指数族的通用形式>11.2.1 指数族的通用形式</a></li><li><a href=#1122-指数族的核心性质>11.2.2 指数族的核心性质</a></li><li><a href=#1123-常见分布属于指数族>11.2.3 常见分布属于指数族</a><ul><li><a href=#1-高斯分布>(1) 高斯分布</a></li><li><a href=#2-伯努利分布>(2) 伯努利分布</a></li><li><a href=#3-泊松分布>(3) 泊松分布</a></li></ul></li></ul></li><li><a href=#113-glm的三要素>11.3 GLM的三要素</a><ul><li><a href=#1131-随机成分-random-component>11.3.1 随机成分 (Random Component)</a></li><li><a href=#1132-系统成分-systematic-component>11.3.2 系统成分 (Systematic Component)</a></li><li><a href=#1133-链接函数-link-function>11.3.3 链接函数 (Link Function)</a><ul><li><a href=#常见链接函数>常见链接函数</a></li></ul></li></ul></li><li><a href=#114-glm的参数估计>11.4 GLM的参数估计</a><ul><li><a href=#1141-极大似然估计>11.4.1 极大似然估计</a></li><li><a href=#1142-梯度计算>11.4.2 梯度计算</a></li><li><a href=#1143-迭代加权最小二乘-irls>11.4.3 迭代加权最小二乘 (IRLS)</a></li></ul></li><li><a href=#115-案例分析统一框架下的三大模型>11.5 案例分析：统一框架下的三大模型</a><ul><li><a href=#1151-线性回归>11.5.1 线性回归</a></li><li><a href=#1152-逻辑回归>11.5.2 逻辑回归</a></li><li><a href=#1153-泊松回归>11.5.3 泊松回归</a></li><li><a href=#1154-统一框架的威力>11.5.4 统一框架的威力</a></li></ul></li><li><a href=#116-模型诊断与评估>11.6 模型诊断与评估</a><ul><li><a href=#1161-偏差-deviance>11.6.1 偏差 (Deviance)</a></li><li><a href=#1162-pearson-残差>11.6.2 Pearson 残差</a></li><li><a href=#1163-aic-与-bic>11.6.3 AIC 与 BIC</a></li></ul></li><li><a href=#117-glm的扩展>11.7 GLM的扩展</a><ul><li><a href=#1171-准似然-quasi-likelihood>11.7.1 准似然 (Quasi-likelihood)</a></li><li><a href=#1172-零膨胀模型-zero-inflated-models>11.7.2 零膨胀模型 (Zero-Inflated Models)</a></li><li><a href=#1173-广义加性模型-gam>11.7.3 广义加性模型 (GAM)</a></li></ul></li><li><a href=#118-实践案例保险索赔建模>11.8 实践案例：保险索赔建模</a><ul><li><a href=#1181-问题背景>11.8.1 问题背景</a></li><li><a href=#1182-模型选择>11.8.2 模型选择</a></li><li><a href=#1183-模型拟合>11.8.3 模型拟合</a></li><li><a href=#1184-模型诊断>11.8.4 模型诊断</a></li></ul></li><li><a href=#119-理论深化glm与指数族的深层联系>11.9 理论深化：GLM与指数族的深层联系</a><ul><li><a href=#1191-充分统计量与信息几何>11.9.1 充分统计量与信息几何</a></li><li><a href=#1192-fisher-信息矩阵>11.9.2 Fisher 信息矩阵</a></li><li><a href=#1193-glm的渐近性质>11.9.3 GLM的渐近性质</a></li></ul></li><li><a href=#1110-总结与展望>11.10 总结与展望</a><ul><li><a href=#11101-核心要点回顾>11.10.1 核心要点回顾</a></li><li><a href=#11102-glm与其他模型的关系>11.10.2 GLM与其他模型的关系</a></li><li><a href=#11103-进一步学习方向>11.10.3 进一步学习方向</a></li><li><a href=#11104-哲学思考>11.10.4 哲学思考</a></li></ul></li><li><a href=#参考文献>参考文献</a></li><li><a href=#附录python实现示例>附录：Python实现示例</a><ul><li><a href=#a1-使用-statsmodels-拟合glm>A.1 使用 statsmodels 拟合GLM</a></li><li><a href=#a2-手动实现irls算法>A.2 手动实现IRLS算法</a></li></ul></li></ul></nav></div></aside></main></body></html>