<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第13章 概率图模型：表示# “The purpose of computing is insight, not numbers.” — Richard Hamming
“Graphical models are a marriage between probability theory and graph theory.” — Michael I. Jordan
13.1 引言：为什么需要概率图模型？# 13.1.1 高维联合概率分布的困境# 考虑 $n$ 个二值随机变量 $X_1, X_2, \ldots, X_n$。完整的联合概率分布 $P(X_1, X_2, \ldots, X_n)$ 需要存储 $2^n - 1$ 个参数（减1是因为概率和为1的约束）。
问题：
存储复杂度：随着变量数量指数增长，参数空间爆炸。 估计复杂度：从数据中估计如此多的参数需要海量样本。 推断复杂度：在高维空间中进行边缘化或条件化计算不可行。 解决方案：利用变量间的条件独立性来分解联合概率分布。
13.1.2 条件独立性的威力# 如果变量 $X$ 和 $Y$ 在给定 $Z$ 的条件下独立，记作 $X \perp Y \mid Z$，则：
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第13章 概率图模型 表示"><meta property="og:description" content="第13章 概率图模型：表示# “The purpose of computing is insight, not numbers.” — Richard Hamming
“Graphical models are a marriage between probability theory and graph theory.” — Michael I. Jordan
13.1 引言：为什么需要概率图模型？# 13.1.1 高维联合概率分布的困境# 考虑 $n$ 个二值随机变量 $X_1, X_2, \ldots, X_n$。完整的联合概率分布 $P(X_1, X_2, \ldots, X_n)$ 需要存储 $2^n - 1$ 个参数（减1是因为概率和为1的约束）。
问题：
存储复杂度：随着变量数量指数增长，参数空间爆炸。 估计复杂度：从数据中估计如此多的参数需要海量样本。 推断复杂度：在高维空间中进行边缘化或条件化计算不可行。 解决方案：利用变量间的条件独立性来分解联合概率分布。
13.1.2 条件独立性的威力# 如果变量 $X$ 和 $Y$ 在给定 $Z$ 的条件下独立，记作 $X \perp Y \mid Z$，则："><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第13章 概率图模型 表示"><meta itemprop=description content="第13章 概率图模型：表示# “The purpose of computing is insight, not numbers.” — Richard Hamming
“Graphical models are a marriage between probability theory and graph theory.” — Michael I. Jordan
13.1 引言：为什么需要概率图模型？# 13.1.1 高维联合概率分布的困境# 考虑 $n$ 个二值随机变量 $X_1, X_2, \ldots, X_n$。完整的联合概率分布 $P(X_1, X_2, \ldots, X_n)$ 需要存储 $2^n - 1$ 个参数（减1是因为概率和为1的约束）。
问题：
存储复杂度：随着变量数量指数增长，参数空间爆炸。 估计复杂度：从数据中估计如此多的参数需要海量样本。 推断复杂度：在高维空间中进行边缘化或条件化计算不可行。 解决方案：利用变量间的条件独立性来分解联合概率分布。
13.1.2 条件独立性的威力# 如果变量 $X$ 和 $Y$ 在给定 $Z$ 的条件下独立，记作 $X \perp Y \mid Z$，则："><meta itemprop=wordCount content="796"><title>第13章 概率图模型 表示 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle checked>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/ class=active>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第13章 概率图模型 表示</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#131-引言为什么需要概率图模型>13.1 引言：为什么需要概率图模型？</a><ul><li><a href=#1311-高维联合概率分布的困境>13.1.1 高维联合概率分布的困境</a></li><li><a href=#1312-条件独立性的威力>13.1.2 条件独立性的威力</a></li><li><a href=#1313-图模型的两大家族>13.1.3 图模型的两大家族</a></li></ul></li><li><a href=#132-贝叶斯网络bayesian-networks>13.2 贝叶斯网络（Bayesian Networks）</a><ul><li><a href=#1321-定义与基本结构>13.2.1 定义与基本结构</a></li><li><a href=#1322-局部马尔可夫性>13.2.2 局部马尔可夫性</a></li><li><a href=#1323-d-分离d-separation>13.2.3 D-分离（D-Separation）</a></li><li><a href=#1324-典型结构朴素贝叶斯分类器>13.2.4 典型结构：朴素贝叶斯分类器</a></li><li><a href=#1325-典型结构隐马尔可夫模型hmm>13.2.5 典型结构：隐马尔可夫模型（HMM）</a></li></ul></li><li><a href=#133-马尔可夫随机场markov-random-fields>13.3 马尔可夫随机场（Markov Random Fields）</a><ul><li><a href=#1331-定义与基本概念>13.3.1 定义与基本概念</a></li><li><a href=#1332-团与最大团>13.3.2 团与最大团</a></li><li><a href=#1333-hammersley-clifford-定理>13.3.3 Hammersley-Clifford 定理</a></li><li><a href=#1334-gibbs-分布与能量函数>13.3.4 Gibbs 分布与能量函数</a></li><li><a href=#1335-典型结构ising-模型>13.3.5 典型结构：Ising 模型</a></li><li><a href=#1336-典型应用图像去噪>13.3.6 典型应用：图像去噪</a></li></ul></li><li><a href=#134-因子图factor-graphs>13.4 因子图（Factor Graphs）</a><ul><li><a href=#1341-动机统一表示>13.4.1 动机：统一表示</a></li><li><a href=#1342-定义>13.4.2 定义</a></li><li><a href=#1343-与其他图模型的关系>13.4.3 与其他图模型的关系</a></li><li><a href=#1344-示例hmm-的因子图表示>13.4.4 示例：HMM 的因子图表示</a></li></ul></li><li><a href=#135-有向图与无向图的转换>13.5 有向图与无向图的转换</a><ul><li><a href=#1351-道德图moralization>13.5.1 道德图（Moralization）</a></li><li><a href=#1352-三角化triangulation>13.5.2 三角化（Triangulation）</a></li></ul></li><li><a href=#136-表示能力的比较>13.6 表示能力的比较</a></li><li><a href=#137-小结>13.7 小结</a></li><li><a href=#练习题>练习题</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第13章-概率图模型表示>第13章 概率图模型：表示<a class=anchor href=#%e7%ac%ac13%e7%ab%a0-%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b%e8%a1%a8%e7%a4%ba>#</a></h1><blockquote class=book-hint><p>&ldquo;The purpose of computing is insight, not numbers.&rdquo;
— Richard Hamming</p></blockquote><blockquote class=book-hint><p>&ldquo;Graphical models are a marriage between probability theory and graph theory.&rdquo;
— Michael I. Jordan</p></blockquote><hr><h2 id=131-引言为什么需要概率图模型>13.1 引言：为什么需要概率图模型？<a class=anchor href=#131-%e5%bc%95%e8%a8%80%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e6%a6%82%e7%8e%87%e5%9b%be%e6%a8%a1%e5%9e%8b>#</a></h2><h3 id=1311-高维联合概率分布的困境>13.1.1 高维联合概率分布的困境<a class=anchor href=#1311-%e9%ab%98%e7%bb%b4%e8%81%94%e5%90%88%e6%a6%82%e7%8e%87%e5%88%86%e5%b8%83%e7%9a%84%e5%9b%b0%e5%a2%83>#</a></h3><p>考虑 $n$ 个二值随机变量 $X_1, X_2, \ldots, X_n$。完整的联合概率分布 $P(X_1, X_2, \ldots, X_n)$ 需要存储 $2^n - 1$ 个参数（减1是因为概率和为1的约束）。</p><p><strong>问题</strong>：</p><ul><li><strong>存储复杂度</strong>：随着变量数量指数增长，参数空间爆炸。</li><li><strong>估计复杂度</strong>：从数据中估计如此多的参数需要海量样本。</li><li><strong>推断复杂度</strong>：在高维空间中进行边缘化或条件化计算不可行。</li></ul><p><strong>解决方案</strong>：利用变量间的<strong>条件独立性</strong>来分解联合概率分布。</p><h3 id=1312-条件独立性的威力>13.1.2 条件独立性的威力<a class=anchor href=#1312-%e6%9d%a1%e4%bb%b6%e7%8b%ac%e7%ab%8b%e6%80%a7%e7%9a%84%e5%a8%81%e5%8a%9b>#</a></h3><p>如果变量 $X$ 和 $Y$ 在给定 $Z$ 的条件下独立，记作 $X \perp Y \mid Z$，则：</p><p>$$
P(X, Y \mid Z) = P(X \mid Z) P(Y \mid Z)
$$</p><p>这种独立性结构可以用<strong>图</strong>来表示：</p><ul><li><strong>节点</strong>代表随机变量。</li><li><strong>边</strong>代表变量间的依赖关系。</li></ul><p>概率图模型（Probabilistic Graphical Models, PGM）通过图结构编码条件独立性，将高维联合分布分解为低维因子的乘积。</p><h3 id=1313-图模型的两大家族>13.1.3 图模型的两大家族<a class=anchor href=#1313-%e5%9b%be%e6%a8%a1%e5%9e%8b%e7%9a%84%e4%b8%a4%e5%a4%a7%e5%ae%b6%e6%97%8f>#</a></h3><ol><li><strong>贝叶斯网络（Bayesian Networks）</strong>：使用<strong>有向无环图</strong>（DAG）表示因果关系。</li><li><strong>马尔可夫随机场（Markov Random Fields）</strong>：使用<strong>无向图</strong>表示对称的局部依赖关系。</li></ol><hr><h2 id=132-贝叶斯网络bayesian-networks>13.2 贝叶斯网络（Bayesian Networks）<a class=anchor href=#132-%e8%b4%9d%e5%8f%b6%e6%96%af%e7%bd%91%e7%bb%9cbayesian-networks>#</a></h2><h3 id=1321-定义与基本结构>13.2.1 定义与基本结构<a class=anchor href=#1321-%e5%ae%9a%e4%b9%89%e4%b8%8e%e5%9f%ba%e6%9c%ac%e7%bb%93%e6%9e%84>#</a></h3><p><strong>定义 13.1（贝叶斯网络）</strong>
贝叶斯网络是一个有向无环图 $G = (V, E)$，其中：</p><ul><li>每个节点 $v_i \in V$ 对应随机变量 $X_i$。</li><li>每条有向边 $v_i \to v_j$ 表示 $X_i$ 对 $X_j$ 有直接影响。</li><li>联合概率分布分解为：</li></ul><p>$$
P(X_1, X_2, \ldots, X_n) = \prod_{i=1}^{n} P(X_i \mid \text{Pa}(X_i))
$$</p><p>其中 $\text{Pa}(X_i)$ 是 $X_i$ 的父节点集合。</p><p><strong>物理直觉</strong>：每个变量只依赖于其直接原因（父节点），这体现了<strong>局部马尔可夫性</strong>。</p><h3 id=1322-局部马尔可夫性>13.2.2 局部马尔可夫性<a class=anchor href=#1322-%e5%b1%80%e9%83%a8%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%e6%80%a7>#</a></h3><p><strong>定理 13.1（局部马尔可夫性）</strong>
在贝叶斯网络中，每个变量在给定其父节点的条件下，与其非后代节点条件独立：</p><p>$$
X_i \perp \text{NonDesc}(X_i) \mid \text{Pa}(X_i)
$$</p><p><strong>证明思路</strong>：
由链式法则分解联合概率，观察到 $X_i$ 的条件概率只涉及 $\text{Pa}(X_i)$，与其他非后代节点无关。</p><h3 id=1323-d-分离d-separation>13.2.3 D-分离（D-Separation）<a class=anchor href=#1323-d-%e5%88%86%e7%a6%bbd-separation>#</a></h3><p>D-分离是判定贝叶斯网络中条件独立性的核心工具。</p><p><strong>定义 13.2（D-分离）</strong>
给定节点集合 $Z$，如果所有从 $X$ 到 $Y$ 的路径都被 $Z$ &ldquo;阻塞&rdquo;（blocked），则称 $X$ 和 $Y$ 被 $Z$ D-分离，记作 $X \perp_d Y \mid Z$。</p><p><strong>阻塞规则</strong>：路径被阻塞当且仅当路径上存在节点 $W$ 满足以下条件之一：</p><ol><li><p><strong>Head-to-Tail（串联）</strong>：$X \to W \to Y$</p><ul><li>如果 $W \in Z$，路径被阻塞。</li><li>物理意义：观测到中间变量后，信息传递被切断。</li></ul></li><li><p><strong>Tail-to-Tail（分叉）</strong>：$X \leftarrow W \to Y$</p><ul><li>如果 $W \in Z$，路径被阻塞。</li><li>物理意义：观测到共同原因后，结果变量独立。</li></ul></li><li><p><strong>Head-to-Head（碰撞）</strong>：$X \to W \leftarrow Y$</p><ul><li>如果 $W \notin Z$ 且 $W$ 的后代都不在 $Z$ 中，路径被阻塞。</li><li>物理意义：未观测共同结果时，原因变量独立；观测后反而产生依赖（&ldquo;解释效应&rdquo;）。</li></ul></li></ol><p><strong>定理 13.2（D-分离与条件独立）</strong>
在贝叶斯网络中，$X \perp_d Y \mid Z$ 当且仅当 $X \perp Y \mid Z$（对于任何满足该网络的概率分布）。</p><p><strong>示例 13.1（解释效应）</strong>
考虑网络：$\text{雨} \to \text{地湿} \leftarrow \text{洒水器}$。</p><ul><li>未观测地湿时：雨和洒水器独立。</li><li>观测到地湿后：知道下雨了，会降低洒水器开启的概率（解释了地湿）。</li></ul><p>这是 Head-to-Head 结构的经典例子。</p><h3 id=1324-典型结构朴素贝叶斯分类器>13.2.4 典型结构：朴素贝叶斯分类器<a class=anchor href=#1324-%e5%85%b8%e5%9e%8b%e7%bb%93%e6%9e%84%e6%9c%b4%e7%b4%a0%e8%b4%9d%e5%8f%b6%e6%96%af%e5%88%86%e7%b1%bb%e5%99%a8>#</a></h3><p><strong>结构</strong>：类别变量 $C$ 作为根节点，所有特征 $X_1, \ldots, X_d$ 作为子节点。</p><p>$$
P(C, X_1, \ldots, X_d) = P(C) \prod_{i=1}^{d} P(X_i \mid C)
$$</p><p><strong>假设</strong>：特征在给定类别条件下独立（朴素假设）。</p><p>$$
P(C \mid X_1, \ldots, X_d) \propto P(C) \prod_{i=1}^{d} P(X_i \mid C)
$$</p><p><strong>优点</strong>：</p><ul><li>参数数量从 $O(2^d)$ 降至 $O(d)$。</li><li>计算高效，对小样本鲁棒。</li></ul><p><strong>局限</strong>：朴素假设往往不成立，但实践中效果依然良好（为什么？后续章节讨论）。</p><h3 id=1325-典型结构隐马尔可夫模型hmm>13.2.5 典型结构：隐马尔可夫模型（HMM）<a class=anchor href=#1325-%e5%85%b8%e5%9e%8b%e7%bb%93%e6%9e%84%e9%9a%90%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%e6%a8%a1%e5%9e%8bhmm>#</a></h3><p><strong>结构</strong>：</p><ul><li>隐状态序列 $Z_1 \to Z_2 \to \cdots \to Z_T$（马尔可夫链）。</li><li>观测序列 $X_1, X_2, \ldots, X_T$，每个 $X_t$ 依赖于 $Z_t$。</li></ul><p>$$
P(Z_{1:T}, X_{1:T}) = P(Z_1) \prod_{t=2}^{T} P(Z_t \mid Z_{t-1}) \prod_{t=1}^{T} P(X_t \mid Z_t)
$$</p><p><strong>应用</strong>：语音识别、自然语言处理、基因序列分析。</p><hr><h2 id=133-马尔可夫随机场markov-random-fields>13.3 马尔可夫随机场（Markov Random Fields）<a class=anchor href=#133-%e9%a9%ac%e5%b0%94%e5%8f%af%e5%a4%ab%e9%9a%8f%e6%9c%ba%e5%9c%bamarkov-random-fields>#</a></h2><h3 id=1331-定义与基本概念>13.3.1 定义与基本概念<a class=anchor href=#1331-%e5%ae%9a%e4%b9%89%e4%b8%8e%e5%9f%ba%e6%9c%ac%e6%a6%82%e5%bf%b5>#</a></h3><p><strong>定义 13.3（马尔可夫随机场）</strong>
马尔可夫随机场是一个无向图 $G = (V, E)$，其中：</p><ul><li>每个节点 $v_i \in V$ 对应随机变量 $X_i$。</li><li>边 ${v_i, v_j} \in E$ 表示 $X_i$ 和 $X_j$ 直接相关。</li></ul><p><strong>全局马尔可夫性</strong>：给定邻居节点，每个节点与其他节点条件独立。</p><p>$$
X_i \perp X_{V \setminus {i} \cup \text{Ne}(i)} \mid X_{\text{Ne}(i)}
$$</p><p>其中 $\text{Ne}(i)$ 是 $i$ 的邻居节点。</p><p><strong>成对马尔可夫性</strong>：如果两个节点不相邻，则在给定其他所有节点条件下独立。</p><p>$$
X_i \perp X_j \mid X_{V \setminus {i, j}} \quad \text{if } {i, j} \notin E
$$</p><h3 id=1332-团与最大团>13.3.2 团与最大团<a class=anchor href=#1332-%e5%9b%a2%e4%b8%8e%e6%9c%80%e5%a4%a7%e5%9b%a2>#</a></h3><p><strong>定义 13.4（团）</strong>
图 $G$ 的一个<strong>团</strong>（Clique）是节点的子集 $C \subseteq V$，其中任意两个节点都相邻。</p><p><strong>定义 13.5（最大团）</strong>
<strong>最大团</strong>（Maximal Clique）是不能再添加任何节点的团。</p><p><strong>示例</strong>：在三角形图（3个全连接节点）中，整个图是唯一的最大团。</p><h3 id=1333-hammersley-clifford-定理>13.3.3 Hammersley-Clifford 定理<a class=anchor href=#1333-hammersley-clifford-%e5%ae%9a%e7%90%86>#</a></h3><p><strong>定理 13.3（Hammersley-Clifford 定理）</strong>
如果概率分布 $P(X)$ 严格为正，则 $P(X)$ 满足马尔可夫随机场 $G$ 当且仅当它可以分解为最大团上的势函数乘积：</p><p>$$
P(X) = \frac{1}{Z} \prod_{C \in \mathcal{C}} \psi_C(X_C)
$$</p><p>其中：</p><ul><li>$\mathcal{C}$ 是所有最大团的集合。</li><li>$\psi_C(X_C)$ 是定义在团 $C$ 上的<strong>势函数</strong>（非负函数）。</li><li>$Z = \sum_{X} \prod_{C \in \mathcal{C}} \psi_C(X_C)$ 是<strong>配分函数</strong>（归一化常数）。</li></ul><p><strong>物理意义</strong>：</p><ul><li>势函数编码局部偏好（类比物理系统中的能量）。</li><li>配分函数确保概率归一化（类比统计物理中的配分函数）。</li></ul><p><strong>证明思路</strong>：</p><ul><li>必要性：由局部马尔可夫性推导因子分解。</li><li>充分性：由因子分解验证条件独立性。</li></ul><h3 id=1334-gibbs-分布与能量函数>13.3.4 Gibbs 分布与能量函数<a class=anchor href=#1334-gibbs-%e5%88%86%e5%b8%83%e4%b8%8e%e8%83%bd%e9%87%8f%e5%87%bd%e6%95%b0>#</a></h3><p>势函数通常写为指数形式：</p><p>$$
\psi_C(X_C) = \exp(-E_C(X_C))
$$</p><p>其中 $E_C(X_C)$ 是<strong>能量函数</strong>。联合分布变为：</p><p>$$
P(X) = \frac{1}{Z} \exp\left(-\sum_{C \in \mathcal{C}} E_C(X_C)\right)
$$</p><p>这称为<strong>Gibbs 分布</strong>。物理直觉：低能量状态概率高（类比玻尔兹曼分布）。</p><h3 id=1335-典型结构ising-模型>13.3.5 典型结构：Ising 模型<a class=anchor href=#1335-%e5%85%b8%e5%9e%8b%e7%bb%93%e6%9e%84ising-%e6%a8%a1%e5%9e%8b>#</a></h3><p><strong>定义</strong>：二值变量 $X_i \in {-1, +1}$ 排列在网格上，只有相邻节点有边。</p><p>$$
P(X) = \frac{1}{Z} \exp\left(\sum_{{i,j} \in E} \theta_{ij} X_i X_j + \sum_{i \in V} \theta_i X_i\right)
$$</p><p><strong>参数</strong>：</p><ul><li>$\theta_{ij}$：耦合强度（相邻节点倾向于相同符号）。</li><li>$\theta_i$：外部场（节点的先验偏好）。</li></ul><p><strong>应用</strong>：</p><ul><li>统计物理（铁磁性）。</li><li>计算机视觉（图像分割、去噪）。</li></ul><h3 id=1336-典型应用图像去噪>13.3.6 典型应用：图像去噪<a class=anchor href=#1336-%e5%85%b8%e5%9e%8b%e5%ba%94%e7%94%a8%e5%9b%be%e5%83%8f%e5%8e%bb%e5%99%aa>#</a></h3><p><strong>建模</strong>：</p><ul><li>观测像素 $Y_{ij}$（带噪声）。</li><li>真实像素 $X_{ij}$（待恢复）。</li></ul><p><strong>能量函数</strong>：</p><p>$$
E(X, Y) = \sum_{i,j} (X_{ij} - Y_{ij})^2 + \lambda \sum_{\text{neighbors}} (X_{ij} - X_{kl})^2
$$</p><ul><li>第一项：数据项，鼓励 $X$ 接近观测 $Y$。</li><li>第二项：平滑项，鼓励相邻像素相似（去噪）。</li><li>$\lambda$：平衡参数。</li></ul><p><strong>推断</strong>：通过最大后验（MAP）或边缘化求解最优 $X$。</p><hr><h2 id=134-因子图factor-graphs>13.4 因子图（Factor Graphs）<a class=anchor href=#134-%e5%9b%a0%e5%ad%90%e5%9b%befactor-graphs>#</a></h2><h3 id=1341-动机统一表示>13.4.1 动机：统一表示<a class=anchor href=#1341-%e5%8a%a8%e6%9c%ba%e7%bb%9f%e4%b8%80%e8%a1%a8%e7%a4%ba>#</a></h3><p>贝叶斯网络和马尔可夫随机场各有优势：</p><ul><li>贝叶斯网络：有向图，清晰编码因果关系。</li><li>马尔可夫随机场：无向图，对称编码局部依赖。</li></ul><p><strong>问题</strong>：如何统一表示两者？</p><p><strong>答案</strong>：因子图（Factor Graph）。</p><h3 id=1342-定义>13.4.2 定义<a class=anchor href=#1342-%e5%ae%9a%e4%b9%89>#</a></h3><p><strong>定义 13.6（因子图）</strong>
因子图是一个二部图 $G = (V \cup F, E)$，包含：</p><ul><li><strong>变量节点</strong> $V$：对应随机变量 $X_i$。</li><li><strong>因子节点</strong> $F$：对应因子函数 $f_a(X_a)$。</li><li><strong>边</strong> $E$：连接因子和其涉及的变量。</li></ul><p>联合概率分布分解为：</p><p>$$
P(X) = \frac{1}{Z} \prod_{a \in F} f_a(X_a)
$$</p><p>其中 $X_a$ 是因子 $f_a$ 涉及的变量子集。</p><h3 id=1343-与其他图模型的关系>13.4.3 与其他图模型的关系<a class=anchor href=#1343-%e4%b8%8e%e5%85%b6%e4%bb%96%e5%9b%be%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%85%b3%e7%b3%bb>#</a></h3><ol><li><p><strong>从贝叶斯网络到因子图</strong>：
每个条件概率 $P(X_i \mid \text{Pa}(X_i))$ 对应一个因子。</p></li><li><p><strong>从马尔可夫随机场到因子图</strong>：
每个势函数 $\psi_C(X_C)$ 对应一个因子。</p></li></ol><p><strong>优势</strong>：</p><ul><li>显式表示因子，便于推断算法（如 Belief Propagation）。</li><li>避免有向图和无向图的转换歧义。</li></ul><h3 id=1344-示例hmm-的因子图表示>13.4.4 示例：HMM 的因子图表示<a class=anchor href=#1344-%e7%a4%ba%e4%be%8bhmm-%e7%9a%84%e5%9b%a0%e5%ad%90%e5%9b%be%e8%a1%a8%e7%a4%ba>#</a></h3><p>对于 HMM：</p><p>$$
P(Z_{1:T}, X_{1:T}) = f_0(Z_1) \prod_{t=2}^{T} f_t(Z_{t-1}, Z_t) \prod_{t=1}^{T} g_t(Z_t, X_t)
$$</p><p>因子图包含：</p><ul><li>变量节点：$Z_1, \ldots, Z_T, X_1, \ldots, X_T$。</li><li>因子节点：$f_0, f_2, \ldots, f_T, g_1, \ldots, g_T$。</li></ul><hr><h2 id=135-有向图与无向图的转换>13.5 有向图与无向图的转换<a class=anchor href=#135-%e6%9c%89%e5%90%91%e5%9b%be%e4%b8%8e%e6%97%a0%e5%90%91%e5%9b%be%e7%9a%84%e8%bd%ac%e6%8d%a2>#</a></h2><h3 id=1351-道德图moralization>13.5.1 道德图（Moralization）<a class=anchor href=#1351-%e9%81%93%e5%be%b7%e5%9b%bemoralization>#</a></h3><p>将有向图转换为无向图的过程称为<strong>道德化</strong>：</p><ol><li>为每个节点的父节点之间添加无向边（&ldquo;结婚&rdquo;）。</li><li>移除所有边的方向。</li></ol><p><strong>结果</strong>：道德图是一个无向图，但可能引入额外的边（丢失部分独立性信息）。</p><h3 id=1352-三角化triangulation>13.5.2 三角化（Triangulation）<a class=anchor href=#1352-%e4%b8%89%e8%a7%92%e5%8c%96triangulation>#</a></h3><p>为确保无向图可以高效推断，需要进行<strong>三角化</strong>：
在每个长度 $\geq 4$ 的环中添加弦，使得图中没有无弦环。</p><p><strong>目的</strong>：简化推断算法（如变量消除）。</p><hr><h2 id=136-表示能力的比较>13.6 表示能力的比较<a class=anchor href=#136-%e8%a1%a8%e7%a4%ba%e8%83%bd%e5%8a%9b%e7%9a%84%e6%af%94%e8%be%83>#</a></h2><p><strong>定理 13.4（I-map 与 P-map）</strong></p><ul><li><strong>I-map</strong>（Independence Map）：图 $G$ 蕴含的独立性都在分布 $P$ 中成立。</li><li><strong>P-map</strong>（Perfect Map）：图 $G$ 蕴含的独立性恰好是 $P$ 中的独立性。</li></ul><p><strong>观察</strong>：</p><ul><li>有向图和无向图各有所长，但表示能力不同。</li><li>某些分布只能用有向图完美表示（如 Head-to-Head 结构）。</li><li>某些分布只能用无向图完美表示（如循环依赖）。</li></ul><hr><h2 id=137-小结>13.7 小结<a class=anchor href=#137-%e5%b0%8f%e7%bb%93>#</a></h2><p>本章介绍了概率图模型的<strong>表示</strong>理论：</p><ol><li><p><strong>贝叶斯网络</strong>：</p><ul><li>有向无环图，编码因果关系。</li><li>局部马尔可夫性与 D-分离规则。</li><li>典型应用：朴素贝叶斯、HMM。</li></ul></li><li><p><strong>马尔可夫随机场</strong>：</p><ul><li>无向图，编码对称依赖。</li><li>Hammersley-Clifford 定理：分解为势函数乘积。</li><li>典型应用：Ising 模型、图像去噪。</li></ul></li><li><p><strong>因子图</strong>：</p><ul><li>统一表示框架，显式因子节点。</li><li>为推断算法提供便利。</li></ul></li><li><p><strong>表示能力</strong>：</p><ul><li>有向图与无向图表达不同的独立性结构。</li><li>道德化和三角化用于图转换。</li></ul></li></ol><p><strong>下一章预告</strong>：我们将探讨如何在这些图模型上进行<strong>推断</strong>（Inference），包括精确推断（变量消除、信念传播）和近似推断（MCMC、变分推断）。</p><hr><h2 id=练习题>练习题<a class=anchor href=#%e7%bb%83%e4%b9%a0%e9%a2%98>#</a></h2><p><strong>13.1</strong> 证明局部马尔可夫性：在贝叶斯网络中，$X_i \perp \text{NonDesc}(X_i) \mid \text{Pa}(X_i)$。</p><p><strong>13.2</strong> 给定贝叶斯网络：$A \to B \to C \leftarrow D$，判断以下独立性是否成立：</p><ul><li>(a) $A \perp D$</li><li>(b) $A \perp D \mid B$</li><li>(c) $A \perp D \mid C$</li></ul><p><strong>13.3</strong> 推导 Ising 模型的配分函数 $Z$（提示：在小规模网格上枚举所有状态）。</p><p><strong>13.4</strong> 绘制朴素贝叶斯分类器的因子图表示。</p><p><strong>13.5</strong> 将以下马尔可夫随机场转换为道德图：一个环形图 $X_1 - X_2 - X_3 - X_4 - X_1$。</p><hr><h2 id=参考文献>参考文献<a class=anchor href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae>#</a></h2><ol><li>Koller, D., & Friedman, N. (2009). <em>Probabilistic Graphical Models: Principles and Techniques</em>. MIT Press.</li><li>Bishop, C. M. (2006). <em>Pattern Recognition and Machine Learning</em>. Springer. (Chapter 8)</li><li>Pearl, J. (1988). <em>Probabilistic Reasoning in Intelligent Systems</em>. Morgan Kaufmann.</li><li>Wainwright, M. J., & Jordan, M. I. (2008). <em>Graphical Models, Exponential Families, and Variational Inference</em>. Foundations and Trends in Machine Learning.</li></ol><hr><p><strong>版权所有 © 2026</strong>
<em>本章内容遵循 CC BY-NC-SA 4.0 许可协议</em></p></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第11章 广义线性模型(GLM)</span>
</a></span><span><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/ class="flex align-center"><span>第14章 概率图模型 推断</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#131-引言为什么需要概率图模型>13.1 引言：为什么需要概率图模型？</a><ul><li><a href=#1311-高维联合概率分布的困境>13.1.1 高维联合概率分布的困境</a></li><li><a href=#1312-条件独立性的威力>13.1.2 条件独立性的威力</a></li><li><a href=#1313-图模型的两大家族>13.1.3 图模型的两大家族</a></li></ul></li><li><a href=#132-贝叶斯网络bayesian-networks>13.2 贝叶斯网络（Bayesian Networks）</a><ul><li><a href=#1321-定义与基本结构>13.2.1 定义与基本结构</a></li><li><a href=#1322-局部马尔可夫性>13.2.2 局部马尔可夫性</a></li><li><a href=#1323-d-分离d-separation>13.2.3 D-分离（D-Separation）</a></li><li><a href=#1324-典型结构朴素贝叶斯分类器>13.2.4 典型结构：朴素贝叶斯分类器</a></li><li><a href=#1325-典型结构隐马尔可夫模型hmm>13.2.5 典型结构：隐马尔可夫模型（HMM）</a></li></ul></li><li><a href=#133-马尔可夫随机场markov-random-fields>13.3 马尔可夫随机场（Markov Random Fields）</a><ul><li><a href=#1331-定义与基本概念>13.3.1 定义与基本概念</a></li><li><a href=#1332-团与最大团>13.3.2 团与最大团</a></li><li><a href=#1333-hammersley-clifford-定理>13.3.3 Hammersley-Clifford 定理</a></li><li><a href=#1334-gibbs-分布与能量函数>13.3.4 Gibbs 分布与能量函数</a></li><li><a href=#1335-典型结构ising-模型>13.3.5 典型结构：Ising 模型</a></li><li><a href=#1336-典型应用图像去噪>13.3.6 典型应用：图像去噪</a></li></ul></li><li><a href=#134-因子图factor-graphs>13.4 因子图（Factor Graphs）</a><ul><li><a href=#1341-动机统一表示>13.4.1 动机：统一表示</a></li><li><a href=#1342-定义>13.4.2 定义</a></li><li><a href=#1343-与其他图模型的关系>13.4.3 与其他图模型的关系</a></li><li><a href=#1344-示例hmm-的因子图表示>13.4.4 示例：HMM 的因子图表示</a></li></ul></li><li><a href=#135-有向图与无向图的转换>13.5 有向图与无向图的转换</a><ul><li><a href=#1351-道德图moralization>13.5.1 道德图（Moralization）</a></li><li><a href=#1352-三角化triangulation>13.5.2 三角化（Triangulation）</a></li></ul></li><li><a href=#136-表示能力的比较>13.6 表示能力的比较</a></li><li><a href=#137-小结>13.7 小结</a></li><li><a href=#练习题>练习题</a></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></aside></main></body></html>