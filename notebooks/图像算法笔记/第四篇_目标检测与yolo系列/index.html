<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第四篇：目标检测深入(YOLO系列重点)# 核心篇章 - 深入讲解YOLO系列从v1到YOLO11的完整演进，理论与实战并重
篇章定位# 本篇是整个计算机视觉笔记的重点篇章，专注于目标检测领域最重要的YOLO系列算法。从2016年YOLOv1的横空出世，到2024年YOLO11的最新进展，我们将系统学习YOLO如何改变目标检测领域。
为什么YOLO如此重要？# 单阶段检测的开创者 - 将检测问题转换为回归问题，实现真正的实时检测 工业界首选方案 - 在速度和精度间达到最佳平衡，广泛应用于生产环境 持续快速迭代 - 从v1到v11，每一代都带来显著的性能提升和创新 易用性强 - Ultralytics提供的API简洁高效，降低了应用门槛 内容结构# 第9章：YOLO系列演进(理论核心)# 深入讲解YOLO各版本的架构演进和核心创新：
9.1 YOLOv1-v3：单阶段检测的崛起
YOLOv1：开创性的单阶段检测 YOLOv2(YOLO9000)：Anchor机制引入 YOLOv3：多尺度特征金字塔 9.2 YOLOv4-v5：工程优化与实用化
YOLOv4：Bag of Freebies和Bag of Specials YOLOv5：Ultralytics的工程实现 9.3 YOLOv6-v7：架构创新
YOLOv6：工业应用优化 YOLOv7：可训练Bag-of-Freebies 9.4 YOLOv8：Ultralytics新一代
Anchor-free设计 多任务统一框架 性能基准 9.5 YOLOv9、YOLOv10、YOLO11：最新进展
YOLOv9：PGI和GELAN YOLOv10：NMS-free设计 YOLO11：当前最优方案 9.6 YOLO-World：开放词汇检测
零样本检测能力 与视觉-语言模型的结合 第10章：YOLO实战项目(代码实战)# 基于最新的YOLOv8和YOLO11的完整实战：
10.1 YOLOv8快速上手
环境配置 预训练模型使用 多种推理模式 10.2 自定义数据集训练
数据集准备和标注 训练配置详解 训练监控和调优 10.3 模型导出与部署
ONNX导出 TensorRT加速 边缘设备部署 10.4 实战：构建实时检测系统
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第四篇 目标检测与YOLO系列"><meta property="og:description" content="第四篇：目标检测深入(YOLO系列重点)# 核心篇章 - 深入讲解YOLO系列从v1到YOLO11的完整演进，理论与实战并重
篇章定位# 本篇是整个计算机视觉笔记的重点篇章，专注于目标检测领域最重要的YOLO系列算法。从2016年YOLOv1的横空出世，到2024年YOLO11的最新进展，我们将系统学习YOLO如何改变目标检测领域。
为什么YOLO如此重要？# 单阶段检测的开创者 - 将检测问题转换为回归问题，实现真正的实时检测 工业界首选方案 - 在速度和精度间达到最佳平衡，广泛应用于生产环境 持续快速迭代 - 从v1到v11，每一代都带来显著的性能提升和创新 易用性强 - Ultralytics提供的API简洁高效，降低了应用门槛 内容结构# 第9章：YOLO系列演进(理论核心)# 深入讲解YOLO各版本的架构演进和核心创新：
9.1 YOLOv1-v3：单阶段检测的崛起
YOLOv1：开创性的单阶段检测 YOLOv2(YOLO9000)：Anchor机制引入 YOLOv3：多尺度特征金字塔 9.2 YOLOv4-v5：工程优化与实用化
YOLOv4：Bag of Freebies和Bag of Specials YOLOv5：Ultralytics的工程实现 9.3 YOLOv6-v7：架构创新
YOLOv6：工业应用优化 YOLOv7：可训练Bag-of-Freebies 9.4 YOLOv8：Ultralytics新一代
Anchor-free设计 多任务统一框架 性能基准 9.5 YOLOv9、YOLOv10、YOLO11：最新进展
YOLOv9：PGI和GELAN YOLOv10：NMS-free设计 YOLO11：当前最优方案 9.6 YOLO-World：开放词汇检测
零样本检测能力 与视觉-语言模型的结合 第10章：YOLO实战项目(代码实战)# 基于最新的YOLOv8和YOLO11的完整实战：
10.1 YOLOv8快速上手
环境配置 预训练模型使用 多种推理模式 10.2 自定义数据集训练
数据集准备和标注 训练配置详解 训练监控和调优 10.3 模型导出与部署
ONNX导出 TensorRT加速 边缘设备部署 10.4 实战：构建实时检测系统"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第四篇 目标检测与YOLO系列"><meta itemprop=description content="第四篇：目标检测深入(YOLO系列重点)# 核心篇章 - 深入讲解YOLO系列从v1到YOLO11的完整演进，理论与实战并重
篇章定位# 本篇是整个计算机视觉笔记的重点篇章，专注于目标检测领域最重要的YOLO系列算法。从2016年YOLOv1的横空出世，到2024年YOLO11的最新进展，我们将系统学习YOLO如何改变目标检测领域。
为什么YOLO如此重要？# 单阶段检测的开创者 - 将检测问题转换为回归问题，实现真正的实时检测 工业界首选方案 - 在速度和精度间达到最佳平衡，广泛应用于生产环境 持续快速迭代 - 从v1到v11，每一代都带来显著的性能提升和创新 易用性强 - Ultralytics提供的API简洁高效，降低了应用门槛 内容结构# 第9章：YOLO系列演进(理论核心)# 深入讲解YOLO各版本的架构演进和核心创新：
9.1 YOLOv1-v3：单阶段检测的崛起
YOLOv1：开创性的单阶段检测 YOLOv2(YOLO9000)：Anchor机制引入 YOLOv3：多尺度特征金字塔 9.2 YOLOv4-v5：工程优化与实用化
YOLOv4：Bag of Freebies和Bag of Specials YOLOv5：Ultralytics的工程实现 9.3 YOLOv6-v7：架构创新
YOLOv6：工业应用优化 YOLOv7：可训练Bag-of-Freebies 9.4 YOLOv8：Ultralytics新一代
Anchor-free设计 多任务统一框架 性能基准 9.5 YOLOv9、YOLOv10、YOLO11：最新进展
YOLOv9：PGI和GELAN YOLOv10：NMS-free设计 YOLO11：当前最优方案 9.6 YOLO-World：开放词汇检测
零样本检测能力 与视觉-语言模型的结合 第10章：YOLO实战项目(代码实战)# 基于最新的YOLOv8和YOLO11的完整实战：
10.1 YOLOv8快速上手
环境配置 预训练模型使用 多种推理模式 10.2 自定义数据集训练
数据集准备和标注 训练配置详解 训练监控和调优 10.3 模型导出与部署
ONNX导出 TensorRT加速 边缘设备部署 10.4 实战：构建实时检测系统"><meta itemprop=wordCount content="5578"><title>第四篇 目标检测与YOLO系列 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle checked>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/ class=active>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第四篇 目标检测与YOLO系列</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#篇章定位>篇章定位</a></li><li><a href=#为什么yolo如此重要>为什么YOLO如此重要？</a></li><li><a href=#内容结构>内容结构</a><ul><li><a href=#第9章yolo系列演进理论核心>第9章：YOLO系列演进(理论核心)</a></li><li><a href=#第10章yolo实战项目代码实战>第10章：YOLO实战项目(代码实战)</a></li></ul></li><li><a href=#技术栈>技术栈</a></li><li><a href=#学习路径建议>学习路径建议</a><ul><li><a href=#初学者路径>初学者路径</a></li><li><a href=#进阶路径>进阶路径</a></li><li><a href=#研究路径>研究路径</a></li></ul></li><li><a href=#实践项目建议>实践项目建议</a><ul><li><a href=#入门项目>入门项目</a></li><li><a href=#进阶项目>进阶项目</a></li><li><a href=#高级项目>高级项目</a></li></ul></li><li><a href=#性能对比一览>性能对比一览</a></li><li><a href=#应用场景>应用场景</a></li><li><a href=#学习目标>学习目标</a></li><li><a href=#参考资源>参考资源</a><ul><li><a href=#官方文档>官方文档</a></li><li><a href=#论文原文>论文原文</a></li><li><a href=#社区资源>社区资源</a></li></ul></li><li><a href=#开始学习>开始学习</a></li></ul><ul><li><a href=#本章概览>本章概览</a></li><li><a href=#81-目标检测任务>8.1 目标检测任务</a><ul><li><a href=#811-什么是目标检测>8.1.1 什么是目标检测？</a></li><li><a href=#812-与相关任务的区别>8.1.2 与相关任务的区别</a></li><li><a href=#813-应用场景>8.1.3 应用场景</a></li></ul></li><li><a href=#82-评价指标>8.2 评价指标</a><ul><li><a href=#821-iou交并比>8.2.1 IoU（交并比）</a></li><li><a href=#822-precision与recall>8.2.2 Precision与Recall</a></li><li><a href=#823-ap与map>8.2.3 AP与mAP</a></li></ul></li><li><a href=#83-两阶段检测器>8.3 两阶段检测器</a><ul><li><a href=#831-r-cnn2014>8.3.1 R-CNN（2014）</a></li><li><a href=#832-fast-r-cnn2015>8.3.2 Fast R-CNN（2015）</a></li><li><a href=#833-faster-r-cnn2016>8.3.3 Faster R-CNN（2016）</a></li><li><a href=#834-两阶段方法总结>8.3.4 两阶段方法总结</a></li></ul></li><li><a href=#84-为什么需要单阶段检测>8.4 为什么需要单阶段检测？</a><ul><li><a href=#841-两阶段的速度瓶颈>8.4.1 两阶段的速度瓶颈</a></li><li><a href=#842-单阶段的思路>8.4.2 单阶段的思路</a></li><li><a href=#843-单阶段-vs-两阶段>8.4.3 单阶段 vs 两阶段</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心知识点>核心知识点</a></li><li><a href=#下一步>下一步</a></li></ul></li></ul><ul><li><a href=#本章概览-1>本章概览</a></li><li><a href=#为什么要学习yolo演进史>为什么要学习YOLO演进史？</a></li><li><a href=#章节结构>章节结构</a></li><li><a href=#91-yolov1-v3单阶段检测的崛起>9.1 YOLOv1-v3：单阶段检测的崛起</a><ul><li><a href=#911-yolov1开创性的单阶段检测>9.1.1 YOLOv1：开创性的单阶段检测</a><ul><li><a href=#核心思想>核心思想</a></li><li><a href=#架构设计>架构设计</a></li><li><a href=#损失函数>损失函数</a></li><li><a href=#优缺点>优缺点</a></li></ul></li><li><a href=#912-yolov2yolo9000更好更快更强>9.1.2 YOLOv2（YOLO9000）：更好、更快、更强</a><ul><li><a href=#better准确度提升>Better：准确度提升</a></li><li><a href=#faster速度提升>Faster：速度提升</a></li><li><a href=#stronger检测类别扩展>Stronger：检测类别扩展</a></li><li><a href=#性能>性能</a></li></ul></li><li><a href=#913-yolov3渐进式改进>9.1.3 YOLOv3：渐进式改进</a><ul><li><a href=#核心改进>核心改进</a></li><li><a href=#性能表现>性能表现</a></li><li><a href=#yolov3的实践意义>YOLOv3的实践意义</a></li></ul></li></ul></li><li><a href=#92-yolov4-v5工程优化与实用化>9.2 YOLOv4-v5：工程优化与实用化</a><ul><li><a href=#921-yolov4bag-of-freebies和bag-of-specials>9.2.1 YOLOv4：Bag of Freebies和Bag of Specials</a><ul><li><a href=#核心贡献>核心贡献</a></li><li><a href=#架构组成>架构组成</a></li><li><a href=#bag-of-freebies训练技巧>Bag of Freebies（训练技巧）</a></li><li><a href=#bag-of-specials推理技巧>Bag of Specials（推理技巧）</a></li><li><a href=#性能表现-1>性能表现</a></li></ul></li><li><a href=#922-yolov5ultralytics的工程实现>9.2.2 YOLOv5：Ultralytics的工程实现</a><ul><li><a href=#yolov5-vs-yolov4>YOLOv5 vs YOLOv4</a></li><li><a href=#代码示例>代码示例</a></li><li><a href=#性能-1>性能</a></li><li><a href=#争议与影响>争议与影响</a></li></ul></li></ul></li><li><a href=#93-yolov6-v7架构创新>9.3 YOLOv6-v7：架构创新</a><ul><li><a href=#931-yolov6工业应用优化>9.3.1 YOLOv6：工业应用优化</a><ul><li><a href=#核心创新>核心创新</a></li><li><a href=#模型系列>模型系列</a></li><li><a href=#工业化特性>工业化特性</a></li></ul></li><li><a href=#932-yolov7可训练bag-of-freebies>9.3.2 YOLOv7：可训练Bag-of-Freebies</a><ul><li><a href=#核心创新-1>核心创新</a></li><li><a href=#架构设计-1>架构设计</a></li><li><a href=#性能表现-2>性能表现</a></li><li><a href=#trainable-bag-of-freebies>Trainable Bag-of-Freebies</a></li></ul></li></ul></li><li><a href=#94-yolov8ultralytics新一代>9.4 YOLOv8：Ultralytics新一代</a><ul><li><a href=#941-核心特性>9.4.1 核心特性</a></li><li><a href=#942-多任务支持>9.4.2 多任务支持</a></li><li><a href=#943-模型变体>9.4.3 模型变体</a></li><li><a href=#944-api设计>9.4.4 API设计</a></li><li><a href=#945-性能特点>9.4.5 性能特点</a></li></ul></li><li><a href=#95-yolov9yolov10yolo11最新进展>9.5 YOLOv9、YOLOv10、YOLO11：最新进展</a><ul><li><a href=#951-yolov9pgi和gelan>9.5.1 YOLOv9：PGI和GELAN</a><ul><li><a href=#核心贡献-1>核心贡献</a></li><li><a href=#模型变体>模型变体</a></li><li><a href=#性能对比>性能对比</a></li><li><a href=#使用示例>使用示例</a></li></ul></li><li><a href=#952-yolov10nms-free端到端检测>9.5.2 YOLOv10：NMS-Free端到端检测</a><ul><li><a href=#核心创新-2>核心创新</a></li><li><a href=#模型变体-1>模型变体</a></li><li><a href=#性能亮点>性能亮点</a></li><li><a href=#使用示例-1>使用示例</a></li></ul></li><li><a href=#953-yolo11当前最优方案>9.5.3 YOLO11：当前最优方案</a><ul><li><a href=#核心改进-1>核心改进</a></li><li><a href=#模型性能>模型性能</a></li><li><a href=#多任务支持>多任务支持</a></li><li><a href=#使用示例-2>使用示例</a></li><li><a href=#适用场景>适用场景</a></li></ul></li></ul></li><li><a href=#96-yolo-world开放词汇检测>9.6 YOLO-World：开放词汇检测</a><ul><li><a href=#961-什么是开放词汇检测>9.6.1 什么是开放词汇检测？</a></li><li><a href=#962-核心技术>9.6.2 核心技术</a></li><li><a href=#963-模型变体>9.6.3 模型变体</a></li><li><a href=#964-使用示例>9.6.4 使用示例</a></li><li><a href=#965-应用场景>9.6.5 应用场景</a></li><li><a href=#966-性能特点>9.6.6 性能特点</a></li></ul></li><li><a href=#97-yolo系列总结与展望>9.7 YOLO系列总结与展望</a><ul><li><a href=#971-演进时间线>9.7.1 演进时间线</a></li><li><a href=#972-技术趋势>9.7.2 技术趋势</a></li><li><a href=#973-版本选择建议>9.7.3 版本选择建议</a></li><li><a href=#974-未来展望>9.7.4 未来展望</a></li></ul></li><li><a href=#本章小结-1>本章小结</a></li></ul><ul><li><a href=#本章概览-2>本章概览</a></li><li><a href=#101-yolov8快速上手>10.1 YOLOv8快速上手</a><ul><li><a href=#1011-环境配置>10.1.1 环境配置</a></li><li><a href=#1012-预训练模型使用>10.1.2 预训练模型使用</a></li><li><a href=#1013-理解检测结果>10.1.3 理解检测结果</a></li><li><a href=#1014-不同输入源的推理>10.1.4 不同输入源的推理</a></li></ul></li><li><a href=#102-自定义数据集训练>10.2 自定义数据集训练</a><ul><li><a href=#1021-数据集准备>10.2.1 数据集准备</a></li><li><a href=#1022-数据标注工具>10.2.2 数据标注工具</a></li><li><a href=#1023-数据增强>10.2.3 数据增强</a></li><li><a href=#1024-训练流程>10.2.4 训练流程</a></li><li><a href=#1025-训练监控>10.2.5 训练监控</a></li><li><a href=#1026-模型验证>10.2.6 模型验证</a></li></ul></li><li><a href=#103-模型导出与部署>10.3 模型导出与部署</a><ul><li><a href=#1031-模型导出>10.3.1 模型导出</a></li><li><a href=#1032-onnx推理>10.3.2 ONNX推理</a></li><li><a href=#1033-tensorrt加速>10.3.3 TensorRT加速</a></li><li><a href=#1034-移动端部署>10.3.4 移动端部署</a></li></ul></li><li><a href=#104-实战构建实时检测系统>10.4 实战：构建实时检测系统</a><ul><li><a href=#1041-项目需求分析>10.4.1 项目需求分析</a></li><li><a href=#1042-系统架构设计>10.4.2 系统架构设计</a></li><li><a href=#1043-完整代码实现>10.4.3 完整代码实现</a></li><li><a href=#1044-性能优化技巧>10.4.4 性能优化技巧</a></li><li><a href=#1045-gradio-web界面>10.4.5 Gradio Web界面</a></li><li><a href=#1046-docker容器化部署>10.4.6 Docker容器化部署</a></li></ul></li><li><a href=#105-最佳实践与常见问题>10.5 最佳实践与常见问题</a><ul><li><a href=#1051-最佳实践>10.5.1 最佳实践</a></li><li><a href=#1052-常见问题>10.5.2 常见问题</a></li></ul></li><li><a href=#本章小结-2>本章小结</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第四篇目标检测深入yolo系列重点>第四篇：目标检测深入(YOLO系列重点)<a class=anchor href=#%e7%ac%ac%e5%9b%9b%e7%af%87%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e6%b7%b1%e5%85%a5yolo%e7%b3%bb%e5%88%97%e9%87%8d%e7%82%b9>#</a></h1><blockquote class=book-hint><p><strong>核心篇章</strong> - 深入讲解YOLO系列从v1到YOLO11的完整演进，理论与实战并重</p></blockquote><h2 id=篇章定位>篇章定位<a class=anchor href=#%e7%af%87%e7%ab%a0%e5%ae%9a%e4%bd%8d>#</a></h2><p>本篇是整个计算机视觉笔记的<strong>重点篇章</strong>，专注于目标检测领域最重要的YOLO系列算法。从2016年YOLOv1的横空出世，到2024年YOLO11的最新进展，我们将系统学习YOLO如何改变目标检测领域。</p><h2 id=为什么yolo如此重要>为什么YOLO如此重要？<a class=anchor href=#%e4%b8%ba%e4%bb%80%e4%b9%88yolo%e5%a6%82%e6%ad%a4%e9%87%8d%e8%a6%81>#</a></h2><ol><li><strong>单阶段检测的开创者</strong> - 将检测问题转换为回归问题，实现真正的实时检测</li><li><strong>工业界首选方案</strong> - 在速度和精度间达到最佳平衡，广泛应用于生产环境</li><li><strong>持续快速迭代</strong> - 从v1到v11，每一代都带来显著的性能提升和创新</li><li><strong>易用性强</strong> - Ultralytics提供的API简洁高效，降低了应用门槛</li></ol><h2 id=内容结构>内容结构<a class=anchor href=#%e5%86%85%e5%ae%b9%e7%bb%93%e6%9e%84>#</a></h2><h3 id=第9章yolo系列演进理论核心>第9章：YOLO系列演进(理论核心)<a class=anchor href=#%e7%ac%ac9%e7%ab%a0yolo%e7%b3%bb%e5%88%97%e6%bc%94%e8%bf%9b%e7%90%86%e8%ae%ba%e6%a0%b8%e5%bf%83>#</a></h3><p>深入讲解YOLO各版本的架构演进和核心创新：</p><ul><li><p><strong>9.1 YOLOv1-v3：单阶段检测的崛起</strong></p><ul><li>YOLOv1：开创性的单阶段检测</li><li>YOLOv2(YOLO9000)：Anchor机制引入</li><li>YOLOv3：多尺度特征金字塔</li></ul></li><li><p><strong>9.2 YOLOv4-v5：工程优化与实用化</strong></p><ul><li>YOLOv4：Bag of Freebies和Bag of Specials</li><li>YOLOv5：Ultralytics的工程实现</li></ul></li><li><p><strong>9.3 YOLOv6-v7：架构创新</strong></p><ul><li>YOLOv6：工业应用优化</li><li>YOLOv7：可训练Bag-of-Freebies</li></ul></li><li><p><strong>9.4 YOLOv8：Ultralytics新一代</strong></p><ul><li>Anchor-free设计</li><li>多任务统一框架</li><li>性能基准</li></ul></li><li><p><strong>9.5 YOLOv9、YOLOv10、YOLO11：最新进展</strong></p><ul><li>YOLOv9：PGI和GELAN</li><li>YOLOv10：NMS-free设计</li><li>YOLO11：当前最优方案</li></ul></li><li><p><strong>9.6 YOLO-World：开放词汇检测</strong></p><ul><li>零样本检测能力</li><li>与视觉-语言模型的结合</li></ul></li></ul><h3 id=第10章yolo实战项目代码实战>第10章：YOLO实战项目(代码实战)<a class=anchor href=#%e7%ac%ac10%e7%ab%a0yolo%e5%ae%9e%e6%88%98%e9%a1%b9%e7%9b%ae%e4%bb%a3%e7%a0%81%e5%ae%9e%e6%88%98>#</a></h3><p>基于最新的YOLOv8和YOLO11的完整实战：</p><ul><li><p><strong>10.1 YOLOv8快速上手</strong></p><ul><li>环境配置</li><li>预训练模型使用</li><li>多种推理模式</li></ul></li><li><p><strong>10.2 自定义数据集训练</strong></p><ul><li>数据集准备和标注</li><li>训练配置详解</li><li>训练监控和调优</li></ul></li><li><p><strong>10.3 模型导出与部署</strong></p><ul><li>ONNX导出</li><li>TensorRT加速</li><li>边缘设备部署</li></ul></li><li><p><strong>10.4 实战：构建实时检测系统</strong></p><ul><li>视频流处理</li><li>性能优化</li><li>完整项目架构</li></ul></li></ul><h2 id=技术栈>技术栈<a class=anchor href=#%e6%8a%80%e6%9c%af%e6%a0%88>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>核心库</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>ultralytics==8.3.0+ </span><span class=w> </span><span class=c># 官方YOLO实现</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>torch&gt;=1.8.0        </span><span class=w> </span><span class=c># PyTorch深度学习框架</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>opencv-python       </span><span class=w> </span><span class=c># 图像处理</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>onnx                </span><span class=w> </span><span class=c># 模型导出</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>onnxruntime         </span><span class=w> </span><span class=c># ONNX推理</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>可选加速</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>tensorrt            </span><span class=w> </span><span class=c># NVIDIA GPU加速</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span>- <span class=l>openvino            </span><span class=w> </span><span class=c># Intel CPU优化</span></span></span></code></pre></div><h2 id=学习路径建议>学习路径建议<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84%e5%bb%ba%e8%ae%ae>#</a></h2><h3 id=初学者路径>初学者路径<a class=anchor href=#%e5%88%9d%e5%ad%a6%e8%80%85%e8%b7%af%e5%be%84>#</a></h3><ol><li>先看第9章了解YOLO发展历程（重点关注9.4 YOLOv8）</li><li>直接进入第10章动手实践</li><li>从10.1快速上手开始，逐步深入</li><li>完成一个自定义数据集的训练项目</li></ol><h3 id=进阶路径>进阶路径<a class=anchor href=#%e8%bf%9b%e9%98%b6%e8%b7%af%e5%be%84>#</a></h3><ol><li>系统学习第9章所有版本的演进</li><li>理解每个版本的核心创新点</li><li>第10章深入学习模型优化和部署</li><li>尝试将YOLO应用到实际生产环境</li></ol><h3 id=研究路径>研究路径<a class=anchor href=#%e7%a0%94%e7%a9%b6%e8%b7%af%e5%be%84>#</a></h3><ol><li>精读第9章各版本的论文原文</li><li>对比分析不同版本的架构差异</li><li>研究YOLOv9的PGI、YOLOv10的NMS-free等前沿技术</li><li>探索YOLO-World的开放词汇检测能力</li></ol><h2 id=实践项目建议>实践项目建议<a class=anchor href=#%e5%ae%9e%e8%b7%b5%e9%a1%b9%e7%9b%ae%e5%bb%ba%e8%ae%ae>#</a></h2><h3 id=入门项目>入门项目<a class=anchor href=#%e5%85%a5%e9%97%a8%e9%a1%b9%e7%9b%ae>#</a></h3><ul><li><strong>项目1</strong>：使用YOLOv8完成一个简单的物体检测任务</li><li><strong>项目2</strong>：在自己的数据集上训练YOLOv8模型</li><li><strong>项目3</strong>：实现实时视频流检测</li></ul><h3 id=进阶项目>进阶项目<a class=anchor href=#%e8%bf%9b%e9%98%b6%e9%a1%b9%e7%9b%ae>#</a></h3><ul><li><strong>项目4</strong>：对比YOLOv8、YOLOv10、YOLO11的性能</li><li><strong>项目5</strong>：将YOLOv8模型导出为ONNX并优化推理速度</li><li><strong>项目6</strong>：在边缘设备（如树莓派、Jetson）上部署YOLO</li></ul><h3 id=高级项目>高级项目<a class=anchor href=#%e9%ab%98%e7%ba%a7%e9%a1%b9%e7%9b%ae>#</a></h3><ul><li><strong>项目7</strong>：使用YOLO-World实现零样本检测</li><li><strong>项目8</strong>：结合目标跟踪算法实现多目标跟踪系统</li><li><strong>项目9</strong>：开发一个完整的视频分析系统</li></ul><h2 id=性能对比一览>性能对比一览<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%af%b9%e6%af%94%e4%b8%80%e8%a7%88>#</a></h2><p>基于COCO数据集的最新性能（2024年数据）：</p><table><thead><tr><th>模型</th><th>mAP 50-95</th><th>参数量</th><th>推理速度(A100)</th><th>特点</th></tr></thead><tbody><tr><td>YOLOv8n</td><td>37.3</td><td>3.2M</td><td>0.99ms</td><td>轻量高效</td></tr><tr><td>YOLOv8s</td><td>44.9</td><td>11.2M</td><td>1.20ms</td><td>速度精度平衡</td></tr><tr><td>YOLOv8m</td><td>50.2</td><td>25.9M</td><td>1.83ms</td><td>中等规模</td></tr><tr><td>YOLOv8l</td><td>52.9</td><td>43.7M</td><td>2.39ms</td><td>高精度</td></tr><tr><td>YOLOv8x</td><td>53.9</td><td>68.2M</td><td>3.53ms</td><td>最高精度</td></tr><tr><td>YOLOv9c</td><td>53.0</td><td>25.5M</td><td>-</td><td>创新架构</td></tr><tr><td>YOLOv10x</td><td>54.4</td><td>29.5M</td><td>10.70ms</td><td>NMS-free</td></tr><tr><td>YOLO11m</td><td>51.5</td><td>20.1M</td><td>-</td><td>参数更少，性能更优</td></tr><tr><td>YOLO11x</td><td>54.7</td><td>56.9M</td><td>11.3ms</td><td>当前最优</td></tr></tbody></table><h2 id=应用场景>应用场景<a class=anchor href=#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h2><p>YOLO系列在以下场景表现出色：</p><ol><li><strong>自动驾驶</strong> - 实时检测车辆、行人、交通标志</li><li><strong>智能监控</strong> - 异常行为检测、人员计数</li><li><strong>工业质检</strong> - 产品缺陷检测、零件识别</li><li><strong>零售分析</strong> - 商品识别、货架管理</li><li><strong>医疗影像</strong> - 病灶检测、细胞计数</li><li><strong>体育分析</strong> - 运动员追踪、姿态分析</li><li><strong>农业应用</strong> - 作物病害检测、成熟度判断</li><li><strong>安防领域</strong> - 周界入侵检测、可疑物品识别</li></ol><h2 id=学习目标>学习目标<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e7%9b%ae%e6%a0%87>#</a></h2><p>完成本篇学习后，你将能够：</p><ol><li>✅ 理解YOLO系列从v1到v11的完整演进脉络</li><li>✅ 掌握单阶段检测器的核心原理和关键技术</li><li>✅ 熟练使用Ultralytics库进行模型训练和推理</li><li>✅ 能够在自定义数据集上训练高性能检测模型</li><li>✅ 掌握模型优化和部署的完整流程</li><li>✅ 能够将YOLO应用到实际项目中</li><li>✅ 了解最新的检测技术趋势（开放词汇检测等）</li></ol><h2 id=参考资源>参考资源<a class=anchor href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%ba%90>#</a></h2><h3 id=官方文档>官方文档<a class=anchor href=#%e5%ae%98%e6%96%b9%e6%96%87%e6%a1%a3>#</a></h3><ul><li><a href=https://docs.ultralytics.com/>Ultralytics官方文档</a> - 最权威的参考</li><li><a href=https://github.com/ultralytics/ultralytics>Ultralytics GitHub</a> - 源码和示例</li></ul><h3 id=论文原文>论文原文<a class=anchor href=#%e8%ae%ba%e6%96%87%e5%8e%9f%e6%96%87>#</a></h3><ul><li>YOLOv1: &ldquo;You Only Look Once: Unified, Real-Time Object Detection&rdquo; (CVPR 2016)</li><li>YOLOv2: &ldquo;YOLO9000: Better, Faster, Stronger&rdquo; (CVPR 2017)</li><li>YOLOv3: &ldquo;YOLOv3: An Incremental Improvement&rdquo; (arXiv 2018)</li><li>YOLOv4: &ldquo;YOLOv4: Optimal Speed and Accuracy of Object Detection&rdquo; (arXiv 2020)</li><li>YOLOv7: &ldquo;YOLOv7: Trainable bag-of-freebies&rdquo; (CVPR 2023)</li><li>YOLOv9: &ldquo;YOLOv9: Learning What You Want to Learn&rdquo; (arXiv 2024)</li><li>YOLOv10: &ldquo;YOLOv10: Real-Time End-to-End Object Detection&rdquo; (arXiv 2024)</li></ul><h3 id=社区资源>社区资源<a class=anchor href=#%e7%a4%be%e5%8c%ba%e8%b5%84%e6%ba%90>#</a></h3><ul><li>Roboflow - 数据集管理和标注平台</li><li>Ultralytics HUB - 云端训练和部署平台</li></ul><h2 id=开始学习>开始学习<a class=anchor href=#%e5%bc%80%e5%a7%8b%e5%ad%a6%e4%b9%a0>#</a></h2><p>准备好了吗？让我们从第8章开始，先了解目标检测的基础知识，然后进入YOLO的精彩演进历程！</p><p><strong>下一步</strong>：<a href=./chapter08/README.md>第8章：目标检测基础</a></p><hr><p><strong>更新日期</strong>：2024年11月
<strong>基于版本</strong>：ultralytics 8.3.0+, YOLO11</p><hr><h1 id=第8章目标检测基础>第8章：目标检测基础<a class=anchor href=#%e7%ac%ac8%e7%ab%a0%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e5%9f%ba%e7%a1%80>#</a></h1><blockquote class=book-hint><p><strong>基础篇</strong> - 理解目标检测任务、评价指标与经典方法</p></blockquote><h2 id=本章概览>本章概览<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%a7%88>#</a></h2><p>在深入YOLO之前，我们需要先理解目标检测的基本概念。本章将系统介绍：</p><ul><li>目标检测任务定义</li><li>评价指标（IoU、mAP）</li><li>两阶段检测方法（R-CNN系列）</li><li>为什么需要单阶段检测</li></ul><h2 id=81-目标检测任务>8.1 目标检测任务<a class=anchor href=#81-%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e4%bb%bb%e5%8a%a1>#</a></h2><h3 id=811-什么是目标检测>8.1.1 什么是目标检测？<a class=anchor href=#811-%e4%bb%80%e4%b9%88%e6%98%af%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b>#</a></h3><p><strong>目标检测 = 定位 + 分类</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入：一张图像
</span></span><span class=line><span class=cl>输出：图像中所有目标的位置（边界框）和类别
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>每个检测结果包含：
</span></span><span class=line><span class=cl>- 边界框: (x, y, w, h) 或 (x1, y1, x2, y2)
</span></span><span class=line><span class=cl>- 类别: person, car, dog, ...
</span></span><span class=line><span class=cl>- 置信度: 0-1之间的概率值</span></span></code></pre></div><h3 id=812-与相关任务的区别>8.1.2 与相关任务的区别<a class=anchor href=#812-%e4%b8%8e%e7%9b%b8%e5%85%b3%e4%bb%bb%e5%8a%a1%e7%9a%84%e5%8c%ba%e5%88%ab>#</a></h3><table><thead><tr><th>任务</th><th>输出</th><th>示例</th></tr></thead><tbody><tr><td><strong>图像分类</strong></td><td>单个类别标签</td><td>&ldquo;这是一只猫&rdquo;</td></tr><tr><td><strong>目标检测</strong></td><td>多个边界框 + 类别</td><td>&ldquo;左边有只猫，右边有只狗&rdquo;</td></tr><tr><td><strong>语义分割</strong></td><td>像素级类别</td><td>每个像素属于哪个类别</td></tr><tr><td><strong>实例分割</strong></td><td>检测 + 分割掩码</td><td>每个物体的精确轮廓</td></tr></tbody></table><h3 id=813-应用场景>8.1.3 应用场景<a class=anchor href=#813-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h3><p><strong>1. 自动驾驶</strong></p><ul><li>行人检测、车辆检测</li><li>交通标志识别</li><li>障碍物检测</li></ul><p><strong>2. 安防监控</strong></p><ul><li>人脸检测</li><li>异常行为检测</li><li>入侵检测</li></ul><p><strong>3. 工业检测</strong></p><ul><li>缺陷检测</li><li>零件识别</li><li>产品计数</li></ul><p><strong>4. 零售应用</strong></p><ul><li>商品识别</li><li>货架管理</li><li>无人结算</li></ul><hr><h2 id=82-评价指标>8.2 评价指标<a class=anchor href=#82-%e8%af%84%e4%bb%b7%e6%8c%87%e6%a0%87>#</a></h2><h3 id=821-iou交并比>8.2.1 IoU（交并比）<a class=anchor href=#821-iou%e4%ba%a4%e5%b9%b6%e6%af%94>#</a></h3><p><strong>Intersection over Union</strong> 衡量预测框与真实框的重叠程度：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>IoU = 交集面积 / 并集面积
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>示例：
</span></span><span class=line><span class=cl>真实框: [100, 100, 200, 200]
</span></span><span class=line><span class=cl>预测框: [110, 110, 210, 210]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>交集: 90 × 90 = 8100
</span></span><span class=line><span class=cl>并集: 100×100 + 100×100 - 8100 = 11900
</span></span><span class=line><span class=cl>IoU = 8100 / 11900 ≈ 0.68</span></span></code></pre></div><p><strong>Python实现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>calculate_iou</span><span class=p>(</span><span class=n>box1</span><span class=p>,</span> <span class=n>box2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算两个边界框的IoU
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        box1, box2: [x1, y1, x2, y2] 格式的边界框
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        iou: 交并比值
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 计算交集</span>
</span></span><span class=line><span class=cl>    <span class=n>x1_inter</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>box1</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>box2</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>y1_inter</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>box1</span><span class=p>[</span><span class=mi>1</span><span class=p>],</span> <span class=n>box2</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>x2_inter</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>box1</span><span class=p>[</span><span class=mi>2</span><span class=p>],</span> <span class=n>box2</span><span class=p>[</span><span class=mi>2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>y2_inter</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>box1</span><span class=p>[</span><span class=mi>3</span><span class=p>],</span> <span class=n>box2</span><span class=p>[</span><span class=mi>3</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 交集面积</span>
</span></span><span class=line><span class=cl>    <span class=n>inter_width</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>x2_inter</span> <span class=o>-</span> <span class=n>x1_inter</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>inter_height</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>y2_inter</span> <span class=o>-</span> <span class=n>y1_inter</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>inter_area</span> <span class=o>=</span> <span class=n>inter_width</span> <span class=o>*</span> <span class=n>inter_height</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 各自面积</span>
</span></span><span class=line><span class=cl>    <span class=n>box1_area</span> <span class=o>=</span> <span class=p>(</span><span class=n>box1</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>-</span> <span class=n>box1</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>*</span> <span class=p>(</span><span class=n>box1</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span> <span class=o>-</span> <span class=n>box1</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=n>box2_area</span> <span class=o>=</span> <span class=p>(</span><span class=n>box2</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>-</span> <span class=n>box2</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span> <span class=o>*</span> <span class=p>(</span><span class=n>box2</span><span class=p>[</span><span class=mi>3</span><span class=p>]</span> <span class=o>-</span> <span class=n>box2</span><span class=p>[</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 并集面积</span>
</span></span><span class=line><span class=cl>    <span class=n>union_area</span> <span class=o>=</span> <span class=n>box1_area</span> <span class=o>+</span> <span class=n>box2_area</span> <span class=o>-</span> <span class=n>inter_area</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># IoU</span>
</span></span><span class=line><span class=cl>    <span class=n>iou</span> <span class=o>=</span> <span class=n>inter_area</span> <span class=o>/</span> <span class=n>union_area</span> <span class=k>if</span> <span class=n>union_area</span> <span class=o>&gt;</span> <span class=mi>0</span> <span class=k>else</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>iou</span></span></span></code></pre></div><p><strong>IoU阈值的含义</strong>：</p><table><thead><tr><th>IoU阈值</th><th>含义</th></tr></thead><tbody><tr><td>0.5</td><td>COCO标准（宽松）</td></tr><tr><td>0.75</td><td>严格匹配</td></tr><tr><td>0.5:0.95</td><td>COCO mAP（多阈值平均）</td></tr></tbody></table><h3 id=822-precision与recall>8.2.2 Precision与Recall<a class=anchor href=#822-precision%e4%b8%8erecall>#</a></h3><p><strong>精确率（Precision）</strong>：预测为正的样本中，真正为正的比例</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Precision = TP / (TP + FP)
</span></span><span class=line><span class=cl>          = 正确检测数 / 总检测数</span></span></code></pre></div><p><strong>召回率（Recall）</strong>：所有正样本中，被正确预测的比例</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Recall = TP / (TP + FN)
</span></span><span class=line><span class=cl>       = 正确检测数 / 真实目标总数</span></span></code></pre></div><p><strong>示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>场景：图像中有10个目标，模型检测出8个框
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>正确检测（TP）: 6个
</span></span><span class=line><span class=cl>错误检测（FP）: 2个
</span></span><span class=line><span class=cl>漏检（FN）: 4个
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Precision = 6 / 8 = 0.75 (75%的检测是正确的)
</span></span><span class=line><span class=cl>Recall = 6 / 10 = 0.6 (找到了60%的目标)</span></span></code></pre></div><h3 id=823-ap与map>8.2.3 AP与mAP<a class=anchor href=#823-ap%e4%b8%8emap>#</a></h3><p><strong>AP（Average Precision）</strong>：PR曲线下的面积</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>calculate_ap</span><span class=p>(</span><span class=n>precisions</span><span class=p>,</span> <span class=n>recalls</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    计算单个类别的AP
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        precisions: 精确率列表
</span></span></span><span class=line><span class=cl><span class=s2>        recalls: 召回率列表
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        ap: 平均精确率
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 在召回率点上插值</span>
</span></span><span class=line><span class=cl>    <span class=n>recalls</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=nb>list</span><span class=p>(</span><span class=n>recalls</span><span class=p>)</span> <span class=o>+</span> <span class=p>[</span><span class=mi>1</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>precisions</span> <span class=o>=</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>+</span> <span class=nb>list</span><span class=p>(</span><span class=n>precisions</span><span class=p>)</span> <span class=o>+</span> <span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 从右向左取最大值（单调递减）</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>precisions</span><span class=p>)</span> <span class=o>-</span> <span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>precisions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>=</span> <span class=nb>max</span><span class=p>(</span><span class=n>precisions</span><span class=p>[</span><span class=n>i</span><span class=p>],</span> <span class=n>precisions</span><span class=p>[</span><span class=n>i</span> <span class=o>+</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算面积</span>
</span></span><span class=line><span class=cl>    <span class=n>ap</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>recalls</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=n>ap</span> <span class=o>+=</span> <span class=p>(</span><span class=n>recalls</span><span class=p>[</span><span class=n>i</span><span class=p>]</span> <span class=o>-</span> <span class=n>recalls</span><span class=p>[</span><span class=n>i</span> <span class=o>-</span> <span class=mi>1</span><span class=p>])</span> <span class=o>*</span> <span class=n>precisions</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>ap</span></span></span></code></pre></div><p><strong>mAP（mean Average Precision）</strong>：所有类别AP的平均值</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>mAP = (1/N) × Σ AP_i
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中N是类别数</span></span></code></pre></div><p><strong>COCO评价标准</strong>：</p><table><thead><tr><th>指标</th><th>定义</th></tr></thead><tbody><tr><td><strong>AP</strong></td><td>IoU=0.5:0.95的平均mAP</td></tr><tr><td><strong>AP50</strong></td><td>IoU=0.5时的mAP</td></tr><tr><td><strong>AP75</strong></td><td>IoU=0.75时的mAP</td></tr><tr><td><strong>AP_S</strong></td><td>小目标(area&lt;32²)的AP</td></tr><tr><td><strong>AP_M</strong></td><td>中目标(32²&lt;area&lt;96²)的AP</td></tr><tr><td><strong>AP_L</strong></td><td>大目标(area>96²)的AP</td></tr></tbody></table><hr><h2 id=83-两阶段检测器>8.3 两阶段检测器<a class=anchor href=#83-%e4%b8%a4%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b%e5%99%a8>#</a></h2><h3 id=831-r-cnn2014>8.3.1 R-CNN（2014）<a class=anchor href=#831-r-cnn2014>#</a></h3><p><strong>Regions with CNN Features</strong></p><p><strong>核心思想</strong>：</p><ol><li>使用选择性搜索（Selective Search）生成约2000个候选区域</li><li>对每个区域用CNN提取特征</li><li>使用SVM进行分类</li><li>边界框回归精修位置</li></ol><p><strong>流程</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>选择性搜索 → 2000个候选区域
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>对每个区域:
</span></span><span class=line><span class=cl>  ├── resize到固定尺寸(227×227)
</span></span><span class=line><span class=cl>  ├── CNN提取特征(AlexNet)
</span></span><span class=line><span class=cl>  ├── SVM分类
</span></span><span class=line><span class=cl>  └── 边界框回归
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>NMS后处理 → 最终检测结果</span></span></code></pre></div><p><strong>问题</strong>：</p><ul><li>每张图像需要2000次前向传播，非常慢</li><li>训练复杂，多阶段流程</li><li>测试速度：~47秒/张图</li></ul><h3 id=832-fast-r-cnn2015>8.3.2 Fast R-CNN（2015）<a class=anchor href=#832-fast-r-cnn2015>#</a></h3><p><strong>改进</strong>：</p><ol><li>整张图像只需一次CNN前向传播</li><li>使用RoI Pooling从特征图中提取区域特征</li><li>多任务损失（分类 + 回归）</li></ol><p><strong>流程</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>CNN → 整图特征图
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>候选区域(仍用选择性搜索)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>RoI Pooling → 固定尺寸特征
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>全连接层 → 分类 + 回归</span></span></code></pre></div><p><strong>RoI Pooling</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>roi_pooling</span><span class=p>(</span><span class=n>feature_map</span><span class=p>,</span> <span class=n>roi</span><span class=p>,</span> <span class=n>output_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    将任意大小的RoI转换为固定尺寸的特征
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        feature_map: CNN特征图 (C, H, W)
</span></span></span><span class=line><span class=cl><span class=s2>        roi: 候选区域 [x1, y1, x2, y2]
</span></span></span><span class=line><span class=cl><span class=s2>        output_size: 输出尺寸 (7, 7)
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        pooled: (C, 7, 7) 的特征
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将RoI划分为 output_size 个bins</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对每个bin做max pooling</span>
</span></span><span class=line><span class=cl>    <span class=o>...</span></span></span></code></pre></div><p><strong>改进效果</strong>：</p><ul><li>训练：比R-CNN快9倍</li><li>测试：比R-CNN快213倍（~2秒/张图）</li><li>但候选区域生成仍是瓶颈</li></ul><h3 id=833-faster-r-cnn2016>8.3.3 Faster R-CNN（2016）<a class=anchor href=#833-faster-r-cnn2016>#</a></h3><p><strong>核心创新：Region Proposal Network (RPN)</strong></p><p>用神经网络替代选择性搜索，实现端到端训练！</p><p><strong>RPN架构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入特征图
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>3×3卷积 (滑动窗口)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>┌────────────┴────────────┐
</span></span><span class=line><span class=cl>↓                         ↓
</span></span><span class=line><span class=cl>1×1卷积                   1×1卷积
</span></span><span class=line><span class=cl>↓                         ↓
</span></span><span class=line><span class=cl>分类层(2k通道)            回归层(4k通道)
</span></span><span class=line><span class=cl>↓                         ↓
</span></span><span class=line><span class=cl>前景/背景                 边界框调整
</span></span><span class=line><span class=cl>(是否有物体)              (dx, dy, dw, dh)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>k = anchor数量(通常9个)</span></span></code></pre></div><p><strong>Anchor机制</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>每个位置预设k个anchor:
</span></span><span class=line><span class=cl>- 3种尺度: 128², 256², 512²
</span></span><span class=line><span class=cl>- 3种比例: 1:1, 1:2, 2:1
</span></span><span class=line><span class=cl>共9个anchor
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>特征图大小: 60×40
</span></span><span class=line><span class=cl>总anchor数: 60 × 40 × 9 = 21,600</span></span></code></pre></div><p><strong>完整流程</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Backbone(VGG/ResNet) → 特征图
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>RPN → 候选区域(~2000个)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>RoI Pooling → 固定尺寸特征
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>分类 + 边界框回归
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>NMS → 最终结果</span></span></code></pre></div><p><strong>性能</strong>：</p><ul><li>5 FPS (VGG-16)</li><li>17 FPS (ZF Net)</li><li>开启了实时检测的可能</li></ul><h3 id=834-两阶段方法总结>8.3.4 两阶段方法总结<a class=anchor href=#834-%e4%b8%a4%e9%98%b6%e6%ae%b5%e6%96%b9%e6%b3%95%e6%80%bb%e7%bb%93>#</a></h3><table><thead><tr><th>方法</th><th>候选区域</th><th>特征提取</th><th>速度</th><th>mAP</th></tr></thead><tbody><tr><td>R-CNN</td><td>选择性搜索</td><td>每个区域单独</td><td>47s</td><td>58.5</td></tr><tr><td>Fast R-CNN</td><td>选择性搜索</td><td>共享特征图</td><td>2s</td><td>70.0</td></tr><tr><td>Faster R-CNN</td><td>RPN</td><td>共享特征图</td><td>0.2s</td><td>73.2</td></tr></tbody></table><p><strong>两阶段的优缺点</strong>：</p><p>优点：</p><ul><li>精度高</li><li>可以处理复杂场景</li></ul><p>缺点：</p><ul><li>速度相对较慢</li><li>结构复杂</li><li>候选区域与分类分开优化</li></ul><hr><h2 id=84-为什么需要单阶段检测>8.4 为什么需要单阶段检测？<a class=anchor href=#84-%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%8d%95%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b>#</a></h2><h3 id=841-两阶段的速度瓶颈>8.4.1 两阶段的速度瓶颈<a class=anchor href=#841-%e4%b8%a4%e9%98%b6%e6%ae%b5%e7%9a%84%e9%80%9f%e5%ba%a6%e7%93%b6%e9%a2%88>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Faster R-CNN的计算分布:
</span></span><span class=line><span class=cl>- Backbone前向: 40%
</span></span><span class=line><span class=cl>- RPN: 15%
</span></span><span class=line><span class=cl>- RoI Pooling + FC: 35%
</span></span><span class=line><span class=cl>- NMS后处理: 10%
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>即使用RPN，仍需要两次预测:
</span></span><span class=line><span class=cl>1. RPN: 是否有物体
</span></span><span class=line><span class=cl>2. Detection Head: 是什么物体</span></span></code></pre></div><h3 id=842-单阶段的思路>8.4.2 单阶段的思路<a class=anchor href=#842-%e5%8d%95%e9%98%b6%e6%ae%b5%e7%9a%84%e6%80%9d%e8%b7%af>#</a></h3><p><strong>核心想法</strong>：能否一次性同时预测位置和类别？</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>两阶段:
</span></span><span class=line><span class=cl>图像 → 特征 → 候选区域 → 分类/回归
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>单阶段:
</span></span><span class=line><span class=cl>图像 → 特征 → 直接回归位置+类别</span></span></code></pre></div><p>这就是<strong>YOLO</strong>的核心思想！</p><h3 id=843-单阶段-vs-两阶段>8.4.3 单阶段 vs 两阶段<a class=anchor href=#843-%e5%8d%95%e9%98%b6%e6%ae%b5-vs-%e4%b8%a4%e9%98%b6%e6%ae%b5>#</a></h3><table><thead><tr><th>特性</th><th>两阶段</th><th>单阶段</th></tr></thead><tbody><tr><td>代表</td><td>Faster R-CNN</td><td>YOLO, SSD</td></tr><tr><td>速度</td><td>较慢(5-17 FPS)</td><td>较快(30-150 FPS)</td></tr><tr><td>精度</td><td>较高</td><td>早期较低，现已接近</td></tr><tr><td>结构</td><td>复杂</td><td>简洁</td></tr><tr><td>训练</td><td>多阶段</td><td>端到端</td></tr><tr><td>小目标</td><td>较好</td><td>早期较差，现已改进</td></tr></tbody></table><hr><h2 id=本章小结>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>#</a></h2><h3 id=核心知识点>核心知识点<a class=anchor href=#%e6%a0%b8%e5%bf%83%e7%9f%a5%e8%af%86%e7%82%b9>#</a></h3><ol><li><p><strong>目标检测任务</strong></p><ul><li>定位 + 分类</li><li>输出：边界框 + 类别 + 置信度</li></ul></li><li><p><strong>评价指标</strong></p><ul><li>IoU：衡量框的重叠程度</li><li>Precision/Recall：精确率与召回率</li><li>mAP：综合评价指标</li></ul></li><li><p><strong>两阶段检测器</strong></p><ul><li>R-CNN → Fast R-CNN → Faster R-CNN</li><li>核心创新：RPN替代选择性搜索</li><li>问题：速度仍不够快</li></ul></li><li><p><strong>单阶段检测的动机</strong></p><ul><li>追求实时性能</li><li>端到端简洁设计</li></ul></li></ol><h3 id=下一步>下一步<a class=anchor href=#%e4%b8%8b%e4%b8%80%e6%ad%a5>#</a></h3><p>现在你已经理解了目标检测的基础知识，让我们进入<a href=../chapter09/README.md>第9章</a>，学习YOLO如何开创单阶段检测的新时代！</p><hr><p><strong>参考资源</strong>：</p><ul><li><a href=https://arxiv.org/abs/1311.2524>R-CNN论文</a></li><li><a href=https://arxiv.org/abs/1504.08083>Fast R-CNN论文</a></li><li><a href=https://arxiv.org/abs/1506.01497>Faster R-CNN论文</a></li><li><a href=https://cocodataset.org/#detection-eval>COCO评价指标文档</a></li></ul><hr><h1 id=第9章yolo系列演进>第9章：YOLO系列演进<a class=anchor href=#%e7%ac%ac9%e7%ab%a0yolo%e7%b3%bb%e5%88%97%e6%bc%94%e8%bf%9b>#</a></h1><blockquote class=book-hint><p><strong>核心章节</strong> - 从YOLOv1到YOLO11，系统学习YOLO如何改变目标检测领域</p></blockquote><h2 id=本章概览-1>本章概览<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%a7%88-1>#</a></h2><p>本章将深入讲解YOLO（You Only Look Once）系列算法的完整演进历程。从2016年YOLOv1的横空出世，到2024年YOLO11的最新进展，我们将系统学习：</p><ul><li>YOLO如何开创单阶段检测范式</li><li>每一代YOLO的核心创新点</li><li>架构演进的内在逻辑</li><li>性能提升的技术路径</li></ul><h2 id=为什么要学习yolo演进史>为什么要学习YOLO演进史？<a class=anchor href=#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%a6%81%e5%ad%a6%e4%b9%a0yolo%e6%bc%94%e8%bf%9b%e5%8f%b2>#</a></h2><ol><li><strong>理解算法发展脉络</strong> - 看清目标检测技术的演进方向</li><li><strong>掌握核心创新思想</strong> - 每一代都有独特的贡献</li><li><strong>为实战打下基础</strong> - 理论指导实践应用</li><li><strong>跟上最新进展</strong> - YOLO仍在快速迭代中</li></ol><h2 id=章节结构>章节结构<a class=anchor href=#%e7%ab%a0%e8%8a%82%e7%bb%93%e6%9e%84>#</a></h2><ul><li><strong>9.1</strong> YOLOv1-v3：单阶段检测的崛起</li><li><strong>9.2</strong> YOLOv4-v5：工程优化与实用化</li><li><strong>9.3</strong> YOLOv6-v7：架构创新</li><li><strong>9.4</strong> YOLOv8：Ultralytics新一代</li><li><strong>9.5</strong> YOLOv9、YOLOv10、YOLO11：最新进展</li><li><strong>9.6</strong> YOLO-World：开放词汇检测</li></ul><hr><h2 id=91-yolov1-v3单阶段检测的崛起>9.1 YOLOv1-v3：单阶段检测的崛起<a class=anchor href=#91-yolov1-v3%e5%8d%95%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b%e7%9a%84%e5%b4%9b%e8%b5%b7>#</a></h2><h3 id=911-yolov1开创性的单阶段检测>9.1.1 YOLOv1：开创性的单阶段检测<a class=anchor href=#911-yolov1%e5%bc%80%e5%88%9b%e6%80%a7%e7%9a%84%e5%8d%95%e9%98%b6%e6%ae%b5%e6%a3%80%e6%b5%8b>#</a></h3><p><strong>论文</strong>：You Only Look Once: Unified, Real-Time Object Detection (CVPR 2016)<br><strong>作者</strong>：Joseph Redmon et al.</p><h4 id=核心思想>核心思想<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3>#</a></h4><p>YOLOv1的革命性贡献在于：<strong>将目标检测重新定义为单一回归问题</strong>，而非传统的两阶段流程（候选区域 + 分类）。</p><p>传统检测器（如R-CNN）的流程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像 → 候选区域生成 → 特征提取 → 分类 + 边界框回归</span></span></code></pre></div><p>YOLOv1的流程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像 → CNN → 直接输出 [类别概率 + 边界框坐标]</span></span></code></pre></div><h4 id=架构设计>架构设计<a class=anchor href=#%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1>#</a></h4><p><strong>1. 网格划分</strong></p><p>将输入图像划分为 S×S 网格（论文中S=7）。如果物体的中心落在某个网格内，该网格就负责检测这个物体。</p><p><strong>2. 边界框预测</strong></p><p>每个网格预测 B 个边界框（B=2），每个边界框包含：</p><ul><li>(x, y): 边界框中心相对于网格的偏移</li><li>(w, h): 边界框的宽高（相对于整张图像）</li><li>confidence: 置信度 = Pr(Object) × IOU</li></ul><p><strong>3. 类别预测</strong></p><p>每个网格预测 C 个类别概率（PASCAL VOC中C=20）</p><p><strong>4. 输出张量</strong></p><p>最终输出：S × S × (B×5 + C) = 7 × 7 × 30</p><p><strong>网络结构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: 448×448×3
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>24个卷积层（受GoogLeNet启发）
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>2个全连接层
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>输出: 7×7×30</span></span></code></pre></div><h4 id=损失函数>损失函数<a class=anchor href=#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0>#</a></h4><p>YOLOv1使用多任务损失（Multi-Part Loss）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Loss = λcoord × 坐标损失 
</span></span><span class=line><span class=cl>     + 置信度损失（有物体）
</span></span><span class=line><span class=cl>     + λnoobj × 置信度损失（无物体）
</span></span><span class=line><span class=cl>     + 分类损失</span></span></code></pre></div><p>关键参数：</p><ul><li>λcoord = 5：增加坐标损失的权重</li><li>λnoobj = 0.5：降低背景框的权重</li></ul><h4 id=优缺点>优缺点<a class=anchor href=#%e4%bc%98%e7%bc%ba%e7%82%b9>#</a></h4><p><strong>优势</strong>：</p><ul><li>速度快：45 FPS（标准版），155 FPS（Fast YOLO）</li><li>全局推理：看到整张图像，减少背景误检</li><li>通用性强：可用于艺术品等非标准领域</li></ul><p><strong>局限</strong>：</p><ul><li>每个网格只能检测一个物体，小物体检测困难</li><li>泛化能力有限，对新的长宽比敏感</li><li>定位精度不如两阶段方法</li></ul><h3 id=912-yolov2yolo9000更好更快更强>9.1.2 YOLOv2（YOLO9000）：更好、更快、更强<a class=anchor href=#912-yolov2yolo9000%e6%9b%b4%e5%a5%bd%e6%9b%b4%e5%bf%ab%e6%9b%b4%e5%bc%ba>#</a></h3><p><strong>论文</strong>：YOLO9000: Better, Faster, Stronger (CVPR 2017)<br><strong>作者</strong>：Joseph Redmon, Ali Farhadi</p><p>YOLOv2在v1的基础上进行了全面改进，论文副标题"Better, Faster, Stronger"概括了三个方向的提升。</p><h4 id=better准确度提升>Better：准确度提升<a class=anchor href=#better%e5%87%86%e7%a1%ae%e5%ba%a6%e6%8f%90%e5%8d%87>#</a></h4><p><strong>1. Batch Normalization</strong></p><ul><li>在所有卷积层后添加BN</li><li>mAP提升2%，去除dropout</li></ul><p><strong>2. High Resolution Classifier</strong></p><ul><li>先在ImageNet 448×448上微调分类网络</li><li>mAP提升约4%</li></ul><p><strong>3. Anchor Boxes</strong></p><ul><li>引入Faster R-CNN的Anchor机制</li><li>使用K-means聚类数据集获取先验框尺寸</li><li>提高召回率</li></ul><p><strong>4. Dimension Clusters</strong></p><ul><li>在数据集上运行K-means得到5个anchor boxes</li><li>比手工设计的anchor更适合数据集</li></ul><p><strong>5. Direct Location Prediction</strong></p><ul><li>预测相对于网格的偏移，使用sigmoid约束</li><li>稳定训练过程</li></ul><p><strong>6. Fine-Grained Features</strong></p><ul><li>引入Passthrough Layer（类似ResNet的identity mapping）</li><li>将26×26的特征图与13×13的融合</li><li>提升小物体检测能力</li></ul><p><strong>7. Multi-Scale Training</strong></p><ul><li>每10个batch随机选择不同尺寸{320, 352, &mldr;, 608}</li><li>增强对不同尺寸的鲁棒性</li></ul><h4 id=faster速度提升>Faster：速度提升<a class=anchor href=#faster%e9%80%9f%e5%ba%a6%e6%8f%90%e5%8d%87>#</a></h4><p><strong>Darknet-19</strong>：</p><ul><li>新的backbone网络</li><li>19个卷积层 + 5个maxpool层</li><li>使用全局平均池化代替全连接</li><li>参数量少，速度快</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: 416×416×3
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>Darknet-19（19 conv layers）
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>输出: 13×13×1024</span></span></code></pre></div><h4 id=stronger检测类别扩展>Stronger：检测类别扩展<a class=anchor href=#stronger%e6%a3%80%e6%b5%8b%e7%b1%bb%e5%88%ab%e6%89%a9%e5%b1%95>#</a></h4><p><strong>YOLO9000</strong>：能检测9000多个类别</p><p><strong>WordTree层次结构</strong>：</p><ul><li>结合ImageNet和COCO数据集</li><li>构建WordNet概念层次树</li><li>支持多级分类预测</li></ul><h4 id=性能>性能<a class=anchor href=#%e6%80%a7%e8%83%bd>#</a></h4><ul><li><strong>YOLOv2-416</strong>：67 FPS，76.8 mAP (VOC 2007)</li><li><strong>YOLOv2-544</strong>：40 FPS，78.6 mAP</li><li>在速度和精度上都超越了SSD和Faster R-CNN</li></ul><h3 id=913-yolov3渐进式改进>9.1.3 YOLOv3：渐进式改进<a class=anchor href=#913-yolov3%e6%b8%90%e8%bf%9b%e5%bc%8f%e6%94%b9%e8%bf%9b>#</a></h3><p><strong>论文</strong>：YOLOv3: An Incremental Improvement (arXiv 2018)<br><strong>作者</strong>：Joseph Redmon, Ali Farhadi</p><p>YOLOv3的改进更加务实，论文标题也很坦诚：&ldquo;渐进式改进&rdquo;。</p><h4 id=核心改进>核心改进<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%94%b9%e8%bf%9b>#</a></h4><p><strong>1. Darknet-53</strong></p><p>更深的backbone网络，借鉴ResNet的残差结构：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: 256×256×3
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>1x Conv: 32 filters
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>2x Conv: 64 filters  ┐
</span></span><span class=line><span class=cl>↓                    │ Residual Block ×1
</span></span><span class=line><span class=cl>Skip Connection ←────┘
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>2x Conv: 128 filters ┐
</span></span><span class=line><span class=cl>↓                    │ Residual Block ×2
</span></span><span class=line><span class=cl>Skip Connection ←────┘
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>2x Conv: 256 filters ┐
</span></span><span class=line><span class=cl>↓                    │ Residual Block ×8
</span></span><span class=line><span class=cl>Skip Connection ←────┘
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>2x Conv: 512 filters ┐
</span></span><span class=line><span class=cl>↓                    │ Residual Block ×8
</span></span><span class=line><span class=cl>Skip Connection ←────┘
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>2x Conv: 1024 filters┐
</span></span><span class=line><span class=cl>↓                    │ Residual Block ×4
</span></span><span class=line><span class=cl>Skip Connection ←────┘</span></span></code></pre></div><p><strong>性能对比</strong>：</p><ul><li>Darknet-53比Darknet-19准确度高</li><li>比ResNet-152快，精度相当</li><li>比ResNet-101快，精度更高</li></ul><p><strong>2. 多尺度预测（Feature Pyramid）</strong></p><p>在3个不同尺度上进行预测：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>13×13 (大物体) ←─ Conv Layers
</span></span><span class=line><span class=cl>                  ↑
</span></span><span class=line><span class=cl>26×26 (中物体) ←─ Upsample + Concat
</span></span><span class=line><span class=cl>                  ↑
</span></span><span class=line><span class=cl>52×52 (小物体) ←─ Upsample + Concat</span></span></code></pre></div><p>每个尺度预测3个anchor boxes，共9个anchors。</p><p><strong>3. 类别预测改进</strong></p><ul><li>使用<strong>逻辑回归</strong>代替softmax</li><li>支持多标签分类（如"人"和"女性"同时）</li><li>更适合复杂场景</li></ul><p><strong>4. 损失函数优化</strong></p><ul><li>边界框坐标：平方误差损失</li><li>物体置信度：二元交叉熵</li><li>类别预测：二元交叉熵（支持多标签）</li></ul><h4 id=性能表现>性能表现<a class=anchor href=#%e6%80%a7%e8%83%bd%e8%a1%a8%e7%8e%b0>#</a></h4><p><strong>COCO数据集</strong>（test-dev）：</p><ul><li>YOLOv3-320：28.2 mAP，22 ms</li><li>YOLOv3-416：31.0 mAP，29 ms</li><li>YOLOv3-608：33.0 mAP，51 ms</li></ul><p><strong>特点</strong>：</p><ul><li>小物体检测显著提升（APS：18.3）</li><li>中物体表现优异（APM：35.4）</li><li>大物体略低于RetinaNet（APL：41.9 vs 44.3）</li></ul><h4 id=yolov3的实践意义>YOLOv3的实践意义<a class=anchor href=#yolov3%e7%9a%84%e5%ae%9e%e8%b7%b5%e6%84%8f%e4%b9%89>#</a></h4><p>虽然论文标题谦虚，但YOLOv3是一个里程碑：</p><ul><li>多尺度预测成为标配</li><li>速度和精度达到良好平衡</li><li>成为工业界主流方案</li></ul><hr><h2 id=92-yolov4-v5工程优化与实用化>9.2 YOLOv4-v5：工程优化与实用化<a class=anchor href=#92-yolov4-v5%e5%b7%a5%e7%a8%8b%e4%bc%98%e5%8c%96%e4%b8%8e%e5%ae%9e%e7%94%a8%e5%8c%96>#</a></h2><h3 id=921-yolov4bag-of-freebies和bag-of-specials>9.2.1 YOLOv4：Bag of Freebies和Bag of Specials<a class=anchor href=#921-yolov4bag-of-freebies%e5%92%8cbag-of-specials>#</a></h3><p><strong>论文</strong>：YOLOv4: Optimal Speed and Accuracy of Object Detection (arXiv 2020)<br><strong>作者</strong>：Alexey Bochkovskiy, Chien-Yao Wang, Hong-Yuan Mark Liao</p><p>YOLOv4的出现标志着YOLO进入"工程化集大成"时代。论文系统性地总结了目标检测的技巧。</p><h4 id=核心贡献>核心贡献<a class=anchor href=#%e6%a0%b8%e5%bf%83%e8%b4%a1%e7%8c%ae>#</a></h4><p>YOLOv4将检测技巧分为两类：</p><p><strong>Bag of Freebies (BoF)</strong>：只增加训练成本，不增加推理成本
<strong>Bag of Specials (BoS)</strong>：略微增加推理成本，但显著提升精度</p><h4 id=架构组成>架构组成<a class=anchor href=#%e6%9e%b6%e6%9e%84%e7%bb%84%e6%88%90>#</a></h4><p>YOLOv4 = Backbone + Neck + Head</p><p><strong>1. Backbone：CSPDarknet53</strong></p><p>Cross Stage Partial（CSP）连接：</p><ul><li>将特征图分成两部分</li><li>一部分经过Dense Block</li><li>另一部分直接连接到末尾</li><li>减少计算量，增强梯度流</li></ul><p><strong>2. Neck：SPP + PAN</strong></p><ul><li><p><strong>SPP（Spatial Pyramid Pooling）</strong>：</p><ul><li>多尺度池化{1×1, 5×5, 9×9, 13×13}</li><li>增大感受野</li></ul></li><li><p><strong>PAN（Path Aggregation Network）</strong>：</p><ul><li>在FPN基础上添加bottom-up路径</li><li>增强低层特征的传播</li></ul></li></ul><p><strong>3. Head：YOLOv3 Head</strong></p><p>保持YOLOv3的检测头设计</p><h4 id=bag-of-freebies训练技巧>Bag of Freebies（训练技巧）<a class=anchor href=#bag-of-freebies%e8%ae%ad%e7%bb%83%e6%8a%80%e5%b7%a7>#</a></h4><p><strong>数据增强</strong>：</p><ul><li>Mosaic augmentation：将4张图像拼接</li><li>Self-Adversarial Training (SAT)</li><li>CutMix、MixUp</li><li>随机擦除</li></ul><p><strong>正则化</strong>：</p><ul><li>DropBlock</li><li>Label Smoothing</li></ul><p><strong>损失函数</strong>：</p><ul><li>CIoU Loss：考虑重叠面积、中心距离、宽高比</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># CIoU Loss伪代码</span>
</span></span><span class=line><span class=cl><span class=n>CIoU</span> <span class=o>=</span> <span class=n>IoU</span> <span class=o>-</span> <span class=p>(</span><span class=n>ρ²</span><span class=p>(</span><span class=n>b</span><span class=p>,</span> <span class=n>b_gt</span><span class=p>)</span> <span class=o>/</span> <span class=n>c²</span><span class=p>)</span> <span class=o>-</span> <span class=n>αv</span>
</span></span><span class=line><span class=cl><span class=n>其中</span><span class=err>：</span>
</span></span><span class=line><span class=cl>  <span class=n>ρ²</span><span class=p>:</span> <span class=n>中心点距离</span>
</span></span><span class=line><span class=cl>  <span class=n>c²</span><span class=p>:</span> <span class=n>最小外接矩形对角线距离</span>
</span></span><span class=line><span class=cl>  <span class=n>v</span><span class=p>:</span> <span class=n>宽高比一致性</span>
</span></span><span class=line><span class=cl>  <span class=n>α</span><span class=p>:</span> <span class=n>权重系数</span></span></span></code></pre></div><h4 id=bag-of-specials推理技巧>Bag of Specials（推理技巧）<a class=anchor href=#bag-of-specials%e6%8e%a8%e7%90%86%e6%8a%80%e5%b7%a7>#</a></h4><p><strong>增强感受野</strong>：</p><ul><li>SPP</li><li>ASFF（Adaptively Spatial Feature Fusion）</li></ul><p><strong>注意力机制</strong>：</p><ul><li>SE（Squeeze-and-Excitation）</li><li>SAM（Spatial Attention Module）</li></ul><p><strong>激活函数</strong>：</p><ul><li>Mish激活：Mish(x) = x * tanh(ln(1 + e^x))</li></ul><p><strong>后处理</strong>：</p><ul><li>DIoU-NMS：考虑中心点距离的NMS</li></ul><h4 id=性能表现-1>性能表现<a class=anchor href=#%e6%80%a7%e8%83%bd%e8%a1%a8%e7%8e%b0-1>#</a></h4><p><strong>MS COCO</strong>（test-dev）：</p><ul><li>YOLOv4-CSP：43.0 mAP，Tesla V100 62 FPS</li><li>相比YOLOv3，AP提升10%，FPS提升12%</li></ul><p><strong>突破</strong>：</p><ul><li>在通用GPU（GTX 1080 Ti）上实现实时检测</li><li>成为工业界首选方案</li></ul><h3 id=922-yolov5ultralytics的工程实现>9.2.2 YOLOv5：Ultralytics的工程实现<a class=anchor href=#922-yolov5ultralytics%e7%9a%84%e5%b7%a5%e7%a8%8b%e5%ae%9e%e7%8e%b0>#</a></h3><p><strong>发布时间</strong>：2020年6月（与YOLOv4几乎同时）<br><strong>开发者</strong>：Glenn Jocher (Ultralytics)<br><strong>特点</strong>：工程化、易用性、生产就绪</p><h4 id=yolov5-vs-yolov4>YOLOv5 vs YOLOv4<a class=anchor href=#yolov5-vs-yolov4>#</a></h4><p>YOLOv5不是学术论文，而是工程实现。主要改进：</p><p><strong>1. 架构改进</strong></p><ul><li><strong>Backbone</strong>：CSPDarknet（Focus结构）</li><li><strong>Neck</strong>：PA-FPN</li><li><strong>Head</strong>：YOLOv3-like head</li></ul><p><strong>Focus结构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Focus层：将空间信息压缩到通道</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>focus</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>channel</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 将 (b, c, w, h) → (b, 4c, w/2, h/2)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>concat</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>[::</span><span class=mi>2</span><span class=p>,</span> <span class=p>::</span><span class=mi>2</span><span class=p>],</span>   <span class=c1># 左上</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=p>::</span><span class=mi>2</span><span class=p>],</span>  <span class=c1># 右上</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>[::</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>],</span>  <span class=c1># 左下</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span><span class=p>[</span><span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>::</span><span class=mi>2</span><span class=p>]</span>  <span class=c1># 右下</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span></span></span></code></pre></div><p><strong>2. 数据增强</strong></p><ul><li>Mosaic增强（从YOLOv4继承）</li><li>自适应anchor计算</li><li>自适应图像缩放</li></ul><p><strong>3. 模型尺寸系列</strong></p><p>提供5个不同规模的模型：</p><table><thead><tr><th>模型</th><th>参数量</th><th>适用场景</th></tr></thead><tbody><tr><td>YOLOv5n</td><td>1.9M</td><td>移动端/边缘设备</td></tr><tr><td>YOLOv5s</td><td>7.2M</td><td>实时应用</td></tr><tr><td>YOLOv5m</td><td>21.2M</td><td>平衡性能</td></tr><tr><td>YOLOv5l</td><td>46.5M</td><td>高精度</td></tr><tr><td>YOLOv5x</td><td>86.7M</td><td>最高精度</td></tr></tbody></table><p><strong>4. 训练策略</strong></p><ul><li>自动学习率调整</li><li>自动混合精度（AMP）训练</li><li>EMA（Exponential Moving Average）权重更新</li><li>多尺度训练</li></ul><p><strong>5. 工程化优势</strong></p><ul><li>PyTorch原生实现，易于理解和修改</li><li>完善的训练脚本和工具链</li><li>支持导出ONNX、TensorRT、CoreML等格式</li><li>丰富的文档和社区支持</li></ul><h4 id=代码示例>代码示例<a class=anchor href=#%e4%bb%a3%e7%a0%81%e7%a4%ba%e4%be%8b>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># YOLOv5的简洁API</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>models.yolo</span> <span class=kn>import</span> <span class=n>Model</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>(</span><span class=s1>&#39;yolov5s.yaml&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;yolov5s.pt&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练</span>
</span></span><span class=line><span class=cl><span class=n>python</span> <span class=n>train</span><span class=o>.</span><span class=n>py</span> <span class=o>--</span><span class=n>data</span> <span class=n>coco</span><span class=o>.</span><span class=n>yaml</span> <span class=o>--</span><span class=n>weights</span> <span class=n>yolov5s</span><span class=o>.</span><span class=n>pt</span> <span class=o>--</span><span class=n>epochs</span> <span class=mi>300</span></span></span></code></pre></div><h4 id=性能-1>性能<a class=anchor href=#%e6%80%a7%e8%83%bd-1>#</a></h4><p><strong>COCO val2017</strong>：</p><ul><li>YOLOv5s：37.4 mAP，~140 FPS（V100）</li><li>YOLOv5m：45.4 mAP，~100 FPS</li><li>YOLOv5l：49.0 mAP，~75 FPS</li><li>YOLOv5x：50.7 mAP，~50 FPS</li></ul><h4 id=争议与影响>争议与影响<a class=anchor href=#%e4%ba%89%e8%ae%ae%e4%b8%8e%e5%bd%b1%e5%93%8d>#</a></h4><p><strong>争议点</strong>：</p><ul><li>命名争议（并非Joseph Redmon的官方延续）</li><li>发布时间紧跟YOLOv4引发讨论</li></ul><p><strong>积极影响</strong>：</p><ul><li>极大降低了YOLO的使用门槛</li><li>推动YOLO在工业界的广泛应用</li><li>为后续YOLOv6-v8奠定基础</li></ul><hr><h2 id=93-yolov6-v7架构创新>9.3 YOLOv6-v7：架构创新<a class=anchor href=#93-yolov6-v7%e6%9e%b6%e6%9e%84%e5%88%9b%e6%96%b0>#</a></h2><h3 id=931-yolov6工业应用优化>9.3.1 YOLOv6：工业应用优化<a class=anchor href=#931-yolov6%e5%b7%a5%e4%b8%9a%e5%ba%94%e7%94%a8%e4%bc%98%e5%8c%96>#</a></h3><p><strong>发布时间</strong>：2022年6月<br><strong>开发者</strong>：美团视觉智能部<br><strong>特点</strong>：面向工业应用的深度优化</p><h4 id=核心创新>核心创新<a class=anchor href=#%e6%a0%b8%e5%bf%83%e5%88%9b%e6%96%b0>#</a></h4><p><strong>1. BiC（Bi-directional Concatenation）模块</strong></p><ul><li>替代传统的Neck结构</li><li>双向特征融合</li><li>减少参数量，提升速度</li></ul><p><strong>2. Anchor-Free设计</strong></p><ul><li>采用Anchor-free检测头</li><li>简化模型结构</li><li>提升小物体检测能力</li></ul><p><strong>3. SimCSPSPPF Backbone</strong></p><ul><li>优化的CSP结构</li><li>融合SPPF（Fast SPP）</li><li>平衡速度和精度</li></ul><p><strong>4. 自蒸馏训练</strong></p><ul><li>使用更大的模型作为教师</li><li>提升小模型性能</li><li>无推理成本增加</li></ul><h4 id=模型系列>模型系列<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e7%b3%bb%e5%88%97>#</a></h4><table><thead><tr><th>模型</th><th>mAP</th><th>延迟(T4)</th><th>参数量</th></tr></thead><tbody><tr><td>YOLOv6-N</td><td>37.5</td><td>1.2ms</td><td>4.7M</td></tr><tr><td>YOLOv6-T</td><td>41.3</td><td>2.9ms</td><td>9.7M</td></tr><tr><td>YOLOv6-S</td><td>45.0</td><td>3.5ms</td><td>18.5M</td></tr><tr><td>YOLOv6-M</td><td>50.0</td><td>7.0ms</td><td>34.9M</td></tr><tr><td>YOLOv6-L</td><td>52.8</td><td>11.4ms</td><td>59.6M</td></tr></tbody></table><h4 id=工业化特性>工业化特性<a class=anchor href=#%e5%b7%a5%e4%b8%9a%e5%8c%96%e7%89%b9%e6%80%a7>#</a></h4><ul><li>支持量化感知训练（QAT）</li><li>INT8量化精度损失小</li><li>针对NVIDIA GPU和ARM处理器优化</li><li>提供完整的部署工具链</li></ul><h3 id=932-yolov7可训练bag-of-freebies>9.3.2 YOLOv7：可训练Bag-of-Freebies<a class=anchor href=#932-yolov7%e5%8f%af%e8%ae%ad%e7%bb%83bag-of-freebies>#</a></h3><p><strong>论文</strong>：YOLOv7: Trainable bag-of-freebies sets new state-of-the-art for real-time object detectors (CVPR 2023)<br><strong>作者</strong>：Chien-Yao Wang, Alexey Bochkovskiy, Hong-Yuan Mark Liao</p><p>YOLOv7是YOLOv4作者团队的最新力作，标题"Trainable bag-of-freebies"道出了核心贡献。</p><h4 id=核心创新-1>核心创新<a class=anchor href=#%e6%a0%b8%e5%bf%83%e5%88%9b%e6%96%b0-1>#</a></h4><p><strong>1. E-ELAN（Extended Efficient Layer Aggregation Network）</strong></p><p>E-ELAN是对ELAN的扩展：</p><ul><li>使用expand、shuffle、merge cardinality策略</li><li>在不破坏原始梯度路径的情况下增强学习能力</li><li>提升特征表达能力</li></ul><p><strong>架构对比</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>ELAN:
</span></span><span class=line><span class=cl>Input → Conv → [Conv × 2] → [Conv × 2] → Concat → Conv
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>E-ELAN:
</span></span><span class=line><span class=cl>Input → Conv → [Group Conv × 2] → [Shuffle] → [Conv × 2] → Concat → Conv</span></span></code></pre></div><p><strong>2. Model Scaling for Concatenation-based Models</strong></p><p>针对基于concatenation的模型提出缩放策略：</p><ul><li>深度缩放：调整模块重复次数</li><li>宽度缩放：调整通道数</li><li><strong>复合缩放</strong>：同时缩放计算块和过渡层</li></ul><p><strong>3. Planned Re-parameterized Convolution</strong></p><p><strong>RepConv</strong>：训练时使用多分支，推理时融合为单路</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 训练时</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>conv3x3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>+</span> <span class=n>conv1x1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span> <span class=o>+</span> <span class=n>identity</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理时（融合后）</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>fused_conv3x3</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># 单个3x3卷积</span></span></span></code></pre></div><p><strong>4. Coarse-to-Fine Lead Guided Label Assignment</strong></p><p>改进标签分配策略：</p><ul><li>Lead head：粗粒度分配，提供先验</li><li>Auxiliary head：细粒度优化</li><li>训练时双头，推理时仅保留lead head</li></ul><h4 id=架构设计-1>架构设计<a class=anchor href=#%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1-1>#</a></h4><p><strong>YOLOv7架构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Input (640×640)
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>E-ELAN Backbone
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>SPPCSPC (Spatial Pyramid Pooling CSP)
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>E-ELAN Neck (PA-FPN)
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>RepConv Head
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>Output (3个尺度)</span></span></code></pre></div><p><strong>变体</strong>：</p><ul><li>YOLOv7：基础版本</li><li>YOLOv7-X：扩展版本，更深更宽</li><li>YOLOv7-W6：针对1280分辨率</li><li>YOLOv7-E6、E6E：针对更高分辨率</li></ul><h4 id=性能表现-2>性能表现<a class=anchor href=#%e6%80%a7%e8%83%bd%e8%a1%a8%e7%8e%b0-2>#</a></h4><p><strong>MS COCO test-dev</strong>：</p><table><thead><tr><th>模型</th><th>mAP</th><th>V100推理速度</th><th>参数量</th><th>FLOPs</th></tr></thead><tbody><tr><td>YOLOv7</td><td>51.4</td><td>161 FPS</td><td>36.9M</td><td>104.7G</td></tr><tr><td>YOLOv7-X</td><td>53.1</td><td>114 FPS</td><td>71.3M</td><td>189.9G</td></tr><tr><td>YOLOv7-W6</td><td>54.9</td><td>84 FPS</td><td>70.4M</td><td>360.0G</td></tr><tr><td>YOLOv7-E6</td><td>56.0</td><td>56 FPS</td><td>97.2M</td><td>515.2G</td></tr><tr><td>YOLOv7-D6</td><td>56.6</td><td>44 FPS</td><td>154.7M</td><td>806.8G</td></tr><tr><td>YOLOv7-E6E</td><td>56.8</td><td>36 FPS</td><td>151.7M</td><td>843.2G</td></tr></tbody></table><p><strong>亮点</strong>：</p><ul><li>YOLOv7在640×640下达到51.4% AP</li><li>速度比YOLOv5快120%</li><li>比YOLOX快180%</li><li>比PP-YOLOE快140%</li></ul><h4 id=trainable-bag-of-freebies>Trainable Bag-of-Freebies<a class=anchor href=#trainable-bag-of-freebies>#</a></h4><p>YOLOv7提出的可训练BoF技巧：</p><p><strong>1. Planned Re-parameterization</strong></p><ul><li>不同深度使用不同的re-parameterization模块</li></ul><p><strong>2. Auxiliary Head + Coarse-to-Fine</strong></p><ul><li>辅助头用于训练优化</li><li>推理时去除，无额外成本</li></ul><p><strong>3. Batch Normalization in Concatenation</strong></p><ul><li>在concatenation层添加BN</li><li>改善梯度流</li></ul><hr><h2 id=94-yolov8ultralytics新一代>9.4 YOLOv8：Ultralytics新一代<a class=anchor href=#94-yolov8ultralytics%e6%96%b0%e4%b8%80%e4%bb%a3>#</a></h2><p><strong>发布时间</strong>：2023年1月<br><strong>开发者</strong>：Ultralytics (Glenn Jocher团队)<br><strong>特点</strong>：统一框架，支持多任务</p><p>YOLOv8是Ultralytics继YOLOv5后的又一力作，代表着YOLO走向成熟和多样化。</p><h3 id=941-核心特性>9.4.1 核心特性<a class=anchor href=#941-%e6%a0%b8%e5%bf%83%e7%89%b9%e6%80%a7>#</a></h3><p><strong>1. Anchor-Free设计</strong></p><p>YOLOv8彻底抛弃anchor：</p><ul><li>简化模型设计</li><li>加速后处理（无需anchor box生成）</li><li>更好的泛化能力</li></ul><p><strong>2. 新的Backbone：C2f模块</strong></p><p>C2f（Cross Stage Partial with 2 convolutions and more）：</p><ul><li>融合YOLOv5的C3和YOLOv7的ELAN设计</li><li>更丰富的梯度流</li><li>保持轻量级</li></ul><p><strong>C2f vs C3对比</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># C3 (YOLOv5)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>C3</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>c1</span><span class=p>,</span> <span class=n>c2</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cv1</span> <span class=o>=</span> <span class=n>Conv</span><span class=p>(</span><span class=n>c1</span><span class=p>,</span> <span class=n>c2</span><span class=o>//</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cv2</span> <span class=o>=</span> <span class=n>Conv</span><span class=p>(</span><span class=n>c1</span><span class=p>,</span> <span class=n>c2</span><span class=o>//</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>m</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span><span class=o>*</span><span class=p>[</span><span class=n>Bottleneck</span><span class=p>(</span><span class=n>c2</span><span class=o>//</span><span class=mi>2</span><span class=p>,</span> <span class=n>c2</span><span class=o>//</span><span class=mi>2</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cv3</span> <span class=o>=</span> <span class=n>Conv</span><span class=p>(</span><span class=n>c2</span><span class=p>,</span> <span class=n>c2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># C2f (YOLOv8)</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>C2f</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>c1</span><span class=p>,</span> <span class=n>c2</span><span class=p>,</span> <span class=n>n</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cv1</span> <span class=o>=</span> <span class=n>Conv</span><span class=p>(</span><span class=n>c1</span><span class=p>,</span> <span class=mi>2</span><span class=o>*</span><span class=n>c2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cv2</span> <span class=o>=</span> <span class=n>Conv</span><span class=p>((</span><span class=mi>2</span><span class=o>+</span><span class=n>n</span><span class=p>)</span><span class=o>*</span><span class=n>c2</span><span class=p>,</span> <span class=n>c2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>m</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>(</span><span class=n>Bottleneck</span><span class=p>(</span><span class=n>c2</span><span class=p>,</span> <span class=n>c2</span><span class=p>)</span> <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>n</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=c1># 每个Bottleneck的输出都concat到一起</span></span></span></code></pre></div><p><strong>3. 解耦头（Decoupled Head）</strong></p><p>分离分类和回归任务：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Feature Map
</span></span><span class=line><span class=cl>    ├── Classification Branch → Class Probabilities
</span></span><span class=line><span class=cl>    └── Regression Branch → Bounding Boxes</span></span></code></pre></div><p><strong>4. 新的损失函数</strong></p><ul><li><p><strong>分类损失</strong>：Varifocal Loss（VFL）</p><ul><li>关注正样本的置信度</li><li>对不平衡问题更鲁棒</li></ul></li><li><p><strong>回归损失</strong>：DFL（Distribution Focal Loss） + CIoU</p><ul><li>DFL将连续值转换为离散分布</li><li>CIoU考虑重叠、距离、宽高比</li></ul></li></ul><p><strong>5. Task-Aligned Assigner</strong></p><p>改进的样本分配策略：</p><ul><li>同时考虑分类分数和IoU</li><li>自适应地选择正负样本</li><li>提升训练效果</li></ul><h3 id=942-多任务支持>9.4.2 多任务支持<a class=anchor href=#942-%e5%a4%9a%e4%bb%bb%e5%8a%a1%e6%94%af%e6%8c%81>#</a></h3><p>YOLOv8统一框架支持5种计算机视觉任务：</p><p><strong>1. Object Detection（目标检测）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>2. Instance Segmentation（实例分割）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n-seg.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>  <span class=c1># 返回masks</span></span></span></code></pre></div><p><strong>3. Image Classification（图像分类）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n-cls.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>4. Pose Estimation（姿态估计）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n-pose.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;person.jpg&#39;</span><span class=p>)</span>  <span class=c1># 返回关键点</span></span></span></code></pre></div><p><strong>5. Oriented Bounding Boxes（旋转框检测）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n-obb.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;aerial.jpg&#39;</span><span class=p>)</span>  <span class=c1># 返回旋转边界框</span></span></span></code></pre></div><h3 id=943-模型变体>9.4.3 模型变体<a class=anchor href=#943-%e6%a8%a1%e5%9e%8b%e5%8f%98%e4%bd%93>#</a></h3><p>YOLOv8提供5个尺寸的模型：</p><p><strong>Detection Models (COCO val2017)</strong>：</p><table><thead><tr><th>模型</th><th>mAP50-95</th><th>速度(A100)</th><th>参数量</th><th>FLOPs</th></tr></thead><tbody><tr><td>YOLOv8n</td><td>37.3</td><td>0.99ms</td><td>3.2M</td><td>8.7G</td></tr><tr><td>YOLOv8s</td><td>44.9</td><td>1.20ms</td><td>11.2M</td><td>28.6G</td></tr><tr><td>YOLOv8m</td><td>50.2</td><td>1.83ms</td><td>25.9M</td><td>78.9G</td></tr><tr><td>YOLOv8l</td><td>52.9</td><td>2.39ms</td><td>43.7M</td><td>165.2G</td></tr><tr><td>YOLOv8x</td><td>53.9</td><td>3.53ms</td><td>68.2M</td><td>257.8G</td></tr></tbody></table><p><strong>Segmentation Models</strong>：</p><ul><li>YOLOv8n-seg: 36.7 mAP (box), 30.5 mAP (mask)</li><li>YOLOv8s-seg: 44.6 / 36.8</li><li>YOLOv8m-seg: 49.9 / 40.8</li><li>YOLOv8l-seg: 52.3 / 42.6</li><li>YOLOv8x-seg: 53.4 / 43.4</li></ul><h3 id=944-api设计>9.4.4 API设计<a class=anchor href=#944-api%e8%ae%be%e8%ae%a1>#</a></h3><p><strong>Python API</strong>：简洁直观</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.yaml&#39;</span><span class=p>)</span>  <span class=c1># 从配置构建</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>    <span class=c1># 加载预训练权重</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.yaml&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>  <span class=c1># 组合</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;coco8.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证</span>
</span></span><span class=line><span class=cl><span class=n>metrics</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>val</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s1>&#39;coco8.yaml&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>map</span><span class=p>)</span>    <span class=c1># mAP50-95</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>map50</span><span class=p>)</span>  <span class=c1># mAP50</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;path/to/image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>([</span><span class=s1>&#39;im1.jpg&#39;</span><span class=p>,</span> <span class=s1>&#39;im2.jpg&#39;</span><span class=p>])</span>  <span class=c1># 批量</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;video.mp4&#39;</span><span class=p>)</span>             <span class=c1># 视频</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;onnx&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;engine&#39;</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># TensorRT</span></span></span></code></pre></div><p><strong>CLI命令</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 训练</span>
</span></span><span class=line><span class=cl>yolo detect train <span class=nv>data</span><span class=o>=</span>coco8.yaml <span class=nv>model</span><span class=o>=</span>yolov8n.pt <span class=nv>epochs</span><span class=o>=</span><span class=m>100</span> <span class=nv>imgsz</span><span class=o>=</span><span class=m>640</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证</span>
</span></span><span class=line><span class=cl>yolo detect val <span class=nv>model</span><span class=o>=</span>yolov8n.pt <span class=nv>data</span><span class=o>=</span>coco8.yaml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl>yolo detect predict <span class=nv>model</span><span class=o>=</span>yolov8n.pt <span class=nv>source</span><span class=o>=</span><span class=s1>&#39;image.jpg&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出</span>
</span></span><span class=line><span class=cl>yolo <span class=nb>export</span> <span class=nv>model</span><span class=o>=</span>yolov8n.pt <span class=nv>format</span><span class=o>=</span>onnx</span></span></code></pre></div><h3 id=945-性能特点>9.4.5 性能特点<a class=anchor href=#945-%e6%80%a7%e8%83%bd%e7%89%b9%e7%82%b9>#</a></h3><p><strong>优势</strong>：</p><ol><li>精度提升：相比YOLOv5，mAP平均提升2-3%</li><li>速度优化：Anchor-free设计加速后处理</li><li>易用性强：统一API，支持多任务</li><li>部署友好：支持多种导出格式</li><li>文档完善：官方文档详尽</li></ol><p><strong>适用场景</strong>：</p><ul><li>实时目标检测</li><li>实例分割任务</li><li>边缘设备部署</li><li>工业质检应用</li><li>智能监控系统</li></ul><hr><h2 id=95-yolov9yolov10yolo11最新进展>9.5 YOLOv9、YOLOv10、YOLO11：最新进展<a class=anchor href=#95-yolov9yolov10yolo11%e6%9c%80%e6%96%b0%e8%bf%9b%e5%b1%95>#</a></h2><h3 id=951-yolov9pgi和gelan>9.5.1 YOLOv9：PGI和GELAN<a class=anchor href=#951-yolov9pgi%e5%92%8cgelan>#</a></h3><p><strong>论文</strong>：YOLOv9: Learning What You Want to Learn Using Programmable Gradient Information (arXiv 2024)<br><strong>作者</strong>：Chien-Yao Wang, I-Hau Yeh, Hong-Yuan Mark Liao<br><strong>发布时间</strong>：2024年2月</p><p>YOLOv9从信息理论角度重新审视深度学习，提出了两项关键创新。</p><h4 id=核心贡献-1>核心贡献<a class=anchor href=#%e6%a0%b8%e5%bf%83%e8%b4%a1%e7%8c%ae-1>#</a></h4><p><strong>1. PGI (Programmable Gradient Information)</strong></p><p><strong>问题</strong>：深度网络中的信息瓶颈</p><ul><li>随着网络加深，信息逐渐丢失</li><li>梯度消失/爆炸问题</li><li>可靠性降低</li></ul><p><strong>解决方案</strong>：PGI机制</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>主分支：用于推理
</span></span><span class=line><span class=cl>辅助分支：提供完整梯度信息（仅训练时）</span></span></code></pre></div><p><strong>原理</strong>：</p><ul><li>使用可逆函数（Reversible Functions）保证信息完整性</li><li>辅助分支生成可靠的梯度</li><li>主分支学习目标任务</li></ul><p><strong>数学表达</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>X = v_ζ(r_ψ(X))
</span></span><span class=line><span class=cl>其中：
</span></span><span class=line><span class=cl>  r_ψ: 信息转换函数
</span></span><span class=line><span class=cl>  v_ζ: 信息恢复函数
</span></span><span class=line><span class=cl>  确保信息可逆，无损失</span></span></code></pre></div><p><strong>2. GELAN (Generalized Efficient Layer Aggregation Network)</strong></p><p>GELAN是一种通用的高效网络架构：</p><p><strong>特点</strong>：</p><ul><li>轻量级设计</li><li>灵活的模块组合</li><li>优秀的参数利用率</li><li>高效的计算性能</li></ul><p><strong>架构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Input
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>GELAN Block 1 ─┐
</span></span><span class=line><span class=cl>↓              │
</span></span><span class=line><span class=cl>GELAN Block 2 ─┤ Concatenation
</span></span><span class=line><span class=cl>↓              │
</span></span><span class=line><span class=cl>GELAN Block 3 ─┘
</span></span><span class=line><span class=cl>↓
</span></span><span class=line><span class=cl>Output</span></span></code></pre></div><p><strong>与CSP的区别</strong>：</p><ul><li>CSP：将特征图分成两部分</li><li>GELAN：所有分支都参与计算，然后聚合</li></ul><h4 id=模型变体>模型变体<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e5%8f%98%e4%bd%93>#</a></h4><table><thead><tr><th>模型</th><th>mAP50-95</th><th>参数量</th><th>FLOPs</th></tr></thead><tbody><tr><td>YOLOv9t</td><td>38.3</td><td>2.0M</td><td>7.7G</td></tr><tr><td>YOLOv9s</td><td>46.8</td><td>7.2M</td><td>26.7G</td></tr><tr><td>YOLOv9m</td><td>51.4</td><td>20.1M</td><td>76.8G</td></tr><tr><td>YOLOv9c</td><td>53.0</td><td>25.5M</td><td>102.8G</td></tr><tr><td>YOLOv9e</td><td>55.6</td><td>58.1M</td><td>192.5G</td></tr></tbody></table><h4 id=性能对比>性能对比<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%af%b9%e6%af%94>#</a></h4><p><strong>vs YOLOv7</strong>：</p><ul><li>YOLOv9c: 参数量少42%，计算量少21%，精度相当</li></ul><p><strong>vs YOLOv8</strong>：</p><ul><li>YOLOv9e: 参数量少15%，计算量少25%，mAP提升1.7%</li></ul><p><strong>vs YOLO MS-S</strong>：</p><ul><li>YOLOv9s: 参数和计算量更少，AP提升0.4-0.6%</li></ul><h4 id=使用示例>使用示例<a class=anchor href=#%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载YOLOv9模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov9c.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练（注意：需要更多资源和时间）</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;coco8.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>=</span><span class=mi>16</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;onnx&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>注意事项</strong>：</p><ul><li>YOLOv9训练需要更多资源</li><li>训练时间比YOLOv8更长</li><li>但推理性能更优</li></ul><h3 id=952-yolov10nms-free端到端检测>9.5.2 YOLOv10：NMS-Free端到端检测<a class=anchor href=#952-yolov10nms-free%e7%ab%af%e5%88%b0%e7%ab%af%e6%a3%80%e6%b5%8b>#</a></h3><p><strong>论文</strong>：YOLOv10: Real-Time End-to-End Object Detection (arXiv 2024)<br><strong>作者</strong>：Ao Wang et al. (清华大学)<br><strong>发布时间</strong>：2024年5月</p><p>YOLOv10的最大突破：<strong>消除NMS（Non-Maximum Suppression）</strong></p><h4 id=核心创新-2>核心创新<a class=anchor href=#%e6%a0%b8%e5%bf%83%e5%88%9b%e6%96%b0-2>#</a></h4><p><strong>1. NMS-Free Training</strong></p><p>传统YOLO流程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>网络输出 → 生成大量候选框 → NMS筛选 → 最终结果</span></span></code></pre></div><p>YOLOv10流程：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>网络输出 → 直接得到最终结果（每个物体一个框）</span></span></code></pre></div><p><strong>实现方式：Consistent Dual Assignments</strong></p><ul><li><strong>One-to-Many分支</strong>：训练时使用，提供丰富监督信号</li><li><strong>One-to-One分支</strong>：推理时使用，每个物体对应一个预测</li></ul><p><strong>2. 效率与精度优化</strong></p><p><strong>Efficiency Optimizations</strong>：</p><p>a) <strong>Lightweight Classification Head</strong></p><ul><li>使用深度可分离卷积（Depthwise Separable Conv）</li><li>减少分类头的计算量</li></ul><p>b) <strong>Spatial-Channel Decoupled Downsampling</strong></p><ul><li>空间下采样和通道变换解耦</li><li>减少信息损失</li></ul><p>c) <strong>Rank-Guided Block Design</strong></p><ul><li>根据特征的"内在冗余度"调整架构</li><li>在不同stage使用不同复杂度的block</li></ul><p><strong>Accuracy Enhancements</strong>：</p><p>a) <strong>Large-Kernel Convolutions</strong></p><ul><li>使用大核卷积（7x7）</li><li>扩大感受野</li></ul><p>b) <strong>Partial Self-Attention (PSA)</strong></p><ul><li>仅在部分特征上使用自注意力</li><li>平衡性能和计算成本</li></ul><h4 id=模型变体-1>模型变体<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e5%8f%98%e4%bd%93-1>#</a></h4><p>YOLOv10提供6个变体，针对不同应用场景：</p><table><thead><tr><th>模型</th><th>mAP50-95</th><th>延迟(T4)</th><th>参数量</th><th>FLOPs</th></tr></thead><tbody><tr><td>YOLOv10-N</td><td>38.5</td><td>1.84ms</td><td>2.3M</td><td>6.7G</td></tr><tr><td>YOLOv10-S</td><td>46.3</td><td>2.49ms</td><td>7.2M</td><td>21.6G</td></tr><tr><td>YOLOv10-M</td><td>51.1</td><td>4.74ms</td><td>15.4M</td><td>59.1G</td></tr><tr><td>YOLOv10-B</td><td>52.5</td><td>5.74ms</td><td>19.1M</td><td>92.0G</td></tr><tr><td>YOLOv10-L</td><td>53.2</td><td>7.28ms</td><td>24.4M</td><td>120.3G</td></tr><tr><td>YOLOv10-X</td><td>54.4</td><td>10.70ms</td><td>29.5M</td><td>160.4G</td></tr></tbody></table><h4 id=性能亮点>性能亮点<a class=anchor href=#%e6%80%a7%e8%83%bd%e4%ba%ae%e7%82%b9>#</a></h4><p><strong>速度对比</strong>：</p><ul><li>YOLOv10-S 比 RT-DETR-R18 快1.8倍，精度相当</li><li>YOLOv10-B 比 YOLOv9-C 延迟降低46%，参数少25%，精度相当</li></ul><p><strong>NMS-Free的优势</strong>：</p><ul><li>推理延迟降低（无需NMS后处理）</li><li>端到端可优化</li><li>更稳定的输出</li></ul><h4 id=使用示例-1>使用示例<a class=anchor href=#%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b-1>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载YOLOv10模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov10n.pt&#39;</span><span class=p>)</span>  <span class=c1># 或 s/m/b/l/x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理（无需NMS后处理）</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;coco8.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出（部分格式支持）</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;onnx&#39;</span><span class=p>)</span>  <span class=c1># ✅</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;engine&#39;</span><span class=p>)</span>  <span class=c1># ✅ TensorRT</span>
</span></span><span class=line><span class=cl><span class=c1># 注意：NCNN导出可能有限制</span></span></span></code></pre></div><h3 id=953-yolo11当前最优方案>9.5.3 YOLO11：当前最优方案<a class=anchor href=#953-yolo11%e5%bd%93%e5%89%8d%e6%9c%80%e4%bc%98%e6%96%b9%e6%a1%88>#</a></h3><p><strong>发布时间</strong>：2024年9月<br><strong>开发者</strong>：Ultralytics<br><strong>版本号</strong>：YOLO11（也称YOLOv11）</p><p>YOLO11是Ultralytics的最新旗舰模型，在YOLOv8基础上进一步优化。</p><h4 id=核心改进-1>核心改进<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%94%b9%e8%bf%9b-1>#</a></h4><p><strong>1. 增强的架构设计</strong></p><ul><li>改进的Backbone和Neck结构</li><li>更好的特征提取能力</li><li>优化的特征融合机制</li></ul><p><strong>2. 参数效率提升</strong></p><p>相比YOLOv8m：</p><ul><li><strong>参数量减少22%</strong></li><li><strong>mAP反而提高</strong></li><li>计算效率更优</li></ul><p><strong>3. 优化的训练流程</strong></p><ul><li>更快的训练收敛</li><li>改进的数据增强策略</li><li>优化的损失函数</li></ul><h4 id=模型性能>模型性能<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e6%80%a7%e8%83%bd>#</a></h4><p><strong>Detection (COCO val2017)</strong>：</p><table><thead><tr><th>模型</th><th>mAP50-95</th><th>速度(T4)</th><th>参数量</th><th>FLOPs</th></tr></thead><tbody><tr><td>YOLO11n</td><td>39.5</td><td>1.5ms</td><td>2.6M</td><td>6.5G</td></tr><tr><td>YOLO11s</td><td>47.0</td><td>2.5ms</td><td>9.4M</td><td>21.5G</td></tr><tr><td>YOLO11m</td><td>51.5</td><td>4.7ms</td><td>20.1M</td><td>68.0G</td></tr><tr><td>YOLO11l</td><td>53.4</td><td>6.2ms</td><td>25.3M</td><td>86.9G</td></tr><tr><td>YOLO11x</td><td>54.7</td><td>11.3ms</td><td>56.9M</td><td>194.9G</td></tr></tbody></table><p><strong>关键指标对比（YOLO11m vs YOLOv8m）</strong>：</p><ul><li>mAP: 51.5 vs 50.2 (+1.3%)</li><li>参数量: 20.1M vs 25.9M (-22%)</li><li>FLOPs: 68.0G vs 78.9G (-14%)</li></ul><h4 id=多任务支持>多任务支持<a class=anchor href=#%e5%a4%9a%e4%bb%bb%e5%8a%a1%e6%94%af%e6%8c%81>#</a></h4><p>YOLO11同样支持多种任务：</p><p><strong>1. Detection</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolo11n.pt&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>2. Segmentation</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolo11n-seg.pt&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>3. Classification</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolo11n-cls.pt&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>4. Pose Estimation</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolo11n-pose.pt&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>5. Oriented Bounding Boxes</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolo11n-obb.pt&#39;</span><span class=p>)</span></span></span></code></pre></div><h4 id=使用示例-2>使用示例<a class=anchor href=#%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b-2>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载YOLO11模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolo11n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;coco8.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span><span class=o>=</span><span class=mi>0</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证</span>
</span></span><span class=line><span class=cl><span class=n>metrics</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>val</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s1>&#39;coco8.yaml&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;video.mp4&#39;</span><span class=p>)</span>  <span class=c1># 视频</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;onnx&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;engine&#39;</span><span class=p>)</span>  <span class=c1># TensorRT</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;coreml&#39;</span><span class=p>)</span>  <span class=c1># CoreML</span></span></span></code></pre></div><h4 id=适用场景>适用场景<a class=anchor href=#%e9%80%82%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h4><ul><li><strong>边缘设备</strong>：YOLO11n/s参数少，适合移动端</li><li><strong>云端部署</strong>：YOLO11m/l平衡性能</li><li><strong>高精度需求</strong>：YOLO11x最高精度</li><li><strong>实时应用</strong>：所有变体都支持实时推理</li></ul><hr><h2 id=96-yolo-world开放词汇检测>9.6 YOLO-World：开放词汇检测<a class=anchor href=#96-yolo-world%e5%bc%80%e6%94%be%e8%af%8d%e6%b1%87%e6%a3%80%e6%b5%8b>#</a></h2><p><strong>论文</strong>：YOLO-World: Real-Time Open-Vocabulary Object Detection<br><strong>开发者</strong>：Tencent AI Lab & Ultralytics<br><strong>发布时间</strong>：2024年</p><p>YOLO-World代表了目标检测的新方向：<strong>开放词汇检测（Open-Vocabulary Detection）</strong></p><h3 id=961-什么是开放词汇检测>9.6.1 什么是开放词汇检测？<a class=anchor href=#961-%e4%bb%80%e4%b9%88%e6%98%af%e5%bc%80%e6%94%be%e8%af%8d%e6%b1%87%e6%a3%80%e6%b5%8b>#</a></h3><p><strong>传统检测</strong>：</p><ul><li>只能检测训练时见过的类别</li><li>例如：COCO的80个类别</li></ul><p><strong>开放词汇检测</strong>：</p><ul><li>可以检测任意文本描述的物体</li><li>无需重新训练</li><li>零样本检测能力</li></ul><p><strong>示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 传统YOLO：只能检测预定义类别</span>
</span></span><span class=line><span class=cl><span class=n>classes</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;person&#39;</span><span class=p>,</span> <span class=s1>&#39;car&#39;</span><span class=p>,</span> <span class=s1>&#39;dog&#39;</span><span class=p>]</span>  <span class=c1># 训练时固定</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># YOLO-World：可以检测任意物体</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;laptop&#39;</span><span class=p>,</span> <span class=s1>&#39;coffee mug&#39;</span><span class=p>,</span> <span class=s1>&#39;smartphone&#39;</span><span class=p>])</span>  <span class=c1># 动态设置</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;red car&#39;</span><span class=p>,</span> <span class=s1>&#39;person wearing hat&#39;</span><span class=p>])</span>  <span class=c1># 支持描述性文本</span></span></span></code></pre></div><h3 id=962-核心技术>9.6.2 核心技术<a class=anchor href=#962-%e6%a0%b8%e5%bf%83%e6%8a%80%e6%9c%af>#</a></h3><p><strong>1. Vision-Language Pre-training</strong></p><p>YOLO-World基于视觉-语言预训练：</p><ul><li>使用大规模图像-文本对数据集</li><li>学习视觉和语言的联合表示</li><li>支持zero-shot推理</li></ul><p><strong>2. Re-parameterizable Vision-Language Path Aggregation Network (RepVL-PAN)</strong></p><p>融合视觉和语言特征：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像特征 ──┐
</span></span><span class=line><span class=cl>           ├─ RepVL-PAN ─→ 检测结果
</span></span><span class=line><span class=cl>文本特征 ──┘</span></span></code></pre></div><p><strong>3. Region-Text Contrastive Loss</strong></p><p>对比学习损失：</p><ul><li>正样本：匹配的区域和文本</li><li>负样本：不匹配的区域和文本</li><li>学习区域-文本对齐</li></ul><h3 id=963-模型变体>9.6.3 模型变体<a class=anchor href=#963-%e6%a8%a1%e5%9e%8b%e5%8f%98%e4%bd%93>#</a></h3><table><thead><tr><th>模型</th><th>Zero-Shot AP</th><th>参数量</th><th>特点</th></tr></thead><tbody><tr><td>YOLO-World-S</td><td>35.4</td><td>13.4M</td><td>轻量级</td></tr><tr><td>YOLO-World-M</td><td>43.0</td><td>34.3M</td><td>平衡</td></tr><tr><td>YOLO-World-L</td><td>45.7</td><td>59.5M</td><td>高精度</td></tr></tbody></table><p><strong>v2版本</strong>：</p><ul><li><code>yolov8s-worldv2.pt</code>：支持训练和导出</li><li><code>yolov8m-worldv2.pt</code>：推荐用于自定义训练</li><li><code>yolov8l-worldv2.pt</code>：最高精度</li></ul><h3 id=964-使用示例>9.6.4 使用示例<a class=anchor href=#964-%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b>#</a></h3><p><strong>1. 基础使用</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLOWorld</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载预训练模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLOWorld</span><span class=p>(</span><span class=s1>&#39;yolov8s-world.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置自定义类别</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;person&#39;</span><span class=p>,</span> <span class=s1>&#39;bus&#39;</span><span class=p>,</span> <span class=s1>&#39;car&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div><p><strong>2. 动态切换类别</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 场景1：检测交通工具</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;car&#39;</span><span class=p>,</span> <span class=s1>&#39;bus&#39;</span><span class=p>,</span> <span class=s1>&#39;truck&#39;</span><span class=p>,</span> <span class=s1>&#39;bicycle&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;traffic.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 场景2：检测动物</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;dog&#39;</span><span class=p>,</span> <span class=s1>&#39;cat&#39;</span><span class=p>,</span> <span class=s1>&#39;bird&#39;</span><span class=p>,</span> <span class=s1>&#39;horse&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;animals.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 场景3：检测办公用品</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;laptop&#39;</span><span class=p>,</span> <span class=s1>&#39;mouse&#39;</span><span class=p>,</span> <span class=s1>&#39;keyboard&#39;</span><span class=p>,</span> <span class=s1>&#39;monitor&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;office.jpg&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>3. 保存自定义模型</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 设置类别后保存</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_classes</span><span class=p>([</span><span class=s1>&#39;person&#39;</span><span class=p>,</span> <span class=s1>&#39;car&#39;</span><span class=p>,</span> <span class=s1>&#39;dog&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s1>&#39;custom_yolov8s_world.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 之后可以直接加载</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLOWorld</span><span class=p>(</span><span class=s1>&#39;custom_yolov8s_world.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>  <span class=c1># 使用保存的类别</span></span></span></code></pre></div><p><strong>4. 训练自定义数据</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLOWorld</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用worldv2模型（支持训练）</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLOWorld</span><span class=p>(</span><span class=s1>&#39;yolov8s-worldv2.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在自定义数据上训练</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;custom_data.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;onnx&#39;</span><span class=p>)</span>  <span class=c1># worldv2支持导出</span></span></span></code></pre></div><h3 id=965-应用场景>9.6.5 应用场景<a class=anchor href=#965-%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h3><p><strong>1. 零样本检测</strong></p><ul><li>检测罕见物体</li><li>无需收集训练数据</li></ul><p><strong>2. 快速原型开发</strong></p><ul><li>快速验证想法</li><li>无需训练模型</li></ul><p><strong>3. 多场景应用</strong></p><ul><li>同一模型适应不同场景</li><li>动态调整检测类别</li></ul><p><strong>4. 长尾类别检测</strong></p><ul><li>处理训练数据不足的类别</li><li>利用预训练知识</li></ul><h3 id=966-性能特点>9.6.6 性能特点<a class=anchor href=#966-%e6%80%a7%e8%83%bd%e7%89%b9%e7%82%b9>#</a></h3><p><strong>优势</strong>：</p><ul><li>零样本检测能力</li><li>灵活的类别设置</li><li>实时推理速度</li><li>无需重新训练</li></ul><p><strong>局限</strong>：</p><ul><li>精度略低于专用检测器</li><li>对描述性文本的理解有限</li><li>需要合适的类别描述</li></ul><p><strong>vs 传统YOLO</strong>：</p><ul><li>传统YOLO：固定类别，精度高</li><li>YOLO-World：开放类别，灵活性强</li></ul><hr><h2 id=97-yolo系列总结与展望>9.7 YOLO系列总结与展望<a class=anchor href=#97-yolo%e7%b3%bb%e5%88%97%e6%80%bb%e7%bb%93%e4%b8%8e%e5%b1%95%e6%9c%9b>#</a></h2><h3 id=971-演进时间线>9.7.1 演进时间线<a class=anchor href=#971-%e6%bc%94%e8%bf%9b%e6%97%b6%e9%97%b4%e7%ba%bf>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2016    YOLOv1      开创单阶段检测
</span></span><span class=line><span class=cl>         ↓
</span></span><span class=line><span class=cl>2017    YOLOv2      Anchor + 多尺度
</span></span><span class=line><span class=cl>         ↓
</span></span><span class=line><span class=cl>2018    YOLOv3      多尺度预测 + Darknet-53
</span></span><span class=line><span class=cl>         ↓
</span></span><span class=line><span class=cl>2020    YOLOv4      Bag of Freebies/Specials
</span></span><span class=line><span class=cl>        YOLOv5      工程化实现
</span></span><span class=line><span class=cl>         ↓
</span></span><span class=line><span class=cl>2022    YOLOv6      工业优化
</span></span><span class=line><span class=cl>        YOLOv7      Trainable BoF
</span></span><span class=line><span class=cl>         ↓
</span></span><span class=line><span class=cl>2023    YOLOv8      Anchor-free + 多任务
</span></span><span class=line><span class=cl>         ↓
</span></span><span class=line><span class=cl>2024    YOLOv9      PGI + GELAN
</span></span><span class=line><span class=cl>        YOLOv10     NMS-free
</span></span><span class=line><span class=cl>        YOLO11      当前最优
</span></span><span class=line><span class=cl>        YOLO-World  开放词汇</span></span></code></pre></div><h3 id=972-技术趋势>9.7.2 技术趋势<a class=anchor href=#972-%e6%8a%80%e6%9c%af%e8%b6%8b%e5%8a%bf>#</a></h3><p><strong>1. Anchor-Free成为主流</strong></p><ul><li>YOLOv1: 直接预测</li><li>YOLOv2-v7: Anchor-based</li><li>YOLOv8+: Anchor-free</li></ul><p><strong>2. 端到端优化</strong></p><ul><li>YOLOv10: 消除NMS</li><li>未来: 完全端到端可微</li></ul><p><strong>3. 多任务统一</strong></p><ul><li>检测、分割、分类、姿态估计</li><li>统一框架，降低学习成本</li></ul><p><strong>4. 开放词汇能力</strong></p><ul><li>YOLO-World: 零样本检测</li><li>与大模型结合</li></ul><h3 id=973-版本选择建议>9.7.3 版本选择建议<a class=anchor href=#973-%e7%89%88%e6%9c%ac%e9%80%89%e6%8b%a9%e5%bb%ba%e8%ae%ae>#</a></h3><p><strong>项目需求导向</strong>：</p><table><thead><tr><th>需求</th><th>推荐版本</th><th>理由</th></tr></thead><tbody><tr><td>工业部署</td><td>YOLOv8/YOLO11</td><td>稳定、文档完善</td></tr><tr><td>最高精度</td><td>YOLO11x/YOLOv9e</td><td>SOTA性能</td></tr><tr><td>边缘设备</td><td>YOLO11n/YOLOv8n</td><td>轻量级</td></tr><tr><td>学术研究</td><td>YOLOv9/v10</td><td>创新技术</td></tr><tr><td>零样本检测</td><td>YOLO-World</td><td>开放词汇</td></tr><tr><td>快速原型</td><td>YOLOv8</td><td>易用性强</td></tr></tbody></table><p><strong>学习路径建议</strong>：</p><ol><li><strong>入门</strong>：从YOLOv8开始，API简洁，文档丰富</li><li><strong>进阶</strong>：学习YOLO11，了解最新优化</li><li><strong>研究</strong>：深入YOLOv9/v10的创新技术</li><li><strong>探索</strong>：尝试YOLO-World的开放词汇能力</li></ol><h3 id=974-未来展望>9.7.4 未来展望<a class=anchor href=#974-%e6%9c%aa%e6%9d%a5%e5%b1%95%e6%9c%9b>#</a></h3><p><strong>技术方向</strong>：</p><ol><li>与大模型深度融合</li><li>更强的零样本/少样本能力</li><li>端到端全流程优化</li><li>更高效的架构设计</li></ol><p><strong>应用拓展</strong>：</p><ol><li>3D目标检测</li><li>视频理解</li><li>多模态融合</li><li>边缘智能</li></ol><hr><h2 id=本章小结-1>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93-1>#</a></h2><p>本章系统学习了YOLO系列从v1到v11的完整演进：</p><p><strong>核心里程碑</strong>：</p><ul><li>YOLOv1：开创单阶段检测范式</li><li>YOLOv3：多尺度预测成为标准</li><li>YOLOv5：工程化降低使用门槛</li><li>YOLOv8：Anchor-free + 多任务统一</li><li>YOLO11：参数效率与性能的最优平衡</li><li>YOLO-World：开启开放词汇时代</li></ul><p><strong>技术演进脉络</strong>：</p><ol><li>检测范式：Anchor → Anchor-free → End-to-end</li><li>架构设计：Darknet → CSP → C2f → GELAN</li><li>训练策略：基础增强 → BoF/BoS → PGI</li><li>应用范围：单一检测 → 多任务 → 开放词汇</li></ol><p><strong>下一步</strong>：
完成理论学习后，让我们在<a href=../chapter10/README.md>第10章</a>动手实践，用YOLOv8/YOLO11构建实际项目！</p><hr><p><strong>参考资源</strong>：</p><ul><li><a href=https://docs.ultralytics.com/>Ultralytics官方文档</a></li><li><a href=https://github.com/ultralytics/ultralytics#documentation>YOLO论文合集</a></li><li><a href=https://github.com/ultralytics/ultralytics>YOLO GitHub仓库</a></li></ul><hr><h1 id=第10章yolo实战项目>第10章：YOLO实战项目<a class=anchor href=#%e7%ac%ac10%e7%ab%a0yolo%e5%ae%9e%e6%88%98%e9%a1%b9%e7%9b%ae>#</a></h1><blockquote class=book-hint><p><strong>实战核心</strong> - 从零开始，掌握YOLO的完整应用流程</p></blockquote><h2 id=本章概览-2>本章概览<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%a7%88-2>#</a></h2><p>本章将通过完整的实战项目，学习如何使用YOLOv8/YOLO11解决实际的目标检测问题。我们将覆盖从环境配置到模型部署的完整流程。</p><p><strong>学习目标</strong>：</p><ul><li>掌握YOLO的完整使用流程</li><li>能够在自定义数据集上训练模型</li><li>理解模型优化和部署技巧</li><li>构建实用的检测系统</li></ul><p><strong>实战项目</strong>：</p><ol><li>使用预训练模型进行检测</li><li>准备自定义数据集并训练</li><li>模型导出和性能优化</li><li>构建实时检测系统</li></ol><hr><h2 id=101-yolov8快速上手>10.1 YOLOv8快速上手<a class=anchor href=#101-yolov8%e5%bf%ab%e9%80%9f%e4%b8%8a%e6%89%8b>#</a></h2><h3 id=1011-环境配置>10.1.1 环境配置<a class=anchor href=#1011-%e7%8e%af%e5%a2%83%e9%85%8d%e7%bd%ae>#</a></h3><p><strong>系统要求</strong>：</p><ul><li>Python >= 3.8</li><li>PyTorch >= 1.8</li><li>CUDA >= 11.0 (GPU加速,可选)</li></ul><p><strong>安装ultralytics库</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 方式1：使用pip（推荐）</span>
</span></span><span class=line><span class=cl>pip install ultralytics
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方式2：从源码安装（获取最新功能）</span>
</span></span><span class=line><span class=cl>git clone https://github.com/ultralytics/ultralytics.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> ultralytics
</span></span><span class=line><span class=cl>pip install -e .
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证安装</span>
</span></span><span class=line><span class=cl>yolo version</span></span></code></pre></div><p><strong>依赖检查</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># check_environment.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;PyTorch版本: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CUDA可用: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CUDA版本: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GPU设备: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试YOLO</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;✅ Ultralytics YOLO安装成功！&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1012-预训练模型使用>10.1.2 预训练模型使用<a class=anchor href=#1012-%e9%a2%84%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b%e4%bd%bf%e7%94%a8>#</a></h3><p><strong>可用的预训练模型</strong>：</p><table><thead><tr><th>模型</th><th>任务</th><th>预训练数据集</th></tr></thead><tbody><tr><td>yolov8n.pt</td><td>检测</td><td>COCO</td></tr><tr><td>yolov8s.pt</td><td>检测</td><td>COCO</td></tr><tr><td>yolov8m.pt</td><td>检测</td><td>COCO</td></tr><tr><td>yolov8l.pt</td><td>检测</td><td>COCO</td></tr><tr><td>yolov8x.pt</td><td>检测</td><td>COCO</td></tr><tr><td>yolov8n-seg.pt</td><td>分割</td><td>COCO</td></tr><tr><td>yolov8n-pose.pt</td><td>姿态</td><td>COCO-Pose</td></tr><tr><td>yolov8n-cls.pt</td><td>分类</td><td>ImageNet</td></tr><tr><td>yolov8n-obb.pt</td><td>旋转框</td><td>DOTAv1</td></tr></tbody></table><p><strong>基础推理示例</strong>：</p><p>参见代码文件：<a href=../../chapter29/code/chapter10_yolo_practice/yolov8_quickstart.py><code>code/chapter10_yolo_practice/yolov8_quickstart.py</code></a></p><h3 id=1013-理解检测结果>10.1.3 理解检测结果<a class=anchor href=#1013-%e7%90%86%e8%a7%a3%e6%a3%80%e6%b5%8b%e7%bb%93%e6%9e%9c>#</a></h3><p><strong>Results对象结构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Results是一个列表，每张图像对应一个Result对象</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>results</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 主要属性</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>boxes</span><span class=p>)</span>      <span class=c1># 边界框信息</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>masks</span><span class=p>)</span>      <span class=c1># 分割掩码（如果是分割任务）</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>keypoints</span><span class=p>)</span>  <span class=c1># 关键点（如果是姿态任务）</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>probs</span><span class=p>)</span>      <span class=c1># 分类概率（如果是分类任务）</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>orig_img</span><span class=p>)</span>   <span class=c1># 原始图像</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=o>.</span><span class=n>path</span><span class=p>)</span>       <span class=c1># 图像路径</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Boxes对象</span>
</span></span><span class=line><span class=cl><span class=n>boxes</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>boxes</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>boxes</span><span class=o>.</span><span class=n>xyxy</span><span class=p>)</span>        <span class=c1># 坐标格式: [x1, y1, x2, y2]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>boxes</span><span class=o>.</span><span class=n>xywh</span><span class=p>)</span>        <span class=c1># 坐标格式: [x_center, y_center, width, height]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>boxes</span><span class=o>.</span><span class=n>conf</span><span class=p>)</span>        <span class=c1># 置信度</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>boxes</span><span class=o>.</span><span class=n>cls</span><span class=p>)</span>         <span class=c1># 类别ID</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>boxes</span><span class=o>.</span><span class=n>data</span><span class=p>)</span>        <span class=c1># 完整数据 [x1, y1, x2, y2, conf, cls]</span></span></span></code></pre></div><p><strong>可视化和保存</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 方法1：直接显示</span>
</span></span><span class=line><span class=cl><span class=n>result</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方法2：保存到文件</span>
</span></span><span class=line><span class=cl><span class=n>result</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s1>&#39;result.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方法3：自定义绘制</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>orig_img</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>box</span> <span class=ow>in</span> <span class=n>result</span><span class=o>.</span><span class=n>boxes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=n>x2</span><span class=p>,</span> <span class=n>y2</span> <span class=o>=</span> <span class=n>box</span><span class=o>.</span><span class=n>xyxy</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>conf</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>box</span><span class=o>.</span><span class=n>conf</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=bp>cls</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>box</span><span class=o>.</span><span class=n>cls</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 绘制边界框</span>
</span></span><span class=line><span class=cl>    <span class=n>cv2</span><span class=o>.</span><span class=n>rectangle</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>),</span> <span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>),</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 绘制标签</span>
</span></span><span class=line><span class=cl>    <span class=n>label</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>model</span><span class=o>.</span><span class=n>names</span><span class=p>[</span><span class=bp>cls</span><span class=p>]</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>conf</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>cv2</span><span class=o>.</span><span class=n>putText</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=n>label</span><span class=p>,</span> <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=o>-</span><span class=mi>10</span><span class=p>),</span> 
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>FONT_HERSHEY_SIMPLEX</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>cv2</span><span class=o>.</span><span class=n>imwrite</span><span class=p>(</span><span class=s1>&#39;custom_result.jpg&#39;</span><span class=p>,</span> <span class=n>img</span><span class=p>)</span></span></span></code></pre></div><h3 id=1014-不同输入源的推理>10.1.4 不同输入源的推理<a class=anchor href=#1014-%e4%b8%8d%e5%90%8c%e8%be%93%e5%85%a5%e6%ba%90%e7%9a%84%e6%8e%a8%e7%90%86>#</a></h3><p><strong>图像推理</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 单张图像</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 多张图像</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>([</span><span class=s1>&#39;img1.jpg&#39;</span><span class=p>,</span> <span class=s1>&#39;img2.jpg&#39;</span><span class=p>,</span> <span class=s1>&#39;img3.jpg&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 文件夹</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;images/&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># URL</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;https://ultralytics.com/images/bus.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># NumPy数组</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># PIL Image</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>img</span><span class=p>)</span></span></span></code></pre></div><p><strong>视频推理</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 视频文件</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;video.mp4&#39;</span><span class=p>,</span> <span class=n>stream</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>result</span> <span class=ow>in</span> <span class=n>results</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>  <span class=c1># 实时显示</span>
</span></span><span class=line><span class=cl>    <span class=c1># 或保存帧</span>
</span></span><span class=line><span class=cl>    <span class=c1># result.save(f&#39;frame_{result.frame}.jpg&#39;)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 摄像头</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>stream</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>  <span class=c1># 0是默认摄像头</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>result</span> <span class=ow>in</span> <span class=n>results</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>cv2</span><span class=o>.</span><span class=n>waitKey</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=mh>0xFF</span> <span class=o>==</span> <span class=nb>ord</span><span class=p>(</span><span class=s1>&#39;q&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>break</span></span></span></code></pre></div><p><strong>批量推理</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 批量处理以提高速度</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>([</span><span class=s1>&#39;img1.jpg&#39;</span><span class=p>,</span> <span class=s1>&#39;img2.jpg&#39;</span><span class=p>],</span> <span class=n>batch</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 调整推理参数</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;image.jpg&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>conf</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span>        <span class=c1># 置信度阈值</span>
</span></span><span class=line><span class=cl>    <span class=n>iou</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>         <span class=c1># NMS的IoU阈值</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span>       <span class=c1># 图像尺寸</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>        <span class=c1># GPU设备</span>
</span></span><span class=line><span class=cl>    <span class=n>half</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>       <span class=c1># 使用FP16</span>
</span></span><span class=line><span class=cl>    <span class=n>max_det</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>     <span class=c1># 最大检测数</span>
</span></span><span class=line><span class=cl>    <span class=n>classes</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>],</span>  <span class=c1># 只检测特定类别（person, car）</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><hr><h2 id=102-自定义数据集训练>10.2 自定义数据集训练<a class=anchor href=#102-%e8%87%aa%e5%ae%9a%e4%b9%89%e6%95%b0%e6%8d%ae%e9%9b%86%e8%ae%ad%e7%bb%83>#</a></h2><h3 id=1021-数据集准备>10.2.1 数据集准备<a class=anchor href=#1021-%e6%95%b0%e6%8d%ae%e9%9b%86%e5%87%86%e5%a4%87>#</a></h3><p><strong>目录结构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>my_dataset/
</span></span><span class=line><span class=cl>├── images/
</span></span><span class=line><span class=cl>│   ├── train/
</span></span><span class=line><span class=cl>│   │   ├── img1.jpg
</span></span><span class=line><span class=cl>│   │   ├── img2.jpg
</span></span><span class=line><span class=cl>│   │   └── ...
</span></span><span class=line><span class=cl>│   ├── val/
</span></span><span class=line><span class=cl>│   │   ├── img3.jpg
</span></span><span class=line><span class=cl>│   │   └── ...
</span></span><span class=line><span class=cl>│   └── test/  (可选)
</span></span><span class=line><span class=cl>│       └── ...
</span></span><span class=line><span class=cl>├── labels/
</span></span><span class=line><span class=cl>│   ├── train/
</span></span><span class=line><span class=cl>│   │   ├── img1.txt
</span></span><span class=line><span class=cl>│   │   ├── img2.txt
</span></span><span class=line><span class=cl>│   │   └── ...
</span></span><span class=line><span class=cl>│   └── val/
</span></span><span class=line><span class=cl>│       ├── img3.txt
</span></span><span class=line><span class=cl>│       └── ...
</span></span><span class=line><span class=cl>└── data.yaml</span></span></code></pre></div><p><strong>标注格式</strong> (<code>img1.txt</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl># 每行一个目标: class x_center y_center width height
</span></span><span class=line><span class=cl># 坐标都是归一化的 (0-1之间)
</span></span><span class=line><span class=cl>0 0.5 0.5 0.3 0.4
</span></span><span class=line><span class=cl>1 0.2 0.3 0.1 0.2</span></span></code></pre></div><p><strong>数据集配置文件</strong> (<code>data.yaml</code>):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># 数据集路径（相对或绝对路径）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>path</span><span class=p>:</span><span class=w> </span><span class=l>/path/to/my_dataset </span><span class=w> </span><span class=c># 数据集根目录</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>train</span><span class=p>:</span><span class=w> </span><span class=l>images/train </span><span class=w> </span><span class=c># 训练图像（相对于path）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>val</span><span class=p>:</span><span class=w> </span><span class=l>images/val     </span><span class=w> </span><span class=c># 验证图像（相对于path）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>test</span><span class=p>:</span><span class=w>               </span><span class=c># 测试图像（可选）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># 类别</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>nc</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>  </span><span class=c># 类别数量</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>names</span><span class=p>:</span><span class=w>  </span><span class=c># 类别名称</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>0</span><span class=p>:</span><span class=w> </span><span class=l>class1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>1</span><span class=p>:</span><span class=w> </span><span class=l>class2</span></span></span></code></pre></div><h3 id=1022-数据标注工具>10.2.2 数据标注工具<a class=anchor href=#1022-%e6%95%b0%e6%8d%ae%e6%a0%87%e6%b3%a8%e5%b7%a5%e5%85%b7>#</a></h3><p><strong>推荐工具</strong>：</p><ol><li><p><strong>LabelImg</strong>（最常用）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install labelImg
</span></span><span class=line><span class=cl>labelImg</span></span></code></pre></div><ul><li>输出格式选择YOLO</li><li>自动生成txt文件</li></ul></li><li><p><strong>Roboflow</strong>（在线工具）</p><ul><li>支持协作标注</li><li>自动数据增强</li><li>一键导出YOLO格式</li></ul></li><li><p><strong>CVAT</strong>（功能强大）</p><ul><li>支持多种标注任务</li><li>团队协作</li><li>导出时选择YOLO格式</li></ul></li></ol><p><strong>从COCO格式转换</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics.data.converter</span> <span class=kn>import</span> <span class=n>convert_coco</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 转换COCO标注为YOLO格式</span>
</span></span><span class=line><span class=cl><span class=n>convert_coco</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>labels_dir</span><span class=o>=</span><span class=s1>&#39;path/to/coco/annotations/&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_dir</span><span class=o>=</span><span class=s1>&#39;path/to/yolo/labels/&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>use_segments</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>  <span class=c1># True表示分割任务</span>
</span></span><span class=line><span class=cl>    <span class=n>cls91to80</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># COCO91类到80类的映射</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=1023-数据增强>10.2.3 数据增强<a class=anchor href=#1023-%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba>#</a></h3><p><strong>内置数据增强</strong>（在训练时自动应用）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;data.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># 数据增强参数</span>
</span></span><span class=line><span class=cl>    <span class=n>hsv_h</span><span class=o>=</span><span class=mf>0.015</span><span class=p>,</span>      <span class=c1># HSV色调增强</span>
</span></span><span class=line><span class=cl>    <span class=n>hsv_s</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>        <span class=c1># HSV饱和度</span>
</span></span><span class=line><span class=cl>    <span class=n>hsv_v</span><span class=o>=</span><span class=mf>0.4</span><span class=p>,</span>        <span class=c1># HSV亮度</span>
</span></span><span class=line><span class=cl>    <span class=n>degrees</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>      <span class=c1># 旋转角度</span>
</span></span><span class=line><span class=cl>    <span class=n>translate</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>    <span class=c1># 平移比例</span>
</span></span><span class=line><span class=cl>    <span class=n>scale</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span>        <span class=c1># 缩放比例</span>
</span></span><span class=line><span class=cl>    <span class=n>shear</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>        <span class=c1># 剪切角度</span>
</span></span><span class=line><span class=cl>    <span class=n>perspective</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>  <span class=c1># 透视变换</span>
</span></span><span class=line><span class=cl>    <span class=n>flipud</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>       <span class=c1># 上下翻转概率</span>
</span></span><span class=line><span class=cl>    <span class=n>fliplr</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span>       <span class=c1># 左右翻转概率</span>
</span></span><span class=line><span class=cl>    <span class=n>mosaic</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span>       <span class=c1># Mosaic增强概率</span>
</span></span><span class=line><span class=cl>    <span class=n>mixup</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>        <span class=c1># MixUp增强概率</span>
</span></span><span class=line><span class=cl>    <span class=n>copy_paste</span><span class=o>=</span><span class=mf>0.0</span><span class=p>,</span>   <span class=c1># Copy-Paste增强概率</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>自定义数据增强</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>albumentations</span> <span class=k>as</span> <span class=nn>A</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>albumentations.pytorch</span> <span class=kn>import</span> <span class=n>ToTensorV2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义增强流程</span>
</span></span><span class=line><span class=cl><span class=n>transform</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>RandomBrightnessContrast</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>RandomGamma</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>Blur</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>MedianBlur</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>GaussNoise</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl><span class=p>],</span> <span class=n>bbox_params</span><span class=o>=</span><span class=n>A</span><span class=o>.</span><span class=n>BboxParams</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;yolo&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 应用增强（需要自己写数据加载器）</span></span></span></code></pre></div><h3 id=1024-训练流程>10.2.4 训练流程<a class=anchor href=#1024-%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b>#</a></h3><p><strong>基础训练</strong>：</p><p>参见代码文件：<a href=../../chapter29/code/chapter10_yolo_practice/yolov8_train_custom.py><code>code/chapter10_yolo_practice/yolov8_train_custom.py</code></a></p><p><strong>训练参数详解</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=c1># === 数据相关 ===</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;data.yaml&#39;</span><span class=p>,</span>          <span class=c1># 数据集配置</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>                <span class=c1># 训练轮数</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>                  <span class=c1># 批量大小（-1为自动）</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span>                 <span class=c1># 图像尺寸</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># === 优化器相关 ===</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>,</span>          <span class=c1># 优化器: SGD, Adam, AdamW, auto</span>
</span></span><span class=line><span class=cl>    <span class=n>lr0</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>                  <span class=c1># 初始学习率</span>
</span></span><span class=line><span class=cl>    <span class=n>lrf</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>                  <span class=c1># 最终学习率 (lr0 * lrf)</span>
</span></span><span class=line><span class=cl>    <span class=n>momentum</span><span class=o>=</span><span class=mf>0.937</span><span class=p>,</span>            <span class=c1># SGD动量</span>
</span></span><span class=line><span class=cl>    <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.0005</span><span class=p>,</span>       <span class=c1># 权重衰减</span>
</span></span><span class=line><span class=cl>    <span class=n>warmup_epochs</span><span class=o>=</span><span class=mf>3.0</span><span class=p>,</span>         <span class=c1># 预热轮数</span>
</span></span><span class=line><span class=cl>    <span class=n>warmup_momentum</span><span class=o>=</span><span class=mf>0.8</span><span class=p>,</span>       <span class=c1># 预热动量</span>
</span></span><span class=line><span class=cl>    <span class=n>warmup_bias_lr</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>        <span class=c1># 预热偏置学习率</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># === 模型相关 ===</span>
</span></span><span class=line><span class=cl>    <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>           <span class=c1># 使用预训练权重</span>
</span></span><span class=line><span class=cl>    <span class=n>patience</span><span class=o>=</span><span class=mi>50</span><span class=p>,</span>               <span class=c1># 早停耐心值</span>
</span></span><span class=line><span class=cl>    <span class=n>save</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                 <span class=c1># 保存检查点</span>
</span></span><span class=line><span class=cl>    <span class=n>save_period</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span>            <span class=c1># 每N轮保存一次(-1表示仅最后)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># === 设备相关 ===</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>                  <span class=c1># 设备: 0, [0,1], cpu</span>
</span></span><span class=line><span class=cl>    <span class=n>workers</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>                 <span class=c1># 数据加载线程数</span>
</span></span><span class=line><span class=cl>    <span class=n>amp</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                  <span class=c1># 自动混合精度训练</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># === 验证相关 ===</span>
</span></span><span class=line><span class=cl>    <span class=n>val</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                  <span class=c1># 每轮后验证</span>
</span></span><span class=line><span class=cl>    <span class=n>plots</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>                <span class=c1># 保存训练图表</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># === 其他 ===</span>
</span></span><span class=line><span class=cl>    <span class=n>seed</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>                    <span class=c1># 随机种子</span>
</span></span><span class=line><span class=cl>    <span class=n>deterministic</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>        <span class=c1># 确定性训练</span>
</span></span><span class=line><span class=cl>    <span class=n>single_cls</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>          <span class=c1># 单类训练</span>
</span></span><span class=line><span class=cl>    <span class=n>rect</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>                <span class=c1># 矩形训练</span>
</span></span><span class=line><span class=cl>    <span class=n>cos_lr</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>              <span class=c1># 余弦学习率</span>
</span></span><span class=line><span class=cl>    <span class=n>close_mosaic</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span>           <span class=c1># 最后N轮禁用mosaic</span>
</span></span><span class=line><span class=cl>    <span class=n>resume</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>              <span class=c1># 恢复训练</span>
</span></span><span class=line><span class=cl>    <span class=n>project</span><span class=o>=</span><span class=s1>&#39;runs/detect&#39;</span><span class=p>,</span>     <span class=c1># 项目目录</span>
</span></span><span class=line><span class=cl>    <span class=n>name</span><span class=o>=</span><span class=s1>&#39;exp&#39;</span><span class=p>,</span>                <span class=c1># 实验名称</span>
</span></span><span class=line><span class=cl>    <span class=n>exist_ok</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>            <span class=c1># 覆盖已存在的实验</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>多GPU训练</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 使用所有可用GPU</span>
</span></span><span class=line><span class=cl>yolo detect train <span class=nv>data</span><span class=o>=</span>data.yaml <span class=nv>model</span><span class=o>=</span>yolov8n.pt <span class=nv>epochs</span><span class=o>=</span><span class=m>100</span> <span class=nv>device</span><span class=o>=</span>0,1,2,3
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Python API</span>
</span></span><span class=line><span class=cl>model.train<span class=o>(</span><span class=nv>data</span><span class=o>=</span><span class=s1>&#39;data.yaml&#39;</span>, <span class=nv>device</span><span class=o>=[</span>0, 1, 2, 3<span class=o>])</span></span></span></code></pre></div><p><strong>恢复训练</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 从检查点恢复</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;runs/detect/exp/weights/last.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>resume</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div><h3 id=1025-训练监控>10.2.5 训练监控<a class=anchor href=#1025-%e8%ae%ad%e7%bb%83%e7%9b%91%e6%8e%a7>#</a></h3><p><strong>实时监控</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用回调函数</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics.utils</span> <span class=kn>import</span> <span class=n>callbacks</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>on_train_epoch_end</span><span class=p>(</span><span class=n>trainer</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch </span><span class=si>{</span><span class=n>trainer</span><span class=o>.</span><span class=n>epoch</span><span class=si>}</span><span class=s2>: Loss=</span><span class=si>{</span><span class=n>trainer</span><span class=o>.</span><span class=n>loss</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>callbacks</span><span class=o>.</span><span class=n>on_train_epoch_end</span> <span class=o>=</span> <span class=n>on_train_epoch_end</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=s1>&#39;data.yaml&#39;</span><span class=p>,</span> <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span></span></span></code></pre></div><p><strong>TensorBoard可视化</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 启动TensorBoard</span>
</span></span><span class=line><span class=cl>tensorboard --logdir runs/detect
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在浏览器打开 http://localhost:6006</span></span></span></code></pre></div><p><strong>Weights & Biases集成</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 自动集成W&amp;B（需要先登录）</span>
</span></span><span class=line><span class=cl><span class=c1># wandb login</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;data.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>project</span><span class=o>=</span><span class=s1>&#39;my-yolo-project&#39;</span><span class=p>,</span>  <span class=c1># W&amp;B项目名</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=1026-模型验证>10.2.6 模型验证<a class=anchor href=#1026-%e6%a8%a1%e5%9e%8b%e9%aa%8c%e8%af%81>#</a></h3><p><strong>验证训练好的模型</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载训练好的模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;runs/detect/exp/weights/best.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证</span>
</span></span><span class=line><span class=cl><span class=n>metrics</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>val</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>data</span><span class=o>=</span><span class=s1>&#39;data.yaml&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>split</span><span class=o>=</span><span class=s1>&#39;val&#39;</span><span class=p>,</span>      <span class=c1># 或 &#39;test&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>imgsz</span><span class=o>=</span><span class=mi>640</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>conf</span><span class=o>=</span><span class=mf>0.25</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>iou</span><span class=o>=</span><span class=mf>0.6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看指标</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;mAP50-95: </span><span class=si>{</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>map</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;mAP50: </span><span class=si>{</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>map50</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;mAP75: </span><span class=si>{</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>map75</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 各类别的AP</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>ap</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>ap_class_index</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>model</span><span class=o>.</span><span class=n>names</span><span class=p>[</span><span class=n>i</span><span class=p>]</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>metrics</span><span class=o>.</span><span class=n>box</span><span class=o>.</span><span class=n>ap</span><span class=p>[</span><span class=n>ap</span><span class=p>]</span><span class=si>:</span><span class=s2>.3f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>混淆矩阵分析</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 训练时会自动生成混淆矩阵</span>
</span></span><span class=line><span class=cl><span class=c1># 查看: runs/detect/exp/confusion_matrix.png</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或手动生成</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics.utils.plotting</span> <span class=kn>import</span> <span class=n>plot_results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>plot_results</span><span class=p>(</span><span class=n>file</span><span class=o>=</span><span class=s1>&#39;runs/detect/exp/results.csv&#39;</span><span class=p>)</span></span></span></code></pre></div><hr><h2 id=103-模型导出与部署>10.3 模型导出与部署<a class=anchor href=#103-%e6%a8%a1%e5%9e%8b%e5%af%bc%e5%87%ba%e4%b8%8e%e9%83%a8%e7%bd%b2>#</a></h2><h3 id=1031-模型导出>10.3.1 模型导出<a class=anchor href=#1031-%e6%a8%a1%e5%9e%8b%e5%af%bc%e5%87%ba>#</a></h3><p>参见代码文件：<a href=../../chapter29/code/chapter10_yolo_practice/yolov8_export.py><code>code/chapter10_yolo_practice/yolov8_export.py</code></a></p><p><strong>支持的导出格式</strong>：</p><table><thead><tr><th>格式</th><th>参数</th><th>用途</th></tr></thead><tbody><tr><td>PyTorch</td><td><code>.pt</code></td><td>Python推理</td></tr><tr><td>TorchScript</td><td><code>torchscript</code></td><td>部署</td></tr><tr><td>ONNX</td><td><code>onnx</code></td><td>跨平台</td></tr><tr><td>OpenVINO</td><td><code>openvino</code></td><td>Intel优化</td></tr><tr><td>TensorRT</td><td><code>engine</code></td><td>NVIDIA GPU</td></tr><tr><td>CoreML</td><td><code>coreml</code></td><td>iOS/macOS</td></tr><tr><td>TF SavedModel</td><td><code>saved_model</code></td><td>TensorFlow</td></tr><tr><td>TF GraphDef</td><td><code>pb</code></td><td>TensorFlow</td></tr><tr><td>TFLite</td><td><code>tflite</code></td><td>移动端</td></tr><tr><td>TFLite Edge TPU</td><td><code>edgetpu</code></td><td>Edge TPU</td></tr><tr><td>TF.js</td><td><code>tfjs</code></td><td>Web</td></tr><tr><td>PaddlePaddle</td><td><code>paddle</code></td><td>百度飞桨</td></tr><tr><td>NCNN</td><td><code>ncnn</code></td><td>移动端</td></tr></tbody></table><p><strong>导出示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ONNX导出（最通用）</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;onnx&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TensorRT导出（NVIDIA GPU加速）</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;engine&#39;</span><span class=p>,</span> <span class=n>device</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>half</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># CoreML导出（iOS）</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;coreml&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># TFLite导出（移动端）</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;tflite&#39;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1032-onnx推理>10.3.2 ONNX推理<a class=anchor href=#1032-onnx%e6%8e%a8%e7%90%86>#</a></h3><p><strong>使用ONNX Runtime</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>onnxruntime</span> <span class=k>as</span> <span class=nn>ort</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载ONNX模型</span>
</span></span><span class=line><span class=cl><span class=n>session</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s1>&#39;yolov8n.onnx&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>providers</span><span class=o>=</span><span class=p>[</span><span class=s1>&#39;CUDAExecutionProvider&#39;</span><span class=p>,</span> <span class=s1>&#39;CPUExecutionProvider&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预处理</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>resize</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=p>(</span><span class=mi>640</span><span class=p>,</span> <span class=mi>640</span><span class=p>))</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># HWC -&gt; CHW</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span> <span class=o>/</span> <span class=mf>255.0</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>  <span class=c1># 添加batch维度</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=n>input_name</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>get_inputs</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>session</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=p>{</span><span class=n>input_name</span><span class=p>:</span> <span class=n>img</span><span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 后处理</span>
</span></span><span class=line><span class=cl><span class=n>predictions</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>  <span class=c1># shape: (1, 84, 8400)</span>
</span></span><span class=line><span class=cl><span class=c1># 需要进行NMS等后处理...</span></span></span></code></pre></div><p><strong>完整的ONNX推理流程</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>onnxruntime</span> <span class=k>as</span> <span class=nn>ort</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>YOLOv8ONNX</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>onnx_path</span><span class=p>,</span> <span class=n>conf_threshold</span><span class=o>=</span><span class=mf>0.5</span><span class=p>,</span> <span class=n>iou_threshold</span><span class=o>=</span><span class=mf>0.5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>session</span> <span class=o>=</span> <span class=n>ort</span><span class=o>.</span><span class=n>InferenceSession</span><span class=p>(</span><span class=n>onnx_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conf_threshold</span> <span class=o>=</span> <span class=n>conf_threshold</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>iou_threshold</span> <span class=o>=</span> <span class=n>iou_threshold</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_name</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>session</span><span class=o>.</span><span class=n>get_inputs</span><span class=p>()[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>name</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>preprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>img</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>resize</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=p>(</span><span class=mi>640</span><span class=p>,</span> <span class=mi>640</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>cvtColor</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=n>cv2</span><span class=o>.</span><span class=n>COLOR_BGR2RGB</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>float32</span><span class=p>)</span> <span class=o>/</span> <span class=mf>255.0</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>expand_dims</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>postprocess</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>outputs</span><span class=p>,</span> <span class=n>orig_shape</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>predictions</span> <span class=o>=</span> <span class=n>outputs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># (1, 84, 8400) -&gt; (1, 8400, 84)</span>
</span></span><span class=line><span class=cl>        <span class=n>boxes</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=n>class_ids</span> <span class=o>=</span> <span class=p>[],</span> <span class=p>[],</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>pred</span> <span class=ow>in</span> <span class=n>predictions</span><span class=p>[</span><span class=mi>0</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=c1># pred: [x, y, w, h, cls0_conf, cls1_conf, ...]</span>
</span></span><span class=line><span class=cl>            <span class=n>box</span> <span class=o>=</span> <span class=n>pred</span><span class=p>[:</span><span class=mi>4</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>class_scores</span> <span class=o>=</span> <span class=n>pred</span><span class=p>[</span><span class=mi>4</span><span class=p>:]</span>
</span></span><span class=line><span class=cl>            <span class=n>class_id</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=n>class_scores</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>conf</span> <span class=o>=</span> <span class=n>class_scores</span><span class=p>[</span><span class=n>class_id</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>conf</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>conf_threshold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 转换坐标</span>
</span></span><span class=line><span class=cl>                <span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>w</span><span class=p>,</span> <span class=n>h</span> <span class=o>=</span> <span class=n>box</span>
</span></span><span class=line><span class=cl>                <span class=n>x1</span> <span class=o>=</span> <span class=n>x</span> <span class=o>-</span> <span class=n>w</span><span class=o>/</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>                <span class=n>y1</span> <span class=o>=</span> <span class=n>y</span> <span class=o>-</span> <span class=n>h</span><span class=o>/</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>                <span class=n>x2</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=n>w</span><span class=o>/</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>                <span class=n>y2</span> <span class=o>=</span> <span class=n>y</span> <span class=o>+</span> <span class=n>h</span><span class=o>/</span><span class=mi>2</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=n>boxes</span><span class=o>.</span><span class=n>append</span><span class=p>([</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                <span class=n>scores</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>conf</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>class_ids</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>class_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># NMS</span>
</span></span><span class=line><span class=cl>        <span class=n>indices</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>dnn</span><span class=o>.</span><span class=n>NMSBoxes</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>boxes</span><span class=p>,</span> <span class=n>scores</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>conf_threshold</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>iou_threshold</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;box&#39;</span><span class=p>:</span> <span class=n>boxes</span><span class=p>[</span><span class=n>i</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;score&#39;</span><span class=p>:</span> <span class=n>scores</span><span class=p>[</span><span class=n>i</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;class_id&#39;</span><span class=p>:</span> <span class=n>class_ids</span><span class=p>[</span><span class=n>i</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>})</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>detect</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>img</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>orig_shape</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>shape</span><span class=p>[:</span><span class=mi>2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>input_tensor</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>preprocess</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>session</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=kc>None</span><span class=p>,</span> <span class=p>{</span><span class=bp>self</span><span class=o>.</span><span class=n>input_name</span><span class=p>:</span> <span class=n>input_tensor</span><span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>postprocess</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>orig_shape</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>detector</span> <span class=o>=</span> <span class=n>YOLOv8ONNX</span><span class=p>(</span><span class=s1>&#39;yolov8n.onnx&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>detector</span><span class=o>.</span><span class=n>detect</span><span class=p>(</span><span class=n>img</span><span class=p>)</span></span></span></code></pre></div><h3 id=1033-tensorrt加速>10.3.3 TensorRT加速<a class=anchor href=#1033-tensorrt%e5%8a%a0%e9%80%9f>#</a></h3><p><strong>导出TensorRT引擎</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 导出TensorRT引擎</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=nb>format</span><span class=o>=</span><span class=s1>&#39;engine&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span>           <span class=c1># GPU设备</span>
</span></span><span class=line><span class=cl>    <span class=n>half</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>          <span class=c1># FP16精度</span>
</span></span><span class=line><span class=cl>    <span class=n>workspace</span><span class=o>=</span><span class=mi>4</span><span class=p>,</span>        <span class=c1># 工作空间大小(GB)</span>
</span></span><span class=line><span class=cl>    <span class=n>simplify</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>      <span class=c1># 简化ONNX</span>
</span></span><span class=line><span class=cl>    <span class=n>dynamic</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span>      <span class=c1># 动态batch</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>使用TensorRT推理</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 直接加载TensorRT引擎</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.engine&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理（速度显著提升）</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=s1>&#39;image.jpg&#39;</span><span class=p>)</span></span></span></code></pre></div><p><strong>性能对比</strong>：</p><table><thead><tr><th>模型格式</th><th>延迟(V100)</th><th>加速比</th></tr></thead><tbody><tr><td>PyTorch (FP32)</td><td>3.5ms</td><td>1.0x</td></tr><tr><td>ONNX (FP32)</td><td>2.8ms</td><td>1.25x</td></tr><tr><td>TensorRT (FP32)</td><td>1.5ms</td><td>2.3x</td></tr><tr><td>TensorRT (FP16)</td><td>0.8ms</td><td>4.4x</td></tr></tbody></table><h3 id=1034-移动端部署>10.3.4 移动端部署<a class=anchor href=#1034-%e7%a7%bb%e5%8a%a8%e7%ab%af%e9%83%a8%e7%bd%b2>#</a></h3><p><strong>iOS (CoreML)</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 导出CoreML</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;coreml&#39;</span><span class=p>,</span> <span class=n>nms</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># iOS Swift代码</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=kn>import</span> <span class=nn>CoreML</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>let</span> <span class=n>model</span> <span class=o>=</span> <span class=k>try</span> <span class=n>yolov8n</span><span class=p>(</span><span class=n>configuration</span><span class=p>:</span> <span class=n>MLModelConfiguration</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>let</span> <span class=n>prediction</span> <span class=o>=</span> <span class=k>try</span> <span class=n>model</span><span class=o>.</span><span class=n>prediction</span><span class=p>(</span><span class=n>image</span><span class=p>:</span> <span class=n>pixelBuffer</span><span class=p>)</span></span></span></code></pre></div><p><strong>Android (TFLite)</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 导出TFLite</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;tflite&#39;</span><span class=p>,</span> <span class=n>int8</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>  <span class=c1># INT8量化</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Android Kotlin代码</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=kn>import</span> <span class=nn>org.tensorflow.lite.Interpreter</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>val</span> <span class=n>interpreter</span> <span class=o>=</span> <span class=n>Interpreter</span><span class=p>(</span><span class=n>loadModelFile</span><span class=p>())</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>interpreter</span><span class=o>.</span><span class=n>run</span><span class=p>(</span><span class=n>inputArray</span><span class=p>,</span> <span class=n>outputArray</span><span class=p>)</span></span></span></code></pre></div><p><strong>边缘设备 (NCNN)</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 导出NCNN</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>export</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s1>&#39;ncnn&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># C++代码</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=c1>#include &#34;ncnn/net.h&#34;</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>ncnn</span><span class=p>::</span><span class=n>Net</span> <span class=n>net</span><span class=p>;</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>net</span><span class=o>.</span><span class=n>load_param</span><span class=p>(</span><span class=s2>&#34;yolov8n.param&#34;</span><span class=p>);</span>
</span></span><span class=line><span class=cl><span class=o>//</span> <span class=n>net</span><span class=o>.</span><span class=n>load_model</span><span class=p>(</span><span class=s2>&#34;yolov8n.bin&#34;</span><span class=p>);</span></span></span></code></pre></div><hr><h2 id=104-实战构建实时检测系统>10.4 实战：构建实时检测系统<a class=anchor href=#104-%e5%ae%9e%e6%88%98%e6%9e%84%e5%bb%ba%e5%ae%9e%e6%97%b6%e6%a3%80%e6%b5%8b%e7%b3%bb%e7%bb%9f>#</a></h2><h3 id=1041-项目需求分析>10.4.1 项目需求分析<a class=anchor href=#1041-%e9%a1%b9%e7%9b%ae%e9%9c%80%e6%b1%82%e5%88%86%e6%9e%90>#</a></h3><p><strong>项目目标</strong>：构建一个实时视频检测系统</p><p><strong>功能需求</strong>：</p><ol><li>支持多种输入源（摄像头、视频文件、RTSP流）</li><li>实时检测并显示结果</li><li>支持录制检测结果</li><li>性能监控（FPS、延迟）</li><li>可配置的检测参数</li></ol><p><strong>技术选型</strong>：</p><ul><li>检测模型：YOLOv8n/s（平衡速度和精度）</li><li>视频处理：OpenCV</li><li>界面：OpenCV GUI 或 Gradio</li><li>部署：Docker容器化</li></ul><h3 id=1042-系统架构设计>10.4.2 系统架构设计<a class=anchor href=#1042-%e7%b3%bb%e7%bb%9f%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌─────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│          Input Sources                  │
</span></span><span class=line><span class=cl>│  (Webcam / Video / RTSP Stream)         │
</span></span><span class=line><span class=cl>└──────────────┬──────────────────────────┘
</span></span><span class=line><span class=cl>               │
</span></span><span class=line><span class=cl>               ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│      Frame Preprocessing                │
</span></span><span class=line><span class=cl>│  (Resize, Normalize, Format)            │
</span></span><span class=line><span class=cl>└──────────────┬──────────────────────────┘
</span></span><span class=line><span class=cl>               │
</span></span><span class=line><span class=cl>               ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│      YOLO Detection Engine              │
</span></span><span class=line><span class=cl>│  (Model Inference + Post-process)       │
</span></span><span class=line><span class=cl>└──────────────┬──────────────────────────┘
</span></span><span class=line><span class=cl>               │
</span></span><span class=line><span class=cl>               ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│      Result Rendering                   │
</span></span><span class=line><span class=cl>│  (Draw Boxes, Labels, FPS)              │
</span></span><span class=line><span class=cl>└──────────────┬──────────────────────────┘
</span></span><span class=line><span class=cl>               │
</span></span><span class=line><span class=cl>               ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│      Output &amp; Storage                   │
</span></span><span class=line><span class=cl>│  (Display / Save / Stream)              │
</span></span><span class=line><span class=cl>└─────────────────────────────────────────┘</span></span></code></pre></div><h3 id=1043-完整代码实现>10.4.3 完整代码实现<a class=anchor href=#1043-%e5%ae%8c%e6%95%b4%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0>#</a></h3><p><strong>主系统类</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># real_time_detector.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>collections</span> <span class=kn>import</span> <span class=n>deque</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>RealTimeDetector</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;实时目标检测系统&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_path</span><span class=o>=</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>,</span> <span class=n>conf_threshold</span><span class=o>=</span><span class=mf>0.5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            model_path: YOLO模型路径
</span></span></span><span class=line><span class=cl><span class=s2>            conf_threshold: 置信度阈值
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=n>model_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conf_threshold</span> <span class=o>=</span> <span class=n>conf_threshold</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 性能监控</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fps_queue</span> <span class=o>=</span> <span class=n>deque</span><span class=p>(</span><span class=n>maxlen</span><span class=o>=</span><span class=mi>30</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>process_times</span> <span class=o>=</span> <span class=n>deque</span><span class=p>(</span><span class=n>maxlen</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 统计信息</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>detection_count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>detect_frame</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>frame</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        检测单帧
</span></span></span><span class=line><span class=cl><span class=s2>        
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            frame: 输入图像(BGR)
</span></span></span><span class=line><span class=cl><span class=s2>            
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            result: YOLO检测结果
</span></span></span><span class=line><span class=cl><span class=s2>            process_time: 处理时间(ms)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># YOLO推理</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>frame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>conf</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>conf_threshold</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>verbose</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>process_time</span> <span class=o>=</span> <span class=p>(</span><span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span><span class=p>)</span> <span class=o>*</span> <span class=mi>1000</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>process_times</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>process_time</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>results</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>process_time</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>draw_results</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>frame</span><span class=p>,</span> <span class=n>result</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        在图像上绘制检测结果
</span></span></span><span class=line><span class=cl><span class=s2>        
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            frame: 输入图像
</span></span></span><span class=line><span class=cl><span class=s2>            result: YOLO检测结果
</span></span></span><span class=line><span class=cl><span class=s2>            
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            frame: 绘制后的图像
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 复制图像避免修改原图</span>
</span></span><span class=line><span class=cl>        <span class=n>annotated_frame</span> <span class=o>=</span> <span class=n>frame</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 绘制边界框</span>
</span></span><span class=line><span class=cl>        <span class=n>boxes</span> <span class=o>=</span> <span class=n>result</span><span class=o>.</span><span class=n>boxes</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>boxes</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>box</span> <span class=ow>in</span> <span class=n>boxes</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=c1># 获取坐标和信息</span>
</span></span><span class=line><span class=cl>                <span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=n>x2</span><span class=p>,</span> <span class=n>y2</span> <span class=o>=</span> <span class=n>box</span><span class=o>.</span><span class=n>xyxy</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>conf</span> <span class=o>=</span> <span class=nb>float</span><span class=p>(</span><span class=n>box</span><span class=o>.</span><span class=n>conf</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                <span class=bp>cls</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>box</span><span class=o>.</span><span class=n>cls</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 绘制矩形</span>
</span></span><span class=line><span class=cl>                <span class=n>color</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_get_color</span><span class=p>(</span><span class=bp>cls</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>rectangle</span><span class=p>(</span><span class=n>annotated_frame</span><span class=p>,</span> <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>),</span> <span class=p>(</span><span class=n>x2</span><span class=p>,</span> <span class=n>y2</span><span class=p>),</span> <span class=n>color</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 绘制标签</span>
</span></span><span class=line><span class=cl>                <span class=n>label</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>names</span><span class=p>[</span><span class=bp>cls</span><span class=p>]</span><span class=si>}</span><span class=s2> </span><span class=si>{</span><span class=n>conf</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>                <span class=n>label_size</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>getTextSize</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>label</span><span class=p>,</span> <span class=n>cv2</span><span class=o>.</span><span class=n>FONT_HERSHEY_SIMPLEX</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 标签背景</span>
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>rectangle</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>annotated_frame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span> <span class=o>-</span> <span class=n>label_size</span><span class=p>[</span><span class=mi>1</span><span class=p>]</span> <span class=o>-</span> <span class=mi>10</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=p>(</span><span class=n>x1</span> <span class=o>+</span> <span class=n>label_size</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>y1</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=n>color</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=o>-</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 标签文字</span>
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>putText</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                    <span class=n>annotated_frame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=n>label</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span> <span class=o>-</span> <span class=mi>5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=n>cv2</span><span class=o>.</span><span class=n>FONT_HERSHEY_SIMPLEX</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=mf>0.5</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=p>(</span><span class=mi>255</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>255</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                    <span class=mi>1</span>
</span></span><span class=line><span class=cl>                <span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>detection_count</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>annotated_frame</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>draw_stats</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>frame</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        绘制统计信息
</span></span></span><span class=line><span class=cl><span class=s2>        
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            frame: 输入图像
</span></span></span><span class=line><span class=cl><span class=s2>            
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            frame: 添加统计信息后的图像
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 计算FPS</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fps_queue</span><span class=p>)</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>fps</span> <span class=o>=</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fps_queue</span><span class=p>)</span> <span class=o>/</span> <span class=nb>sum</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fps_queue</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>fps</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 计算平均处理时间</span>
</span></span><span class=line><span class=cl>        <span class=n>avg_process_time</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>process_times</span><span class=p>)</span> <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>process_times</span> <span class=k>else</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 准备统计文本</span>
</span></span><span class=line><span class=cl>        <span class=n>stats</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=sa>f</span><span class=s2>&#34;FPS: </span><span class=si>{</span><span class=n>fps</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=sa>f</span><span class=s2>&#34;Process Time: </span><span class=si>{</span><span class=n>avg_process_time</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>ms&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=sa>f</span><span class=s2>&#34;Frame: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=sa>f</span><span class=s2>&#34;Detections: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>detection_count</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 绘制半透明背景</span>
</span></span><span class=line><span class=cl>        <span class=n>overlay</span> <span class=o>=</span> <span class=n>frame</span><span class=o>.</span><span class=n>copy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>cv2</span><span class=o>.</span><span class=n>rectangle</span><span class=p>(</span><span class=n>overlay</span><span class=p>,</span> <span class=p>(</span><span class=mi>10</span><span class=p>,</span> <span class=mi>10</span><span class=p>),</span> <span class=p>(</span><span class=mi>300</span><span class=p>,</span> <span class=mi>120</span><span class=p>),</span> <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>cv2</span><span class=o>.</span><span class=n>addWeighted</span><span class=p>(</span><span class=n>overlay</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>,</span> <span class=n>frame</span><span class=p>,</span> <span class=mf>0.4</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 绘制统计文本</span>
</span></span><span class=line><span class=cl>        <span class=n>y_offset</span> <span class=o>=</span> <span class=mi>30</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>stat</span> <span class=ow>in</span> <span class=n>stats</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>cv2</span><span class=o>.</span><span class=n>putText</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>frame</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>stat</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=mi>20</span><span class=p>,</span> <span class=n>y_offset</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>FONT_HERSHEY_SIMPLEX</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=mf>0.6</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=mi>2</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>y_offset</span> <span class=o>+=</span> <span class=mi>25</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>frame</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_video</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>source</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>output_path</span><span class=o>=</span><span class=kc>None</span><span class=p>,</span> <span class=n>display</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        处理视频流
</span></span></span><span class=line><span class=cl><span class=s2>        
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            source: 视频源（0=摄像头，路径=视频文件，URL=RTSP流）
</span></span></span><span class=line><span class=cl><span class=s2>            output_path: 输出视频路径（可选）
</span></span></span><span class=line><span class=cl><span class=s2>            display: 是否显示结果
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 打开视频流</span>
</span></span><span class=line><span class=cl>        <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>cap</span><span class=o>.</span><span class=n>isOpened</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;无法打开视频源: </span><span class=si>{</span><span class=n>source</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 获取视频属性</span>
</span></span><span class=line><span class=cl>        <span class=n>fps</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FPS</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>width</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_WIDTH</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>height</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_HEIGHT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;视频源信息: </span><span class=si>{</span><span class=n>width</span><span class=si>}</span><span class=s2>x</span><span class=si>{</span><span class=n>height</span><span class=si>}</span><span class=s2> @ </span><span class=si>{</span><span class=n>fps</span><span class=si>}</span><span class=s2>FPS&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 创建视频写入器</span>
</span></span><span class=line><span class=cl>        <span class=n>writer</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>output_path</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>fourcc</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoWriter_fourcc</span><span class=p>(</span><span class=o>*</span><span class=s1>&#39;mp4v&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>writer</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoWriter</span><span class=p>(</span><span class=n>output_path</span><span class=p>,</span> <span class=n>fourcc</span><span class=p>,</span> <span class=n>fps</span><span class=p>,</span> <span class=p>(</span><span class=n>width</span><span class=p>,</span> <span class=n>height</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 重置统计</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>detection_count</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;开始处理... (按&#39;q&#39;退出)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>frame_start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 读取帧</span>
</span></span><span class=line><span class=cl>                <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=ow>not</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=k>break</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 检测</span>
</span></span><span class=line><span class=cl>                <span class=n>result</span><span class=p>,</span> <span class=n>process_time</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>detect_frame</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 绘制结果</span>
</span></span><span class=line><span class=cl>                <span class=n>annotated_frame</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>draw_results</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 绘制统计信息</span>
</span></span><span class=line><span class=cl>                <span class=n>annotated_frame</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>draw_stats</span><span class=p>(</span><span class=n>annotated_frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 保存视频</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>writer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>writer</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>annotated_frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 显示</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>display</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>cv2</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=s1>&#39;YOLO Real-Time Detection&#39;</span><span class=p>,</span> <span class=n>annotated_frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    
</span></span><span class=line><span class=cl>                    <span class=c1># 按键处理</span>
</span></span><span class=line><span class=cl>                    <span class=n>key</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>waitKey</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=mh>0xFF</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=n>key</span> <span class=o>==</span> <span class=nb>ord</span><span class=p>(</span><span class=s1>&#39;q&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                        <span class=k>break</span>
</span></span><span class=line><span class=cl>                    <span class=k>elif</span> <span class=n>key</span> <span class=o>==</span> <span class=nb>ord</span><span class=p>(</span><span class=s1>&#39;s&#39;</span><span class=p>):</span>  <span class=c1># 截图</span>
</span></span><span class=line><span class=cl>                        <span class=n>cv2</span><span class=o>.</span><span class=n>imwrite</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;screenshot_</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span><span class=si>}</span><span class=s1>.jpg&#39;</span><span class=p>,</span> <span class=n>annotated_frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;截图已保存: screenshot_</span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span><span class=si>}</span><span class=s2>.jpg&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=c1># 更新FPS</span>
</span></span><span class=line><span class=cl>                <span class=n>frame_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>frame_start</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>fps_queue</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame_time</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>        <span class=k>finally</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 清理资源</span>
</span></span><span class=line><span class=cl>            <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>writer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>writer</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>display</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>destroyAllWindows</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>处理完成!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;总帧数: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;总检测数: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>detection_count</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;平均FPS: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>frame_count</span> <span class=o>/</span> <span class=nb>sum</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>fps_queue</span><span class=p>)</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_get_color</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>class_id</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;获取类别颜色&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>seed</span><span class=p>(</span><span class=n>class_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=nb>tuple</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span><span class=o>.</span><span class=n>tolist</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s1>&#39;__main__&#39;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 创建检测器</span>
</span></span><span class=line><span class=cl>    <span class=n>detector</span> <span class=o>=</span> <span class=n>RealTimeDetector</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model_path</span><span class=o>=</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>conf_threshold</span><span class=o>=</span><span class=mf>0.5</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 处理摄像头</span>
</span></span><span class=line><span class=cl>    <span class=n>detector</span><span class=o>.</span><span class=n>process_video</span><span class=p>(</span><span class=n>source</span><span class=o>=</span><span class=mi>0</span><span class=p>,</span> <span class=n>output_path</span><span class=o>=</span><span class=s1>&#39;output.mp4&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 或处理视频文件</span>
</span></span><span class=line><span class=cl>    <span class=c1># detector.process_video(source=&#39;input.mp4&#39;, output_path=&#39;output.mp4&#39;)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=c1># 或处理RTSP流</span>
</span></span><span class=line><span class=cl>    <span class=c1># detector.process_video(source=&#39;rtsp://...&#39;, display=True)</span></span></span></code></pre></div><h3 id=1044-性能优化技巧>10.4.4 性能优化技巧<a class=anchor href=#1044-%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96%e6%8a%80%e5%b7%a7>#</a></h3><p><strong>1. 模型优化</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用较小的模型</span>
</span></span><span class=line><span class=cl><span class=n>detector</span> <span class=o>=</span> <span class=n>RealTimeDetector</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>  <span class=c1># 而非yolov8x.pt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 降低输入分辨率</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>imgsz</span><span class=o>=</span><span class=mi>416</span><span class=p>)</span>  <span class=c1># 默认640</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用FP16精度</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>half</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 减少检测类别</span>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>classes</span><span class=o>=</span><span class=p>[</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>5</span><span class=p>])</span>  <span class=c1># 只检测特定类别</span></span></span></code></pre></div><p><strong>2. 多线程处理</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>threading</span> <span class=kn>import</span> <span class=n>Thread</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>queue</span> <span class=kn>import</span> <span class=n>Queue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ThreadedDetector</span><span class=p>(</span><span class=n>RealTimeDetector</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;多线程检测器&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>(</span><span class=o>*</span><span class=n>args</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>frame_queue</span> <span class=o>=</span> <span class=n>Queue</span><span class=p>(</span><span class=n>maxsize</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>result_queue</span> <span class=o>=</span> <span class=n>Queue</span><span class=p>(</span><span class=n>maxsize</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>capture_thread</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>source</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;视频捕获线程&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>source</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=n>cap</span><span class=o>.</span><span class=n>isOpened</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>frame_queue</span><span class=o>.</span><span class=n>put</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>detection_thread</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;检测线程&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>frame</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>frame_queue</span><span class=o>.</span><span class=n>get</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>frame</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>break</span>
</span></span><span class=line><span class=cl>            <span class=n>result</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>detect_frame</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>result_queue</span><span class=o>.</span><span class=n>put</span><span class=p>((</span><span class=n>frame</span><span class=p>,</span> <span class=n>result</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>process_video_threaded</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>source</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;多线程处理&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 启动捕获线程</span>
</span></span><span class=line><span class=cl>        <span class=n>capture</span> <span class=o>=</span> <span class=n>Thread</span><span class=p>(</span><span class=n>target</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>capture_thread</span><span class=p>,</span> <span class=n>args</span><span class=o>=</span><span class=p>(</span><span class=n>source</span><span class=p>,))</span>
</span></span><span class=line><span class=cl>        <span class=n>capture</span><span class=o>.</span><span class=n>daemon</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=n>capture</span><span class=o>.</span><span class=n>start</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 启动检测线程</span>
</span></span><span class=line><span class=cl>        <span class=n>detection</span> <span class=o>=</span> <span class=n>Thread</span><span class=p>(</span><span class=n>target</span><span class=o>=</span><span class=bp>self</span><span class=o>.</span><span class=n>detection_thread</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>detection</span><span class=o>.</span><span class=n>daemon</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=n>detection</span><span class=o>.</span><span class=n>start</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=c1># 主线程显示</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=bp>self</span><span class=o>.</span><span class=n>result_queue</span><span class=o>.</span><span class=n>empty</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                <span class=n>frame</span><span class=p>,</span> <span class=n>result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>result_queue</span><span class=o>.</span><span class=n>get</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=n>annotated</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>draw_results</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>annotated</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>draw_stats</span><span class=p>(</span><span class=n>annotated</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>cv2</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=s1>&#39;Detection&#39;</span><span class=p>,</span> <span class=n>annotated</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=n>cv2</span><span class=o>.</span><span class=n>waitKey</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&amp;</span> <span class=mh>0xFF</span> <span class=o>==</span> <span class=nb>ord</span><span class=p>(</span><span class=s1>&#39;q&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                    <span class=k>break</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>cv2</span><span class=o>.</span><span class=n>destroyAllWindows</span><span class=p>()</span></span></span></code></pre></div><p><strong>3. GPU批处理</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>batch_detect</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>frames</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;批量检测多帧&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>frames</span><span class=p>,</span> <span class=n>batch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>frames</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span></span></span></code></pre></div><h3 id=1045-gradio-web界面>10.4.5 Gradio Web界面<a class=anchor href=#1045-gradio-web%e7%95%8c%e9%9d%a2>#</a></h3><p><strong>构建Web应用</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>gradio</span> <span class=k>as</span> <span class=nn>gr</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>ultralytics</span> <span class=kn>import</span> <span class=n>YOLO</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>YOLO</span><span class=p>(</span><span class=s1>&#39;yolov8n.pt&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>detect_image</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>conf_threshold</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;图像检测函数&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>conf</span><span class=o>=</span><span class=n>conf_threshold</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>plot</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>detect_video</span><span class=p>(</span><span class=n>video</span><span class=p>,</span> <span class=n>conf_threshold</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;视频检测函数&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 处理视频并返回</span>
</span></span><span class=line><span class=cl>    <span class=k>pass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建Gradio界面</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>gr</span><span class=o>.</span><span class=n>Blocks</span><span class=p>()</span> <span class=k>as</span> <span class=n>demo</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>gr</span><span class=o>.</span><span class=n>Markdown</span><span class=p>(</span><span class=s2>&#34;# YOLO实时检测系统&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>gr</span><span class=o>.</span><span class=n>Tab</span><span class=p>(</span><span class=s2>&#34;图像检测&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>gr</span><span class=o>.</span><span class=n>Row</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>image_input</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Image</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>image_output</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Image</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>image_conf</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Slider</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;置信度阈值&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>image_btn</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Button</span><span class=p>(</span><span class=s2>&#34;检测&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>image_btn</span><span class=o>.</span><span class=n>click</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>detect_image</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>inputs</span><span class=o>=</span><span class=p>[</span><span class=n>image_input</span><span class=p>,</span> <span class=n>image_conf</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span><span class=o>=</span><span class=n>image_output</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>    
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>gr</span><span class=o>.</span><span class=n>Tab</span><span class=p>(</span><span class=s2>&#34;视频检测&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>gr</span><span class=o>.</span><span class=n>Row</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>video_input</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Video</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>video_output</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Video</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>video_conf</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Slider</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=n>label</span><span class=o>=</span><span class=s2>&#34;置信度阈值&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>video_btn</span> <span class=o>=</span> <span class=n>gr</span><span class=o>.</span><span class=n>Button</span><span class=p>(</span><span class=s2>&#34;检测&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        
</span></span><span class=line><span class=cl>        <span class=n>video_btn</span><span class=o>.</span><span class=n>click</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>detect_video</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>inputs</span><span class=o>=</span><span class=p>[</span><span class=n>video_input</span><span class=p>,</span> <span class=n>video_conf</span><span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span><span class=o>=</span><span class=n>video_output</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动应用</span>
</span></span><span class=line><span class=cl><span class=n>demo</span><span class=o>.</span><span class=n>launch</span><span class=p>(</span><span class=n>share</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div><h3 id=1046-docker容器化部署>10.4.6 Docker容器化部署<a class=anchor href=#1046-docker%e5%ae%b9%e5%99%a8%e5%8c%96%e9%83%a8%e7%bd%b2>#</a></h3><p><strong>Dockerfile</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=s>ultralytics/ultralytics:latest</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>WORKDIR</span><span class=w> </span><span class=s>/app</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 复制应用代码</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>COPY</span> real_time_detector.py /app/<span class=err>
</span></span></span><span class=line><span class=cl><span class=k>COPY</span> requirements.txt /app/<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 安装依赖</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>RUN</span> pip install -r requirements.txt<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 下载模型</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>RUN</span> yolo download yolov8n.pt<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 暴露端口（如果使用Gradio）</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>EXPOSE</span><span class=w> </span><span class=s>7860</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 启动命令</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>CMD</span> <span class=p>[</span><span class=s2>&#34;python&#34;</span><span class=p>,</span> <span class=s2>&#34;real_time_detector.py&#34;</span><span class=p>]</span></span></span></code></pre></div><p><strong>docker-compose.yml</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>version</span><span class=p>:</span><span class=w> </span><span class=s1>&#39;3.8&#39;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>services</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>yolo-detector</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>build</span><span class=p>:</span><span class=w> </span><span class=l>.</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>container_name</span><span class=p>:</span><span class=w> </span><span class=l>yolo_detector</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>runtime</span><span class=p>:</span><span class=w> </span><span class=l>nvidia </span><span class=w> </span><span class=c># 使用GPU</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>environment</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>NVIDIA_VISIBLE_DEVICES=all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>volumes</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>./videos:/app/videos</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=l>./outputs:/app/outputs</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>ports</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>      </span>- <span class=s2>&#34;7860:7860&#34;</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span><span class=nt>command</span><span class=p>:</span><span class=w> </span><span class=l>python app.py</span></span></span></code></pre></div><p><strong>启动</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 构建镜像</span>
</span></span><span class=line><span class=cl>docker-compose build
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动服务</span>
</span></span><span class=line><span class=cl>docker-compose up -d
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看日志</span>
</span></span><span class=line><span class=cl>docker-compose logs -f</span></span></code></pre></div><hr><h2 id=105-最佳实践与常见问题>10.5 最佳实践与常见问题<a class=anchor href=#105-%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5%e4%b8%8e%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98>#</a></h2><h3 id=1051-最佳实践>10.5.1 最佳实践<a class=anchor href=#1051-%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5>#</a></h3><p><strong>1. 数据集准备</strong></p><ul><li>确保标注质量：使用多人交叉验证</li><li>数据平衡：各类别样本数量要均衡</li><li>数据增强：适度使用，避免过度</li><li>验证集选择：确保与训练集分布一致</li></ul><p><strong>2. 训练策略</strong></p><ul><li>使用预训练权重：从COCO开始微调</li><li>学习率调整：使用warmup和cosine schedule</li><li>早停策略：设置patience避免过拟合</li><li>多尺度训练：提升对不同尺度的鲁棒性</li></ul><p><strong>3. 性能优化</strong></p><ul><li>选择合适的模型大小：n/s用于实时，m/l/x用于精度</li><li>量化加速：FP16或INT8量化</li><li>批处理：合理设置batch size</li><li>TensorRT：在NVIDIA GPU上使用TensorRT</li></ul><p><strong>4. 部署建议</strong></p><ul><li>容器化：使用Docker统一环境</li><li>监控：添加性能监控和日志</li><li>版本管理：模型版本控制</li><li>A/B测试：新旧模型对比测试</li></ul><h3 id=1052-常见问题>10.5.2 常见问题<a class=anchor href=#1052-%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98>#</a></h3><p><strong>Q1: 训练loss不下降？</strong></p><p>A: 检查以下几点：</p><ul><li>学习率是否合适（尝试降低）</li><li>数据标注是否正确</li><li>是否使用了预训练权重</li><li>batch size是否太小</li></ul><p><strong>Q2: mAP很低？</strong></p><p>A: 可能原因：</p><ul><li>训练轮数不够（增加epochs）</li><li>数据集质量问题（检查标注）</li><li>模型太小（尝试更大的模型）</li><li>超参数不合适（调整学习率、数据增强）</li></ul><p><strong>Q3: 推理速度慢？</strong></p><p>A: 优化方法：</p><ul><li>使用更小的模型（yolov8n）</li><li>降低输入分辨率</li><li>使用FP16/INT8</li><li>TensorRT加速</li><li>批处理多张图像</li></ul><p><strong>Q4: GPU内存不足？</strong></p><p>A: 解决方案：</p><ul><li>减小batch size</li><li>使用更小的模型</li><li>降低图像分辨率</li><li>使用梯度累积</li></ul><p><strong>Q5: 检测结果不稳定？</strong></p><p>A: 调整参数：</p><ul><li>提高置信度阈值</li><li>调整NMS的IoU阈值</li><li>使用时序平滑（视频检测）</li></ul><hr><h2 id=本章小结-2>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93-2>#</a></h2><p>本章通过完整的实战项目，我们学习了：</p><p><strong>核心技能</strong>：</p><ol><li>YOLOv8的快速上手和基础使用</li><li>自定义数据集的准备和训练流程</li><li>模型导出和多种部署方案</li><li>实时检测系统的完整开发</li></ol><p><strong>实战成果</strong>：</p><ul><li>完整的训练pipeline</li><li>多格式模型导出（ONNX、TensorRT等）</li><li>实时检测系统原型</li><li>Web应用和容器化部署</li></ul><p><strong>下一步</strong>：</p><ul><li>探索YOLO的其他任务（分割、姿态估计）</li><li>学习模型优化技术（剪枝、蒸馏）</li><li>深入研究最新的YOLO变体</li><li>将YOLO应用到实际项目中</li></ul><hr><p><strong>完整代码</strong>：</p><ul><li><a href=../../chapter29/code/chapter10_yolo_practice/yolov8_quickstart.py>yolov8_quickstart.py</a> - 快速入门</li><li><a href=../../chapter29/code/chapter10_yolo_practice/yolov8_train_custom.py>yolov8_train_custom.py</a> - 自定义训练</li><li><a href=../../chapter29/code/chapter10_yolo_practice/yolov8_export.py>yolov8_export.py</a> - 模型导出</li></ul><p><strong>参考资源</strong>：</p><ul><li><a href=https://docs.ultralytics.com/>Ultralytics文档</a></li><li><a href=https://github.com/ultralytics/ultralytics>YOLO GitHub</a></li><li><a href=https://universe.roboflow.com/>Roboflow数据集</a></li></ul><p>恭喜你完成第四篇的学习！你已经掌握了YOLO系列从理论到实战的完整知识体系。</p><hr></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第三篇 计算机视觉核心技术</span>
</a></span><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/ class="flex align-center"><span>第五篇 图像分割</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#篇章定位>篇章定位</a></li><li><a href=#为什么yolo如此重要>为什么YOLO如此重要？</a></li><li><a href=#内容结构>内容结构</a><ul><li><a href=#第9章yolo系列演进理论核心>第9章：YOLO系列演进(理论核心)</a></li><li><a href=#第10章yolo实战项目代码实战>第10章：YOLO实战项目(代码实战)</a></li></ul></li><li><a href=#技术栈>技术栈</a></li><li><a href=#学习路径建议>学习路径建议</a><ul><li><a href=#初学者路径>初学者路径</a></li><li><a href=#进阶路径>进阶路径</a></li><li><a href=#研究路径>研究路径</a></li></ul></li><li><a href=#实践项目建议>实践项目建议</a><ul><li><a href=#入门项目>入门项目</a></li><li><a href=#进阶项目>进阶项目</a></li><li><a href=#高级项目>高级项目</a></li></ul></li><li><a href=#性能对比一览>性能对比一览</a></li><li><a href=#应用场景>应用场景</a></li><li><a href=#学习目标>学习目标</a></li><li><a href=#参考资源>参考资源</a><ul><li><a href=#官方文档>官方文档</a></li><li><a href=#论文原文>论文原文</a></li><li><a href=#社区资源>社区资源</a></li></ul></li><li><a href=#开始学习>开始学习</a></li></ul><ul><li><a href=#本章概览>本章概览</a></li><li><a href=#81-目标检测任务>8.1 目标检测任务</a><ul><li><a href=#811-什么是目标检测>8.1.1 什么是目标检测？</a></li><li><a href=#812-与相关任务的区别>8.1.2 与相关任务的区别</a></li><li><a href=#813-应用场景>8.1.3 应用场景</a></li></ul></li><li><a href=#82-评价指标>8.2 评价指标</a><ul><li><a href=#821-iou交并比>8.2.1 IoU（交并比）</a></li><li><a href=#822-precision与recall>8.2.2 Precision与Recall</a></li><li><a href=#823-ap与map>8.2.3 AP与mAP</a></li></ul></li><li><a href=#83-两阶段检测器>8.3 两阶段检测器</a><ul><li><a href=#831-r-cnn2014>8.3.1 R-CNN（2014）</a></li><li><a href=#832-fast-r-cnn2015>8.3.2 Fast R-CNN（2015）</a></li><li><a href=#833-faster-r-cnn2016>8.3.3 Faster R-CNN（2016）</a></li><li><a href=#834-两阶段方法总结>8.3.4 两阶段方法总结</a></li></ul></li><li><a href=#84-为什么需要单阶段检测>8.4 为什么需要单阶段检测？</a><ul><li><a href=#841-两阶段的速度瓶颈>8.4.1 两阶段的速度瓶颈</a></li><li><a href=#842-单阶段的思路>8.4.2 单阶段的思路</a></li><li><a href=#843-单阶段-vs-两阶段>8.4.3 单阶段 vs 两阶段</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心知识点>核心知识点</a></li><li><a href=#下一步>下一步</a></li></ul></li></ul><ul><li><a href=#本章概览-1>本章概览</a></li><li><a href=#为什么要学习yolo演进史>为什么要学习YOLO演进史？</a></li><li><a href=#章节结构>章节结构</a></li><li><a href=#91-yolov1-v3单阶段检测的崛起>9.1 YOLOv1-v3：单阶段检测的崛起</a><ul><li><a href=#911-yolov1开创性的单阶段检测>9.1.1 YOLOv1：开创性的单阶段检测</a><ul><li><a href=#核心思想>核心思想</a></li><li><a href=#架构设计>架构设计</a></li><li><a href=#损失函数>损失函数</a></li><li><a href=#优缺点>优缺点</a></li></ul></li><li><a href=#912-yolov2yolo9000更好更快更强>9.1.2 YOLOv2（YOLO9000）：更好、更快、更强</a><ul><li><a href=#better准确度提升>Better：准确度提升</a></li><li><a href=#faster速度提升>Faster：速度提升</a></li><li><a href=#stronger检测类别扩展>Stronger：检测类别扩展</a></li><li><a href=#性能>性能</a></li></ul></li><li><a href=#913-yolov3渐进式改进>9.1.3 YOLOv3：渐进式改进</a><ul><li><a href=#核心改进>核心改进</a></li><li><a href=#性能表现>性能表现</a></li><li><a href=#yolov3的实践意义>YOLOv3的实践意义</a></li></ul></li></ul></li><li><a href=#92-yolov4-v5工程优化与实用化>9.2 YOLOv4-v5：工程优化与实用化</a><ul><li><a href=#921-yolov4bag-of-freebies和bag-of-specials>9.2.1 YOLOv4：Bag of Freebies和Bag of Specials</a><ul><li><a href=#核心贡献>核心贡献</a></li><li><a href=#架构组成>架构组成</a></li><li><a href=#bag-of-freebies训练技巧>Bag of Freebies（训练技巧）</a></li><li><a href=#bag-of-specials推理技巧>Bag of Specials（推理技巧）</a></li><li><a href=#性能表现-1>性能表现</a></li></ul></li><li><a href=#922-yolov5ultralytics的工程实现>9.2.2 YOLOv5：Ultralytics的工程实现</a><ul><li><a href=#yolov5-vs-yolov4>YOLOv5 vs YOLOv4</a></li><li><a href=#代码示例>代码示例</a></li><li><a href=#性能-1>性能</a></li><li><a href=#争议与影响>争议与影响</a></li></ul></li></ul></li><li><a href=#93-yolov6-v7架构创新>9.3 YOLOv6-v7：架构创新</a><ul><li><a href=#931-yolov6工业应用优化>9.3.1 YOLOv6：工业应用优化</a><ul><li><a href=#核心创新>核心创新</a></li><li><a href=#模型系列>模型系列</a></li><li><a href=#工业化特性>工业化特性</a></li></ul></li><li><a href=#932-yolov7可训练bag-of-freebies>9.3.2 YOLOv7：可训练Bag-of-Freebies</a><ul><li><a href=#核心创新-1>核心创新</a></li><li><a href=#架构设计-1>架构设计</a></li><li><a href=#性能表现-2>性能表现</a></li><li><a href=#trainable-bag-of-freebies>Trainable Bag-of-Freebies</a></li></ul></li></ul></li><li><a href=#94-yolov8ultralytics新一代>9.4 YOLOv8：Ultralytics新一代</a><ul><li><a href=#941-核心特性>9.4.1 核心特性</a></li><li><a href=#942-多任务支持>9.4.2 多任务支持</a></li><li><a href=#943-模型变体>9.4.3 模型变体</a></li><li><a href=#944-api设计>9.4.4 API设计</a></li><li><a href=#945-性能特点>9.4.5 性能特点</a></li></ul></li><li><a href=#95-yolov9yolov10yolo11最新进展>9.5 YOLOv9、YOLOv10、YOLO11：最新进展</a><ul><li><a href=#951-yolov9pgi和gelan>9.5.1 YOLOv9：PGI和GELAN</a><ul><li><a href=#核心贡献-1>核心贡献</a></li><li><a href=#模型变体>模型变体</a></li><li><a href=#性能对比>性能对比</a></li><li><a href=#使用示例>使用示例</a></li></ul></li><li><a href=#952-yolov10nms-free端到端检测>9.5.2 YOLOv10：NMS-Free端到端检测</a><ul><li><a href=#核心创新-2>核心创新</a></li><li><a href=#模型变体-1>模型变体</a></li><li><a href=#性能亮点>性能亮点</a></li><li><a href=#使用示例-1>使用示例</a></li></ul></li><li><a href=#953-yolo11当前最优方案>9.5.3 YOLO11：当前最优方案</a><ul><li><a href=#核心改进-1>核心改进</a></li><li><a href=#模型性能>模型性能</a></li><li><a href=#多任务支持>多任务支持</a></li><li><a href=#使用示例-2>使用示例</a></li><li><a href=#适用场景>适用场景</a></li></ul></li></ul></li><li><a href=#96-yolo-world开放词汇检测>9.6 YOLO-World：开放词汇检测</a><ul><li><a href=#961-什么是开放词汇检测>9.6.1 什么是开放词汇检测？</a></li><li><a href=#962-核心技术>9.6.2 核心技术</a></li><li><a href=#963-模型变体>9.6.3 模型变体</a></li><li><a href=#964-使用示例>9.6.4 使用示例</a></li><li><a href=#965-应用场景>9.6.5 应用场景</a></li><li><a href=#966-性能特点>9.6.6 性能特点</a></li></ul></li><li><a href=#97-yolo系列总结与展望>9.7 YOLO系列总结与展望</a><ul><li><a href=#971-演进时间线>9.7.1 演进时间线</a></li><li><a href=#972-技术趋势>9.7.2 技术趋势</a></li><li><a href=#973-版本选择建议>9.7.3 版本选择建议</a></li><li><a href=#974-未来展望>9.7.4 未来展望</a></li></ul></li><li><a href=#本章小结-1>本章小结</a></li></ul><ul><li><a href=#本章概览-2>本章概览</a></li><li><a href=#101-yolov8快速上手>10.1 YOLOv8快速上手</a><ul><li><a href=#1011-环境配置>10.1.1 环境配置</a></li><li><a href=#1012-预训练模型使用>10.1.2 预训练模型使用</a></li><li><a href=#1013-理解检测结果>10.1.3 理解检测结果</a></li><li><a href=#1014-不同输入源的推理>10.1.4 不同输入源的推理</a></li></ul></li><li><a href=#102-自定义数据集训练>10.2 自定义数据集训练</a><ul><li><a href=#1021-数据集准备>10.2.1 数据集准备</a></li><li><a href=#1022-数据标注工具>10.2.2 数据标注工具</a></li><li><a href=#1023-数据增强>10.2.3 数据增强</a></li><li><a href=#1024-训练流程>10.2.4 训练流程</a></li><li><a href=#1025-训练监控>10.2.5 训练监控</a></li><li><a href=#1026-模型验证>10.2.6 模型验证</a></li></ul></li><li><a href=#103-模型导出与部署>10.3 模型导出与部署</a><ul><li><a href=#1031-模型导出>10.3.1 模型导出</a></li><li><a href=#1032-onnx推理>10.3.2 ONNX推理</a></li><li><a href=#1033-tensorrt加速>10.3.3 TensorRT加速</a></li><li><a href=#1034-移动端部署>10.3.4 移动端部署</a></li></ul></li><li><a href=#104-实战构建实时检测系统>10.4 实战：构建实时检测系统</a><ul><li><a href=#1041-项目需求分析>10.4.1 项目需求分析</a></li><li><a href=#1042-系统架构设计>10.4.2 系统架构设计</a></li><li><a href=#1043-完整代码实现>10.4.3 完整代码实现</a></li><li><a href=#1044-性能优化技巧>10.4.4 性能优化技巧</a></li><li><a href=#1045-gradio-web界面>10.4.5 Gradio Web界面</a></li><li><a href=#1046-docker容器化部署>10.4.6 Docker容器化部署</a></li></ul></li><li><a href=#105-最佳实践与常见问题>10.5 最佳实践与常见问题</a><ul><li><a href=#1051-最佳实践>10.5.1 最佳实践</a></li><li><a href=#1052-常见问题>10.5.2 常见问题</a></li></ul></li><li><a href=#本章小结-2>本章小结</a></li></ul></nav></div></aside></main></body></html>