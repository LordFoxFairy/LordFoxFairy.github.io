<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第三篇:计算机视觉核心技术# 篇章概述# 本篇深入讲解现代计算机视觉的核心技术,包括经典CNN架构、注意力机制、Transformer以及先进的训练技巧。这些技术是当今计算机视觉领域的基石。
本篇目标# 掌握现代CNN架构:ResNet、MobileNet、EfficientNet的设计思想和实现 理解注意力机制:从Self-Attention到Vision Transformer的演进 掌握训练技巧:数据增强、学习率调度、正则化等高级技术 实战能力:能够使用预训练模型进行迁移学习和fine-tuning 技术栈# 框架: PyTorch 2.x 模型库: torchvision.models, timm, transformers 数据增强: albumentations 工具: tensorboard, wandb(可选) 章节安排# 第5章:现代CNN架构# 深入讲解ResNet、MobileNet、EfficientNet等经典架构,理解残差连接、深度可分离卷积、复合缩放等核心概念。
核心内容:
ResNet残差连接解决梯度消失 MobileNet轻量化设计思想 EfficientNet复合缩放策略 迁移学习与fine-tuning实战 实战项目: 使用ResNet50在自定义数据集上进行迁移学习
第6章:Attention与Transformer# 从注意力机制的基本原理出发,深入理解Transformer架构,并学习Vision Transformer(ViT)在图像领域的应用。
核心内容:
Self-Attention机制原理 Multi-Head Attention设计 Transformer架构详解 Vision Transformer(ViT)实现 实战项目: 使用ViT进行图像分类
第7章:数据增强与训练技巧# 掌握现代深度学习训练的各种技巧,包括数据增强、学习率调度、正则化等,构建高性能训练流程。
核心内容:
传统数据增强:翻转、裁剪、色彩变换 现代数据增强:Mixup、CutMix、AutoAugment 学习率调度:Cosine Annealing、Warmup 完整训练流程设计 实战项目: 构建生产级训练流程
学习路径# 第5章:现代CNN架构 ↓ 理解残差连接、轻量化设计 ↓ 第6章:Attention与Transformer ↓ 掌握注意力机制、ViT架构 ↓ 第7章:数据增强与训练技巧 ↓ 完整训练流程实战环境准备# # 安装核心依赖 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 pip install timm # PyTorch Image Models pip install transformers # Hugging Face Transformers pip install albumentations # 数据增强 pip install tensorboard # 可视化 pip install opencv-python pillow matplotlib # 可选:实验追踪 pip install wandb性能基准# 不同架构在ImageNet-1K上的性能对比(Top-1准确率):
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第三篇 计算机视觉核心技术"><meta property="og:description" content="第三篇:计算机视觉核心技术# 篇章概述# 本篇深入讲解现代计算机视觉的核心技术,包括经典CNN架构、注意力机制、Transformer以及先进的训练技巧。这些技术是当今计算机视觉领域的基石。
本篇目标# 掌握现代CNN架构:ResNet、MobileNet、EfficientNet的设计思想和实现 理解注意力机制:从Self-Attention到Vision Transformer的演进 掌握训练技巧:数据增强、学习率调度、正则化等高级技术 实战能力:能够使用预训练模型进行迁移学习和fine-tuning 技术栈# 框架: PyTorch 2.x 模型库: torchvision.models, timm, transformers 数据增强: albumentations 工具: tensorboard, wandb(可选) 章节安排# 第5章:现代CNN架构# 深入讲解ResNet、MobileNet、EfficientNet等经典架构,理解残差连接、深度可分离卷积、复合缩放等核心概念。
核心内容:
ResNet残差连接解决梯度消失 MobileNet轻量化设计思想 EfficientNet复合缩放策略 迁移学习与fine-tuning实战 实战项目: 使用ResNet50在自定义数据集上进行迁移学习
第6章:Attention与Transformer# 从注意力机制的基本原理出发,深入理解Transformer架构,并学习Vision Transformer(ViT)在图像领域的应用。
核心内容:
Self-Attention机制原理 Multi-Head Attention设计 Transformer架构详解 Vision Transformer(ViT)实现 实战项目: 使用ViT进行图像分类
第7章:数据增强与训练技巧# 掌握现代深度学习训练的各种技巧,包括数据增强、学习率调度、正则化等,构建高性能训练流程。
核心内容:
传统数据增强:翻转、裁剪、色彩变换 现代数据增强:Mixup、CutMix、AutoAugment 学习率调度:Cosine Annealing、Warmup 完整训练流程设计 实战项目: 构建生产级训练流程
学习路径# 第5章:现代CNN架构 ↓ 理解残差连接、轻量化设计 ↓ 第6章:Attention与Transformer ↓ 掌握注意力机制、ViT架构 ↓ 第7章:数据增强与训练技巧 ↓ 完整训练流程实战环境准备# # 安装核心依赖 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 pip install timm # PyTorch Image Models pip install transformers # Hugging Face Transformers pip install albumentations # 数据增强 pip install tensorboard # 可视化 pip install opencv-python pillow matplotlib # 可选:实验追踪 pip install wandb性能基准# 不同架构在ImageNet-1K上的性能对比(Top-1准确率):"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第三篇 计算机视觉核心技术"><meta itemprop=description content="第三篇:计算机视觉核心技术# 篇章概述# 本篇深入讲解现代计算机视觉的核心技术,包括经典CNN架构、注意力机制、Transformer以及先进的训练技巧。这些技术是当今计算机视觉领域的基石。
本篇目标# 掌握现代CNN架构:ResNet、MobileNet、EfficientNet的设计思想和实现 理解注意力机制:从Self-Attention到Vision Transformer的演进 掌握训练技巧:数据增强、学习率调度、正则化等高级技术 实战能力:能够使用预训练模型进行迁移学习和fine-tuning 技术栈# 框架: PyTorch 2.x 模型库: torchvision.models, timm, transformers 数据增强: albumentations 工具: tensorboard, wandb(可选) 章节安排# 第5章:现代CNN架构# 深入讲解ResNet、MobileNet、EfficientNet等经典架构,理解残差连接、深度可分离卷积、复合缩放等核心概念。
核心内容:
ResNet残差连接解决梯度消失 MobileNet轻量化设计思想 EfficientNet复合缩放策略 迁移学习与fine-tuning实战 实战项目: 使用ResNet50在自定义数据集上进行迁移学习
第6章:Attention与Transformer# 从注意力机制的基本原理出发,深入理解Transformer架构,并学习Vision Transformer(ViT)在图像领域的应用。
核心内容:
Self-Attention机制原理 Multi-Head Attention设计 Transformer架构详解 Vision Transformer(ViT)实现 实战项目: 使用ViT进行图像分类
第7章:数据增强与训练技巧# 掌握现代深度学习训练的各种技巧,包括数据增强、学习率调度、正则化等,构建高性能训练流程。
核心内容:
传统数据增强:翻转、裁剪、色彩变换 现代数据增强:Mixup、CutMix、AutoAugment 学习率调度:Cosine Annealing、Warmup 完整训练流程设计 实战项目: 构建生产级训练流程
学习路径# 第5章:现代CNN架构 ↓ 理解残差连接、轻量化设计 ↓ 第6章:Attention与Transformer ↓ 掌握注意力机制、ViT架构 ↓ 第7章:数据增强与训练技巧 ↓ 完整训练流程实战环境准备# # 安装核心依赖 pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118 pip install timm # PyTorch Image Models pip install transformers # Hugging Face Transformers pip install albumentations # 数据增强 pip install tensorboard # 可视化 pip install opencv-python pillow matplotlib # 可选:实验追踪 pip install wandb性能基准# 不同架构在ImageNet-1K上的性能对比(Top-1准确率):"><meta itemprop=wordCount content="4690"><title>第三篇 计算机视觉核心技术 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle checked>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/ class=active>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第三篇 计算机视觉核心技术</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#篇章概述>篇章概述</a></li><li><a href=#本篇目标>本篇目标</a></li><li><a href=#技术栈>技术栈</a></li><li><a href=#章节安排>章节安排</a><ul><li><a href=#第5章现代cnn架构>第5章:现代CNN架构</a></li><li><a href=#第6章attention与transformer>第6章:Attention与Transformer</a></li><li><a href=#第7章数据增强与训练技巧>第7章:数据增强与训练技巧</a></li></ul></li><li><a href=#学习路径>学习路径</a></li><li><a href=#环境准备>环境准备</a></li><li><a href=#性能基准>性能基准</a></li><li><a href=#核心概念速查>核心概念速查</a><ul><li><a href=#残差连接residual-connection>残差连接(Residual Connection)</a></li><li><a href=#深度可分离卷积depthwise-separable-convolution>深度可分离卷积(Depthwise Separable Convolution)</a></li><li><a href=#self-attention>Self-Attention</a></li></ul></li><li><a href=#实战项目概览>实战项目概览</a><ul><li><a href=#项目1resnet迁移学习>项目1:ResNet迁移学习</a></li><li><a href=#项目2vit图像分类>项目2:ViT图像分类</a></li><li><a href=#项目3高级训练流程>项目3:高级训练流程</a></li></ul></li><li><a href=#最佳实践>最佳实践</a><ul><li><a href=#1-模型选择>1. 模型选择</a></li><li><a href=#2-迁移学习策略>2. 迁移学习策略</a></li><li><a href=#3-学习率设置>3. 学习率设置</a></li></ul></li><li><a href=#常见问题>常见问题</a><ul><li><a href=#q1-resnet为什么能训练更深的网络>Q1: ResNet为什么能训练更深的网络?</a></li><li><a href=#q2-vit为什么需要大量数据>Q2: ViT为什么需要大量数据?</a></li><li><a href=#q3-如何选择数据增强策略>Q3: 如何选择数据增强策略?</a></li></ul></li><li><a href=#进阶资源>进阶资源</a><ul><li><a href=#论文必读>论文必读</a></li><li><a href=#代码仓库>代码仓库</a></li></ul></li><li><a href=#本篇总结>本篇总结</a></li></ul><ul><li><a href=#本章概述>本章概述</a></li><li><a href=#学习目标>学习目标</a></li><li><a href=#51-resnet残差连接革命>5.1 ResNet:残差连接革命</a><ul><li><a href=#核心问题网络退化>核心问题:网络退化</a></li><li><a href=#残差连接residual-connection-1>残差连接(Residual Connection)</a></li><li><a href=#残差块residual-block>残差块(Residual Block)</a></li><li><a href=#resnet架构族>ResNet架构族</a></li><li><a href=#resnet-50架构详解>ResNet-50架构详解</a></li><li><a href=#实现要点>实现要点</a></li></ul></li><li><a href=#52-mobilenet轻量化设计>5.2 MobileNet:轻量化设计</a><ul><li><a href=#设计目标>设计目标</a></li><li><a href=#深度可分离卷积depthwise-separable-convolution-1>深度可分离卷积(Depthwise Separable Convolution)</a></li><li><a href=#mobilenetv1架构>MobileNetV1架构</a></li><li><a href=#mobilenetv2倒残差结构inverted-residual>MobileNetV2:倒残差结构(Inverted Residual)</a></li><li><a href=#mobilenetv3神经架构搜索nas>MobileNetV3:神经架构搜索(NAS)</a></li><li><a href=#性能对比>性能对比</a></li></ul></li><li><a href=#53-efficientnet复合缩放>5.3 EfficientNet:复合缩放</a><ul><li><a href=#模型缩放的三个维度>模型缩放的三个维度</a></li><li><a href=#复合缩放compound-scaling>复合缩放(Compound Scaling)</a></li><li><a href=#efficientnet架构>EfficientNet架构</a></li><li><a href=#efficientnet系列>EfficientNet系列</a></li><li><a href=#核心优势>核心优势</a></li></ul></li><li><a href=#54-实战迁移学习与fine-tuning>5.4 实战:迁移学习与Fine-tuning</a><ul><li><a href=#迁移学习策略>迁移学习策略</a></li><li><a href=#实现步骤>实现步骤</a></li><li><a href=#fine-tuning技巧>Fine-tuning技巧</a></li><li><a href=#完整训练流程>完整训练流程</a></li></ul></li><li><a href=#架构选择指南>架构选择指南</a><ul><li><a href=#场景匹配>场景匹配</a></li><li><a href=#性能对比imagenet-1k>性能对比(ImageNet-1K)</a></li></ul></li><li><a href=#本章总结>本章总结</a><ul><li><a href=#核心概念>核心概念</a></li><li><a href=#关键技术>关键技术</a></li><li><a href=#实战能力>实战能力</a></li><li><a href=#进阶方向>进阶方向</a></li></ul></li><li><a href=#练习题>练习题</a></li><li><a href=#参考资料>参考资料</a><ul><li><a href=#论文>论文</a></li><li><a href=#代码资源>代码资源</a></li></ul></li></ul><ul><li><a href=#本章概述-1>本章概述</a></li><li><a href=#学习目标-1>学习目标</a></li><li><a href=#61-注意力机制原理>6.1 注意力机制原理</a><ul><li><a href=#注意力的直观理解>注意力的直观理解</a></li><li><a href=#attention机制演进>Attention机制演进</a></li><li><a href=#self-attention数学原理>Self-Attention数学原理</a></li><li><a href=#self-attention示例>Self-Attention示例</a></li><li><a href=#计算复杂度>计算复杂度</a></li><li><a href=#self-attention实现>Self-Attention实现</a></li></ul></li><li><a href=#62-transformer架构详解>6.2 Transformer架构详解</a><ul><li><a href=#transformer整体架构>Transformer整体架构</a></li><li><a href=#multi-head-attention>Multi-Head Attention</a></li><li><a href=#位置编码positional-encoding>位置编码(Positional Encoding)</a></li><li><a href=#feed-forward-network-ffn>Feed-Forward Network (FFN)</a></li><li><a href=#layer-normalization>Layer Normalization</a></li><li><a href=#完整transformer-encoder实现>完整Transformer Encoder实现</a></li></ul></li><li><a href=#63-vision-transformer-vit>6.3 Vision Transformer (ViT)</a><ul><li><a href=#vit核心思想>ViT核心思想</a></li><li><a href=#vit架构详解>ViT架构详解</a></li><li><a href=#vit模型配置>ViT模型配置</a></li><li><a href=#vit-vs-cnn>ViT vs CNN</a></li><li><a href=#vit变体>ViT变体</a></li></ul></li><li><a href=#64-实战vit图像分类>6.4 实战:ViT图像分类</a><ul><li><a href=#使用timm库>使用timm库</a></li><li><a href=#完整训练流程-1>完整训练流程</a></li><li><a href=#vit训练技巧>ViT训练技巧</a></li><li><a href=#性能优化>性能优化</a></li></ul></li><li><a href=#注意力可视化>注意力可视化</a><ul><li><a href=#可视化注意力图>可视化注意力图</a></li></ul></li><li><a href=#本章总结-1>本章总结</a><ul><li><a href=#核心概念-1>核心概念</a></li><li><a href=#关键公式>关键公式</a></li><li><a href=#vit优势与挑战>ViT优势与挑战</a></li><li><a href=#实战技巧>实战技巧</a></li></ul></li><li><a href=#练习题-1>练习题</a></li><li><a href=#参考资料-1>参考资料</a><ul><li><a href=#论文-1>论文</a></li><li><a href=#代码资源-1>代码资源</a></li></ul></li></ul><ul><li><a href=#本章概览>本章概览</a></li><li><a href=#为什么训练技巧如此重要>为什么训练技巧如此重要？</a></li><li><a href=#71-传统数据增强>7.1 传统数据增强</a><ul><li><a href=#711-基础几何变换>7.1.1 基础几何变换</a></li><li><a href=#712-色彩变换>7.1.2 色彩变换</a></li><li><a href=#713-使用albumentations>7.1.3 使用Albumentations</a></li></ul></li><li><a href=#72-现代数据增强>7.2 现代数据增强</a><ul><li><a href=#721-mixup>7.2.1 Mixup</a></li><li><a href=#722-cutmix>7.2.2 CutMix</a></li><li><a href=#723-autoaugment>7.2.3 AutoAugment</a></li><li><a href=#724-randaugment>7.2.4 RandAugment</a></li><li><a href=#725-增强策略对比>7.2.5 增强策略对比</a></li></ul></li><li><a href=#73-学习率调度>7.3 学习率调度</a><ul><li><a href=#731-常用调度器>7.3.1 常用调度器</a></li><li><a href=#732-warmup策略>7.3.2 Warmup策略</a></li><li><a href=#733-调度策略对比>7.3.3 调度策略对比</a></li></ul></li><li><a href=#74-正则化与防过拟合>7.4 正则化与防过拟合</a><ul><li><a href=#741-weight-decayl2正则化>7.4.1 Weight Decay（L2正则化）</a></li><li><a href=#742-dropout>7.4.2 Dropout</a></li><li><a href=#743-label-smoothing>7.4.3 Label Smoothing</a></li><li><a href=#744-stochastic-depth随机深度>7.4.4 Stochastic Depth（随机深度）</a></li><li><a href=#745-防过拟合策略总结>7.4.5 防过拟合策略总结</a></li></ul></li><li><a href=#75-混合精度训练>7.5 混合精度训练</a><ul><li><a href=#751-pytorch-amp>7.5.1 PyTorch AMP</a></li></ul></li><li><a href=#76-实战完整训练流程>7.6 实战：完整训练流程</a><ul><li><a href=#完整训练脚本>完整训练脚本</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心技术要点>核心技术要点</a></li><li><a href=#推荐训练配置>推荐训练配置</a></li><li><a href=#下一步>下一步</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第三篇计算机视觉核心技术>第三篇:计算机视觉核心技术<a class=anchor href=#%e7%ac%ac%e4%b8%89%e7%af%87%e8%ae%a1%e7%ae%97%e6%9c%ba%e8%a7%86%e8%a7%89%e6%a0%b8%e5%bf%83%e6%8a%80%e6%9c%af>#</a></h1><h2 id=篇章概述>篇章概述<a class=anchor href=#%e7%af%87%e7%ab%a0%e6%a6%82%e8%bf%b0>#</a></h2><p>本篇深入讲解现代计算机视觉的核心技术,包括经典CNN架构、注意力机制、Transformer以及先进的训练技巧。这些技术是当今计算机视觉领域的基石。</p><h2 id=本篇目标>本篇目标<a class=anchor href=#%e6%9c%ac%e7%af%87%e7%9b%ae%e6%a0%87>#</a></h2><ol><li><strong>掌握现代CNN架构</strong>:ResNet、MobileNet、EfficientNet的设计思想和实现</li><li><strong>理解注意力机制</strong>:从Self-Attention到Vision Transformer的演进</li><li><strong>掌握训练技巧</strong>:数据增强、学习率调度、正则化等高级技术</li><li><strong>实战能力</strong>:能够使用预训练模型进行迁移学习和fine-tuning</li></ol><h2 id=技术栈>技术栈<a class=anchor href=#%e6%8a%80%e6%9c%af%e6%a0%88>#</a></h2><ul><li><strong>框架</strong>: PyTorch 2.x</li><li><strong>模型库</strong>: torchvision.models, timm, transformers</li><li><strong>数据增强</strong>: albumentations</li><li><strong>工具</strong>: tensorboard, wandb(可选)</li></ul><h2 id=章节安排>章节安排<a class=anchor href=#%e7%ab%a0%e8%8a%82%e5%ae%89%e6%8e%92>#</a></h2><h3 id=第5章现代cnn架构>第5章:现代CNN架构<a class=anchor href=#%e7%ac%ac5%e7%ab%a0%e7%8e%b0%e4%bb%a3cnn%e6%9e%b6%e6%9e%84>#</a></h3><p>深入讲解ResNet、MobileNet、EfficientNet等经典架构,理解残差连接、深度可分离卷积、复合缩放等核心概念。</p><p><strong>核心内容</strong>:</p><ul><li>ResNet残差连接解决梯度消失</li><li>MobileNet轻量化设计思想</li><li>EfficientNet复合缩放策略</li><li>迁移学习与fine-tuning实战</li></ul><p><strong>实战项目</strong>: 使用ResNet50在自定义数据集上进行迁移学习</p><h3 id=第6章attention与transformer>第6章:Attention与Transformer<a class=anchor href=#%e7%ac%ac6%e7%ab%a0attention%e4%b8%8etransformer>#</a></h3><p>从注意力机制的基本原理出发,深入理解Transformer架构,并学习Vision Transformer(ViT)在图像领域的应用。</p><p><strong>核心内容</strong>:</p><ul><li>Self-Attention机制原理</li><li>Multi-Head Attention设计</li><li>Transformer架构详解</li><li>Vision Transformer(ViT)实现</li></ul><p><strong>实战项目</strong>: 使用ViT进行图像分类</p><h3 id=第7章数据增强与训练技巧>第7章:数据增强与训练技巧<a class=anchor href=#%e7%ac%ac7%e7%ab%a0%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba%e4%b8%8e%e8%ae%ad%e7%bb%83%e6%8a%80%e5%b7%a7>#</a></h3><p>掌握现代深度学习训练的各种技巧,包括数据增强、学习率调度、正则化等,构建高性能训练流程。</p><p><strong>核心内容</strong>:</p><ul><li>传统数据增强:翻转、裁剪、色彩变换</li><li>现代数据增强:Mixup、CutMix、AutoAugment</li><li>学习率调度:Cosine Annealing、Warmup</li><li>完整训练流程设计</li></ul><p><strong>实战项目</strong>: 构建生产级训练流程</p><h2 id=学习路径>学习路径<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>第5章:现代CNN架构
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>理解残差连接、轻量化设计
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>第6章:Attention与Transformer
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>掌握注意力机制、ViT架构
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>第7章:数据增强与训练技巧
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>完整训练流程实战</span></span></code></pre></div><h2 id=环境准备>环境准备<a class=anchor href=#%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 安装核心依赖</span>
</span></span><span class=line><span class=cl>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
</span></span><span class=line><span class=cl>pip install timm  <span class=c1># PyTorch Image Models</span>
</span></span><span class=line><span class=cl>pip install transformers  <span class=c1># Hugging Face Transformers</span>
</span></span><span class=line><span class=cl>pip install albumentations  <span class=c1># 数据增强</span>
</span></span><span class=line><span class=cl>pip install tensorboard  <span class=c1># 可视化</span>
</span></span><span class=line><span class=cl>pip install opencv-python pillow matplotlib
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 可选:实验追踪</span>
</span></span><span class=line><span class=cl>pip install wandb</span></span></code></pre></div><h2 id=性能基准>性能基准<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%9f%ba%e5%87%86>#</a></h2><p>不同架构在ImageNet-1K上的性能对比(Top-1准确率):</p><table><thead><tr><th>模型</th><th>参数量</th><th>FLOPs</th><th>Top-1准确率</th><th>推理速度(GPU)</th></tr></thead><tbody><tr><td>ResNet-50</td><td>25.6M</td><td>4.1G</td><td>76.2%</td><td>22ms</td></tr><tr><td>MobileNetV3-Large</td><td>5.4M</td><td>0.22G</td><td>75.2%</td><td>6ms</td></tr><tr><td>EfficientNet-B0</td><td>5.3M</td><td>0.39G</td><td>77.1%</td><td>8ms</td></tr><tr><td>ViT-B/16</td><td>86M</td><td>17.6G</td><td>81.8%</td><td>45ms</td></tr><tr><td>ViT-L/16</td><td>307M</td><td>61.6G</td><td>82.6%</td><td>120ms</td></tr></tbody></table><p><em>注: 推理速度基于NVIDIA V100 GPU, batch_size=1</em></p><h2 id=核心概念速查>核心概念速查<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5%e9%80%9f%e6%9f%a5>#</a></h2><h3 id=残差连接residual-connection>残差连接(Residual Connection)<a class=anchor href=#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5residual-connection>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>F(x) = H(x) - x
</span></span><span class=line><span class=cl>H(x) = F(x) + x  # 输出 = 残差 + 输入</span></span></code></pre></div><h3 id=深度可分离卷积depthwise-separable-convolution>深度可分离卷积(Depthwise Separable Convolution)<a class=anchor href=#%e6%b7%b1%e5%ba%a6%e5%8f%af%e5%88%86%e7%a6%bb%e5%8d%b7%e7%a7%afdepthwise-separable-convolution>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>计算量: 标准卷积 vs 深度可分离卷积
</span></span><span class=line><span class=cl>标准: D_K × D_K × M × N × D_F × D_F
</span></span><span class=line><span class=cl>深度可分离: D_K × D_K × M × D_F × D_F + M × N × D_F × D_F
</span></span><span class=line><span class=cl>压缩比: 1/N + 1/D_K²</span></span></code></pre></div><h3 id=self-attention>Self-Attention<a class=anchor href=#self-attention>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Attention(Q, K, V) = softmax(QK^T / √d_k) × V</span></span></code></pre></div><h2 id=实战项目概览>实战项目概览<a class=anchor href=#%e5%ae%9e%e6%88%98%e9%a1%b9%e7%9b%ae%e6%a6%82%e8%a7%88>#</a></h2><h3 id=项目1resnet迁移学习>项目1:ResNet迁移学习<a class=anchor href=#%e9%a1%b9%e7%9b%ae1resnet%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0>#</a></h3><ul><li><strong>数据集</strong>: 自定义分类数据集</li><li><strong>模型</strong>: ResNet-50(ImageNet预训练)</li><li><strong>技术</strong>: 冻结特征提取器、fine-tuning</li><li><strong>文件</strong>: <code>chapter05/code/resnet_transfer_learning.py</code></li></ul><h3 id=项目2vit图像分类>项目2:ViT图像分类<a class=anchor href=#%e9%a1%b9%e7%9b%ae2vit%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb>#</a></h3><ul><li><strong>数据集</strong>: CIFAR-10/自定义数据集</li><li><strong>模型</strong>: ViT-B/16(ImageNet-21K预训练)</li><li><strong>技术</strong>: Patch embedding、Position encoding</li><li><strong>文件</strong>: <code>chapter06/code/vit_classification.py</code></li></ul><h3 id=项目3高级训练流程>项目3:高级训练流程<a class=anchor href=#%e9%a1%b9%e7%9b%ae3%e9%ab%98%e7%ba%a7%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b>#</a></h3><ul><li><strong>技术栈</strong>: PyTorch + albumentations</li><li><strong>功能</strong>:<ul><li>多种数据增强策略</li><li>学习率调度(Cosine、Warmup)</li><li>混合精度训练(AMP)</li><li>TensorBoard可视化</li></ul></li><li><strong>文件</strong>: <code>chapter07/code/advanced_training.py</code></li></ul><h2 id=最佳实践>最佳实践<a class=anchor href=#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5>#</a></h2><h3 id=1-模型选择>1. 模型选择<a class=anchor href=#1-%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9>#</a></h3><ul><li><strong>高精度需求</strong>: ViT-L、EfficientNet-B7</li><li><strong>速度优先</strong>: MobileNetV3、EfficientNet-B0</li><li><strong>平衡</strong>: ResNet-50、EfficientNet-B3</li></ul><h3 id=2-迁移学习策略>2. 迁移学习策略<a class=anchor href=#2-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e7%ad%96%e7%95%a5>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 小数据集:冻结大部分层</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=c1># 只训练分类头</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 中等数据集:冻结早期层</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s1>&#39;layer1&#39;</span> <span class=ow>in</span> <span class=n>name</span> <span class=ow>or</span> <span class=s1>&#39;layer2&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 大数据集:全模型fine-tune</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>True</span></span></span></code></pre></div><h3 id=3-学习率设置>3. 学习率设置<a class=anchor href=#3-%e5%ad%a6%e4%b9%a0%e7%8e%87%e8%ae%be%e7%bd%ae>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 迁移学习典型设置</span>
</span></span><span class=line><span class=cl><span class=n>lr_backbone</span> <span class=o>=</span> <span class=mf>1e-4</span>  <span class=c1># 预训练层</span>
</span></span><span class=line><span class=cl><span class=n>lr_head</span> <span class=o>=</span> <span class=mf>1e-3</span>      <span class=c1># 新增层</span></span></span></code></pre></div><h2 id=常见问题>常见问题<a class=anchor href=#%e5%b8%b8%e8%a7%81%e9%97%ae%e9%a2%98>#</a></h2><h3 id=q1-resnet为什么能训练更深的网络>Q1: ResNet为什么能训练更深的网络?<a class=anchor href=#q1-resnet%e4%b8%ba%e4%bb%80%e4%b9%88%e8%83%bd%e8%ae%ad%e7%bb%83%e6%9b%b4%e6%b7%b1%e7%9a%84%e7%bd%91%e7%bb%9c>#</a></h3><p>A: 残差连接通过恒等映射提供了梯度的直接通路,避免了梯度消失问题。即使某些层学习失败,网络至少可以保持恒等映射。</p><h3 id=q2-vit为什么需要大量数据>Q2: ViT为什么需要大量数据?<a class=anchor href=#q2-vit%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e5%a4%a7%e9%87%8f%e6%95%b0%e6%8d%ae>#</a></h3><p>A: ViT缺少CNN的归纳偏置(局部性、平移不变性),需要更多数据来学习这些特性。在ImageNet-1K上表现不如ResNet,但在ImageNet-21K上效果更好。</p><h3 id=q3-如何选择数据增强策略>Q3: 如何选择数据增强策略?<a class=anchor href=#q3-%e5%a6%82%e4%bd%95%e9%80%89%e6%8b%a9%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba%e7%ad%96%e7%95%a5>#</a></h3><p>A:</p><ul><li>分类任务:RandAugment、AutoAugment</li><li>检测任务:Mosaic、Mixup</li><li>小数据集:强增强(AutoAugment)</li><li>大数据集:基础增强即可</li></ul><h2 id=进阶资源>进阶资源<a class=anchor href=#%e8%bf%9b%e9%98%b6%e8%b5%84%e6%ba%90>#</a></h2><h3 id=论文必读>论文必读<a class=anchor href=#%e8%ae%ba%e6%96%87%e5%bf%85%e8%af%bb>#</a></h3><ol><li><strong>ResNet</strong>: Deep Residual Learning for Image Recognition (CVPR 2016)</li><li><strong>MobileNet</strong>: MobileNets: Efficient CNNs for Mobile Vision (2017)</li><li><strong>EfficientNet</strong>: EfficientNet: Rethinking Model Scaling (ICML 2019)</li><li><strong>ViT</strong>: An Image is Worth 16x16 Words: Transformers for Image Recognition (ICLR 2021)</li><li><strong>AutoAugment</strong>: AutoAugment: Learning Augmentation Policies (CVPR 2019)</li></ol><h3 id=代码仓库>代码仓库<a class=anchor href=#%e4%bb%a3%e7%a0%81%e4%bb%93%e5%ba%93>#</a></h3><ul><li><strong>timm</strong>: <a href=https://github.com/huggingface/pytorch-image-models>https://github.com/huggingface/pytorch-image-models</a></li><li><strong>torchvision</strong>: <a href=https://github.com/pytorch/vision>https://github.com/pytorch/vision</a></li><li><strong>transformers</strong>: <a href=https://github.com/huggingface/transformers>https://github.com/huggingface/transformers</a></li><li><strong>albumentations</strong>: <a href=https://github.com/albumentations-team/albumentations>https://github.com/albumentations-team/albumentations</a></li></ul><h2 id=本篇总结>本篇总结<a class=anchor href=#%e6%9c%ac%e7%af%87%e6%80%bb%e7%bb%93>#</a></h2><p>通过本篇学习,你将:</p><ol><li>理解现代CNN架构的演进逻辑</li><li>掌握注意力机制和Transformer在视觉领域的应用</li><li>学会使用各种训练技巧提升模型性能</li><li>具备完整的深度学习项目开发能力</li></ol><p>下一篇将进入目标检测领域,学习YOLO、Faster R-CNN等经典检测算法。</p><hr><h1 id=第5章现代cnn架构-1>第5章:现代CNN架构<a class=anchor href=#%e7%ac%ac5%e7%ab%a0%e7%8e%b0%e4%bb%a3cnn%e6%9e%b6%e6%9e%84-1>#</a></h1><h2 id=本章概述>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0>#</a></h2><p>本章深入讲解现代CNN架构的设计思想,包括ResNet的残差连接、MobileNet的轻量化设计、EfficientNet的复合缩放策略,并通过迁移学习实战掌握这些模型的使用。</p><h2 id=学习目标>学习目标<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e7%9b%ae%e6%a0%87>#</a></h2><ul><li>理解ResNet残差连接如何解决梯度消失问题</li><li>掌握MobileNet的深度可分离卷积和倒残差结构</li><li>学习EfficientNet的复合缩放方法</li><li>实战:使用预训练模型进行迁移学习</li></ul><h2 id=51-resnet残差连接革命>5.1 ResNet:残差连接革命<a class=anchor href=#51-resnet%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5%e9%9d%a9%e5%91%bd>#</a></h2><h3 id=核心问题网络退化>核心问题:网络退化<a class=anchor href=#%e6%a0%b8%e5%bf%83%e9%97%ae%e9%a2%98%e7%bd%91%e7%bb%9c%e9%80%80%e5%8c%96>#</a></h3><p>在ResNet之前,深度网络面临严重问题:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>现象: 56层网络训练误差 &gt; 20层网络训练误差
</span></span><span class=line><span class=cl>原因: 不是过拟合(训练误差更高),而是优化困难</span></span></code></pre></div><p><strong>退化问题示意</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>浅层网络(20层) → 训练误差: 15%
</span></span><span class=line><span class=cl>深层网络(56层) → 训练误差: 20% (理论上应该≤15%)</span></span></code></pre></div><h3 id=残差连接residual-connection-1>残差连接(Residual Connection)<a class=anchor href=#%e6%ae%8b%e5%b7%ae%e8%bf%9e%e6%8e%a5residual-connection-1>#</a></h3><p><strong>核心思想</strong>: 学习残差而非直接学习目标映射</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>传统: H(x) = 目标映射
</span></span><span class=line><span class=cl>ResNet: F(x) = H(x) - x
</span></span><span class=line><span class=cl>        H(x) = F(x) + x</span></span></code></pre></div><p><strong>直观理解</strong>:</p><ul><li>如果恒等映射是最优的,网络只需学习F(x)=0</li><li>比直接学习H(x)=x更容易</li></ul><h3 id=残差块residual-block>残差块(Residual Block)<a class=anchor href=#%e6%ae%8b%e5%b7%ae%e5%9d%97residual-block>#</a></h3><p><strong>基础残差块</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入x
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>3×3 Conv → BN → ReLU
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>3×3 Conv → BN
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>  + ← x (跳跃连接)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>ReLU
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>输出</span></span></code></pre></div><p><strong>瓶颈残差块(Bottleneck)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入x (256维)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>1×1 Conv(64) → BN → ReLU  # 降维
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>3×3 Conv(64) → BN → ReLU  # 特征提取
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>1×1 Conv(256) → BN         # 升维
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>  + ← x
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>ReLU
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>输出(256维)</span></span></code></pre></div><p><strong>计算量对比</strong>:</p><ul><li>基础块: 3×3×256×256 × 2 = 1.18M</li><li>瓶颈块: 1×1×256×64 + 3×3×64×64 + 1×1×64×256 = 69K</li><li>压缩比: 17倍</li></ul><h3 id=resnet架构族>ResNet架构族<a class=anchor href=#resnet%e6%9e%b6%e6%9e%84%e6%97%8f>#</a></h3><table><thead><tr><th>模型</th><th>层数</th><th>参数量</th><th>FLOPs</th><th>ImageNet Top-1</th></tr></thead><tbody><tr><td>ResNet-18</td><td>18</td><td>11.7M</td><td>1.8G</td><td>69.8%</td></tr><tr><td>ResNet-34</td><td>34</td><td>21.8M</td><td>3.7G</td><td>73.3%</td></tr><tr><td>ResNet-50</td><td>50</td><td>25.6M</td><td>4.1G</td><td>76.2%</td></tr><tr><td>ResNet-101</td><td>101</td><td>44.5M</td><td>7.8G</td><td>77.4%</td></tr><tr><td>ResNet-152</td><td>152</td><td>60.2M</td><td>11.6G</td><td>78.3%</td></tr></tbody></table><h3 id=resnet-50架构详解>ResNet-50架构详解<a class=anchor href=#resnet-50%e6%9e%b6%e6%9e%84%e8%af%a6%e8%a7%a3>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: 224×224×3
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Conv1: 7×7, 64, stride=2 → 112×112×64
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>MaxPool: 3×3, stride=2 → 56×56×64
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Layer1: [1×1,64; 3×3,64; 1×1,256] × 3 → 56×56×256
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Layer2: [1×1,128; 3×3,128; 1×1,512] × 4 → 28×28×512
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Layer3: [1×1,256; 3×3,256; 1×1,1024] × 6 → 14×14×1024
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Layer4: [1×1,512; 3×3,512; 1×1,2048] × 3 → 7×7×2048
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>AvgPool: 7×7 → 1×1×2048
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>FC: 1000 classes</span></span></code></pre></div><h3 id=实现要点>实现要点<a class=anchor href=#%e5%ae%9e%e7%8e%b0%e8%a6%81%e7%82%b9>#</a></h3><p><strong>1. 维度匹配</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ResidualBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>stride</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 如果维度不匹配,使用1×1卷积调整</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>stride</span> <span class=o>!=</span> <span class=mi>1</span> <span class=ow>or</span> <span class=n>in_channels</span> <span class=o>!=</span> <span class=n>out_channels</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>stride</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>out</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>+=</span> <span class=bp>self</span><span class=o>.</span><span class=n>shortcut</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># 残差连接</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>out</span></span></span></code></pre></div><p><strong>2. 梯度流动</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>反向传播:
</span></span><span class=line><span class=cl>∂L/∂x = ∂L/∂H × (∂F/∂x + I)
</span></span><span class=line><span class=cl>      = ∂L/∂H × ∂F/∂x + ∂L/∂H
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>关键: ∂L/∂H 直接传播,不经过中间层!</span></span></code></pre></div><h2 id=52-mobilenet轻量化设计>5.2 MobileNet:轻量化设计<a class=anchor href=#52-mobilenet%e8%bd%bb%e9%87%8f%e5%8c%96%e8%ae%be%e8%ae%a1>#</a></h2><h3 id=设计目标>设计目标<a class=anchor href=#%e8%ae%be%e8%ae%a1%e7%9b%ae%e6%a0%87>#</a></h3><p><strong>目标场景</strong>: 移动端、嵌入式设备
<strong>核心指标</strong>:</p><ul><li>模型大小 &lt; 10MB</li><li>推理速度 &lt; 50ms (CPU)</li><li>准确率损失 &lt; 5%</li></ul><h3 id=深度可分离卷积depthwise-separable-convolution-1>深度可分离卷积(Depthwise Separable Convolution)<a class=anchor href=#%e6%b7%b1%e5%ba%a6%e5%8f%af%e5%88%86%e7%a6%bb%e5%8d%b7%e7%a7%afdepthwise-separable-convolution-1>#</a></h3><p><strong>标准卷积</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: H × W × M
</span></span><span class=line><span class=cl>卷积核: D_K × D_K × M × N
</span></span><span class=line><span class=cl>输出: H × W × N
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>计算量: D_K × D_K × M × N × H × W</span></span></code></pre></div><p><strong>深度可分离卷积 = Depthwise + Pointwise</strong>:</p><p><strong>步骤1: Depthwise卷积</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: H × W × M
</span></span><span class=line><span class=cl>卷积核: D_K × D_K × 1 × M (每个通道独立卷积)
</span></span><span class=line><span class=cl>输出: H × W × M
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>计算量: D_K × D_K × M × H × W</span></span></code></pre></div><p><strong>步骤2: Pointwise卷积</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: H × W × M
</span></span><span class=line><span class=cl>卷积核: 1 × 1 × M × N
</span></span><span class=line><span class=cl>输出: H × W × N
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>计算量: M × N × H × W</span></span></code></pre></div><p><strong>总计算量</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>深度可分离: D_K² × M × HW + M × N × HW
</span></span><span class=line><span class=cl>标准卷积: D_K² × M × N × HW
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>压缩比: (D_K² × M + M × N) / (D_K² × M × N)
</span></span><span class=line><span class=cl>       = 1/N + 1/D_K²
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>例: D_K=3, N=128
</span></span><span class=line><span class=cl>压缩比 = 1/128 + 1/9 ≈ 0.119 (压缩8.4倍)</span></span></code></pre></div><h3 id=mobilenetv1架构>MobileNetV1架构<a class=anchor href=#mobilenetv1%e6%9e%b6%e6%9e%84>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: 224×224×3
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Conv: 3×3, 32, stride=2 → 112×112×32
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>DW: 3×3, 32
</span></span><span class=line><span class=cl>PW: 1×1, 64 → 112×112×64
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>DW: 3×3, 64, stride=2
</span></span><span class=line><span class=cl>PW: 1×1, 128 → 56×56×128
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>DW: 3×3, 128
</span></span><span class=line><span class=cl>PW: 1×1, 128 → 56×56×128
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>... (重复若干次)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>AvgPool → 1×1×1024
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>FC: 1000</span></span></code></pre></div><h3 id=mobilenetv2倒残差结构inverted-residual>MobileNetV2:倒残差结构(Inverted Residual)<a class=anchor href=#mobilenetv2%e5%80%92%e6%ae%8b%e5%b7%ae%e7%bb%93%e6%9e%84inverted-residual>#</a></h3><p><strong>设计思想</strong>: 低维→高维→低维</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>传统残差块: 高维 → 低维 → 高维
</span></span><span class=line><span class=cl>倒残差块: 低维 → 高维 → 低维</span></span></code></pre></div><p><strong>倒残差块结构</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: H × W × C (低维, 如32)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>1×1 Conv, C×t (扩展, t=6) → H × W × C×6 (高维, 192)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>3×3 DW Conv → H × W × C×6
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>1×1 Conv, C → H × W × C (压缩回低维)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>+ ← 输入 (残差连接)</span></span></code></pre></div><p><strong>关键设计</strong>:</p><ol><li><strong>扩展因子</strong> t=6: 在高维空间提取特征</li><li><strong>线性瓶颈</strong>: 最后一层不使用ReLU(避免信息损失)</li><li><strong>残差连接</strong>: 仅在输入输出维度相同时使用</li></ol><h3 id=mobilenetv3神经架构搜索nas>MobileNetV3:神经架构搜索(NAS)<a class=anchor href=#mobilenetv3%e7%a5%9e%e7%bb%8f%e6%9e%b6%e6%9e%84%e6%90%9c%e7%b4%a2nas>#</a></h3><p><strong>改进点</strong>:</p><ol><li><strong>SE模块</strong>(Squeeze-and-Excitation):</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入 → Global Pool → FC → ReLU → FC → Sigmoid → 乘回输入</span></span></code></pre></div><ol start=2><li><strong>h-swish激活</strong>:</li></ol><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>h-swish(x) = x × ReLU6(x + 3) / 6
</span></span><span class=line><span class=cl>优点: 比ReLU性能好,比swish计算快</span></span></code></pre></div><ol start=3><li><strong>优化首尾结构</strong>:</li></ol><ul><li>首层: 减少卷积核数量</li><li>尾层: 提前进行全局池化</li></ul><h3 id=性能对比>性能对比<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>模型</th><th>参数量</th><th>FLOPs</th><th>Top-1(%)</th><th>推理速度(CPU)</th></tr></thead><tbody><tr><td>MobileNetV1</td><td>4.2M</td><td>0.57G</td><td>70.6</td><td>35ms</td></tr><tr><td>MobileNetV2</td><td>3.5M</td><td>0.30G</td><td>72.0</td><td>28ms</td></tr><tr><td>MobileNetV3-Large</td><td>5.4M</td><td>0.22G</td><td>75.2</td><td>25ms</td></tr><tr><td>MobileNetV3-Small</td><td>2.5M</td><td>0.06G</td><td>67.4</td><td>12ms</td></tr></tbody></table><h2 id=53-efficientnet复合缩放>5.3 EfficientNet:复合缩放<a class=anchor href=#53-efficientnet%e5%a4%8d%e5%90%88%e7%bc%a9%e6%94%be>#</a></h2><h3 id=模型缩放的三个维度>模型缩放的三个维度<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e7%bc%a9%e6%94%be%e7%9a%84%e4%b8%89%e4%b8%aa%e7%bb%b4%e5%ba%a6>#</a></h3><p><strong>传统方法</strong>: 单独调整一个维度</p><ul><li><strong>深度(Depth)</strong>: 增加层数 (ResNet-50 → ResNet-101)</li><li><strong>宽度(Width)</strong>: 增加通道数 (ResNet-50 → ResNet-50-Wide)</li><li><strong>分辨率(Resolution)</strong>: 增大输入尺寸 (224×224 → 299×299)</li></ul><h3 id=复合缩放compound-scaling>复合缩放(Compound Scaling)<a class=anchor href=#%e5%a4%8d%e5%90%88%e7%bc%a9%e6%94%becompound-scaling>#</a></h3><p><strong>核心思想</strong>: 平衡三个维度的缩放</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>深度: d = α^φ
</span></span><span class=line><span class=cl>宽度: w = β^φ
</span></span><span class=line><span class=cl>分辨率: r = γ^φ
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>约束: α × β² × γ² ≈ 2
</span></span><span class=line><span class=cl>      α ≥ 1, β ≥ 1, γ ≥ 1</span></span></code></pre></div><p><strong>参数解释</strong>:</p><ul><li>φ: 缩放系数(用户指定)</li><li>α, β, γ: 每个维度的基础缩放因子(通过网格搜索)</li></ul><p><strong>为什么是β²和γ²</strong>:</p><ul><li>FLOPs ∝ d × w² × r²</li><li>约束条件确保FLOPs增长约为2^φ倍</li></ul><h3 id=efficientnet架构>EfficientNet架构<a class=anchor href=#efficientnet%e6%9e%b6%e6%9e%84>#</a></h3><p><strong>基础架构(EfficientNet-B0)</strong>:</p><table><thead><tr><th>Stage</th><th>Operator</th><th>Resolution</th><th>Channels</th><th>Layers</th></tr></thead><tbody><tr><td>1</td><td>Conv3×3</td><td>224×224</td><td>32</td><td>1</td></tr><tr><td>2</td><td>MBConv1, k3×3</td><td>112×112</td><td>16</td><td>1</td></tr><tr><td>3</td><td>MBConv6, k3×3</td><td>112×112</td><td>24</td><td>2</td></tr><tr><td>4</td><td>MBConv6, k5×5</td><td>56×56</td><td>40</td><td>2</td></tr><tr><td>5</td><td>MBConv6, k3×3</td><td>28×28</td><td>80</td><td>3</td></tr><tr><td>6</td><td>MBConv6, k5×5</td><td>14×14</td><td>112</td><td>3</td></tr><tr><td>7</td><td>MBConv6, k5×5</td><td>14×14</td><td>192</td><td>4</td></tr><tr><td>8</td><td>MBConv6, k3×3</td><td>7×7</td><td>320</td><td>1</td></tr><tr><td>9</td><td>Conv1×1, Pool, FC</td><td>7×7</td><td>1280</td><td>1</td></tr></tbody></table><p><strong>MBConv</strong>: MobileNetV2倒残差块 + SE模块</p><h3 id=efficientnet系列>EfficientNet系列<a class=anchor href=#efficientnet%e7%b3%bb%e5%88%97>#</a></h3><p><strong>缩放参数</strong>(α=1.2, β=1.1, γ=1.15):</p><table><thead><tr><th>模型</th><th>φ</th><th>深度</th><th>宽度</th><th>分辨率</th><th>参数量</th><th>FLOPs</th><th>Top-1(%)</th></tr></thead><tbody><tr><td>B0</td><td>0</td><td>1.0</td><td>1.0</td><td>224</td><td>5.3M</td><td>0.39G</td><td>77.1</td></tr><tr><td>B1</td><td>1</td><td>1.2</td><td>1.1</td><td>240</td><td>7.8M</td><td>0.70G</td><td>79.1</td></tr><tr><td>B2</td><td>2</td><td>1.4</td><td>1.2</td><td>260</td><td>9.2M</td><td>1.0G</td><td>80.1</td></tr><tr><td>B3</td><td>3</td><td>1.6</td><td>1.3</td><td>300</td><td>12M</td><td>1.8G</td><td>81.6</td></tr><tr><td>B4</td><td>4</td><td>1.9</td><td>1.4</td><td>380</td><td>19M</td><td>4.2G</td><td>82.9</td></tr><tr><td>B5</td><td>5</td><td>2.3</td><td>1.5</td><td>456</td><td>30M</td><td>9.9G</td><td>83.6</td></tr><tr><td>B6</td><td>6</td><td>2.8</td><td>1.6</td><td>528</td><td>43M</td><td>19G</td><td>84.0</td></tr><tr><td>B7</td><td>7</td><td>3.3</td><td>1.7</td><td>600</td><td>66M</td><td>37G</td><td>84.3</td></tr></tbody></table><h3 id=核心优势>核心优势<a class=anchor href=#%e6%a0%b8%e5%bf%83%e4%bc%98%e5%8a%bf>#</a></h3><p><strong>参数效率</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>同样83%准确率:
</span></span><span class=line><span class=cl>- ResNet-152: 60M参数, 11.6G FLOPs
</span></span><span class=line><span class=cl>- EfficientNet-B3: 12M参数, 1.8G FLOPs
</span></span><span class=line><span class=cl>压缩比: 5倍参数, 6.4倍FLOPs</span></span></code></pre></div><h2 id=54-实战迁移学习与fine-tuning>5.4 实战:迁移学习与Fine-tuning<a class=anchor href=#54-%e5%ae%9e%e6%88%98%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e4%b8%8efine-tuning>#</a></h2><h3 id=迁移学习策略>迁移学习策略<a class=anchor href=#%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e7%ad%96%e7%95%a5>#</a></h3><p><strong>场景分类</strong>:</p><table><thead><tr><th>数据集大小</th><th>与预训练数据相似度</th><th>策略</th></tr></thead><tbody><tr><td>小(&lt;1k)</td><td>高</td><td>冻结所有层,只训练分类头</td></tr><tr><td>小(&lt;1k)</td><td>低</td><td>冻结早期层,微调后期层</td></tr><tr><td>中(1k-10k)</td><td>高</td><td>微调后半部分网络</td></tr><tr><td>中(1k-10k)</td><td>低</td><td>微调大部分网络</td></tr><tr><td>大(>10k)</td><td>高</td><td>全网络微调,小学习率</td></tr><tr><td>大(>10k)</td><td>低</td><td>全网络微调,正常学习率</td></tr></tbody></table><h3 id=实现步骤>实现步骤<a class=anchor href=#%e5%ae%9e%e7%8e%b0%e6%ad%a5%e9%aa%a4>#</a></h3><p><strong>1. 加载预训练模型</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision.models</span> <span class=k>as</span> <span class=nn>models</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方式1: 直接加载</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>models</span><span class=o>.</span><span class=n>resnet50</span><span class=p>(</span><span class=n>weights</span><span class=o>=</span><span class=n>models</span><span class=o>.</span><span class=n>ResNet50_Weights</span><span class=o>.</span><span class=n>IMAGENET1K_V2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方式2: 使用timm(更多模型)</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>timm</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>create_model</span><span class=p>(</span><span class=s1>&#39;resnet50&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div><p><strong>2. 冻结层</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 冻结所有参数</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 冻结特定层</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=s1>&#39;layer1&#39;</span> <span class=ow>in</span> <span class=n>name</span> <span class=ow>or</span> <span class=s1>&#39;layer2&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span></span></span></code></pre></div><p><strong>3. 替换分类头</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ResNet</span>
</span></span><span class=line><span class=cl><span class=n>num_classes</span> <span class=o>=</span> <span class=mi>10</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>fc</span><span class=o>.</span><span class=n>in_features</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># EfficientNet (timm)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>classifier</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>classifier</span><span class=o>.</span><span class=n>in_features</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span></span></span></code></pre></div><p><strong>4. 差异化学习率</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 方式1: 参数分组</span>
</span></span><span class=line><span class=cl><span class=n>params_to_update</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl><span class=n>params_backbone</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=s1>&#39;fc&#39;</span> <span class=ow>in</span> <span class=n>name</span> <span class=ow>or</span> <span class=s1>&#39;classifier&#39;</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>params_to_update</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>param</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>params_backbone</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>param</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>params_backbone</span><span class=p>,</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=mf>1e-4</span><span class=p>},</span>  <span class=c1># 小学习率</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>params_to_update</span><span class=p>,</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=mf>1e-3</span><span class=p>}</span>  <span class=c1># 大学习率</span>
</span></span><span class=line><span class=cl><span class=p>])</span></span></span></code></pre></div><h3 id=fine-tuning技巧>Fine-tuning技巧<a class=anchor href=#fine-tuning%e6%8a%80%e5%b7%a7>#</a></h3><p><strong>1. 渐进式解冻</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># Epoch 1-5: 只训练分类头</span>
</span></span><span class=line><span class=cl><span class=c1># Epoch 6-10: 解冻layer4</span>
</span></span><span class=line><span class=cl><span class=c1># Epoch 11-15: 解冻layer3</span>
</span></span><span class=line><span class=cl><span class=c1># ...</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>unfreeze_layer</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>layer_name</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>model</span><span class=o>.</span><span class=n>named_parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>layer_name</span> <span class=ow>in</span> <span class=n>name</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>True</span></span></span></code></pre></div><p><strong>2. 判别式学习率</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 越深的层学习率越大</span>
</span></span><span class=line><span class=cl><span class=n>lr_mult</span> <span class=o>=</span> <span class=p>[</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.3</span><span class=p>,</span> <span class=mf>0.6</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>]</span>  <span class=c1># layer1-4</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>layer1</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>base_lr</span> <span class=o>*</span> <span class=n>lr_mult</span><span class=p>[</span><span class=mi>0</span><span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>layer2</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>base_lr</span> <span class=o>*</span> <span class=n>lr_mult</span><span class=p>[</span><span class=mi>1</span><span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>layer3</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>base_lr</span> <span class=o>*</span> <span class=n>lr_mult</span><span class=p>[</span><span class=mi>2</span><span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>layer4</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>base_lr</span> <span class=o>*</span> <span class=n>lr_mult</span><span class=p>[</span><span class=mi>3</span><span class=p>]},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s1>&#39;params&#39;</span><span class=p>:</span> <span class=n>model</span><span class=o>.</span><span class=n>fc</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>base_lr</span> <span class=o>*</span> <span class=mi>10</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>],</span> <span class=n>momentum</span><span class=o>=</span><span class=mf>0.9</span><span class=p>)</span></span></span></code></pre></div><p><strong>3. 学习率预热</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>LinearLR</span><span class=p>,</span> <span class=n>SequentialLR</span><span class=p>,</span> <span class=n>CosineAnnealingLR</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>warmup_epochs</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl><span class=n>total_epochs</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预热阶段</span>
</span></span><span class=line><span class=cl><span class=n>warmup_scheduler</span> <span class=o>=</span> <span class=n>LinearLR</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=p>,</span> <span class=n>start_factor</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>end_factor</span><span class=o>=</span><span class=mf>1.0</span><span class=p>,</span> <span class=n>total_iters</span><span class=o>=</span><span class=n>warmup_epochs</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 主训练阶段</span>
</span></span><span class=line><span class=cl><span class=n>main_scheduler</span> <span class=o>=</span> <span class=n>CosineAnnealingLR</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=p>,</span> <span class=n>T_max</span><span class=o>=</span><span class=n>total_epochs</span> <span class=o>-</span> <span class=n>warmup_epochs</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 组合调度器</span>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>SequentialLR</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>schedulers</span><span class=o>=</span><span class=p>[</span><span class=n>warmup_scheduler</span><span class=p>,</span> <span class=n>main_scheduler</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=n>milestones</span><span class=o>=</span><span class=p>[</span><span class=n>warmup_epochs</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=完整训练流程>完整训练流程<a class=anchor href=#%e5%ae%8c%e6%95%b4%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b>#</a></h3><p>见代码文件: <code>code/chapter05_modern_cnn/resnet_transfer_learning.py</code></p><p><strong>核心流程</strong>:</p><ol><li>数据准备与增强</li><li>加载预训练模型</li><li>冻结策略与学习率设置</li><li>训练循环与验证</li><li>模型保存与评估</li></ol><h2 id=架构选择指南>架构选择指南<a class=anchor href=#%e6%9e%b6%e6%9e%84%e9%80%89%e6%8b%a9%e6%8c%87%e5%8d%97>#</a></h2><h3 id=场景匹配>场景匹配<a class=anchor href=#%e5%9c%ba%e6%99%af%e5%8c%b9%e9%85%8d>#</a></h3><table><thead><tr><th>场景</th><th>推荐模型</th><th>理由</th></tr></thead><tbody><tr><td>服务器端高精度</td><td>EfficientNet-B7, ViT-L</td><td>最高精度</td></tr><tr><td>服务器端平衡</td><td>ResNet-50, EfficientNet-B3</td><td>速度精度平衡</td></tr><tr><td>移动端</td><td>MobileNetV3, EfficientNet-B0</td><td>轻量快速</td></tr><tr><td>边缘设备</td><td>MobileNetV3-Small</td><td>极致轻量</td></tr><tr><td>实时应用</td><td>MobileNetV3, EfficientNet-Lite</td><td>低延迟</td></tr></tbody></table><h3 id=性能对比imagenet-1k>性能对比(ImageNet-1K)<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%af%b9%e6%af%94imagenet-1k>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>准确率排序:
</span></span><span class=line><span class=cl>EfficientNet-B7 (84.3%) &gt; ResNet-152 (78.3%) &gt; ResNet-50 (76.2%) &gt; MobileNetV3 (75.2%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>速度排序(GPU):
</span></span><span class=line><span class=cl>MobileNetV3-Small (5ms) &gt; MobileNetV3-Large (8ms) &gt; ResNet-50 (22ms) &gt; EfficientNet-B7 (80ms)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>参数量排序:
</span></span><span class=line><span class=cl>MobileNetV3-Small (2.5M) &lt; MobileNetV3-Large (5.4M) &lt; ResNet-50 (25.6M) &lt; EfficientNet-B7 (66M)</span></span></code></pre></div><h2 id=本章总结>本章总结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%80%bb%e7%bb%93>#</a></h2><h3 id=核心概念>核心概念<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5>#</a></h3><ol><li><strong>ResNet残差连接</strong>: 解决梯度消失,使训练超深网络成为可能</li><li><strong>MobileNet深度可分离卷积</strong>: 大幅降低计算量,适合移动端</li><li><strong>EfficientNet复合缩放</strong>: 平衡深度、宽度、分辨率,实现最佳性能</li></ol><h3 id=关键技术>关键技术<a class=anchor href=#%e5%85%b3%e9%94%ae%e6%8a%80%e6%9c%af>#</a></h3><ul><li>残差连接: <code>y = F(x) + x</code></li><li>深度可分离卷积: Depthwise + Pointwise</li><li>复合缩放: <code>d=α^φ, w=β^φ, r=γ^φ</code></li><li>迁移学习: 冻结+微调</li></ul><h3 id=实战能力>实战能力<a class=anchor href=#%e5%ae%9e%e6%88%98%e8%83%bd%e5%8a%9b>#</a></h3><ul><li>使用torchvision和timm加载预训练模型</li><li>设计合理的冻结策略</li><li>设置差异化学习率</li><li>实现完整的训练流程</li></ul><h3 id=进阶方向>进阶方向<a class=anchor href=#%e8%bf%9b%e9%98%b6%e6%96%b9%e5%90%91>#</a></h3><ul><li><strong>架构搜索</strong>: NAS, AutoML</li><li><strong>知识蒸馏</strong>: 大模型→小模型</li><li><strong>剪枝量化</strong>: 模型压缩</li><li><strong>多任务学习</strong>: 共享特征提取器</li></ul><h2 id=练习题>练习题<a class=anchor href=#%e7%bb%83%e4%b9%a0%e9%a2%98>#</a></h2><ol><li><strong>理论题</strong>: 推导深度可分离卷积相比标准卷积的计算量压缩比</li><li><strong>实现题</strong>: 从零实现一个基础ResNet-18</li><li><strong>实战题</strong>: 在Caltech-101数据集上对比ResNet、MobileNet、EfficientNet的性能</li><li><strong>思考题</strong>: 为什么ViT需要更大的数据集,而ResNet在小数据集上表现更好?</li></ol><h2 id=参考资料>参考资料<a class=anchor href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99>#</a></h2><h3 id=论文>论文<a class=anchor href=#%e8%ae%ba%e6%96%87>#</a></h3><ul><li><a href=https://arxiv.org/abs/1512.03385>Deep Residual Learning for Image Recognition</a> (ResNet, CVPR 2016)</li><li><a href=https://arxiv.org/abs/1704.04861>MobileNets: Efficient CNNs for Mobile Vision</a> (MobileNetV1, 2017)</li><li><a href=https://arxiv.org/abs/1801.04381>MobileNetV2: Inverted Residuals and Linear Bottlenecks</a> (CVPR 2018)</li><li><a href=https://arxiv.org/abs/1905.02244>Searching for MobileNetV3</a> (ICCV 2019)</li><li><a href=https://arxiv.org/abs/1905.11946>EfficientNet: Rethinking Model Scaling for CNNs</a> (ICML 2019)</li></ul><h3 id=代码资源>代码资源<a class=anchor href=#%e4%bb%a3%e7%a0%81%e8%b5%84%e6%ba%90>#</a></h3><ul><li>torchvision.models: <a href=https://pytorch.org/vision/stable/models.html>https://pytorch.org/vision/stable/models.html</a></li><li>timm: <a href=https://github.com/huggingface/pytorch-image-models>https://github.com/huggingface/pytorch-image-models</a></li><li>EfficientNet官方实现: <a href=https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet>https://github.com/tensorflow/tpu/tree/master/models/official/efficientnet</a></li></ul><hr><h1 id=第6章attention与transformer-1>第6章:Attention与Transformer<a class=anchor href=#%e7%ac%ac6%e7%ab%a0attention%e4%b8%8etransformer-1>#</a></h1><h2 id=本章概述-1>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0-1>#</a></h2><p>本章深入讲解注意力机制和Transformer架构在计算机视觉中的应用。从Self-Attention的基本原理出发,理解Multi-Head Attention的设计,最终掌握Vision Transformer(ViT)的完整实现。</p><h2 id=学习目标-1>学习目标<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e7%9b%ae%e6%a0%87-1>#</a></h2><ul><li>理解Self-Attention机制的数学原理</li><li>掌握Multi-Head Attention的设计思想</li><li>深入理解Transformer架构</li><li>实战:使用ViT进行图像分类</li></ul><h2 id=61-注意力机制原理>6.1 注意力机制原理<a class=anchor href=#61-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6%e5%8e%9f%e7%90%86>#</a></h2><h3 id=注意力的直观理解>注意力的直观理解<a class=anchor href=#%e6%b3%a8%e6%84%8f%e5%8a%9b%e7%9a%84%e7%9b%b4%e8%a7%82%e7%90%86%e8%a7%a3>#</a></h3><p><strong>人类视觉注意力</strong>:</p><ul><li>看图片时不会平等关注所有区域</li><li>会聚焦到重要的区域(如人脸、物体)</li><li>根据上下文动态调整注意力</li></ul><p><strong>计算机视觉中的注意力</strong>:</p><ul><li>让模型学习"关注哪里"</li><li>动态加权不同位置的特征</li><li>建模长距离依赖关系</li></ul><h3 id=attention机制演进>Attention机制演进<a class=anchor href=#attention%e6%9c%ba%e5%88%b6%e6%bc%94%e8%bf%9b>#</a></h3><p><strong>1. Soft Attention (2015)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>α_i = exp(e_i) / Σ exp(e_j)  # 注意力权重
</span></span><span class=line><span class=cl>output = Σ α_i × v_i           # 加权求和</span></span></code></pre></div><p><strong>2. Self-Attention (2017)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>从序列自身计算注意力
</span></span><span class=line><span class=cl>不依赖外部信息</span></span></code></pre></div><p><strong>3. Multi-Head Attention (2017)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>多个注意力头
</span></span><span class=line><span class=cl>捕获不同类型的关系</span></span></code></pre></div><h3 id=self-attention数学原理>Self-Attention数学原理<a class=anchor href=#self-attention%e6%95%b0%e5%ad%a6%e5%8e%9f%e7%90%86>#</a></h3><p><strong>输入</strong>: 序列 X = [x₁, x₂, &mldr;, xₙ] ∈ ℝⁿˣᵈ</p><p><strong>三个关键矩阵</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Query (查询): Q = XW_Q ∈ ℝⁿˣᵈₖ
</span></span><span class=line><span class=cl>Key (键): K = XW_K ∈ ℝⁿˣᵈₖ
</span></span><span class=line><span class=cl>Value (值): V = XW_V ∈ ℝⁿˣᵈᵥ
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>参数: W_Q, W_K ∈ ℝᵈˣᵈₖ, W_V ∈ ℝᵈˣᵈᵥ</span></span></code></pre></div><p><strong>Scaled Dot-Product Attention</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Attention(Q, K, V) = softmax(QK^T / √d_k) × V
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>步骤:
</span></span><span class=line><span class=cl>1. 计算相似度: S = QK^T ∈ ℝⁿˣⁿ
</span></span><span class=line><span class=cl>2. 缩放: S = S / √d_k (防止梯度消失)
</span></span><span class=line><span class=cl>3. 归一化: A = softmax(S) (注意力权重)
</span></span><span class=line><span class=cl>4. 加权求和: Output = A × V</span></span></code></pre></div><p><strong>为什么要缩放(除以√d_k)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>假设 Q, K 的元素独立同分布 N(0, 1)
</span></span><span class=line><span class=cl>则 QK^T 的元素方差约为 d_k
</span></span><span class=line><span class=cl>除以 √d_k 使方差归一化到 1
</span></span><span class=line><span class=cl>避免 softmax 进入饱和区(梯度消失)</span></span></code></pre></div><h3 id=self-attention示例>Self-Attention示例<a class=anchor href=#self-attention%e7%a4%ba%e4%be%8b>#</a></h3><p><strong>输入序列</strong>: &ldquo;我 爱 自然语言处理&rdquo;</p><p><strong>计算过程</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>1. 将每个词映射到Q, K, V:
</span></span><span class=line><span class=cl>   Q_我 = [0.2, 0.5, ...], K_我 = [0.3, 0.1, ...], V_我 = [0.8, 0.2, ...]
</span></span><span class=line><span class=cl>   ...
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>2. 计算&#34;我&#34;对所有词的注意力分数:
</span></span><span class=line><span class=cl>   score(我, 我) = Q_我 · K_我 = 0.8
</span></span><span class=line><span class=cl>   score(我, 爱) = Q_我 · K_爱 = 0.6
</span></span><span class=line><span class=cl>   score(我, 自然语言处理) = Q_我 · K_自然语言处理 = 0.2
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>3. 归一化(softmax):
</span></span><span class=line><span class=cl>   α_我→我 = 0.4
</span></span><span class=line><span class=cl>   α_我→爱 = 0.5
</span></span><span class=line><span class=cl>   α_我→自然语言处理 = 0.1
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>4. 加权求和:
</span></span><span class=line><span class=cl>   Output_我 = 0.4 × V_我 + 0.5 × V_爱 + 0.1 × V_自然语言处理</span></span></code></pre></div><h3 id=计算复杂度>计算复杂度<a class=anchor href=#%e8%ae%a1%e7%ae%97%e5%a4%8d%e6%9d%82%e5%ba%a6>#</a></h3><p><strong>时间复杂度</strong>: O(n²d)</p><ul><li>计算 QK^T: O(n²d)</li><li>计算 AV: O(n²d)</li><li>总计: O(n²d)</li></ul><p><strong>空间复杂度</strong>: O(n²)</p><ul><li>注意力矩阵: n×n</li></ul><p><strong>问题</strong>: 序列长度n大时(如高分辨率图像),复杂度过高</p><h3 id=self-attention实现>Self-Attention实现<a class=anchor href=#self-attention%e5%ae%9e%e7%8e%b0>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SelfAttention</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>:</span> <span class=nb>int</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>:</span> <span class=nb>int</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embed_dim</span> <span class=o>=</span> <span class=n>embed_dim</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>head_dim</span> <span class=o>=</span> <span class=n>head_dim</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Q, K, V投影</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>,</span> <span class=n>head_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scale</span> <span class=o>=</span> <span class=n>head_dim</span> <span class=o>**</span> <span class=o>-</span><span class=mf>0.5</span>  <span class=c1># 1/√d_k</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            x: (batch_size, seq_len, embed_dim)
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            (batch_size, seq_len, head_dim)
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>B</span><span class=p>,</span> <span class=n>N</span><span class=p>,</span> <span class=n>C</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 投影</span>
</span></span><span class=line><span class=cl>        <span class=n>Q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>q_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># (B, N, head_dim)</span>
</span></span><span class=line><span class=cl>        <span class=n>K</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>k_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># (B, N, head_dim)</span>
</span></span><span class=line><span class=cl>        <span class=n>V</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>v_proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># (B, N, head_dim)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算注意力分数</span>
</span></span><span class=line><span class=cl>        <span class=n>attn</span> <span class=o>=</span> <span class=p>(</span><span class=n>Q</span> <span class=o>@</span> <span class=n>K</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=o>-</span><span class=mi>2</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>))</span> <span class=o>*</span> <span class=bp>self</span><span class=o>.</span><span class=n>scale</span>  <span class=c1># (B, N, N)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 归一化</span>
</span></span><span class=line><span class=cl>        <span class=n>attn</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>attn</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># (B, N, N)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 加权求和</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>attn</span> <span class=o>@</span> <span class=n>V</span>  <span class=c1># (B, N, head_dim)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>out</span></span></span></code></pre></div><h2 id=62-transformer架构详解>6.2 Transformer架构详解<a class=anchor href=#62-transformer%e6%9e%b6%e6%9e%84%e8%af%a6%e8%a7%a3>#</a></h2><h3 id=transformer整体架构>Transformer整体架构<a class=anchor href=#transformer%e6%95%b4%e4%bd%93%e6%9e%b6%e6%9e%84>#</a></h3><p><strong>原始Transformer</strong>(用于NLP):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入序列
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Embedding + Positional Encoding
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Encoder (N层):
</span></span><span class=line><span class=cl>  - Multi-Head Attention
</span></span><span class=line><span class=cl>  - Add &amp; Norm
</span></span><span class=line><span class=cl>  - Feed Forward
</span></span><span class=line><span class=cl>  - Add &amp; Norm
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Decoder (N层):
</span></span><span class=line><span class=cl>  - Masked Multi-Head Attention
</span></span><span class=line><span class=cl>  - Add &amp; Norm
</span></span><span class=line><span class=cl>  - Cross Attention
</span></span><span class=line><span class=cl>  - Add &amp; Norm
</span></span><span class=line><span class=cl>  - Feed Forward
</span></span><span class=line><span class=cl>  - Add &amp; Norm
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>输出</span></span></code></pre></div><p><strong>编码器层(Encoder Layer)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入 x
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Multi-Head Attention → Add &amp; Norm
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Feed Forward Network → Add &amp; Norm
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>输出</span></span></code></pre></div><h3 id=multi-head-attention>Multi-Head Attention<a class=anchor href=#multi-head-attention>#</a></h3><p><strong>核心思想</strong>: 多个注意力头并行计算,捕获不同类型的关系</p><p><strong>架构</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入 X ∈ ℝⁿˣᵈ
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>分成h个头,每个头维度 d_k = d/h
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Head₁ = Attention(XW_Q1, XW_K1, XW_V1)
</span></span><span class=line><span class=cl>Head₂ = Attention(XW_Q2, XW_K2, XW_V2)
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>Headₕ = Attention(XW_Qh, XW_Kh, XW_Vh)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Concat(Head₁, Head₂, ..., Headₕ)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>线性投影 W_O
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>输出 ∈ ℝⁿˣᵈ</span></span></code></pre></div><p><strong>数学表达</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>MultiHead(Q, K, V) = Concat(head₁, ..., headₕ)W_O
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中:
</span></span><span class=line><span class=cl>head_i = Attention(QW_Qi, KW_Ki, VW_Vi)</span></span></code></pre></div><p><strong>为什么要多头</strong>:</p><ul><li>不同的头可以关注不同的特征</li><li>类比CNN的多个卷积核</li><li>增强模型的表达能力</li></ul><p><strong>示例</strong>(h=8, d=512):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>每个头的维度: d_k = 512/8 = 64
</span></span><span class=line><span class=cl>Head 1: 关注局部纹理
</span></span><span class=line><span class=cl>Head 2: 关注全局形状
</span></span><span class=line><span class=cl>Head 3: 关注颜色
</span></span><span class=line><span class=cl>...</span></span></code></pre></div><h3 id=位置编码positional-encoding>位置编码(Positional Encoding)<a class=anchor href=#%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81positional-encoding>#</a></h3><p><strong>问题</strong>: Self-Attention对位置不敏感</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: [A, B, C]
</span></span><span class=line><span class=cl>输入: [C, B, A]
</span></span><span class=line><span class=cl>注意力矩阵相同(如果Q, K, V投影相同)</span></span></code></pre></div><p><strong>解决</strong>: 添加位置信息</p><p><strong>正弦位置编码</strong>(原始Transformer):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>PE(pos, 2i) = sin(pos / 10000^(2i/d))
</span></span><span class=line><span class=cl>PE(pos, 2i+1) = cos(pos / 10000^(2i/d))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中:
</span></span><span class=line><span class=cl>- pos: 位置索引
</span></span><span class=line><span class=cl>- i: 维度索引
</span></span><span class=line><span class=cl>- d: 嵌入维度</span></span></code></pre></div><p><strong>可学习位置编码</strong>(ViT使用):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>position_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))</span></span></code></pre></div><h3 id=feed-forward-network-ffn>Feed-Forward Network (FFN)<a class=anchor href=#feed-forward-network-ffn>#</a></h3><p><strong>结构</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>FFN(x) = max(0, xW₁ + b₁)W₂ + b₂
</span></span><span class=line><span class=cl>      = GELU(xW₁ + b₁)W₂ + b₂  (现代变体)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中:
</span></span><span class=line><span class=cl>- W₁: d → d_ff (通常 d_ff = 4d)
</span></span><span class=line><span class=cl>- W₂: d_ff → d</span></span></code></pre></div><p><strong>作用</strong>:</p><ul><li>增加非线性</li><li>独立处理每个位置</li><li>增强表达能力</li></ul><h3 id=layer-normalization>Layer Normalization<a class=anchor href=#layer-normalization>#</a></h3><p><strong>公式</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>LN(x) = γ × (x - μ) / σ + β
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中:
</span></span><span class=line><span class=cl>- μ, σ: 沿特征维度计算的均值和标准差
</span></span><span class=line><span class=cl>- γ, β: 可学习参数</span></span></code></pre></div><p><strong>位置</strong>: Pre-LN vs Post-LN</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Post-LN (原始):
</span></span><span class=line><span class=cl>x = x + Attention(LN(x))
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Pre-LN (更稳定):
</span></span><span class=line><span class=cl>x = LN(x + Attention(x))</span></span></code></pre></div><h3 id=完整transformer-encoder实现>完整Transformer Encoder实现<a class=anchor href=#%e5%ae%8c%e6%95%b4transformer-encoder%e5%ae%9e%e7%8e%b0>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>TransformerEncoder</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>embed_dim</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>768</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>num_heads</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>12</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>mlp_ratio</span><span class=p>:</span> <span class=nb>int</span> <span class=o>=</span> <span class=mi>4</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>dropout</span><span class=p>:</span> <span class=nb>float</span> <span class=o>=</span> <span class=mf>0.1</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>attn</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>MultiheadAttention</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>embed_dim</span><span class=p>,</span> <span class=n>num_heads</span><span class=p>,</span> <span class=n>dropout</span><span class=o>=</span><span class=n>dropout</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>norm2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>LayerNorm</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>,</span> <span class=n>embed_dim</span> <span class=o>*</span> <span class=n>mlp_ratio</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embed_dim</span> <span class=o>*</span> <span class=n>mlp_ratio</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>dropout</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># Multi-Head Attention</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>attn</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>x</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>norm1</span><span class=p>(</span><span class=n>x</span><span class=p>))[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># FFN</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>mlp</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>norm2</span><span class=p>(</span><span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span></span></span></code></pre></div><h2 id=63-vision-transformer-vit>6.3 Vision Transformer (ViT)<a class=anchor href=#63-vision-transformer-vit>#</a></h2><h3 id=vit核心思想>ViT核心思想<a class=anchor href=#vit%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3>#</a></h3><p><strong>将图像视为序列</strong>:</p><ul><li>图像分成固定大小的patch</li><li>每个patch展平成向量</li><li>当作序列输入Transformer</li></ul><h3 id=vit架构详解>ViT架构详解<a class=anchor href=#vit%e6%9e%b6%e6%9e%84%e8%af%a6%e8%a7%a3>#</a></h3><p><strong>完整流程</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入图像: H × W × C (如 224×224×3)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>分割成patch: (H/P) × (W/P) × (P²C)
</span></span><span class=line><span class=cl>  例: 224/16 × 224/16 × (16²×3) = 14×14×768
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>展平: N × (P²C), N = (H/W)² = 196
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>线性投影: N × D (D=768)
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>添加 [CLS] token: (N+1) × D
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>添加位置编码: (N+1) × D
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>Transformer Encoder × L层
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>提取 [CLS] token
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>MLP Head → 分类</span></span></code></pre></div><p><strong>关键组件</strong>:</p><p><strong>1. Patch Embedding</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 方式1: 展平 + 线性投影</span>
</span></span><span class=line><span class=cl><span class=n>patch_size</span> <span class=o>=</span> <span class=mi>16</span>
</span></span><span class=line><span class=cl><span class=n>num_patches</span> <span class=o>=</span> <span class=p>(</span><span class=mi>224</span> <span class=o>//</span> <span class=mi>16</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>  <span class=c1># 196</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 输入: (B, 3, 224, 224)</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>unfold</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=n>patch_size</span><span class=p>,</span> <span class=n>patch_size</span><span class=p>)</span><span class=o>.</span><span class=n>unfold</span><span class=p>(</span><span class=mi>3</span><span class=p>,</span> <span class=n>patch_size</span><span class=p>,</span> <span class=n>patch_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># (B, 3, 14, 14, 16, 16)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>4</span><span class=p>,</span> <span class=mi>5</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>num_patches</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># (B, 196, 768)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>linear_projection</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># (B, 196, embed_dim)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方式2: 卷积(等价且更快)</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>patch_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>in_channels</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>out_channels</span><span class=o>=</span><span class=n>embed_dim</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>kernel_size</span><span class=o>=</span><span class=n>patch_size</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>stride</span><span class=o>=</span><span class=n>patch_size</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>2. CLS Token</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 可学习的分类token</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>cls_token</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 添加到序列开头</span>
</span></span><span class=line><span class=cl><span class=n>cls_tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>cls_token</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># (B, 1, embed_dim)</span>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>cls_tokens</span><span class=p>,</span> <span class=n>x</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># (B, N+1, embed_dim)</span></span></span></code></pre></div><p><strong>3. 位置编码</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 可学习位置编码</span>
</span></span><span class=line><span class=cl><span class=bp>self</span><span class=o>.</span><span class=n>pos_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_patches</span> <span class=o>+</span> <span class=mi>1</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>pos_embed</span></span></span></code></pre></div><h3 id=vit模型配置>ViT模型配置<a class=anchor href=#vit%e6%a8%a1%e5%9e%8b%e9%85%8d%e7%bd%ae>#</a></h3><p><strong>标准配置</strong>:</p><table><thead><tr><th>模型</th><th>Patch Size</th><th>Embed Dim</th><th>Depth</th><th>Heads</th><th>MLP Ratio</th><th>Params</th></tr></thead><tbody><tr><td>ViT-Ti/16</td><td>16</td><td>192</td><td>12</td><td>3</td><td>4</td><td>5.7M</td></tr><tr><td>ViT-S/16</td><td>16</td><td>384</td><td>12</td><td>6</td><td>4</td><td>22M</td></tr><tr><td>ViT-B/16</td><td>16</td><td>768</td><td>12</td><td>12</td><td>4</td><td>86M</td></tr><tr><td>ViT-B/32</td><td>32</td><td>768</td><td>12</td><td>12</td><td>4</td><td>88M</td></tr><tr><td>ViT-L/16</td><td>16</td><td>1024</td><td>24</td><td>16</td><td>4</td><td>307M</td></tr><tr><td>ViT-H/14</td><td>14</td><td>1280</td><td>32</td><td>16</td><td>4</td><td>632M</td></tr></tbody></table><p><strong>命名规则</strong>: ViT-{Size}/{Patch Size}</p><h3 id=vit-vs-cnn>ViT vs CNN<a class=anchor href=#vit-vs-cnn>#</a></h3><p><strong>归纳偏置(Inductive Bias)</strong>:</p><table><thead><tr><th>特性</th><th>CNN</th><th>ViT</th></tr></thead><tbody><tr><td>局部性</td><td>强(卷积核)</td><td>弱(全局注意力)</td></tr><tr><td>平移不变性</td><td>强</td><td>弱</td></tr><tr><td>数据需求</td><td>中等</td><td>大量</td></tr><tr><td>计算复杂度</td><td>O(n)</td><td>O(n²)</td></tr></tbody></table><p><strong>性能对比</strong>(ImageNet-1K):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>小数据集(&lt;100k):
</span></span><span class=line><span class=cl>ResNet-50 (76.2%) &gt; ViT-B/16 (75.0%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>大数据集(ImageNet-21K预训练):
</span></span><span class=line><span class=cl>ViT-B/16 (84.0%) &gt; ResNet-50 (80.4%)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>超大数据集(JFT-300M预训练):
</span></span><span class=line><span class=cl>ViT-H/14 (88.5%) &gt;&gt; ResNet-152 (82.0%)</span></span></code></pre></div><h3 id=vit变体>ViT变体<a class=anchor href=#vit%e5%8f%98%e4%bd%93>#</a></h3><p><strong>1. DeiT (Data-efficient ViT)</strong>:</p><ul><li>知识蒸馏</li><li>在ImageNet-1K上训练即可</li><li>性能接近大规模预训练的ViT</li></ul><p><strong>2. Swin Transformer</strong>:</p><ul><li>层次化架构(类似CNN)</li><li>窗口注意力(降低复杂度)</li><li>适合密集预测任务</li></ul><p><strong>3. PVT (Pyramid Vision Transformer)</strong>:</p><ul><li>金字塔结构</li><li>渐进式降采样</li><li>多尺度特征</li></ul><h2 id=64-实战vit图像分类>6.4 实战:ViT图像分类<a class=anchor href=#64-%e5%ae%9e%e6%88%98vit%e5%9b%be%e5%83%8f%e5%88%86%e7%b1%bb>#</a></h2><h3 id=使用timm库>使用timm库<a class=anchor href=#%e4%bd%bf%e7%94%a8timm%e5%ba%93>#</a></h3><p><strong>加载预训练模型</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>timm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看可用模型</span>
</span></span><span class=line><span class=cl><span class=n>models</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>list_models</span><span class=p>(</span><span class=s1>&#39;vit*&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>models</span><span class=p>[:</span><span class=mi>5</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=c1># [&#39;vit_base_patch16_224&#39;, &#39;vit_base_patch32_224&#39;, ...]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>create_model</span><span class=p>(</span><span class=s1>&#39;vit_base_patch16_224&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 查看模型结构</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>model</span><span class=p>)</span></span></span></code></pre></div><h3 id=完整训练流程-1>完整训练流程<a class=anchor href=#%e5%ae%8c%e6%95%b4%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b-1>#</a></h3><p>见代码文件: <code>code/chapter06_transformer/vit_classification.py</code></p><p><strong>关键点</strong>:</p><ol><li><strong>数据增强</strong>: 更强的增强(RandAugment, CutMix)</li><li><strong>学习率</strong>: 较小的学习率(1e-4)</li><li><strong>训练轮数</strong>: 更多epoch(300+)</li><li><strong>正则化</strong>: Dropout, Stochastic Depth</li><li><strong>优化器</strong>: AdamW + 权重衰减</li></ol><h3 id=vit训练技巧>ViT训练技巧<a class=anchor href=#vit%e8%ae%ad%e7%bb%83%e6%8a%80%e5%b7%a7>#</a></h3><p><strong>1. 预训练权重</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># ImageNet-1K预训练</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>create_model</span><span class=p>(</span><span class=s1>&#39;vit_base_patch16_224&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ImageNet-21K预训练(更好)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>create_model</span><span class=p>(</span><span class=s1>&#39;vit_base_patch16_224.augreg_in21k&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div><p><strong>2. 图像尺寸调整</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 预训练: 224×224</span>
</span></span><span class=line><span class=cl><span class=c1># 微调: 可以用更大尺寸(384×384)</span>
</span></span><span class=line><span class=cl><span class=c1># 需要插值位置编码</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>interpolate_pos_embed</span><span class=p>(</span><span class=n>pos_embed</span><span class=p>,</span> <span class=n>orig_size</span><span class=p>,</span> <span class=n>new_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># pos_embed: (1, N+1, D)</span>
</span></span><span class=line><span class=cl>    <span class=n>cls_pos</span> <span class=o>=</span> <span class=n>pos_embed</span><span class=p>[:,</span> <span class=p>:</span><span class=mi>1</span><span class=p>,</span> <span class=p>:]</span>  <span class=c1># CLS token</span>
</span></span><span class=line><span class=cl>    <span class=n>patch_pos</span> <span class=o>=</span> <span class=n>pos_embed</span><span class=p>[:,</span> <span class=mi>1</span><span class=p>:,</span> <span class=p>:]</span>  <span class=c1># Patch positions</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 插值</span>
</span></span><span class=line><span class=cl>    <span class=n>patch_pos</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>interpolate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>patch_pos</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>orig_size</span><span class=p>,</span> <span class=n>orig_size</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>size</span><span class=o>=</span><span class=p>(</span><span class=n>new_size</span><span class=p>,</span> <span class=n>new_size</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>mode</span><span class=o>=</span><span class=s1>&#39;bicubic&#39;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>patch_pos</span> <span class=o>=</span> <span class=n>patch_pos</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>pos_embed</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=o>-</span><span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>cls_pos</span><span class=p>,</span> <span class=n>patch_pos</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></div><p><strong>3. 混合精度训练</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.cuda.amp</span> <span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>dataloader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span></span></span></code></pre></div><h3 id=性能优化>性能优化<a class=anchor href=#%e6%80%a7%e8%83%bd%e4%bc%98%e5%8c%96>#</a></h3><p><strong>1. 降低计算复杂度</strong>:</p><ul><li>使用更小的patch size(ViT-B/32 vs ViT-B/16)</li><li>使用Swin Transformer(窗口注意力)</li></ul><p><strong>2. 加速训练</strong>:</p><ul><li>混合精度训练(FP16)</li><li>梯度累积</li><li>分布式训练</li></ul><p><strong>3. 提升精度</strong>:</p><ul><li>更强的数据增强</li><li>知识蒸馏</li><li>模型ensemble</li></ul><h2 id=注意力可视化>注意力可视化<a class=anchor href=#%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%8f%af%e8%a7%86%e5%8c%96>#</a></h2><h3 id=可视化注意力图>可视化注意力图<a class=anchor href=#%e5%8f%af%e8%a7%86%e5%8c%96%e6%b3%a8%e6%84%8f%e5%8a%9b%e5%9b%be>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>visualize_attention</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>image</span><span class=p>,</span> <span class=n>layer_idx</span><span class=o>=</span><span class=mi>11</span><span class=p>,</span> <span class=n>head_idx</span><span class=o>=</span><span class=mi>0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    可视化ViT的注意力图
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        model: ViT模型
</span></span></span><span class=line><span class=cl><span class=s2>        image: 输入图像
</span></span></span><span class=line><span class=cl><span class=s2>        layer_idx: Transformer层索引
</span></span></span><span class=line><span class=cl><span class=s2>        head_idx: 注意力头索引
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 注册hook获取注意力权重</span>
</span></span><span class=line><span class=cl>    <span class=n>attentions</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>hook_fn</span><span class=p>(</span><span class=n>module</span><span class=p>,</span> <span class=nb>input</span><span class=p>,</span> <span class=n>output</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># output: (attn_weights, attn_output)</span>
</span></span><span class=line><span class=cl>        <span class=n>attentions</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>hook</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>blocks</span><span class=p>[</span><span class=n>layer_idx</span><span class=p>]</span><span class=o>.</span><span class=n>attn</span><span class=o>.</span><span class=n>attn_drop</span><span class=o>.</span><span class=n>register_forward_hook</span><span class=p>(</span><span class=n>hook_fn</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 前向传播</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>_</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>hook</span><span class=o>.</span><span class=n>remove</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 获取注意力权重: (B, num_heads, N+1, N+1)</span>
</span></span><span class=line><span class=cl>    <span class=n>attn</span> <span class=o>=</span> <span class=n>attentions</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>,</span> <span class=n>head_idx</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>:]</span>  <span class=c1># CLS对所有patch的注意力</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 重塑为2D</span>
</span></span><span class=line><span class=cl>    <span class=n>size</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>attn</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span> <span class=o>**</span> <span class=mf>0.5</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>attn_map</span> <span class=o>=</span> <span class=n>attn</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=n>size</span><span class=p>,</span> <span class=n>size</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 可视化</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>attn_map</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;viridis&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>colorbar</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;Attention Map - Layer </span><span class=si>{</span><span class=n>layer_idx</span><span class=si>}</span><span class=s1>, Head </span><span class=si>{</span><span class=n>head_idx</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span></span></span></code></pre></div><h2 id=本章总结-1>本章总结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%80%bb%e7%bb%93-1>#</a></h2><h3 id=核心概念-1>核心概念<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5-1>#</a></h3><ol><li><strong>Self-Attention</strong>: 通过Q、K、V矩阵计算序列内部关系</li><li><strong>Multi-Head Attention</strong>: 多个头捕获不同类型的依赖</li><li><strong>Transformer</strong>: 完全基于注意力的架构,无卷积</li><li><strong>Vision Transformer</strong>: 将图像分patch,用Transformer处理</li></ol><h3 id=关键公式>关键公式<a class=anchor href=#%e5%85%b3%e9%94%ae%e5%85%ac%e5%bc%8f>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Self-Attention:
</span></span><span class=line><span class=cl>Attention(Q, K, V) = softmax(QK^T / √d_k) × V
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Multi-Head:
</span></span><span class=line><span class=cl>MultiHead(Q, K, V) = Concat(head₁, ..., headₕ)W_O
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Positional Encoding:
</span></span><span class=line><span class=cl>PE(pos, 2i) = sin(pos / 10000^(2i/d))
</span></span><span class=line><span class=cl>PE(pos, 2i+1) = cos(pos / 10000^(2i/d))</span></span></code></pre></div><h3 id=vit优势与挑战>ViT优势与挑战<a class=anchor href=#vit%e4%bc%98%e5%8a%bf%e4%b8%8e%e6%8c%91%e6%88%98>#</a></h3><p><strong>优势</strong>:</p><ul><li>全局感受野</li><li>可扩展性强</li><li>大数据集上性能优异</li></ul><p><strong>挑战</strong>:</p><ul><li>需要大量数据</li><li>计算复杂度高(O(n²))</li><li>缺少归纳偏置</li></ul><h3 id=实战技巧>实战技巧<a class=anchor href=#%e5%ae%9e%e6%88%98%e6%8a%80%e5%b7%a7>#</a></h3><ul><li>使用ImageNet-21K预训练权重</li><li>强数据增强(RandAugment, Mixup)</li><li>较小学习率 + 更多epoch</li><li>混合精度训练加速</li></ul><h2 id=练习题-1>练习题<a class=anchor href=#%e7%bb%83%e4%b9%a0%e9%a2%98-1>#</a></h2><ol><li><strong>理论题</strong>: 推导Self-Attention的计算复杂度为O(n²d)</li><li><strong>实现题</strong>: 从零实现Multi-Head Attention</li><li><strong>实战题</strong>: 在CIFAR-100上对比ResNet和ViT</li><li><strong>思考题</strong>: 为什么ViT在大数据集上表现更好?</li></ol><h2 id=参考资料-1>参考资料<a class=anchor href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%96%99-1>#</a></h2><h3 id=论文-1>论文<a class=anchor href=#%e8%ae%ba%e6%96%87-1>#</a></h3><ul><li><a href=https://arxiv.org/abs/1706.03762>Attention Is All You Need</a> (Transformer, NeurIPS 2017)</li><li><a href=https://arxiv.org/abs/2010.11929>An Image is Worth 16x16 Words</a> (ViT, ICLR 2021)</li><li><a href=https://arxiv.org/abs/2012.12877>Training data-efficient image transformers</a> (DeiT, 2021)</li><li><a href=https://arxiv.org/abs/2103.14030>Swin Transformer</a> (ICCV 2021)</li></ul><h3 id=代码资源-1>代码资源<a class=anchor href=#%e4%bb%a3%e7%a0%81%e8%b5%84%e6%ba%90-1>#</a></h3><ul><li>timm: <a href=https://github.com/huggingface/pytorch-image-models>https://github.com/huggingface/pytorch-image-models</a></li><li>ViT官方实现: <a href=https://github.com/google-research/vision_transformer>https://github.com/google-research/vision_transformer</a></li><li>Swin Transformer: <a href=https://github.com/microsoft/Swin-Transformer>https://github.com/microsoft/Swin-Transformer</a></li></ul><hr><h1 id=第7章数据增强与训练技巧-1>第7章：数据增强与训练技巧<a class=anchor href=#%e7%ac%ac7%e7%ab%a0%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba%e4%b8%8e%e8%ae%ad%e7%bb%83%e6%8a%80%e5%b7%a7-1>#</a></h1><blockquote class=book-hint><p><strong>训练优化篇</strong> - 掌握现代深度学习训练的核心技术</p></blockquote><h2 id=本章概览>本章概览<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%a7%88>#</a></h2><p>本章系统讲解深度学习训练的各种优化技巧，包括数据增强、学习率调度、正则化等，帮助你构建高性能的训练流程。</p><p><strong>核心内容</strong>：</p><ul><li>传统与现代数据增强技术</li><li>学习率调度策略</li><li>正则化与防过拟合</li><li>完整训练流程设计</li></ul><h2 id=为什么训练技巧如此重要>为什么训练技巧如此重要？<a class=anchor href=#%e4%b8%ba%e4%bb%80%e4%b9%88%e8%ae%ad%e7%bb%83%e6%8a%80%e5%b7%a7%e5%a6%82%e6%ad%a4%e9%87%8d%e8%a6%81>#</a></h2><p><strong>同样的模型架构，不同的训练技巧可能导致5-10%的精度差异！</strong></p><p>影响因素：</p><ol><li><strong>数据增强</strong> - 有效扩充训练数据，提升泛化能力</li><li><strong>学习率调度</strong> - 合适的学习率策略加速收敛</li><li><strong>正则化</strong> - 防止过拟合，提升测试集表现</li><li><strong>训练配置</strong> - batch size、优化器选择等</li></ol><hr><h2 id=71-传统数据增强>7.1 传统数据增强<a class=anchor href=#71-%e4%bc%a0%e7%bb%9f%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba>#</a></h2><h3 id=711-基础几何变换>7.1.1 基础几何变换<a class=anchor href=#711-%e5%9f%ba%e7%a1%80%e5%87%a0%e4%bd%95%e5%8f%98%e6%8d%a2>#</a></h3><p><strong>PyTorch原生实现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision</span> <span class=kn>import</span> <span class=n>transforms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 基础增强组合</span>
</span></span><span class=line><span class=cl><span class=n>basic_transforms</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomHorizontalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>  <span class=c1># 水平翻转</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomVerticalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>    <span class=c1># 垂直翻转（适用于特定任务）</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomRotation</span><span class=p>(</span><span class=n>degrees</span><span class=o>=</span><span class=mi>15</span><span class=p>),</span>    <span class=c1># 随机旋转</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=p>(</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)),</span>  <span class=c1># 随机裁剪缩放</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=p>])</span></span></span></code></pre></div><p><strong>几何变换对比</strong>：</p><table><thead><tr><th>变换</th><th>参数</th><th>适用场景</th><th>注意事项</th></tr></thead><tbody><tr><td><strong>水平翻转</strong></td><td>p=0.5</td><td>通用场景</td><td>文字识别慎用</td></tr><tr><td><strong>垂直翻转</strong></td><td>p=0.1-0.5</td><td>医学影像、卫星图</td><td>自然图像少用</td></tr><tr><td><strong>旋转</strong></td><td>±15-30°</td><td>通用</td><td>数字、字母慎用</td></tr><tr><td><strong>随机裁剪</strong></td><td>scale=(0.8, 1.0)</td><td>通用</td><td>小目标检测少用</td></tr><tr><td><strong>透视变换</strong></td><td>自定义</td><td>文档、OCR</td><td>需保持可读性</td></tr></tbody></table><h3 id=712-色彩变换>7.1.2 色彩变换<a class=anchor href=#712-%e8%89%b2%e5%bd%a9%e5%8f%98%e6%8d%a2>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>color_transforms</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>ColorJitter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>brightness</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span>   <span class=c1># 亮度变化 ±20%</span>
</span></span><span class=line><span class=cl>        <span class=n>contrast</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span>     <span class=c1># 对比度变化 ±20%</span>
</span></span><span class=line><span class=cl>        <span class=n>saturation</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span>   <span class=c1># 饱和度变化 ±20%</span>
</span></span><span class=line><span class=cl>        <span class=n>hue</span><span class=o>=</span><span class=mf>0.1</span>          <span class=c1># 色调变化 ±10%</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomGrayscale</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.1</span><span class=p>),</span>  <span class=c1># 10%概率转灰度</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>GaussianBlur</span><span class=p>(</span><span class=n>kernel_size</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>sigma</span><span class=o>=</span><span class=p>(</span><span class=mf>0.1</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>)),</span>  <span class=c1># 高斯模糊</span>
</span></span><span class=line><span class=cl><span class=p>])</span></span></span></code></pre></div><h3 id=713-使用albumentations>7.1.3 使用Albumentations<a class=anchor href=#713-%e4%bd%bf%e7%94%a8albumentations>#</a></h3><p><strong>Albumentations</strong> 是更强大的数据增强库：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>albumentations</span> <span class=k>as</span> <span class=nn>A</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>albumentations.pytorch</span> <span class=kn>import</span> <span class=n>ToTensorV2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 高级增强组合</span>
</span></span><span class=line><span class=cl><span class=n>train_transforms</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=c1># 几何变换</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>HorizontalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>ShiftScaleRotate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>shift_limit</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>scale_limit</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>rotate_limit</span><span class=o>=</span><span class=mi>15</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span>
</span></span><span class=line><span class=cl>    <span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=n>height</span><span class=o>=</span><span class=mi>224</span><span class=p>,</span> <span class=n>width</span><span class=o>=</span><span class=mi>224</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=p>(</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 色彩变换</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>OneOf</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>A</span><span class=o>.</span><span class=n>ColorJitter</span><span class=p>(</span><span class=n>brightness</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>contrast</span><span class=o>=</span><span class=mf>0.2</span><span class=p>,</span> <span class=n>saturation</span><span class=o>=</span><span class=mf>0.2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>A</span><span class=o>.</span><span class=n>HueSaturationValue</span><span class=p>(</span><span class=n>hue_shift_limit</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>sat_shift_limit</span><span class=o>=</span><span class=mi>30</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>A</span><span class=o>.</span><span class=n>RandomBrightnessContrast</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 噪声与模糊</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>OneOf</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=n>A</span><span class=o>.</span><span class=n>GaussianBlur</span><span class=p>(</span><span class=n>blur_limit</span><span class=o>=</span><span class=mi>3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=n>A</span><span class=o>.</span><span class=n>GaussNoise</span><span class=p>(</span><span class=n>var_limit</span><span class=o>=</span><span class=p>(</span><span class=mf>10.0</span><span class=p>,</span> <span class=mf>50.0</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>        <span class=n>A</span><span class=o>.</span><span class=n>ISONoise</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=p>],</span> <span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 标准化</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span> <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>ToTensorV2</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证集增强（只做标准化）</span>
</span></span><span class=line><span class=cl><span class=n>val_transforms</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>Resize</span><span class=p>(</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span> <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>ToTensorV2</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用方式</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>CustomDataset</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>utils</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>Dataset</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_paths</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>transform</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span> <span class=o>=</span> <span class=n>image_paths</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>labels</span> <span class=o>=</span> <span class=n>labels</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>transform</span> <span class=o>=</span> <span class=n>transform</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__getitem__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>idx</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>[</span><span class=n>idx</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>cvtColor</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cv2</span><span class=o>.</span><span class=n>COLOR_BGR2RGB</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>label</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>labels</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>augmented</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>image</span><span class=o>=</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>image</span> <span class=o>=</span> <span class=n>augmented</span><span class=p>[</span><span class=s1>&#39;image&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>image</span><span class=p>,</span> <span class=n>label</span></span></span></code></pre></div><hr><h2 id=72-现代数据增强>7.2 现代数据增强<a class=anchor href=#72-%e7%8e%b0%e4%bb%a3%e6%95%b0%e6%8d%ae%e5%a2%9e%e5%bc%ba>#</a></h2><h3 id=721-mixup>7.2.1 Mixup<a class=anchor href=#721-mixup>#</a></h3><p><strong>核心思想</strong>：将两张图像线性混合</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>mixup_data</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.2</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Mixup数据增强
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        x: 输入图像 (B, C, H, W)
</span></span></span><span class=line><span class=cl><span class=s2>        y: 标签 (B,)
</span></span></span><span class=line><span class=cl><span class=s2>        alpha: Beta分布参数
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        mixed_x: 混合后的图像
</span></span></span><span class=line><span class=cl><span class=s2>        y_a, y_b: 原始标签对
</span></span></span><span class=line><span class=cl><span class=s2>        lam: 混合比例
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>alpha</span> <span class=o>&gt;</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>lam</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>beta</span><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>lam</span> <span class=o>=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>mixed_x</span> <span class=o>=</span> <span class=n>lam</span> <span class=o>*</span> <span class=n>x</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>lam</span><span class=p>)</span> <span class=o>*</span> <span class=n>x</span><span class=p>[</span><span class=n>index</span><span class=p>,</span> <span class=p>:]</span>
</span></span><span class=line><span class=cl>    <span class=n>y_a</span><span class=p>,</span> <span class=n>y_b</span> <span class=o>=</span> <span class=n>y</span><span class=p>,</span> <span class=n>y</span><span class=p>[</span><span class=n>index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>mixed_x</span><span class=p>,</span> <span class=n>y_a</span><span class=p>,</span> <span class=n>y_b</span><span class=p>,</span> <span class=n>lam</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mixup_criterion</span><span class=p>(</span><span class=n>criterion</span><span class=p>,</span> <span class=n>pred</span><span class=p>,</span> <span class=n>y_a</span><span class=p>,</span> <span class=n>y_b</span><span class=p>,</span> <span class=n>lam</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;Mixup损失函数&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>lam</span> <span class=o>*</span> <span class=n>criterion</span><span class=p>(</span><span class=n>pred</span><span class=p>,</span> <span class=n>y_a</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>lam</span><span class=p>)</span> <span class=o>*</span> <span class=n>criterion</span><span class=p>(</span><span class=n>pred</span><span class=p>,</span> <span class=n>y_b</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练循环中使用</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>cuda</span><span class=p>(),</span> <span class=n>labels</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 应用Mixup</span>
</span></span><span class=line><span class=cl>    <span class=n>images</span><span class=p>,</span> <span class=n>labels_a</span><span class=p>,</span> <span class=n>labels_b</span><span class=p>,</span> <span class=n>lam</span> <span class=o>=</span> <span class=n>mixup_data</span><span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>mixup_criterion</span><span class=p>(</span><span class=n>criterion</span><span class=p>,</span> <span class=n>outputs</span><span class=p>,</span> <span class=n>labels_a</span><span class=p>,</span> <span class=n>labels_b</span><span class=p>,</span> <span class=n>lam</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span></span></span></code></pre></div><h3 id=722-cutmix>7.2.2 CutMix<a class=anchor href=#722-cutmix>#</a></h3><p><strong>核心思想</strong>：将一张图像的矩形区域替换为另一张图像</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>cutmix_data</span><span class=p>(</span><span class=n>x</span><span class=p>,</span> <span class=n>y</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>1.0</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    CutMix数据增强
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        x: 输入图像 (B, C, H, W)
</span></span></span><span class=line><span class=cl><span class=s2>        y: 标签 (B,)
</span></span></span><span class=line><span class=cl><span class=s2>        alpha: Beta分布参数
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>lam</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>beta</span><span class=p>(</span><span class=n>alpha</span><span class=p>,</span> <span class=n>alpha</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>index</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randperm</span><span class=p>(</span><span class=n>batch_size</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>x</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算剪切区域</span>
</span></span><span class=line><span class=cl>    <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>    <span class=n>cut_ratio</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>sqrt</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>lam</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cut_h</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>H</span> <span class=o>*</span> <span class=n>cut_ratio</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cut_w</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>W</span> <span class=o>*</span> <span class=n>cut_ratio</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 随机中心点</span>
</span></span><span class=line><span class=cl>    <span class=n>cx</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>cy</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>random</span><span class=o>.</span><span class=n>randint</span><span class=p>(</span><span class=n>H</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 边界框</span>
</span></span><span class=line><span class=cl>    <span class=n>bbx1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>cx</span> <span class=o>-</span> <span class=n>cut_w</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>bby1</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>cy</span> <span class=o>-</span> <span class=n>cut_h</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>H</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>bbx2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>cx</span> <span class=o>+</span> <span class=n>cut_w</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>bby2</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>cy</span> <span class=o>+</span> <span class=n>cut_h</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=n>H</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 替换区域</span>
</span></span><span class=line><span class=cl>    <span class=n>x</span><span class=p>[:,</span> <span class=p>:,</span> <span class=n>bby1</span><span class=p>:</span><span class=n>bby2</span><span class=p>,</span> <span class=n>bbx1</span><span class=p>:</span><span class=n>bbx2</span><span class=p>]</span> <span class=o>=</span> <span class=n>x</span><span class=p>[</span><span class=n>index</span><span class=p>,</span> <span class=p>:,</span> <span class=n>bby1</span><span class=p>:</span><span class=n>bby2</span><span class=p>,</span> <span class=n>bbx1</span><span class=p>:</span><span class=n>bbx2</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 调整lambda（基于实际裁剪面积）</span>
</span></span><span class=line><span class=cl>    <span class=n>lam</span> <span class=o>=</span> <span class=mi>1</span> <span class=o>-</span> <span class=p>((</span><span class=n>bbx2</span> <span class=o>-</span> <span class=n>bbx1</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=n>bby2</span> <span class=o>-</span> <span class=n>bby1</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=n>W</span> <span class=o>*</span> <span class=n>H</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>y_a</span><span class=p>,</span> <span class=n>y_b</span> <span class=o>=</span> <span class=n>y</span><span class=p>,</span> <span class=n>y</span><span class=p>[</span><span class=n>index</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>x</span><span class=p>,</span> <span class=n>y_a</span><span class=p>,</span> <span class=n>y_b</span><span class=p>,</span> <span class=n>lam</span></span></span></code></pre></div><h3 id=723-autoaugment>7.2.3 AutoAugment<a class=anchor href=#723-autoaugment>#</a></h3><p><strong>核心思想</strong>：使用搜索算法找到最优增强策略</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>AutoAugment</span><span class=p>,</span> <span class=n>AutoAugmentPolicy</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用预定义的AutoAugment策略</span>
</span></span><span class=line><span class=cl><span class=n>auto_augment</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>AutoAugment</span><span class=p>(</span><span class=n>policy</span><span class=o>=</span><span class=n>AutoAugmentPolicy</span><span class=o>.</span><span class=n>IMAGENET</span><span class=p>),</span>  <span class=c1># ImageNet策略</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 可选策略</span>
</span></span><span class=line><span class=cl><span class=c1># - AutoAugmentPolicy.IMAGENET  # ImageNet优化</span>
</span></span><span class=line><span class=cl><span class=c1># - AutoAugmentPolicy.CIFAR10   # CIFAR-10优化</span>
</span></span><span class=line><span class=cl><span class=c1># - AutoAugmentPolicy.SVHN      # SVHN优化</span></span></span></code></pre></div><h3 id=724-randaugment>7.2.4 RandAugment<a class=anchor href=#724-randaugment>#</a></h3><p><strong>更简单的自动增强</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.transforms</span> <span class=kn>import</span> <span class=n>RandAugment</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># N=2: 随机选择2个变换</span>
</span></span><span class=line><span class=cl><span class=c1># M=9: 变换强度（0-30）</span>
</span></span><span class=line><span class=cl><span class=n>rand_augment</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>RandAugment</span><span class=p>(</span><span class=n>num_ops</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>magnitude</span><span class=o>=</span><span class=mi>9</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                        <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=p>])</span></span></span></code></pre></div><h3 id=725-增强策略对比>7.2.5 增强策略对比<a class=anchor href=#725-%e5%a2%9e%e5%bc%ba%e7%ad%96%e7%95%a5%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>方法</th><th>提升幅度</th><th>计算开销</th><th>复杂度</th><th>推荐场景</th></tr></thead><tbody><tr><td><strong>基础增强</strong></td><td>+1-2%</td><td>低</td><td>简单</td><td>快速实验</td></tr><tr><td><strong>Mixup</strong></td><td>+1-2%</td><td>低</td><td>简单</td><td>通用分类</td></tr><tr><td><strong>CutMix</strong></td><td>+1-3%</td><td>低</td><td>简单</td><td>定位相关</td></tr><tr><td><strong>AutoAugment</strong></td><td>+1-3%</td><td>高(搜索)</td><td>复杂</td><td>最终模型</td></tr><tr><td><strong>RandAugment</strong></td><td>+1-2.5%</td><td>中</td><td>简单</td><td>推荐首选</td></tr></tbody></table><hr><h2 id=73-学习率调度>7.3 学习率调度<a class=anchor href=#73-%e5%ad%a6%e4%b9%a0%e7%8e%87%e8%b0%83%e5%ba%a6>#</a></h2><h3 id=731-常用调度器>7.3.1 常用调度器<a class=anchor href=#731-%e5%b8%b8%e7%94%a8%e8%b0%83%e5%ba%a6%e5%99%a8>#</a></h3><p><strong>1. StepLR（阶梯衰减）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>StepLR</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>SGD</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>StepLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>step_size</span><span class=o>=</span><span class=mi>30</span><span class=p>,</span> <span class=n>gamma</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 每30个epoch学习率乘以0.1</span>
</span></span><span class=line><span class=cl><span class=c1># 0.1 -&gt; 0.01 -&gt; 0.001 -&gt; ...</span></span></span></code></pre></div><p><strong>2. CosineAnnealingLR（余弦退火）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>CosineAnnealingLR</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>CosineAnnealingLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>T_max</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>eta_min</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 学习率从初始值余弦衰减到eta_min</span>
</span></span><span class=line><span class=cl><span class=c1># lr = eta_min + 0.5 * (lr_init - eta_min) * (1 + cos(π * t / T_max))</span></span></span></code></pre></div><p><strong>3. CosineAnnealingWarmRestarts（带重启的余弦退火）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>CosineAnnealingWarmRestarts</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>CosineAnnealingWarmRestarts</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>T_0</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>T_mult</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 周期性重启：10, 20, 40, 80... epochs</span></span></span></code></pre></div><p><strong>4. OneCycleLR（一周期策略）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.optim.lr_scheduler</span> <span class=kn>import</span> <span class=n>OneCycleLR</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>OneCycleLR</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_lr</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>steps_per_epoch</span><span class=o>=</span><span class=nb>len</span><span class=p>(</span><span class=n>train_loader</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>pct_start</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span>  <span class=c1># 前30%用于warmup</span>
</span></span><span class=line><span class=cl>    <span class=n>anneal_strategy</span><span class=o>=</span><span class=s1>&#39;cos&#39;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 每个batch后更新</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>batch</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... 训练 ...</span>
</span></span><span class=line><span class=cl>    <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span></span></span></code></pre></div><h3 id=732-warmup策略>7.3.2 Warmup策略<a class=anchor href=#732-warmup%e7%ad%96%e7%95%a5>#</a></h3><p><strong>线性Warmup + Cosine衰减</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>WarmupCosineScheduler</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>warmup_epochs</span><span class=p>,</span> <span class=n>total_epochs</span><span class=p>,</span> <span class=n>min_lr</span><span class=o>=</span><span class=mf>1e-6</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optimizer</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>warmup_epochs</span> <span class=o>=</span> <span class=n>warmup_epochs</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>total_epochs</span> <span class=o>=</span> <span class=n>total_epochs</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>min_lr</span> <span class=o>=</span> <span class=n>min_lr</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>base_lr</span> <span class=o>=</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;lr&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>step</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>epoch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>epoch</span> <span class=o>&lt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_epochs</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 线性warmup</span>
</span></span><span class=line><span class=cl>            <span class=n>lr</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>base_lr</span> <span class=o>*</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_epochs</span>
</span></span><span class=line><span class=cl>        <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 余弦衰减</span>
</span></span><span class=line><span class=cl>            <span class=n>progress</span> <span class=o>=</span> <span class=p>(</span><span class=n>epoch</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_epochs</span><span class=p>)</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>total_epochs</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>warmup_epochs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>lr</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>min_lr</span> <span class=o>+</span> <span class=mf>0.5</span> <span class=o>*</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>base_lr</span> <span class=o>-</span> <span class=bp>self</span><span class=o>.</span><span class=n>min_lr</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>+</span> <span class=n>math</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>math</span><span class=o>.</span><span class=n>pi</span> <span class=o>*</span> <span class=n>progress</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>param_group</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>param_group</span><span class=p>[</span><span class=s1>&#39;lr&#39;</span><span class=p>]</span> <span class=o>=</span> <span class=n>lr</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>lr</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>WarmupCosineScheduler</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>warmup_epochs</span><span class=o>=</span><span class=mi>5</span><span class=p>,</span> <span class=n>total_epochs</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>100</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>lr</span> <span class=o>=</span> <span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>, LR: </span><span class=si>{</span><span class=n>lr</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... 训练 ...</span></span></span></code></pre></div><h3 id=733-调度策略对比>7.3.3 调度策略对比<a class=anchor href=#733-%e8%b0%83%e5%ba%a6%e7%ad%96%e7%95%a5%e5%af%b9%e6%af%94>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>学习率变化曲线示意:
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>StepLR:           ___________
</span></span><span class=line><span class=cl>                           \___________
</span></span><span class=line><span class=cl>                                      \___________
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>CosineAnnealing:  ‾‾‾‾‾‾‾‾‾‾‾\_____________________/
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>OneCycle:              /\
</span></span><span class=line><span class=cl>                      /  \
</span></span><span class=line><span class=cl>                     /    \_______
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>Warmup+Cosine:       /‾‾‾‾‾‾‾‾‾‾\_____________________</span></span></code></pre></div><table><thead><tr><th>策略</th><th>特点</th><th>推荐场景</th></tr></thead><tbody><tr><td><strong>StepLR</strong></td><td>简单直观</td><td>快速实验</td></tr><tr><td><strong>CosineAnnealing</strong></td><td>平滑衰减</td><td>标准训练</td></tr><tr><td><strong>OneCycleLR</strong></td><td>超级收敛</td><td>追求快速收敛</td></tr><tr><td><strong>Warmup+Cosine</strong></td><td>稳定训练</td><td>大模型、Transformer</td></tr></tbody></table><hr><h2 id=74-正则化与防过拟合>7.4 正则化与防过拟合<a class=anchor href=#74-%e6%ad%a3%e5%88%99%e5%8c%96%e4%b8%8e%e9%98%b2%e8%bf%87%e6%8b%9f%e5%90%88>#</a></h2><h3 id=741-weight-decayl2正则化>7.4.1 Weight Decay（L2正则化）<a class=anchor href=#741-weight-decayl2%e6%ad%a3%e5%88%99%e5%8c%96>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>    <span class=n>lr</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>weight_decay</span><span class=o>=</span><span class=mf>0.01</span>  <span class=c1># L2正则化系数</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 注意：AdamW是解耦的weight decay，推荐使用</span>
</span></span><span class=line><span class=cl><span class=c1># SGD + weight_decay = L2正则化</span>
</span></span><span class=line><span class=cl><span class=c1># Adam + weight_decay ≠ 严格的L2正则化</span>
</span></span><span class=line><span class=cl><span class=c1># AdamW = 正确的weight decay实现</span></span></span></code></pre></div><h3 id=742-dropout>7.4.2 Dropout<a class=anchor href=#742-dropout>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ModelWithDropout</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>features</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=c1># ... 卷积层 ...</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>  <span class=c1># 训练时随机丢弃50%</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>2048</span><span class=p>,</span> <span class=mi>512</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Dropout</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.3</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>512</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>features</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>classifier</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span></span></span></code></pre></div><h3 id=743-label-smoothing>7.4.3 Label Smoothing<a class=anchor href=#743-label-smoothing>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>LabelSmoothingLoss</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>,</span> <span class=n>smoothing</span><span class=o>=</span><span class=mf>0.1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_classes</span> <span class=o>=</span> <span class=n>num_classes</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>smoothing</span> <span class=o>=</span> <span class=n>smoothing</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>confidence</span> <span class=o>=</span> <span class=mf>1.0</span> <span class=o>-</span> <span class=n>smoothing</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>pred</span><span class=p>,</span> <span class=n>target</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        pred: (B, num_classes) - 未归一化的logits
</span></span></span><span class=line><span class=cl><span class=s2>        target: (B,) - 类别索引
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>pred</span> <span class=o>=</span> <span class=n>pred</span><span class=o>.</span><span class=n>log_softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=c1># 创建平滑标签</span>
</span></span><span class=line><span class=cl>            <span class=n>true_dist</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros_like</span><span class=p>(</span><span class=n>pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>true_dist</span><span class=o>.</span><span class=n>fill_</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>smoothing</span> <span class=o>/</span> <span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>num_classes</span> <span class=o>-</span> <span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>true_dist</span><span class=o>.</span><span class=n>scatter_</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>target</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>1</span><span class=p>),</span> <span class=bp>self</span><span class=o>.</span><span class=n>confidence</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=o>-</span><span class=n>true_dist</span> <span class=o>*</span> <span class=n>pred</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>LabelSmoothingLoss</span><span class=p>(</span><span class=n>num_classes</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span> <span class=n>smoothing</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或使用PyTorch内置</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>(</span><span class=n>label_smoothing</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span></span></span></code></pre></div><h3 id=744-stochastic-depth随机深度>7.4.4 Stochastic Depth（随机深度）<a class=anchor href=#744-stochastic-depth%e9%9a%8f%e6%9c%ba%e6%b7%b1%e5%ba%a6>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>StochasticDepthResBlock</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;随机深度残差块&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=n>survival_prob</span><span class=o>=</span><span class=mf>0.8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>survival_prob</span> <span class=o>=</span> <span class=n>survival_prob</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>conv2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>,</span> <span class=n>out_channels</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>BatchNorm2d</span><span class=p>(</span><span class=n>out_channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>residual</span> <span class=o>=</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 训练时随机跳过</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>rand</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>survival_prob</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>return</span> <span class=n>residual</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>bn1</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv1</span><span class=p>(</span><span class=n>x</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>bn2</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>conv2</span><span class=p>(</span><span class=n>out</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>training</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>out</span> <span class=o>=</span> <span class=n>out</span> <span class=o>/</span> <span class=bp>self</span><span class=o>.</span><span class=n>survival_prob</span>  <span class=c1># 缩放补偿</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>F</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>out</span> <span class=o>+</span> <span class=n>residual</span><span class=p>)</span></span></span></code></pre></div><h3 id=745-防过拟合策略总结>7.4.5 防过拟合策略总结<a class=anchor href=#745-%e9%98%b2%e8%bf%87%e6%8b%9f%e5%90%88%e7%ad%96%e7%95%a5%e6%80%bb%e7%bb%93>#</a></h3><table><thead><tr><th>方法</th><th>适用场景</th><th>推荐强度</th></tr></thead><tbody><tr><td><strong>Weight Decay</strong></td><td>通用</td><td>0.01-0.1</td></tr><tr><td><strong>Dropout</strong></td><td>全连接层</td><td>0.3-0.5</td></tr><tr><td><strong>Label Smoothing</strong></td><td>分类任务</td><td>0.1</td></tr><tr><td><strong>数据增强</strong></td><td>数据量少</td><td>强增强</td></tr><tr><td><strong>Early Stopping</strong></td><td>验证损失上升</td><td>patience=10-20</td></tr><tr><td><strong>Stochastic Depth</strong></td><td>深层网络</td><td>0.8-0.9</td></tr></tbody></table><hr><h2 id=75-混合精度训练>7.5 混合精度训练<a class=anchor href=#75-%e6%b7%b7%e5%90%88%e7%b2%be%e5%ba%a6%e8%ae%ad%e7%bb%83>#</a></h2><h3 id=751-pytorch-amp>7.5.1 PyTorch AMP<a class=anchor href=#751-pytorch-amp>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.cuda.amp</span> <span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初始化</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Model</span><span class=p>()</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>1e-3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>num_epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>cuda</span><span class=p>(),</span> <span class=n>labels</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 自动混合精度前向传播</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 缩放反向传播</span>
</span></span><span class=line><span class=cl>        <span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 优化器步骤</span>
</span></span><span class=line><span class=cl>        <span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span></span></span></code></pre></div><p><strong>混合精度优势</strong>：</p><table><thead><tr><th>指标</th><th>FP32</th><th>FP16 (AMP)</th></tr></thead><tbody><tr><td><strong>显存占用</strong></td><td>100%</td><td>~50%</td></tr><tr><td><strong>训练速度</strong></td><td>1x</td><td>1.5-3x</td></tr><tr><td><strong>精度损失</strong></td><td>基准</td><td>&lt;0.1%</td></tr></tbody></table><hr><h2 id=76-实战完整训练流程>7.6 实战：完整训练流程<a class=anchor href=#76-%e5%ae%9e%e6%88%98%e5%ae%8c%e6%95%b4%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b>#</a></h2><h3 id=完整训练脚本>完整训练脚本<a class=anchor href=#%e5%ae%8c%e6%95%b4%e8%ae%ad%e7%bb%83%e8%84%9a%e6%9c%ac>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.cuda.amp</span> <span class=kn>import</span> <span class=n>autocast</span><span class=p>,</span> <span class=n>GradScaler</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torch.utils.data</span> <span class=kn>import</span> <span class=n>DataLoader</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>albumentations</span> <span class=k>as</span> <span class=nn>A</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>albumentations.pytorch</span> <span class=kn>import</span> <span class=n>ToTensorV2</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>wandb</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Trainer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>train_loader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>val_loader</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>criterion</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>scheduler</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span>
</span></span><span class=line><span class=cl>    <span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span> <span class=o>=</span> <span class=n>train_loader</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>val_loader</span> <span class=o>=</span> <span class=n>val_loader</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span> <span class=o>=</span> <span class=n>optimizer</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>criterion</span> <span class=o>=</span> <span class=n>criterion</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scheduler</span> <span class=o>=</span> <span class=n>scheduler</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>config</span> <span class=o>=</span> <span class=n>config</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>scaler</span> <span class=o>=</span> <span class=n>GradScaler</span><span class=p>()</span> <span class=k>if</span> <span class=n>config</span><span class=o>.</span><span class=n>use_amp</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>best_acc</span> <span class=o>=</span> <span class=mf>0.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>train_epoch</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>epoch</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>train</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>pbar</span> <span class=o>=</span> <span class=n>tqdm</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span><span class=p>,</span> <span class=n>desc</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>pbar</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>cuda</span><span class=p>(),</span> <span class=n>labels</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># Mixup (可选)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>use_mixup</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>images</span><span class=p>,</span> <span class=n>labels_a</span><span class=p>,</span> <span class=n>labels_b</span><span class=p>,</span> <span class=n>lam</span> <span class=o>=</span> <span class=n>mixup_data</span><span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 混合精度前向</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>use_amp</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>with</span> <span class=n>autocast</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                    <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>use_mixup</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>loss</span> <span class=o>=</span> <span class=n>mixup_criterion</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>criterion</span><span class=p>,</span> <span class=n>outputs</span><span class=p>,</span> <span class=n>labels_a</span><span class=p>,</span> <span class=n>labels_b</span><span class=p>,</span> <span class=n>lam</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                        <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>scaler</span><span class=o>.</span><span class=n>scale</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>scaler</span><span class=o>.</span><span class=n>step</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>scaler</span><span class=o>.</span><span class=n>update</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>use_mixup</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>loss</span> <span class=o>=</span> <span class=n>mixup_criterion</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>criterion</span><span class=p>,</span> <span class=n>outputs</span><span class=p>,</span> <span class=n>labels_a</span><span class=p>,</span> <span class=n>labels_b</span><span class=p>,</span> <span class=n>lam</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>correct</span> <span class=o>+=</span> <span class=n>predicted</span><span class=o>.</span><span class=n>eq</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>pbar</span><span class=o>.</span><span class=n>set_postfix</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;loss&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span><span class=si>:</span><span class=s1>.4f</span><span class=si>}</span><span class=s1>&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;acc&#39;</span><span class=p>:</span> <span class=sa>f</span><span class=s1>&#39;</span><span class=si>{</span><span class=mf>100.</span><span class=o>*</span><span class=n>correct</span><span class=o>/</span><span class=n>total</span><span class=si>:</span><span class=s1>.2f</span><span class=si>}</span><span class=s1>%&#39;</span>
</span></span><span class=line><span class=cl>            <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>train_loader</span><span class=p>),</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@torch.no_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>validate</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>total_loss</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>correct</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>        <span class=n>total</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>val_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=o>=</span> <span class=n>images</span><span class=o>.</span><span class=n>cuda</span><span class=p>(),</span> <span class=n>labels</span><span class=o>.</span><span class=n>cuda</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>loss</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>total_loss</span> <span class=o>+=</span> <span class=n>loss</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>_</span><span class=p>,</span> <span class=n>predicted</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>max</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>total</span> <span class=o>+=</span> <span class=n>labels</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>correct</span> <span class=o>+=</span> <span class=n>predicted</span><span class=o>.</span><span class=n>eq</span><span class=p>(</span><span class=n>labels</span><span class=p>)</span><span class=o>.</span><span class=n>sum</span><span class=p>()</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>total_loss</span> <span class=o>/</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>val_loader</span><span class=p>),</span> <span class=n>correct</span> <span class=o>/</span> <span class=n>total</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>train</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>epochs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=c1># 训练</span>
</span></span><span class=line><span class=cl>            <span class=n>train_loss</span><span class=p>,</span> <span class=n>train_acc</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>train_epoch</span><span class=p>(</span><span class=n>epoch</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 验证</span>
</span></span><span class=line><span class=cl>            <span class=n>val_loss</span><span class=p>,</span> <span class=n>val_acc</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>validate</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 更新学习率</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>scheduler</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>current_lr</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>param_groups</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=s1>&#39;lr&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 日志</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Epoch </span><span class=si>{</span><span class=n>epoch</span><span class=si>}</span><span class=s2>: &#34;</span>
</span></span><span class=line><span class=cl>                  <span class=sa>f</span><span class=s2>&#34;Train Loss: </span><span class=si>{</span><span class=n>train_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>, Train Acc: </span><span class=si>{</span><span class=n>train_acc</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%, &#34;</span>
</span></span><span class=line><span class=cl>                  <span class=sa>f</span><span class=s2>&#34;Val Loss: </span><span class=si>{</span><span class=n>val_loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>, Val Acc: </span><span class=si>{</span><span class=n>val_acc</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%, &#34;</span>
</span></span><span class=line><span class=cl>                  <span class=sa>f</span><span class=s2>&#34;LR: </span><span class=si>{</span><span class=n>current_lr</span><span class=si>:</span><span class=s2>.6f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># W&amp;B记录</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>use_wandb</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>wandb</span><span class=o>.</span><span class=n>log</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;epoch&#39;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;train_loss&#39;</span><span class=p>:</span> <span class=n>train_loss</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;train_acc&#39;</span><span class=p>:</span> <span class=n>train_acc</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;val_loss&#39;</span><span class=p>:</span> <span class=n>val_loss</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;val_acc&#39;</span><span class=p>:</span> <span class=n>val_acc</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;lr&#39;</span><span class=p>:</span> <span class=n>current_lr</span>
</span></span><span class=line><span class=cl>                <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 保存最佳模型</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>val_acc</span> <span class=o>&gt;</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_acc</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=bp>self</span><span class=o>.</span><span class=n>best_acc</span> <span class=o>=</span> <span class=n>val_acc</span>
</span></span><span class=line><span class=cl>                <span class=n>torch</span><span class=o>.</span><span class=n>save</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;epoch&#39;</span><span class=p>:</span> <span class=n>epoch</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;model_state_dict&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;optimizer_state_dict&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>optimizer</span><span class=o>.</span><span class=n>state_dict</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>                    <span class=s1>&#39;best_acc&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>best_acc</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=p>},</span> <span class=s1>&#39;best_model.pth&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;✓ Best model saved (Acc: </span><span class=si>{</span><span class=n>val_acc</span><span class=o>*</span><span class=mi>100</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>%)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 配置</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Config</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>epochs</span> <span class=o>=</span> <span class=mi>100</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>32</span>
</span></span><span class=line><span class=cl>    <span class=n>lr</span> <span class=o>=</span> <span class=mf>0.001</span>
</span></span><span class=line><span class=cl>    <span class=n>weight_decay</span> <span class=o>=</span> <span class=mf>0.01</span>
</span></span><span class=line><span class=cl>    <span class=n>warmup_epochs</span> <span class=o>=</span> <span class=mi>5</span>
</span></span><span class=line><span class=cl>    <span class=n>use_amp</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=n>use_mixup</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>    <span class=n>use_wandb</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>config</span> <span class=o>=</span> <span class=n>Config</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 数据增强</span>
</span></span><span class=line><span class=cl><span class=n>train_transforms</span> <span class=o>=</span> <span class=n>A</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>RandomResizedCrop</span><span class=p>(</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=n>scale</span><span class=o>=</span><span class=p>(</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>1.0</span><span class=p>)),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>HorizontalFlip</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mf>0.5</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>RandAugment</span><span class=p>(</span><span class=n>num_ops</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>magnitude</span><span class=o>=</span><span class=mi>9</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=n>A</span><span class=o>.</span><span class=n>Normalize</span><span class=p>(</span><span class=n>mean</span><span class=o>=</span><span class=p>[</span><span class=mf>0.485</span><span class=p>,</span> <span class=mf>0.456</span><span class=p>,</span> <span class=mf>0.406</span><span class=p>],</span> <span class=n>std</span><span class=o>=</span><span class=p>[</span><span class=mf>0.229</span><span class=p>,</span> <span class=mf>0.224</span><span class=p>,</span> <span class=mf>0.225</span><span class=p>]),</span>
</span></span><span class=line><span class=cl>    <span class=n>ToTensorV2</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>timm</span><span class=o>.</span><span class=n>create_model</span><span class=p>(</span><span class=s1>&#39;resnet50&#39;</span><span class=p>,</span> <span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 优化器</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>AdamW</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>lr</span><span class=p>,</span> <span class=n>weight_decay</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>weight_decay</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 调度器</span>
</span></span><span class=line><span class=cl><span class=n>scheduler</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>lr_scheduler</span><span class=o>.</span><span class=n>CosineAnnealingLR</span><span class=p>(</span><span class=n>optimizer</span><span class=p>,</span> <span class=n>T_max</span><span class=o>=</span><span class=n>config</span><span class=o>.</span><span class=n>epochs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 损失函数</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>(</span><span class=n>label_smoothing</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span> <span class=o>=</span> <span class=n>Trainer</span><span class=p>(</span><span class=n>model</span><span class=p>,</span> <span class=n>train_loader</span><span class=p>,</span> <span class=n>val_loader</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>criterion</span><span class=p>,</span> <span class=n>scheduler</span><span class=p>,</span> <span class=n>config</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>()</span></span></span></code></pre></div><hr><h2 id=本章小结>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>#</a></h2><h3 id=核心技术要点>核心技术要点<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%8a%80%e6%9c%af%e8%a6%81%e7%82%b9>#</a></h3><ol><li><p><strong>数据增强</strong></p><ul><li>传统：翻转、旋转、色彩变换</li><li>现代：Mixup、CutMix、RandAugment</li></ul></li><li><p><strong>学习率调度</strong></p><ul><li>Warmup + Cosine是标准选择</li><li>OneCycleLR用于快速收敛</li></ul></li><li><p><strong>正则化</strong></p><ul><li>Weight Decay（AdamW推荐）</li><li>Label Smoothing（分类任务）</li><li>Dropout（全连接层）</li></ul></li><li><p><strong>混合精度</strong></p><ul><li>AMP训练提速1.5-3倍</li><li>显存减少约50%</li></ul></li></ol><h3 id=推荐训练配置>推荐训练配置<a class=anchor href=#%e6%8e%a8%e8%8d%90%e8%ae%ad%e7%bb%83%e9%85%8d%e7%bd%ae>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=nt>通用分类任务</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>optimizer</span><span class=p>:</span><span class=w> </span><span class=l>AdamW</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>lr</span><span class=p>:</span><span class=w> </span><span class=m>0.001</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>weight_decay</span><span class=p>:</span><span class=w> </span><span class=m>0.01</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>scheduler</span><span class=p>:</span><span class=w> </span><span class=l>CosineAnnealing + Warmup(5 epochs)</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>augmentation</span><span class=p>:</span><span class=w> </span><span class=l>RandAugment</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>regularization</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>label_smoothing</span><span class=p>:</span><span class=w> </span><span class=m>0.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>dropout</span><span class=p>:</span><span class=w> </span><span class=m>0.3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>  </span><span class=nt>training</span><span class=p>:</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>amp</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>    </span>- <span class=nt>mixup</span><span class=p>:</span><span class=w> </span><span class=l>alpha=0.2</span></span></span></code></pre></div><h3 id=下一步>下一步<a class=anchor href=#%e4%b8%8b%e4%b8%80%e6%ad%a5>#</a></h3><p>恭喜完成第三篇！你已经掌握了：</p><ul><li>现代CNN架构（ResNet、MobileNet、EfficientNet）</li><li>Transformer与ViT</li><li>高级训练技巧</li></ul><p>接下来进入<strong>第四篇：目标检测与YOLO系列</strong>，学习视觉任务的另一个核心领域！</p><hr><p><strong>参考资源</strong>：</p><ul><li><a href=https://arxiv.org/abs/1710.09412>mixup: Beyond Empirical Risk Minimization</a></li><li><a href=https://arxiv.org/abs/1905.04899>CutMix: Regularization Strategy</a></li><li><a href=https://arxiv.org/abs/1909.13719>RandAugment: Practical automated data augmentation</a></li><li><a href=https://albumentations.ai/docs/>Albumentations Documentation</a></li></ul><hr><p><strong>更新日期</strong>：2025年11月
<strong>基于版本</strong>：PyTorch 2.x, albumentations 1.4+</p></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第二篇 深度学习基础</span>
</a></span><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/ class="flex align-center"><span>第四篇 目标检测与YOLO系列</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#篇章概述>篇章概述</a></li><li><a href=#本篇目标>本篇目标</a></li><li><a href=#技术栈>技术栈</a></li><li><a href=#章节安排>章节安排</a><ul><li><a href=#第5章现代cnn架构>第5章:现代CNN架构</a></li><li><a href=#第6章attention与transformer>第6章:Attention与Transformer</a></li><li><a href=#第7章数据增强与训练技巧>第7章:数据增强与训练技巧</a></li></ul></li><li><a href=#学习路径>学习路径</a></li><li><a href=#环境准备>环境准备</a></li><li><a href=#性能基准>性能基准</a></li><li><a href=#核心概念速查>核心概念速查</a><ul><li><a href=#残差连接residual-connection>残差连接(Residual Connection)</a></li><li><a href=#深度可分离卷积depthwise-separable-convolution>深度可分离卷积(Depthwise Separable Convolution)</a></li><li><a href=#self-attention>Self-Attention</a></li></ul></li><li><a href=#实战项目概览>实战项目概览</a><ul><li><a href=#项目1resnet迁移学习>项目1:ResNet迁移学习</a></li><li><a href=#项目2vit图像分类>项目2:ViT图像分类</a></li><li><a href=#项目3高级训练流程>项目3:高级训练流程</a></li></ul></li><li><a href=#最佳实践>最佳实践</a><ul><li><a href=#1-模型选择>1. 模型选择</a></li><li><a href=#2-迁移学习策略>2. 迁移学习策略</a></li><li><a href=#3-学习率设置>3. 学习率设置</a></li></ul></li><li><a href=#常见问题>常见问题</a><ul><li><a href=#q1-resnet为什么能训练更深的网络>Q1: ResNet为什么能训练更深的网络?</a></li><li><a href=#q2-vit为什么需要大量数据>Q2: ViT为什么需要大量数据?</a></li><li><a href=#q3-如何选择数据增强策略>Q3: 如何选择数据增强策略?</a></li></ul></li><li><a href=#进阶资源>进阶资源</a><ul><li><a href=#论文必读>论文必读</a></li><li><a href=#代码仓库>代码仓库</a></li></ul></li><li><a href=#本篇总结>本篇总结</a></li></ul><ul><li><a href=#本章概述>本章概述</a></li><li><a href=#学习目标>学习目标</a></li><li><a href=#51-resnet残差连接革命>5.1 ResNet:残差连接革命</a><ul><li><a href=#核心问题网络退化>核心问题:网络退化</a></li><li><a href=#残差连接residual-connection-1>残差连接(Residual Connection)</a></li><li><a href=#残差块residual-block>残差块(Residual Block)</a></li><li><a href=#resnet架构族>ResNet架构族</a></li><li><a href=#resnet-50架构详解>ResNet-50架构详解</a></li><li><a href=#实现要点>实现要点</a></li></ul></li><li><a href=#52-mobilenet轻量化设计>5.2 MobileNet:轻量化设计</a><ul><li><a href=#设计目标>设计目标</a></li><li><a href=#深度可分离卷积depthwise-separable-convolution-1>深度可分离卷积(Depthwise Separable Convolution)</a></li><li><a href=#mobilenetv1架构>MobileNetV1架构</a></li><li><a href=#mobilenetv2倒残差结构inverted-residual>MobileNetV2:倒残差结构(Inverted Residual)</a></li><li><a href=#mobilenetv3神经架构搜索nas>MobileNetV3:神经架构搜索(NAS)</a></li><li><a href=#性能对比>性能对比</a></li></ul></li><li><a href=#53-efficientnet复合缩放>5.3 EfficientNet:复合缩放</a><ul><li><a href=#模型缩放的三个维度>模型缩放的三个维度</a></li><li><a href=#复合缩放compound-scaling>复合缩放(Compound Scaling)</a></li><li><a href=#efficientnet架构>EfficientNet架构</a></li><li><a href=#efficientnet系列>EfficientNet系列</a></li><li><a href=#核心优势>核心优势</a></li></ul></li><li><a href=#54-实战迁移学习与fine-tuning>5.4 实战:迁移学习与Fine-tuning</a><ul><li><a href=#迁移学习策略>迁移学习策略</a></li><li><a href=#实现步骤>实现步骤</a></li><li><a href=#fine-tuning技巧>Fine-tuning技巧</a></li><li><a href=#完整训练流程>完整训练流程</a></li></ul></li><li><a href=#架构选择指南>架构选择指南</a><ul><li><a href=#场景匹配>场景匹配</a></li><li><a href=#性能对比imagenet-1k>性能对比(ImageNet-1K)</a></li></ul></li><li><a href=#本章总结>本章总结</a><ul><li><a href=#核心概念>核心概念</a></li><li><a href=#关键技术>关键技术</a></li><li><a href=#实战能力>实战能力</a></li><li><a href=#进阶方向>进阶方向</a></li></ul></li><li><a href=#练习题>练习题</a></li><li><a href=#参考资料>参考资料</a><ul><li><a href=#论文>论文</a></li><li><a href=#代码资源>代码资源</a></li></ul></li></ul><ul><li><a href=#本章概述-1>本章概述</a></li><li><a href=#学习目标-1>学习目标</a></li><li><a href=#61-注意力机制原理>6.1 注意力机制原理</a><ul><li><a href=#注意力的直观理解>注意力的直观理解</a></li><li><a href=#attention机制演进>Attention机制演进</a></li><li><a href=#self-attention数学原理>Self-Attention数学原理</a></li><li><a href=#self-attention示例>Self-Attention示例</a></li><li><a href=#计算复杂度>计算复杂度</a></li><li><a href=#self-attention实现>Self-Attention实现</a></li></ul></li><li><a href=#62-transformer架构详解>6.2 Transformer架构详解</a><ul><li><a href=#transformer整体架构>Transformer整体架构</a></li><li><a href=#multi-head-attention>Multi-Head Attention</a></li><li><a href=#位置编码positional-encoding>位置编码(Positional Encoding)</a></li><li><a href=#feed-forward-network-ffn>Feed-Forward Network (FFN)</a></li><li><a href=#layer-normalization>Layer Normalization</a></li><li><a href=#完整transformer-encoder实现>完整Transformer Encoder实现</a></li></ul></li><li><a href=#63-vision-transformer-vit>6.3 Vision Transformer (ViT)</a><ul><li><a href=#vit核心思想>ViT核心思想</a></li><li><a href=#vit架构详解>ViT架构详解</a></li><li><a href=#vit模型配置>ViT模型配置</a></li><li><a href=#vit-vs-cnn>ViT vs CNN</a></li><li><a href=#vit变体>ViT变体</a></li></ul></li><li><a href=#64-实战vit图像分类>6.4 实战:ViT图像分类</a><ul><li><a href=#使用timm库>使用timm库</a></li><li><a href=#完整训练流程-1>完整训练流程</a></li><li><a href=#vit训练技巧>ViT训练技巧</a></li><li><a href=#性能优化>性能优化</a></li></ul></li><li><a href=#注意力可视化>注意力可视化</a><ul><li><a href=#可视化注意力图>可视化注意力图</a></li></ul></li><li><a href=#本章总结-1>本章总结</a><ul><li><a href=#核心概念-1>核心概念</a></li><li><a href=#关键公式>关键公式</a></li><li><a href=#vit优势与挑战>ViT优势与挑战</a></li><li><a href=#实战技巧>实战技巧</a></li></ul></li><li><a href=#练习题-1>练习题</a></li><li><a href=#参考资料-1>参考资料</a><ul><li><a href=#论文-1>论文</a></li><li><a href=#代码资源-1>代码资源</a></li></ul></li></ul><ul><li><a href=#本章概览>本章概览</a></li><li><a href=#为什么训练技巧如此重要>为什么训练技巧如此重要？</a></li><li><a href=#71-传统数据增强>7.1 传统数据增强</a><ul><li><a href=#711-基础几何变换>7.1.1 基础几何变换</a></li><li><a href=#712-色彩变换>7.1.2 色彩变换</a></li><li><a href=#713-使用albumentations>7.1.3 使用Albumentations</a></li></ul></li><li><a href=#72-现代数据增强>7.2 现代数据增强</a><ul><li><a href=#721-mixup>7.2.1 Mixup</a></li><li><a href=#722-cutmix>7.2.2 CutMix</a></li><li><a href=#723-autoaugment>7.2.3 AutoAugment</a></li><li><a href=#724-randaugment>7.2.4 RandAugment</a></li><li><a href=#725-增强策略对比>7.2.5 增强策略对比</a></li></ul></li><li><a href=#73-学习率调度>7.3 学习率调度</a><ul><li><a href=#731-常用调度器>7.3.1 常用调度器</a></li><li><a href=#732-warmup策略>7.3.2 Warmup策略</a></li><li><a href=#733-调度策略对比>7.3.3 调度策略对比</a></li></ul></li><li><a href=#74-正则化与防过拟合>7.4 正则化与防过拟合</a><ul><li><a href=#741-weight-decayl2正则化>7.4.1 Weight Decay（L2正则化）</a></li><li><a href=#742-dropout>7.4.2 Dropout</a></li><li><a href=#743-label-smoothing>7.4.3 Label Smoothing</a></li><li><a href=#744-stochastic-depth随机深度>7.4.4 Stochastic Depth（随机深度）</a></li><li><a href=#745-防过拟合策略总结>7.4.5 防过拟合策略总结</a></li></ul></li><li><a href=#75-混合精度训练>7.5 混合精度训练</a><ul><li><a href=#751-pytorch-amp>7.5.1 PyTorch AMP</a></li></ul></li><li><a href=#76-实战完整训练流程>7.6 实战：完整训练流程</a><ul><li><a href=#完整训练脚本>完整训练脚本</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心技术要点>核心技术要点</a></li><li><a href=#推荐训练配置>推荐训练配置</a></li><li><a href=#下一步>下一步</a></li></ul></li></ul></nav></div></aside></main></body></html>