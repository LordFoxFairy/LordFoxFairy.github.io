<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第一篇：机器学习基础（快速回顾）# 篇章概述# 本篇是计算机视觉学习的基础准备篇，快速回顾机器学习核心概念，为后续深度学习和计算机视觉内容打下基础。
学习目标：
理解机器学习的基本概念和分类 掌握损失函数、优化器等核心要素 了解过拟合与正则化 理解传统图像特征提取方法 明确深度学习相比传统方法的优势 适合人群：
有Python基础，想快速了解机器学习概念 准备学习深度学习和计算机视觉 需要回顾机器学习基础知识 章节结构# 第1章：机器学习核心概念# 涵盖机器学习的基本分类、损失函数、优化器等核心概念，并通过sklearn实现手写数字分类的实战案例。
关键内容：
监督学习 vs 无监督学习 损失函数与优化器 过拟合与正则化 实战：手写数字分类（sklearn） 第2章：从传统特征到深度学习# 介绍传统图像特征提取方法（SIFT、HOG等），解释为什么需要深度学习，并准备深度学习环境。
关键内容：
传统图像特征（SIFT、HOG） 传统方法的局限性 为什么需要深度学习 环境准备（PyTorch/TensorFlow） 学习路径# 第1章：机器学习核心概念 ↓ 理解监督学习/无监督学习 ↓ 掌握损失函数和优化器 ↓ 实战：MNIST分类（sklearn） ↓ 第2章：从传统特征到深度学习 ↓ 了解SIFT、HOG等传统特征 ↓ 理解深度学习的优势 ↓ 准备深度学习环境 ↓ 进入第二篇：深度学习基础学习建议# 快速回顾：本篇作为快速回顾，不需要深入每个细节 动手实践：运行所有代码示例，理解实际效果 概念理解：重点理解核心概念，为后续学习打基础 环境准备：确保环境配置正确，能够运行所有示例代码 环境要求# # Python版本 Python 3.10+ # 第1章所需库 pip install scikit-learn numpy matplotlib # 第2章所需库（传统特征） pip install opencv-python scikit-image # 深度学习环境（第2章末尾准备） pip install torch torchvision # PyTorch # 或 pip install tensorflow # TensorFlow预计学习时间# 第1章：2-3小时 第2章：2-3小时 总计：4-6小时 后续安排# 完成本篇后，将进入第二篇：深度学习基础，学习神经网络、卷积神经网络等深度学习核心内容。
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第一篇 机器学习基础"><meta property="og:description" content="第一篇：机器学习基础（快速回顾）# 篇章概述# 本篇是计算机视觉学习的基础准备篇，快速回顾机器学习核心概念，为后续深度学习和计算机视觉内容打下基础。
学习目标：
理解机器学习的基本概念和分类 掌握损失函数、优化器等核心要素 了解过拟合与正则化 理解传统图像特征提取方法 明确深度学习相比传统方法的优势 适合人群：
有Python基础，想快速了解机器学习概念 准备学习深度学习和计算机视觉 需要回顾机器学习基础知识 章节结构# 第1章：机器学习核心概念# 涵盖机器学习的基本分类、损失函数、优化器等核心概念，并通过sklearn实现手写数字分类的实战案例。
关键内容：
监督学习 vs 无监督学习 损失函数与优化器 过拟合与正则化 实战：手写数字分类（sklearn） 第2章：从传统特征到深度学习# 介绍传统图像特征提取方法（SIFT、HOG等），解释为什么需要深度学习，并准备深度学习环境。
关键内容：
传统图像特征（SIFT、HOG） 传统方法的局限性 为什么需要深度学习 环境准备（PyTorch/TensorFlow） 学习路径# 第1章：机器学习核心概念 ↓ 理解监督学习/无监督学习 ↓ 掌握损失函数和优化器 ↓ 实战：MNIST分类（sklearn） ↓ 第2章：从传统特征到深度学习 ↓ 了解SIFT、HOG等传统特征 ↓ 理解深度学习的优势 ↓ 准备深度学习环境 ↓ 进入第二篇：深度学习基础学习建议# 快速回顾：本篇作为快速回顾，不需要深入每个细节 动手实践：运行所有代码示例，理解实际效果 概念理解：重点理解核心概念，为后续学习打基础 环境准备：确保环境配置正确，能够运行所有示例代码 环境要求# # Python版本 Python 3.10+ # 第1章所需库 pip install scikit-learn numpy matplotlib # 第2章所需库（传统特征） pip install opencv-python scikit-image # 深度学习环境（第2章末尾准备） pip install torch torchvision # PyTorch # 或 pip install tensorflow # TensorFlow预计学习时间# 第1章：2-3小时 第2章：2-3小时 总计：4-6小时 后续安排# 完成本篇后，将进入第二篇：深度学习基础，学习神经网络、卷积神经网络等深度学习核心内容。"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第一篇 机器学习基础"><meta itemprop=description content="第一篇：机器学习基础（快速回顾）# 篇章概述# 本篇是计算机视觉学习的基础准备篇，快速回顾机器学习核心概念，为后续深度学习和计算机视觉内容打下基础。
学习目标：
理解机器学习的基本概念和分类 掌握损失函数、优化器等核心要素 了解过拟合与正则化 理解传统图像特征提取方法 明确深度学习相比传统方法的优势 适合人群：
有Python基础，想快速了解机器学习概念 准备学习深度学习和计算机视觉 需要回顾机器学习基础知识 章节结构# 第1章：机器学习核心概念# 涵盖机器学习的基本分类、损失函数、优化器等核心概念，并通过sklearn实现手写数字分类的实战案例。
关键内容：
监督学习 vs 无监督学习 损失函数与优化器 过拟合与正则化 实战：手写数字分类（sklearn） 第2章：从传统特征到深度学习# 介绍传统图像特征提取方法（SIFT、HOG等），解释为什么需要深度学习，并准备深度学习环境。
关键内容：
传统图像特征（SIFT、HOG） 传统方法的局限性 为什么需要深度学习 环境准备（PyTorch/TensorFlow） 学习路径# 第1章：机器学习核心概念 ↓ 理解监督学习/无监督学习 ↓ 掌握损失函数和优化器 ↓ 实战：MNIST分类（sklearn） ↓ 第2章：从传统特征到深度学习 ↓ 了解SIFT、HOG等传统特征 ↓ 理解深度学习的优势 ↓ 准备深度学习环境 ↓ 进入第二篇：深度学习基础学习建议# 快速回顾：本篇作为快速回顾，不需要深入每个细节 动手实践：运行所有代码示例，理解实际效果 概念理解：重点理解核心概念，为后续学习打基础 环境准备：确保环境配置正确，能够运行所有示例代码 环境要求# # Python版本 Python 3.10+ # 第1章所需库 pip install scikit-learn numpy matplotlib # 第2章所需库（传统特征） pip install opencv-python scikit-image # 深度学习环境（第2章末尾准备） pip install torch torchvision # PyTorch # 或 pip install tensorflow # TensorFlow预计学习时间# 第1章：2-3小时 第2章：2-3小时 总计：4-6小时 后续安排# 完成本篇后，将进入第二篇：深度学习基础，学习神经网络、卷积神经网络等深度学习核心内容。"><meta itemprop=wordCount content="1841"><title>第一篇 机器学习基础 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle checked>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/ class=active>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第一篇 机器学习基础</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#篇章概述>篇章概述</a></li><li><a href=#章节结构>章节结构</a><ul><li><a href=#第1章机器学习核心概念>第1章：机器学习核心概念</a></li><li><a href=#第2章从传统特征到深度学习>第2章：从传统特征到深度学习</a></li></ul></li><li><a href=#学习路径>学习路径</a></li><li><a href=#学习建议>学习建议</a></li><li><a href=#环境要求>环境要求</a></li><li><a href=#预计学习时间>预计学习时间</a></li><li><a href=#后续安排>后续安排</a></li></ul><ul><li><a href=#本章概述>本章概述</a></li><li><a href=#11-机器学习基本分类>1.1 机器学习基本分类</a><ul><li><a href=#监督学习supervised-learning>监督学习（Supervised Learning）</a></li><li><a href=#无监督学习unsupervised-learning>无监督学习（Unsupervised Learning）</a></li><li><a href=#对比总结>对比总结</a></li></ul></li><li><a href=#12-损失函数与优化器>1.2 损失函数与优化器</a><ul><li><a href=#损失函数loss-function>损失函数（Loss Function）</a><ul><li><a href=#1-均方误差mse--回归任务>1. 均方误差（MSE）- 回归任务</a></li><li><a href=#2-交叉熵cross-entropy--分类任务>2. 交叉熵（Cross-Entropy）- 分类任务</a></li></ul></li><li><a href=#优化器optimizer>优化器（Optimizer）</a><ul><li><a href=#梯度下降gradient-descent>梯度下降（Gradient Descent）</a></li><li><a href=#常见优化器>常见优化器</a></li></ul></li></ul></li><li><a href=#13-过拟合与正则化>1.3 过拟合与正则化</a><ul><li><a href=#过拟合overfitting>过拟合（Overfitting）</a></li><li><a href=#欠拟合underfitting>欠拟合（Underfitting）</a></li><li><a href=#正则化regularization>正则化（Regularization）</a><ul><li><a href=#1-l1正则化lasso>1. L1正则化（Lasso）</a></li><li><a href=#2-l2正则化ridge>2. L2正则化（Ridge）</a></li><li><a href=#3-elastic-netl1--l2>3. Elastic Net（L1 + L2）</a></li><li><a href=#其他防止过拟合的方法>其他防止过拟合的方法</a></li></ul></li></ul></li><li><a href=#14-实战手写数字分类sklearn>1.4 实战：手写数字分类（sklearn）</a><ul><li><a href=#项目概述>项目概述</a></li><li><a href=#完整代码>完整代码</a></li><li><a href=#运行步骤>运行步骤</a></li><li><a href=#预期输出>预期输出</a></li><li><a href=#代码详解>代码详解</a><ul><li><a href=#1-数据加载>1. 数据加载</a></li><li><a href=#2-数据预处理>2. 数据预处理</a></li><li><a href=#3-模型训练>3. 模型训练</a></li><li><a href=#4-模型评估>4. 模型评估</a></li></ul></li><li><a href=#实验结果分析>实验结果分析</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心概念回顾>核心概念回顾</a></li><li><a href=#实战经验>实战经验</a></li><li><a href=#下一章预告>下一章预告</a></li></ul></li><li><a href=#扩展阅读>扩展阅读</a></li><li><a href=#练习题>练习题</a></li></ul><ul><li><a href=#本章概述-1>本章概述</a></li><li><a href=#21-传统图像特征>2.1 传统图像特征</a><ul><li><a href=#什么是特征>什么是特征？</a></li><li><a href=#211-siftscale-invariant-feature-transform>2.1.1 SIFT（Scale-Invariant Feature Transform）</a></li><li><a href=#212-hoghistogram-of-oriented-gradients>2.1.2 HOG（Histogram of Oriented Gradients）</a></li><li><a href=#213-其他传统特征>2.1.3 其他传统特征</a></li><li><a href=#214-传统特征的优势>2.1.4 传统特征的优势</a></li></ul></li><li><a href=#22-传统方法的局限性>2.2 传统方法的局限性</a><ul><li><a href=#221-特征工程的困境>2.2.1 特征工程的困境</a></li><li><a href=#222-复杂场景下的失效>2.2.2 复杂场景下的失效</a></li><li><a href=#223-性能瓶颈>2.2.3 性能瓶颈</a></li></ul></li><li><a href=#23-为什么需要深度学习>2.3 为什么需要深度学习？</a><ul><li><a href=#231-自动特征学习>2.3.1 自动特征学习</a></li><li><a href=#232-表达能力强大>2.3.2 表达能力强大</a></li><li><a href=#233-可扩展性>2.3.3 可扩展性</a></li><li><a href=#234-迁移学习能力>2.3.4 迁移学习能力</a></li><li><a href=#235-深度学习的优势总结>2.3.5 深度学习的优势总结</a></li></ul></li><li><a href=#24-环境准备>2.4 环境准备</a><ul><li><a href=#241-pytorch环境配置>2.4.1 PyTorch环境配置</a></li><li><a href=#242-tensorflow环境配置可选>2.4.2 TensorFlow环境配置（可选）</a></li><li><a href=#243-完整环境配置脚本>2.4.3 完整环境配置脚本</a></li><li><a href=#244-环境测试代码>2.4.4 环境测试代码</a></li></ul></li><li><a href=#25-第一个深度学习示例>2.5 第一个深度学习示例</a><ul><li><a href=#简单的神经网络>简单的神经网络</a></li></ul></li><li><a href=#本章小结-1>本章小结</a><ul><li><a href=#核心知识点>核心知识点</a></li><li><a href=#从传统到深度学习的转变>从传统到深度学习的转变</a></li><li><a href=#下一步学习>下一步学习</a></li></ul></li><li><a href=#扩展阅读-1>扩展阅读</a></li><li><a href=#练习题-1>练习题</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第一篇机器学习基础快速回顾>第一篇：机器学习基础（快速回顾）<a class=anchor href=#%e7%ac%ac%e4%b8%80%e7%af%87%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e7%a1%80%e5%bf%ab%e9%80%9f%e5%9b%9e%e9%a1%be>#</a></h1><h2 id=篇章概述>篇章概述<a class=anchor href=#%e7%af%87%e7%ab%a0%e6%a6%82%e8%bf%b0>#</a></h2><p>本篇是计算机视觉学习的基础准备篇，快速回顾机器学习核心概念，为后续深度学习和计算机视觉内容打下基础。</p><p><strong>学习目标</strong>：</p><ul><li>理解机器学习的基本概念和分类</li><li>掌握损失函数、优化器等核心要素</li><li>了解过拟合与正则化</li><li>理解传统图像特征提取方法</li><li>明确深度学习相比传统方法的优势</li></ul><p><strong>适合人群</strong>：</p><ul><li>有Python基础，想快速了解机器学习概念</li><li>准备学习深度学习和计算机视觉</li><li>需要回顾机器学习基础知识</li></ul><h2 id=章节结构>章节结构<a class=anchor href=#%e7%ab%a0%e8%8a%82%e7%bb%93%e6%9e%84>#</a></h2><h3 id=第1章机器学习核心概念>第1章：机器学习核心概念<a class=anchor href=#%e7%ac%ac1%e7%ab%a0%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5>#</a></h3><p>涵盖机器学习的基本分类、损失函数、优化器等核心概念，并通过sklearn实现手写数字分类的实战案例。</p><p><strong>关键内容</strong>：</p><ul><li>监督学习 vs 无监督学习</li><li>损失函数与优化器</li><li>过拟合与正则化</li><li>实战：手写数字分类（sklearn）</li></ul><h3 id=第2章从传统特征到深度学习>第2章：从传统特征到深度学习<a class=anchor href=#%e7%ac%ac2%e7%ab%a0%e4%bb%8e%e4%bc%a0%e7%bb%9f%e7%89%b9%e5%be%81%e5%88%b0%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0>#</a></h3><p>介绍传统图像特征提取方法（SIFT、HOG等），解释为什么需要深度学习，并准备深度学习环境。</p><p><strong>关键内容</strong>：</p><ul><li>传统图像特征（SIFT、HOG）</li><li>传统方法的局限性</li><li>为什么需要深度学习</li><li>环境准备（PyTorch/TensorFlow）</li></ul><h2 id=学习路径>学习路径<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>第1章：机器学习核心概念
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>理解监督学习/无监督学习
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>掌握损失函数和优化器
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>实战：MNIST分类（sklearn）
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>第2章：从传统特征到深度学习
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>了解SIFT、HOG等传统特征
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>理解深度学习的优势
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>准备深度学习环境
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>进入第二篇：深度学习基础</span></span></code></pre></div><h2 id=学习建议>学习建议<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e5%bb%ba%e8%ae%ae>#</a></h2><ol><li><strong>快速回顾</strong>：本篇作为快速回顾，不需要深入每个细节</li><li><strong>动手实践</strong>：运行所有代码示例，理解实际效果</li><li><strong>概念理解</strong>：重点理解核心概念，为后续学习打基础</li><li><strong>环境准备</strong>：确保环境配置正确，能够运行所有示例代码</li></ol><h2 id=环境要求>环境要求<a class=anchor href=#%e7%8e%af%e5%a2%83%e8%a6%81%e6%b1%82>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># Python版本</span>
</span></span><span class=line><span class=cl>Python 3.10+
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 第1章所需库</span>
</span></span><span class=line><span class=cl>pip install scikit-learn numpy matplotlib
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 第2章所需库（传统特征）</span>
</span></span><span class=line><span class=cl>pip install opencv-python scikit-image
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 深度学习环境（第2章末尾准备）</span>
</span></span><span class=line><span class=cl>pip install torch torchvision  <span class=c1># PyTorch</span>
</span></span><span class=line><span class=cl><span class=c1># 或</span>
</span></span><span class=line><span class=cl>pip install tensorflow         <span class=c1># TensorFlow</span></span></span></code></pre></div><h2 id=预计学习时间>预计学习时间<a class=anchor href=#%e9%a2%84%e8%ae%a1%e5%ad%a6%e4%b9%a0%e6%97%b6%e9%97%b4>#</a></h2><ul><li>第1章：2-3小时</li><li>第2章：2-3小时</li><li>总计：4-6小时</li></ul><h2 id=后续安排>后续安排<a class=anchor href=#%e5%90%8e%e7%bb%ad%e5%ae%89%e6%8e%92>#</a></h2><p>完成本篇后，将进入<strong>第二篇：深度学习基础</strong>，学习神经网络、卷积神经网络等深度学习核心内容。</p><hr><h1 id=第1章机器学习核心概念-1>第1章：机器学习核心概念<a class=anchor href=#%e7%ac%ac1%e7%ab%a0%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5-1>#</a></h1><h2 id=本章概述>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0>#</a></h2><p>本章快速回顾机器学习的核心概念，包括监督学习与无监督学习的区别、损失函数与优化器的作用、以及如何处理过拟合问题。通过一个完整的手写数字分类实战案例，让你理解机器学习的基本流程。</p><p><strong>学习目标</strong>：</p><ul><li>理解监督学习和无监督学习的区别</li><li>掌握损失函数和优化器的概念</li><li>了解过拟合与正则化方法</li><li>完成手写数字分类实战</li></ul><p><strong>前置知识</strong>：</p><ul><li>Python基础语法</li><li>NumPy基础操作</li></ul><h2 id=11-机器学习基本分类>1.1 机器学习基本分类<a class=anchor href=#11-%e6%9c%ba%e5%99%a8%e5%ad%a6%e4%b9%a0%e5%9f%ba%e6%9c%ac%e5%88%86%e7%b1%bb>#</a></h2><h3 id=监督学习supervised-learning>监督学习（Supervised Learning）<a class=anchor href=#%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0supervised-learning>#</a></h3><p><strong>定义</strong>：从标注数据中学习输入到输出的映射关系。</p><p><strong>特点</strong>：</p><ul><li>训练数据包含输入（特征）和输出（标签）</li><li>目标是学习一个函数 f(x) = y</li><li>可以评估模型在已知标签数据上的表现</li></ul><p><strong>常见任务</strong>：</p><table><thead><tr><th>任务类型</th><th>输出类型</th><th>典型应用</th><th>示例</th></tr></thead><tbody><tr><td>分类（Classification）</td><td>离散值</td><td>图像分类、文本分类</td><td>猫狗识别、垃圾邮件检测</td></tr><tr><td>回归（Regression）</td><td>连续值</td><td>价格预测、温度预测</td><td>房价预测、股票预测</td></tr></tbody></table><p><strong>代码示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>make_classification</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成分类数据</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>make_classification</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=mi>20</span><span class=p>,</span> <span class=n>n_classes</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 监督学习：训练数据包含X和y</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>,</span> <span class=n>y</span><span class=p>)</span>  <span class=c1># 需要标签y</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预测</span>
</span></span><span class=line><span class=cl><span class=n>predictions</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span></span></span></code></pre></div><h3 id=无监督学习unsupervised-learning>无监督学习（Unsupervised Learning）<a class=anchor href=#%e6%97%a0%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0unsupervised-learning>#</a></h3><p><strong>定义</strong>：从未标注数据中发现隐藏的模式和结构。</p><p><strong>特点</strong>：</p><ul><li>训练数据只有输入，没有标签</li><li>目标是发现数据的内在结构</li><li>难以量化评估模型性能</li></ul><p><strong>常见任务</strong>：</p><table><thead><tr><th>任务类型</th><th>目标</th><th>典型应用</th><th>示例</th></tr></thead><tbody><tr><td>聚类（Clustering）</td><td>分组相似样本</td><td>客户分群、图像分割</td><td>K-means聚类</td></tr><tr><td>降维（Dimensionality Reduction）</td><td>减少特征数量</td><td>可视化、压缩</td><td>PCA、t-SNE</td></tr><tr><td>异常检测（Anomaly Detection）</td><td>发现异常样本</td><td>欺诈检测、故障检测</td><td>Isolation Forest</td></tr></tbody></table><p><strong>代码示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.cluster</span> <span class=kn>import</span> <span class=n>KMeans</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>make_blobs</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成聚类数据</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>make_blobs</span><span class=p>(</span><span class=n>n_samples</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>n_features</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>centers</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 无监督学习：训练数据只有X</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>KMeans</span><span class=p>(</span><span class=n>n_clusters</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X</span><span class=p>)</span>  <span class=c1># 不需要标签</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 聚类结果</span>
</span></span><span class=line><span class=cl><span class=n>labels</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X</span><span class=p>)</span></span></span></code></pre></div><h3 id=对比总结>对比总结<a class=anchor href=#%e5%af%b9%e6%af%94%e6%80%bb%e7%bb%93>#</a></h3><table><thead><tr><th>维度</th><th>监督学习</th><th>无监督学习</th></tr></thead><tbody><tr><td>数据标签</td><td>需要标签</td><td>不需要标签</td></tr><tr><td>训练目标</td><td>学习输入到输出的映射</td><td>发现数据内在结构</td></tr><tr><td>性能评估</td><td>容易（有标签对比）</td><td>困难（无标准答案）</td></tr><tr><td>数据成本</td><td>高（需要人工标注）</td><td>低（无需标注）</td></tr><tr><td>典型应用</td><td>分类、回归</td><td>聚类、降维</td></tr></tbody></table><h2 id=12-损失函数与优化器>1.2 损失函数与优化器<a class=anchor href=#12-%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0%e4%b8%8e%e4%bc%98%e5%8c%96%e5%99%a8>#</a></h2><h3 id=损失函数loss-function>损失函数（Loss Function）<a class=anchor href=#%e6%8d%9f%e5%a4%b1%e5%87%bd%e6%95%b0loss-function>#</a></h3><p><strong>定义</strong>：衡量模型预测值与真实值之间差异的函数。</p><p><strong>作用</strong>：</p><ul><li>量化模型的预测误差</li><li>指导模型参数的更新方向</li><li>不同任务使用不同的损失函数</li></ul><p><strong>常见损失函数</strong>：</p><h4 id=1-均方误差mse--回归任务>1. 均方误差（MSE）- 回归任务<a class=anchor href=#1-%e5%9d%87%e6%96%b9%e8%af%af%e5%b7%aemse--%e5%9b%9e%e5%bd%92%e4%bb%bb%e5%8a%a1>#</a></h4><p>$$
\text{MSE} = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{y}_i)^2
$$</p><p><strong>特点</strong>：</p><ul><li>对异常值敏感（平方放大误差）</li><li>可导，便于优化</li><li>适用于回归任务</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>mse_loss</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;均方误差损失&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>((</span><span class=n>y_true</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>1.0</span><span class=p>,</span> <span class=mf>2.0</span><span class=p>,</span> <span class=mf>3.0</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>1.1</span><span class=p>,</span> <span class=mf>2.2</span><span class=p>,</span> <span class=mf>2.9</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>mse_loss</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;MSE Loss: </span><span class=si>{</span><span class=n>loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>  <span class=c1># 0.0233</span></span></span></code></pre></div><h4 id=2-交叉熵cross-entropy--分类任务>2. 交叉熵（Cross-Entropy）- 分类任务<a class=anchor href=#2-%e4%ba%a4%e5%8f%89%e7%86%b5cross-entropy--%e5%88%86%e7%b1%bb%e4%bb%bb%e5%8a%a1>#</a></h4><p><strong>二分类（Binary Cross-Entropy）</strong>：</p><p>$$
\text{BCE} = -\frac{1}{n}\sum_{i=1}^{n}[y_i\log(\hat{y}_i) + (1-y_i)\log(1-\hat{y}_i)]
$$</p><p><strong>多分类（Categorical Cross-Entropy）</strong>：</p><p>$$
\text{CCE} = -\frac{1}{n}\sum_{i=1}^{n}\sum_{j=1}^{C}y_{ij}\log(\hat{y}_{ij})
$$</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>binary_cross_entropy</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;二分类交叉熵&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>epsilon</span> <span class=o>=</span> <span class=mf>1e-15</span>  <span class=c1># 防止log(0)</span>
</span></span><span class=line><span class=cl>    <span class=n>y_pred</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=n>y_pred</span><span class=p>,</span> <span class=n>epsilon</span><span class=p>,</span> <span class=mi>1</span> <span class=o>-</span> <span class=n>epsilon</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=o>-</span><span class=n>np</span><span class=o>.</span><span class=n>mean</span><span class=p>(</span><span class=n>y_true</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=n>y_pred</span><span class=p>)</span> <span class=o>+</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>y_true</span><span class=p>)</span> <span class=o>*</span> <span class=n>np</span><span class=o>.</span><span class=n>log</span><span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>y_pred</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 示例</span>
</span></span><span class=line><span class=cl><span class=n>y_true</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>array</span><span class=p>([</span><span class=mf>0.9</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mf>0.8</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>loss</span> <span class=o>=</span> <span class=n>binary_cross_entropy</span><span class=p>(</span><span class=n>y_true</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;BCE Loss: </span><span class=si>{</span><span class=n>loss</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>  <span class=c1># 0.1336</span></span></span></code></pre></div><p><strong>损失函数选择</strong>：</p><table><thead><tr><th>任务类型</th><th>推荐损失函数</th><th>原因</th></tr></thead><tbody><tr><td>二分类</td><td>Binary Cross-Entropy</td><td>衡量概率分布差异</td></tr><tr><td>多分类</td><td>Categorical Cross-Entropy</td><td>适合softmax输出</td></tr><tr><td>回归</td><td>MSE / MAE</td><td>衡量数值差异</td></tr><tr><td>排序</td><td>Hinge Loss</td><td>最大化分类间隔</td></tr></tbody></table><h3 id=优化器optimizer>优化器（Optimizer）<a class=anchor href=#%e4%bc%98%e5%8c%96%e5%99%a8optimizer>#</a></h3><p><strong>定义</strong>：根据损失函数的梯度更新模型参数的算法。</p><p><strong>核心思想</strong>：通过迭代更新参数，使损失函数最小化。</p><h4 id=梯度下降gradient-descent>梯度下降（Gradient Descent）<a class=anchor href=#%e6%a2%af%e5%ba%a6%e4%b8%8b%e9%99%8dgradient-descent>#</a></h4><p><strong>基本公式</strong>：</p><p>$$
\theta_{t+1} = \theta_t - \eta \cdot \nabla_\theta L(\theta_t)
$$</p><p>其中：</p><ul><li>$\theta$：模型参数</li><li>$\eta$：学习率（learning rate）</li><li>$\nabla_\theta L$：损失函数对参数的梯度</li></ul><p><strong>变体对比</strong>：</p><table><thead><tr><th>优化器</th><th>每次更新使用的数据</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td>批量梯度下降（BGD）</td><td>全部数据</td><td>稳定但慢</td><td>小数据集</td></tr><tr><td>随机梯度下降（SGD）</td><td>单个样本</td><td>快但不稳定</td><td>在线学习</td></tr><tr><td>小批量梯度下降（Mini-batch GD）</td><td>小批量数据</td><td>平衡速度和稳定性</td><td>最常用</td></tr></tbody></table><h4 id=常见优化器>常见优化器<a class=anchor href=#%e5%b8%b8%e8%a7%81%e4%bc%98%e5%8c%96%e5%99%a8>#</a></h4><p><strong>1. SGD（Stochastic Gradient Descent）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># sklearn中的SGD示例</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>SGDClassifier</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>SGDClassifier</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>=</span><span class=s1>&#39;log_loss&#39;</span><span class=p>,</span>        <span class=c1># 损失函数</span>
</span></span><span class=line><span class=cl>    <span class=n>learning_rate</span><span class=o>=</span><span class=s1>&#39;constant&#39;</span><span class=p>,</span>  <span class=c1># 学习率策略</span>
</span></span><span class=line><span class=cl>    <span class=n>eta0</span><span class=o>=</span><span class=mf>0.01</span><span class=p>,</span>             <span class=c1># 初始学习率</span>
</span></span><span class=line><span class=cl>    <span class=n>max_iter</span><span class=o>=</span><span class=mi>1000</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>2. Adam（Adaptive Moment Estimation）</strong></p><p><strong>特点</strong>：</p><ul><li>结合动量（Momentum）和自适应学习率</li><li>对每个参数使用不同的学习率</li><li>最常用的优化器之一</li></ul><p><strong>优势</strong>：</p><ul><li>收敛速度快</li><li>对超参数不敏感</li><li>适合大多数深度学习任务</li></ul><p><strong>优化器选择建议</strong>：</p><table><thead><tr><th>场景</th><th>推荐优化器</th><th>原因</th></tr></thead><tbody><tr><td>快速原型</td><td>Adam</td><td>收敛快，调参少</td></tr><tr><td>最优性能</td><td>SGD + Momentum</td><td>泛化能力好</td></tr><tr><td>稀疏数据</td><td>AdaGrad</td><td>自适应学习率</td></tr><tr><td>RNN/LSTM</td><td>Adam / RMSprop</td><td>处理梯度消失</td></tr></tbody></table><h2 id=13-过拟合与正则化>1.3 过拟合与正则化<a class=anchor href=#13-%e8%bf%87%e6%8b%9f%e5%90%88%e4%b8%8e%e6%ad%a3%e5%88%99%e5%8c%96>#</a></h2><h3 id=过拟合overfitting>过拟合（Overfitting）<a class=anchor href=#%e8%bf%87%e6%8b%9f%e5%90%88overfitting>#</a></h3><p><strong>定义</strong>：模型在训练集上表现很好，但在测试集上表现差。</p><p><strong>表现</strong>：</p><ul><li>训练误差很低</li><li>测试误差很高</li><li>模型记住了训练数据，而非学习了通用模式</li></ul><p><strong>原因</strong>：</p><ul><li>模型过于复杂（参数太多）</li><li>训练数据太少</li><li>训练时间过长</li></ul><p><strong>示例图示</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>训练误差和测试误差随模型复杂度变化：
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>误差
</span></span><span class=line><span class=cl> ↑
</span></span><span class=line><span class=cl> |          测试误差
</span></span><span class=line><span class=cl> |         /‾‾‾‾‾
</span></span><span class=line><span class=cl> |        /
</span></span><span class=line><span class=cl> |       /
</span></span><span class=line><span class=cl> |      /
</span></span><span class=line><span class=cl> |     /_________ 训练误差
</span></span><span class=line><span class=cl> |
</span></span><span class=line><span class=cl> └─────────────────→ 模型复杂度
</span></span><span class=line><span class=cl>        ↑
</span></span><span class=line><span class=cl>    最佳复杂度</span></span></code></pre></div><h3 id=欠拟合underfitting>欠拟合（Underfitting）<a class=anchor href=#%e6%ac%a0%e6%8b%9f%e5%90%88underfitting>#</a></h3><p><strong>定义</strong>：模型过于简单，无法捕捉数据的模式。</p><p><strong>表现</strong>：</p><ul><li>训练误差高</li><li>测试误差高</li><li>模型能力不足</li></ul><h3 id=正则化regularization>正则化（Regularization）<a class=anchor href=#%e6%ad%a3%e5%88%99%e5%8c%96regularization>#</a></h3><p><strong>目的</strong>：防止过拟合，提高模型泛化能力。</p><h4 id=1-l1正则化lasso>1. L1正则化（Lasso）<a class=anchor href=#1-l1%e6%ad%a3%e5%88%99%e5%8c%96lasso>#</a></h4><p><strong>公式</strong>：</p><p>$$
L = L_{\text{original}} + \lambda\sum_{i}|\theta_i|
$$</p><p><strong>特点</strong>：</p><ul><li>惩罚参数的绝对值</li><li>产生稀疏解（部分参数为0）</li><li>可用于特征选择</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>Lasso</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># L1正则化</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Lasso</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>0.1</span><span class=p>)</span>  <span class=c1># alpha是正则化强度</span></span></span></code></pre></div><h4 id=2-l2正则化ridge>2. L2正则化（Ridge）<a class=anchor href=#2-l2%e6%ad%a3%e5%88%99%e5%8c%96ridge>#</a></h4><p><strong>公式</strong>：</p><p>$$
L = L_{\text{original}} + \lambda\sum_{i}\theta_i^2
$$</p><p><strong>特点</strong>：</p><ul><li>惩罚参数的平方</li><li>参数趋向于小值但不为0</li><li>更常用，数值稳定</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>Ridge</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># L2正则化</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Ridge</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>1.0</span><span class=p>)</span>  <span class=c1># alpha是正则化强度</span></span></span></code></pre></div><h4 id=3-elastic-netl1--l2>3. Elastic Net（L1 + L2）<a class=anchor href=#3-elastic-netl1--l2>#</a></h4><p><strong>公式</strong>：</p><p>$$
L = L_{\text{original}} + \lambda_1\sum_{i}|\theta_i| + \lambda_2\sum_{i}\theta_i^2
$$</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>ElasticNet</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># L1 + L2正则化</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>ElasticNet</span><span class=p>(</span><span class=n>alpha</span><span class=o>=</span><span class=mf>0.1</span><span class=p>,</span> <span class=n>l1_ratio</span><span class=o>=</span><span class=mf>0.5</span><span class=p>)</span>  <span class=c1># l1_ratio控制L1和L2的比例</span></span></span></code></pre></div><p><strong>正则化方法对比</strong>：</p><table><thead><tr><th>方法</th><th>惩罚项</th><th>特点</th><th>适用场景</th></tr></thead><tbody><tr><td>L1</td><td>绝对值</td><td>稀疏解，特征选择</td><td>高维稀疏数据</td></tr><tr><td>L2</td><td>平方</td><td>平滑解，数值稳定</td><td>大多数场景</td></tr><tr><td>Elastic Net</td><td>L1+L2</td><td>结合两者优势</td><td>特征相关性高</td></tr><tr><td>Dropout</td><td>随机失活</td><td>集成效果</td><td>深度神经网络</td></tr></tbody></table><h4 id=其他防止过拟合的方法>其他防止过拟合的方法<a class=anchor href=#%e5%85%b6%e4%bb%96%e9%98%b2%e6%ad%a2%e8%bf%87%e6%8b%9f%e5%90%88%e7%9a%84%e6%96%b9%e6%b3%95>#</a></h4><table><thead><tr><th>方法</th><th>原理</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>数据增强</td><td>增加训练样本</td><td>提高泛化能力</td><td>需要领域知识</td></tr><tr><td>Early Stopping</td><td>提前停止训练</td><td>简单有效</td><td>需要验证集</td></tr><tr><td>Dropout</td><td>随机丢弃神经元</td><td>集成效果</td><td>仅用于神经网络</td></tr><tr><td>交叉验证</td><td>多次划分数据</td><td>充分利用数据</td><td>计算成本高</td></tr></tbody></table><h2 id=14-实战手写数字分类sklearn>1.4 实战：手写数字分类（sklearn）<a class=anchor href=#14-%e5%ae%9e%e6%88%98%e6%89%8b%e5%86%99%e6%95%b0%e5%ad%97%e5%88%86%e7%b1%bbsklearn>#</a></h2><h3 id=项目概述>项目概述<a class=anchor href=#%e9%a1%b9%e7%9b%ae%e6%a6%82%e8%bf%b0>#</a></h3><p>使用scikit-learn实现MNIST手写数字分类，这是机器学习领域的"Hello World"项目。</p><p><strong>数据集</strong>：MNIST手写数字数据集</p><ul><li>60,000个训练样本</li><li>10,000个测试样本</li><li>每个图像28×28像素，灰度图</li><li>10个类别（数字0-9）</li></ul><p><strong>目标</strong>：</p><ul><li>加载和探索MNIST数据</li><li>训练多个分类器</li><li>评估模型性能</li><li>可视化结果</li></ul><h3 id=完整代码>完整代码<a class=anchor href=#%e5%ae%8c%e6%95%b4%e4%bb%a3%e7%a0%81>#</a></h3><p>代码文件：<code>code/chapter01_ml_basics/mnist_sklearn.py</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 详见 code/chapter01_ml_basics/mnist_sklearn.py</span></span></span></code></pre></div><h3 id=运行步骤>运行步骤<a class=anchor href=#%e8%bf%90%e8%a1%8c%e6%ad%a5%e9%aa%a4>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. 安装依赖</span>
</span></span><span class=line><span class=cl>pip install scikit-learn numpy matplotlib
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 运行代码</span>
</span></span><span class=line><span class=cl><span class=nb>cd</span> chapter01/code
</span></span><span class=line><span class=cl>python mnist_sklearn.py</span></span></code></pre></div><h3 id=预期输出>预期输出<a class=anchor href=#%e9%a2%84%e6%9c%9f%e8%be%93%e5%87%ba>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>数据集信息：
</span></span><span class=line><span class=cl>训练集: 60000 samples
</span></span><span class=line><span class=cl>测试集: 10000 samples
</span></span><span class=line><span class=cl>图像尺寸: 28x28
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>模型性能比较：
</span></span><span class=line><span class=cl>Logistic Regression - 准确率: 92.50%
</span></span><span class=line><span class=cl>Random Forest - 准确率: 96.80%
</span></span><span class=line><span class=cl>SVM - 准确率: 94.20%
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>最佳模型: Random Forest</span></span></code></pre></div><h3 id=代码详解>代码详解<a class=anchor href=#%e4%bb%a3%e7%a0%81%e8%af%a6%e8%a7%a3>#</a></h3><h4 id=1-数据加载>1. 数据加载<a class=anchor href=#1-%e6%95%b0%e6%8d%ae%e5%8a%a0%e8%bd%bd>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.datasets</span> <span class=kn>import</span> <span class=n>fetch_openml</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载MNIST数据集</span>
</span></span><span class=line><span class=cl><span class=n>mnist</span> <span class=o>=</span> <span class=n>fetch_openml</span><span class=p>(</span><span class=s1>&#39;mnist_784&#39;</span><span class=p>,</span> <span class=n>version</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>parser</span><span class=o>=</span><span class=s1>&#39;auto&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>X</span><span class=p>,</span> <span class=n>y</span> <span class=o>=</span> <span class=n>mnist</span><span class=o>.</span><span class=n>data</span><span class=p>,</span> <span class=n>mnist</span><span class=o>.</span><span class=n>target</span></span></span></code></pre></div><p><strong>关键点</strong>：</p><ul><li><code>fetch_openml</code>从OpenML下载数据集</li><li>数据已经展平为784维向量（28×28）</li><li>标签为字符串，需要转换为整数</li></ul><h4 id=2-数据预处理>2. 数据预处理<a class=anchor href=#2-%e6%95%b0%e6%8d%ae%e9%a2%84%e5%a4%84%e7%90%86>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 归一化</span>
</span></span><span class=line><span class=cl><span class=n>X</span> <span class=o>=</span> <span class=n>X</span> <span class=o>/</span> <span class=mf>255.0</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 划分训练集和测试集</span>
</span></span><span class=line><span class=cl><span class=n>X_train</span><span class=p>,</span> <span class=n>X_test</span> <span class=o>=</span> <span class=n>X</span><span class=p>[:</span><span class=mi>60000</span><span class=p>],</span> <span class=n>X</span><span class=p>[</span><span class=mi>60000</span><span class=p>:]</span>
</span></span><span class=line><span class=cl><span class=n>y_train</span><span class=p>,</span> <span class=n>y_test</span> <span class=o>=</span> <span class=n>y</span><span class=p>[:</span><span class=mi>60000</span><span class=p>],</span> <span class=n>y</span><span class=p>[</span><span class=mi>60000</span><span class=p>:]</span></span></span></code></pre></div><p><strong>为什么归一化</strong>：</p><ul><li>特征值范围统一（0-1）</li><li>加速模型收敛</li><li>防止某些特征主导</li></ul><h4 id=3-模型训练>3. 模型训练<a class=anchor href=#3-%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.linear_model</span> <span class=kn>import</span> <span class=n>LogisticRegression</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LogisticRegression</span><span class=p>(</span><span class=n>max_iter</span><span class=o>=</span><span class=mi>100</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>fit</span><span class=p>(</span><span class=n>X_train</span><span class=p>,</span> <span class=n>y_train</span><span class=p>)</span></span></span></code></pre></div><p><strong>逻辑回归要点</strong>：</p><ul><li>虽然名为"回归"，但用于分类</li><li>多分类使用one-vs-rest策略</li><li><code>max_iter</code>控制最大迭代次数</li></ul><h4 id=4-模型评估>4. 模型评估<a class=anchor href=#4-%e6%a8%a1%e5%9e%8b%e8%af%84%e4%bc%b0>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>sklearn.metrics</span> <span class=kn>import</span> <span class=n>accuracy_score</span><span class=p>,</span> <span class=n>classification_report</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>y_pred</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>predict</span><span class=p>(</span><span class=n>X_test</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>accuracy</span> <span class=o>=</span> <span class=n>accuracy_score</span><span class=p>(</span><span class=n>y_test</span><span class=p>,</span> <span class=n>y_pred</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;准确率: </span><span class=si>{</span><span class=n>accuracy</span><span class=si>:</span><span class=s2>.2%</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>评估指标</strong>：</p><ul><li><strong>准确率（Accuracy）</strong>：正确预测的比例</li><li><strong>精确率（Precision）</strong>：预测为正的样本中真正为正的比例</li><li><strong>召回率（Recall）</strong>：真正为正的样本中被正确预测的比例</li><li><strong>F1分数</strong>：精确率和召回率的调和平均</li></ul><h3 id=实验结果分析>实验结果分析<a class=anchor href=#%e5%ae%9e%e9%aa%8c%e7%bb%93%e6%9e%9c%e5%88%86%e6%9e%90>#</a></h3><p><strong>不同模型对比</strong>：</p><table><thead><tr><th>模型</th><th>准确率</th><th>训练时间</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>Logistic Regression</td><td>~92%</td><td>快</td><td>简单，可解释</td><td>性能一般</td></tr><tr><td>Random Forest</td><td>~97%</td><td>中</td><td>性能好，鲁棒</td><td>模型较大</td></tr><tr><td>SVM</td><td>~94%</td><td>慢</td><td>泛化能力强</td><td>训练慢</td></tr></tbody></table><p><strong>提升性能的方法</strong>：</p><ol><li>特征工程：提取更好的特征</li><li>模型调参：调整超参数</li><li>集成学习：组合多个模型</li><li>深度学习：使用CNN（下一篇）</li></ol><h2 id=本章小结>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>#</a></h2><h3 id=核心概念回顾>核心概念回顾<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%a6%82%e5%bf%b5%e5%9b%9e%e9%a1%be>#</a></h3><ol><li><p><strong>机器学习分类</strong>：</p><ul><li>监督学习：有标签，学习映射关系</li><li>无监督学习：无标签，发现数据结构</li></ul></li><li><p><strong>损失函数</strong>：</p><ul><li>衡量模型预测误差</li><li>回归任务：MSE、MAE</li><li>分类任务：交叉熵</li></ul></li><li><p><strong>优化器</strong>：</p><ul><li>根据梯度更新参数</li><li>SGD、Adam等常用优化器</li><li>学习率是关键超参数</li></ul></li><li><p><strong>过拟合与正则化</strong>：</p><ul><li>过拟合：训练好测试差</li><li>正则化：L1、L2、Dropout</li><li>其他方法：数据增强、Early Stopping</li></ul></li></ol><h3 id=实战经验>实战经验<a class=anchor href=#%e5%ae%9e%e6%88%98%e7%bb%8f%e9%aa%8c>#</a></h3><ul><li><strong>MNIST分类</strong>：传统机器学习可达到~97%准确率</li><li><strong>模型选择</strong>：Random Forest在sklearn中表现最好</li><li><strong>局限性</strong>：传统方法难以处理复杂图像任务</li></ul><h3 id=下一章预告>下一章预告<a class=anchor href=#%e4%b8%8b%e4%b8%80%e7%ab%a0%e9%a2%84%e5%91%8a>#</a></h3><p>第2章将介绍传统图像特征（SIFT、HOG），并解释为什么需要深度学习来突破传统方法的局限。</p><h2 id=扩展阅读>扩展阅读<a class=anchor href=#%e6%89%a9%e5%b1%95%e9%98%85%e8%af%bb>#</a></h2><ol><li><strong>scikit-learn官方文档</strong>：https://scikit-learn.org/</li><li><strong>MNIST数据集</strong>：http://yann.lecun.com/exdb/mnist/</li><li><strong>机器学习实战</strong>：《Hands-On Machine Learning》</li></ol><h2 id=练习题>练习题<a class=anchor href=#%e7%bb%83%e4%b9%a0%e9%a2%98>#</a></h2><ol><li><strong>修改代码</strong>：尝试不同的正则化参数，观察对准确率的影响</li><li><strong>特征工程</strong>：提取新特征（如像素均值、方差），看能否提升性能</li><li><strong>可视化</strong>：绘制混淆矩阵，分析哪些数字容易混淆</li><li><strong>挑战</strong>：使用PCA降维到50维，观察性能变化</li></ol><hr><p><strong>下一章</strong>：<a href=../chapter02/README.md>第2章：从传统特征到深度学习</a></p><hr><h1 id=第2章从传统特征到深度学习-1>第2章：从传统特征到深度学习<a class=anchor href=#%e7%ac%ac2%e7%ab%a0%e4%bb%8e%e4%bc%a0%e7%bb%9f%e7%89%b9%e5%be%81%e5%88%b0%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0-1>#</a></h1><h2 id=本章概述-1>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0-1>#</a></h2><p>本章介绍传统图像特征提取方法（如SIFT、HOG），分析这些方法的优势和局限性，并解释为什么深度学习能够突破这些限制。最后，我们将准备深度学习环境，为后续章节做好准备。</p><p><strong>学习目标</strong>：</p><ul><li>理解传统图像特征提取方法（SIFT、HOG）</li><li>了解传统方法的优势和局限性</li><li>理解深度学习相比传统方法的优势</li><li>配置PyTorch/TensorFlow环境</li></ul><p><strong>前置知识</strong>：</p><ul><li>基本的图像处理概念</li><li>Python和NumPy基础</li><li>第1章的机器学习知识</li></ul><h2 id=21-传统图像特征>2.1 传统图像特征<a class=anchor href=#21-%e4%bc%a0%e7%bb%9f%e5%9b%be%e5%83%8f%e7%89%b9%e5%be%81>#</a></h2><h3 id=什么是特征>什么是特征？<a class=anchor href=#%e4%bb%80%e4%b9%88%e6%98%af%e7%89%b9%e5%be%81>#</a></h3><p><strong>定义</strong>：特征是图像中具有区分性的、可以用数值表示的信息。</p><p><strong>好特征的标准</strong>：</p><ul><li><strong>可区分性</strong>：不同类别的特征值差异大</li><li><strong>不变性</strong>：对光照、旋转、尺度变化鲁棒</li><li><strong>可计算性</strong>：能够高效计算</li><li><strong>紧凑性</strong>：用较少的数值表示丰富的信息</li></ul><p><strong>传统方法的核心思想</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>原始图像 → 手工设计的特征提取器 → 特征向量 → 分类器 → 预测结果</span></span></code></pre></div><h3 id=211-siftscale-invariant-feature-transform>2.1.1 SIFT（Scale-Invariant Feature Transform）<a class=anchor href=#211-siftscale-invariant-feature-transform>#</a></h3><p><strong>发明者</strong>：David Lowe (1999)</p><p><strong>核心思想</strong>：检测图像中的关键点，并计算具有尺度和旋转不变性的特征描述子。</p><p><strong>主要步骤</strong>：</p><ol><li><p><strong>尺度空间极值检测</strong></p><ul><li>使用高斯差分（DoG）在不同尺度上寻找关键点</li><li>对尺度变化具有不变性</li></ul></li><li><p><strong>关键点定位</strong></p><ul><li>精确定位关键点的位置和尺度</li><li>去除低对比度和边缘响应的关键点</li></ul></li><li><p><strong>方向分配</strong></p><ul><li>计算关键点的主方向</li><li>实现旋转不变性</li></ul></li><li><p><strong>关键点描述</strong></p><ul><li>计算128维特征向量</li><li>描述关键点周围的梯度分布</li></ul></li></ol><p><strong>特点</strong>：</p><table><thead><tr><th>特性</th><th>说明</th></tr></thead><tbody><tr><td>尺度不变性</td><td>对图像缩放鲁棒</td></tr><tr><td>旋转不变性</td><td>对图像旋转鲁棒</td></tr><tr><td>亮度不变性</td><td>对光照变化鲁棒</td></tr><tr><td>特征维度</td><td>128维向量</td></tr><tr><td>计算速度</td><td>较慢</td></tr></tbody></table><p><strong>应用场景</strong>：</p><ul><li>图像匹配和拼接</li><li>物体识别</li><li>3D重建</li><li>图像检索</li></ul><p><strong>代码示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>detect_sift_features</span><span class=p>(</span><span class=n>image_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    使用SIFT检测和提取特征
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        image_path: 图像路径
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 读取图像（灰度）</span>
</span></span><span class=line><span class=cl>    <span class=n>img</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>imread</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>cv2</span><span class=o>.</span><span class=n>IMREAD_GRAYSCALE</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 创建SIFT检测器</span>
</span></span><span class=line><span class=cl>    <span class=n>sift</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>SIFT_create</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 检测关键点和计算描述子</span>
</span></span><span class=line><span class=cl>    <span class=n>keypoints</span><span class=p>,</span> <span class=n>descriptors</span> <span class=o>=</span> <span class=n>sift</span><span class=o>.</span><span class=n>detectAndCompute</span><span class=p>(</span><span class=n>img</span><span class=p>,</span> <span class=kc>None</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 绘制关键点</span>
</span></span><span class=line><span class=cl>    <span class=n>img_keypoints</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>drawKeypoints</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>keypoints</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=kc>None</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>flags</span><span class=o>=</span><span class=n>cv2</span><span class=o>.</span><span class=n>DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;检测到 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>keypoints</span><span class=p>)</span><span class=si>}</span><span class=s2> 个关键点&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;描述子维度: </span><span class=si>{</span><span class=n>descriptors</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 显示结果</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>figure</span><span class=p>(</span><span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>img_keypoints</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>title</span><span class=p>(</span><span class=sa>f</span><span class=s1>&#39;SIFT关键点 (共</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>keypoints</span><span class=p>)</span><span class=si>}</span><span class=s1>个)&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;sift_keypoints.png&#39;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span> <span class=n>bbox_inches</span><span class=o>=</span><span class=s1>&#39;tight&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>keypoints</span><span class=p>,</span> <span class=n>descriptors</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=c1># keypoints, descriptors = detect_sift_features(&#39;image.jpg&#39;)</span></span></span></code></pre></div><h3 id=212-hoghistogram-of-oriented-gradients>2.1.2 HOG（Histogram of Oriented Gradients）<a class=anchor href=#212-hoghistogram-of-oriented-gradients>#</a></h3><p><strong>发明者</strong>：Navneet Dalal & Bill Triggs (2005)</p><p><strong>核心思想</strong>：统计图像局部区域的梯度方向直方图，作为特征描述子。</p><p><strong>主要步骤</strong>：</p><ol><li><p><strong>计算梯度</strong></p><ul><li>计算图像每个像素的梯度幅值和方向</li><li>使用Sobel算子或简单差分</li></ul></li><li><p><strong>划分单元格（Cell）</strong></p><ul><li>将图像划分为小的单元格（如8×8像素）</li><li>每个单元格计算梯度方向直方图</li></ul></li><li><p><strong>构建块（Block）</strong></p><ul><li>将多个单元格组成块（如2×2个单元格）</li><li>在块内进行归一化，提高鲁棒性</li></ul></li><li><p><strong>特征向量</strong></p><ul><li>连接所有块的直方图形成最终特征向量</li><li>典型维度：几千维</li></ul></li></ol><p><strong>特点</strong>：</p><table><thead><tr><th>特性</th><th>说明</th></tr></thead><tbody><tr><td>光照不变性</td><td>对亮度变化较鲁棒</td></tr><tr><td>几何不变性</td><td>对小范围的几何变形鲁棒</td></tr><tr><td>特征维度</td><td>通常几千维</td></tr><tr><td>计算速度</td><td>较快</td></tr><tr><td>适用任务</td><td>行人检测、物体检测</td></tr></tbody></table><p><strong>应用场景</strong>：</p><ul><li>行人检测（经典应用）</li><li>物体检测</li><li>姿态估计</li><li>动作识别</li></ul><p><strong>代码示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage.feature</span> <span class=kn>import</span> <span class=n>hog</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>skimage</span> <span class=kn>import</span> <span class=n>exposure</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_hog_features</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>visualize</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    提取HOG特征
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        image: 输入图像（灰度）
</span></span></span><span class=line><span class=cl><span class=s2>        visualize: 是否可视化
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        features: HOG特征向量
</span></span></span><span class=line><span class=cl><span class=s2>        hog_image: HOG可视化图像（如果visualize=True）
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 提取HOG特征</span>
</span></span><span class=line><span class=cl>    <span class=n>features</span><span class=p>,</span> <span class=n>hog_image</span> <span class=o>=</span> <span class=n>hog</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>orientations</span><span class=o>=</span><span class=mi>9</span><span class=p>,</span>           <span class=c1># 梯度方向的bins数量</span>
</span></span><span class=line><span class=cl>        <span class=n>pixels_per_cell</span><span class=o>=</span><span class=p>(</span><span class=mi>8</span><span class=p>,</span> <span class=mi>8</span><span class=p>),</span>   <span class=c1># 每个cell的像素数</span>
</span></span><span class=line><span class=cl>        <span class=n>cells_per_block</span><span class=o>=</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>   <span class=c1># 每个block的cell数</span>
</span></span><span class=line><span class=cl>        <span class=n>visualize</span><span class=o>=</span><span class=n>visualize</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>block_norm</span><span class=o>=</span><span class=s1>&#39;L2-Hys&#39;</span>       <span class=c1># 归一化方法</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>visualize</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 增强对比度以便可视化</span>
</span></span><span class=line><span class=cl>        <span class=n>hog_image_rescaled</span> <span class=o>=</span> <span class=n>exposure</span><span class=o>.</span><span class=n>rescale_intensity</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>hog_image</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>in_range</span><span class=o>=</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 显示原图和HOG特征</span>
</span></span><span class=line><span class=cl>        <span class=n>fig</span><span class=p>,</span> <span class=p>(</span><span class=n>ax1</span><span class=p>,</span> <span class=n>ax2</span><span class=p>)</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>6</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ax1</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax1</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;原始图像&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax1</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>ax2</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>hog_image_rescaled</span><span class=p>,</span> <span class=n>cmap</span><span class=o>=</span><span class=s1>&#39;gray&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax2</span><span class=o>.</span><span class=n>set_title</span><span class=p>(</span><span class=s1>&#39;HOG特征可视化&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax2</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;hog_features.png&#39;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span> <span class=n>bbox_inches</span><span class=o>=</span><span class=s1>&#39;tight&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>plt</span><span class=o>.</span><span class=n>close</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;HOG特征维度: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>features</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>features</span><span class=p>,</span> <span class=n>hog_image</span> <span class=k>if</span> <span class=n>visualize</span> <span class=k>else</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=c1># features, hog_img = extract_hog_features(gray_image)</span></span></span></code></pre></div><h3 id=213-其他传统特征>2.1.3 其他传统特征<a class=anchor href=#213-%e5%85%b6%e4%bb%96%e4%bc%a0%e7%bb%9f%e7%89%b9%e5%be%81>#</a></h3><table><thead><tr><th>特征类型</th><th>主要用途</th><th>特点</th></tr></thead><tbody><tr><td><strong>SURF</strong></td><td>图像匹配</td><td>SIFT的加速版本，使用积分图</td></tr><tr><td><strong>ORB</strong></td><td>实时应用</td><td>快速、免费，结合FAST和BRIEF</td></tr><tr><td><strong>LBP</strong></td><td>纹理分类</td><td>计算简单，对光照鲁棒</td></tr><tr><td><strong>颜色直方图</strong></td><td>图像检索</td><td>简单高效，忽略空间信息</td></tr><tr><td><strong>边缘特征</strong></td><td>形状检测</td><td>Canny、Sobel等边缘检测</td></tr></tbody></table><h3 id=214-传统特征的优势>2.1.4 传统特征的优势<a class=anchor href=#214-%e4%bc%a0%e7%bb%9f%e7%89%b9%e5%be%81%e7%9a%84%e4%bc%98%e5%8a%bf>#</a></h3><p><strong>1. 可解释性强</strong></p><ul><li>特征提取过程清晰</li><li>容易理解和调试</li><li>可以根据领域知识设计</li></ul><p><strong>2. 计算效率高</strong></p><ul><li>不需要大量训练数据</li><li>推理速度快</li><li>适合资源受限的场景</li></ul><p><strong>3. 特定任务表现好</strong></p><ul><li>HOG在行人检测上效果优秀</li><li>SIFT在图像匹配上非常可靠</li><li>在小数据集上可能优于深度学习</li></ul><p><strong>代码示例：传统方法的完整流程</strong></p><p>详见：<code>code/chapter02_traditional_cv/traditional_features.py</code></p><h2 id=22-传统方法的局限性>2.2 传统方法的局限性<a class=anchor href=#22-%e4%bc%a0%e7%bb%9f%e6%96%b9%e6%b3%95%e7%9a%84%e5%b1%80%e9%99%90%e6%80%a7>#</a></h2><h3 id=221-特征工程的困境>2.2.1 特征工程的困境<a class=anchor href=#221-%e7%89%b9%e5%be%81%e5%b7%a5%e7%a8%8b%e7%9a%84%e5%9b%b0%e5%a2%83>#</a></h3><p><strong>问题1：需要领域专家</strong></p><ul><li>设计好的特征需要丰富的经验</li><li>不同任务需要不同的特征</li><li>特征设计是一个试错过程</li></ul><p><strong>问题2：泛化能力有限</strong></p><ul><li>为特定任务设计的特征难以迁移</li><li>对新场景的适应性差</li><li>需要重新设计特征</li></ul><p><strong>问题3：特征表达能力不足</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>传统方法：
</span></span><span class=line><span class=cl>  图像 → 手工特征（数百到数千维）→ 分类器
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>深度学习：
</span></span><span class=line><span class=cl>  图像 → 自动学习特征（数百万参数）→ 分类</span></span></code></pre></div><h3 id=222-复杂场景下的失效>2.2.2 复杂场景下的失效<a class=anchor href=#222-%e5%a4%8d%e6%9d%82%e5%9c%ba%e6%99%af%e4%b8%8b%e7%9a%84%e5%a4%b1%e6%95%88>#</a></h3><p><strong>场景1：复杂背景</strong></p><ul><li>传统特征容易受背景干扰</li><li>难以区分前景和背景</li><li>需要额外的预处理</li></ul><p><strong>场景2：多样性变化</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>| 变化类型 | 传统方法应对 | 效果 |
</span></span><span class=line><span class=cl>|---------|------------|------|
</span></span><span class=line><span class=cl>| 光照变化 | 归一化、不变特征 | 中等 |
</span></span><span class=line><span class=cl>| 尺度变化 | 多尺度检测 | 较好 |
</span></span><span class=line><span class=cl>| 视角变化 | 3D特征、视角不变性 | 较差 |
</span></span><span class=line><span class=cl>| 遮挡 | 局部特征 | 较差 |
</span></span><span class=line><span class=cl>| 类内变化 | 特征选择 | 较差 |</span></span></code></pre></div><p><strong>场景3：高级语义理解</strong></p><ul><li>传统特征难以捕捉高级语义</li><li>无法理解上下文关系</li><li>对抽象概念的表达能力弱</li></ul><h3 id=223-性能瓶颈>2.2.3 性能瓶颈<a class=anchor href=#223-%e6%80%a7%e8%83%bd%e7%93%b6%e9%a2%88>#</a></h3><p><strong>实验数据对比</strong>（ImageNet数据集）：</p><table><thead><tr><th>方法</th><th>Top-5错误率</th><th>年份</th></tr></thead><tbody><tr><td>传统方法（SIFT+SVM）</td><td>~25%</td><td>2012前</td></tr><tr><td>AlexNet（深度学习）</td><td>15.3%</td><td>2012</td></tr><tr><td>ResNet-152</td><td>3.6%</td><td>2015</td></tr><tr><td>人类水平</td><td>~5%</td><td>-</td></tr></tbody></table><p><strong>关键观察</strong>：</p><ul><li>2012年AlexNet的出现是转折点</li><li>深度学习在大规模数据集上显著优于传统方法</li><li>持续改进，已接近甚至超越人类水平</li></ul><h2 id=23-为什么需要深度学习>2.3 为什么需要深度学习？<a class=anchor href=#23-%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0>#</a></h2><h3 id=231-自动特征学习>2.3.1 自动特征学习<a class=anchor href=#231-%e8%87%aa%e5%8a%a8%e7%89%b9%e5%be%81%e5%ad%a6%e4%b9%a0>#</a></h3><p><strong>传统方法 vs 深度学习</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>传统方法：
</span></span><span class=line><span class=cl>  ┌──────────┐    ┌──────────┐    ┌──────────┐
</span></span><span class=line><span class=cl>  │ 原始图像 │ →  │ 手工特征 │ →  │  分类器  │
</span></span><span class=line><span class=cl>  └──────────┘    └──────────┘    └──────────┘
</span></span><span class=line><span class=cl>                      ↑
</span></span><span class=line><span class=cl>                  需要人工设计
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>深度学习：
</span></span><span class=line><span class=cl>  ┌──────────┐    ┌──────────────────────┐    ┌──────────┐
</span></span><span class=line><span class=cl>  │ 原始图像 │ →  │ 自动学习的特征层级   │ →  │  分类器  │
</span></span><span class=line><span class=cl>  └──────────┘    └──────────────────────┘    └──────────┘
</span></span><span class=line><span class=cl>                  低级特征 → 中级特征 → 高级特征
</span></span><span class=line><span class=cl>                      ↑
</span></span><span class=line><span class=cl>                  端到端学习</span></span></code></pre></div><p><strong>优势</strong>：</p><ul><li><strong>自动化</strong>：不需要手工设计特征</li><li><strong>层次化</strong>：自动学习从低级到高级的特征层次</li><li><strong>端到端</strong>：直接从原始数据到最终输出</li></ul><h3 id=232-表达能力强大>2.3.2 表达能力强大<a class=anchor href=#232-%e8%a1%a8%e8%be%be%e8%83%bd%e5%8a%9b%e5%bc%ba%e5%a4%a7>#</a></h3><p><strong>特征层次的自动学习</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>卷积神经网络（CNN）的特征层次：
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>第1层（低级特征）：
</span></span><span class=line><span class=cl>  - 边缘检测器
</span></span><span class=line><span class=cl>  - 颜色斑点
</span></span><span class=line><span class=cl>  - 简单纹理
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>第2-3层（中级特征）：
</span></span><span class=line><span class=cl>  - 简单形状
</span></span><span class=line><span class=cl>  - 纹理组合
</span></span><span class=line><span class=cl>  - 局部模式
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>第4-5层（高级特征）：
</span></span><span class=line><span class=cl>  - 物体部件（眼睛、轮子等）
</span></span><span class=line><span class=cl>  - 复杂模式
</span></span><span class=line><span class=cl>  - 语义概念</span></span></code></pre></div><p><strong>可视化示例</strong>（概念图）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入图像(猫)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>[第1层] 边缘、纹理
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>[第2层] 简单形状
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>[第3层] 猫的局部特征（耳朵、眼睛）
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>[第4层] 猫的整体特征
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>输出：猫（95%置信度）</span></span></code></pre></div><h3 id=233-可扩展性>2.3.3 可扩展性<a class=anchor href=#233-%e5%8f%af%e6%89%a9%e5%b1%95%e6%80%a7>#</a></h3><p><strong>数据规模的影响</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>性能
</span></span><span class=line><span class=cl>  ↑
</span></span><span class=line><span class=cl>  |              深度学习
</span></span><span class=line><span class=cl>  |            /
</span></span><span class=line><span class=cl>  |          /
</span></span><span class=line><span class=cl>  |        /
</span></span><span class=line><span class=cl>  |      /______ 传统方法（性能饱和）
</span></span><span class=line><span class=cl>  |    /
</span></span><span class=line><span class=cl>  |  /
</span></span><span class=line><span class=cl>  |/
</span></span><span class=line><span class=cl>  └─────────────────────→ 数据量</span></span></code></pre></div><p><strong>关键点</strong>：</p><ul><li><strong>小数据</strong>：传统方法可能更好（避免过拟合）</li><li><strong>中等数据</strong>：两者接近</li><li><strong>大数据</strong>：深度学习显著优于传统方法</li></ul><h3 id=234-迁移学习能力>2.3.4 迁移学习能力<a class=anchor href=#234-%e8%bf%81%e7%a7%bb%e5%ad%a6%e4%b9%a0%e8%83%bd%e5%8a%9b>#</a></h3><p><strong>传统方法</strong>：</p><ul><li>特征通常针对特定任务</li><li>难以在不同任务间迁移</li></ul><p><strong>深度学习</strong>：</p><ul><li>预训练模型可以迁移到新任务</li><li>只需微调少量参数</li><li>大大减少训练数据需求</li></ul><p><strong>示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用预训练的ResNet模型</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision.models</span> <span class=k>as</span> <span class=nn>models</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载ImageNet预训练模型</span>
</span></span><span class=line><span class=cl><span class=n>resnet</span> <span class=o>=</span> <span class=n>models</span><span class=o>.</span><span class=n>resnet50</span><span class=p>(</span><span class=n>pretrained</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 只替换最后一层用于新任务</span>
</span></span><span class=line><span class=cl><span class=n>num_classes</span> <span class=o>=</span> <span class=mi>10</span>  <span class=c1># 新任务的类别数</span>
</span></span><span class=line><span class=cl><span class=n>resnet</span><span class=o>.</span><span class=n>fc</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>resnet</span><span class=o>.</span><span class=n>fc</span><span class=o>.</span><span class=n>in_features</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 只训练最后一层，其他层使用预训练权重</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>param</span> <span class=ow>in</span> <span class=n>resnet</span><span class=o>.</span><span class=n>parameters</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>param</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>False</span>
</span></span><span class=line><span class=cl><span class=n>resnet</span><span class=o>.</span><span class=n>fc</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=n>resnet</span><span class=o>.</span><span class=n>fc</span><span class=o>.</span><span class=n>bias</span><span class=o>.</span><span class=n>requires_grad</span> <span class=o>=</span> <span class=kc>True</span></span></span></code></pre></div><h3 id=235-深度学习的优势总结>2.3.5 深度学习的优势总结<a class=anchor href=#235-%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e4%bc%98%e5%8a%bf%e6%80%bb%e7%bb%93>#</a></h3><table><thead><tr><th>维度</th><th>传统方法</th><th>深度学习</th></tr></thead><tbody><tr><td>特征提取</td><td>手工设计</td><td>自动学习</td></tr><tr><td>表达能力</td><td>有限（数百到数千维）</td><td>强大（数百万参数）</td></tr><tr><td>数据需求</td><td>少</td><td>多（或使用预训练模型）</td></tr><tr><td>可解释性</td><td>强</td><td>较弱（黑盒）</td></tr><tr><td>泛化能力</td><td>特定任务</td><td>跨任务迁移</td></tr><tr><td>性能上限</td><td>较低</td><td>高（接近人类）</td></tr><tr><td>计算资源</td><td>少</td><td>多（需要GPU）</td></tr></tbody></table><h2 id=24-环境准备>2.4 环境准备<a class=anchor href=#24-%e7%8e%af%e5%a2%83%e5%87%86%e5%a4%87>#</a></h2><h3 id=241-pytorch环境配置>2.4.1 PyTorch环境配置<a class=anchor href=#241-pytorch%e7%8e%af%e5%a2%83%e9%85%8d%e7%bd%ae>#</a></h3><p><strong>PyTorch简介</strong>：</p><ul><li>Facebook开发的深度学习框架</li><li>动态计算图，灵活易用</li><li>学术界最流行的框架</li></ul><p><strong>安装步骤</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. 创建虚拟环境（推荐）</span>
</span></span><span class=line><span class=cl>python -m venv cv_env
</span></span><span class=line><span class=cl><span class=nb>source</span> cv_env/bin/activate  <span class=c1># Windows: cv_env\Scripts\activate</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 安装PyTorch（根据CUDA版本选择）</span>
</span></span><span class=line><span class=cl><span class=c1># CPU版本</span>
</span></span><span class=line><span class=cl>pip install torch torchvision torchaudio
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># GPU版本（CUDA 11.8）</span>
</span></span><span class=line><span class=cl>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># GPU版本（CUDA 12.1）</span>
</span></span><span class=line><span class=cl>pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 安装其他依赖</span>
</span></span><span class=line><span class=cl>pip install numpy matplotlib opencv-python scikit-image</span></span></code></pre></div><p><strong>验证安装</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;PyTorch版本: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;TorchVision版本: </span><span class=si>{</span><span class=n>torchvision</span><span class=o>.</span><span class=n>__version__</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CUDA可用: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;CUDA版本: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>version</span><span class=o>.</span><span class=n>cuda</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;GPU设备: </span><span class=si>{</span><span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>get_device_name</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>预期输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>PyTorch版本: 2.1.0+cu118
</span></span><span class=line><span class=cl>TorchVision版本: 0.16.0+cu118
</span></span><span class=line><span class=cl>CUDA可用: True
</span></span><span class=line><span class=cl>CUDA版本: 11.8
</span></span><span class=line><span class=cl>GPU设备: NVIDIA GeForce RTX 3080</span></span></code></pre></div><h3 id=242-tensorflow环境配置可选>2.4.2 TensorFlow环境配置（可选）<a class=anchor href=#242-tensorflow%e7%8e%af%e5%a2%83%e9%85%8d%e7%bd%ae%e5%8f%af%e9%80%89>#</a></h3><p><strong>TensorFlow简介</strong>：</p><ul><li>Google开发的深度学习框架</li><li>工业界广泛使用</li><li>提供TensorFlow Lite用于移动端部署</li></ul><p><strong>安装步骤</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 安装TensorFlow（包含GPU支持）</span>
</span></span><span class=line><span class=cl>pip install tensorflow
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 验证安装</span>
</span></span><span class=line><span class=cl>python -c <span class=s2>&#34;import tensorflow as tf; print(f&#39;TensorFlow版本: {tf.__version__}&#39;); print(f&#39;GPU可用: {len(tf.config.list_physical_devices(\&#34;GPU\&#34;))}&#39;)&#34;</span></span></span></code></pre></div><p><strong>本教程选择</strong>：</p><ul><li>主要使用<strong>PyTorch</strong></li><li>原因：代码更直观、调试更方便、学术界主流</li></ul><h3 id=243-完整环境配置脚本>2.4.3 完整环境配置脚本<a class=anchor href=#243-%e5%ae%8c%e6%95%b4%e7%8e%af%e5%a2%83%e9%85%8d%e7%bd%ae%e8%84%9a%e6%9c%ac>#</a></h3><p>创建<code>requirements.txt</code>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-text data-lang=text><span class=line><span class=cl># 深度学习框架
</span></span><span class=line><span class=cl>torch&gt;=2.0.0
</span></span><span class=line><span class=cl>torchvision&gt;=0.15.0
</span></span><span class=line><span class=cl>torchaudio&gt;=2.0.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 图像处理
</span></span><span class=line><span class=cl>opencv-python&gt;=4.8.0
</span></span><span class=line><span class=cl>scikit-image&gt;=0.21.0
</span></span><span class=line><span class=cl>Pillow&gt;=10.0.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 数据处理
</span></span><span class=line><span class=cl>numpy&gt;=1.24.0
</span></span><span class=line><span class=cl>pandas&gt;=2.0.0
</span></span><span class=line><span class=cl>matplotlib&gt;=3.7.0
</span></span><span class=line><span class=cl>seaborn&gt;=0.12.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 机器学习工具
</span></span><span class=line><span class=cl>scikit-learn&gt;=1.3.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># 进度条和可视化
</span></span><span class=line><span class=cl>tqdm&gt;=4.65.0
</span></span><span class=line><span class=cl>tensorboard&gt;=2.13.0
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl># Jupyter支持
</span></span><span class=line><span class=cl>jupyter&gt;=1.0.0
</span></span><span class=line><span class=cl>ipywidgets&gt;=8.0.0</span></span></code></pre></div><p>安装：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install -r requirements.txt</span></span></code></pre></div><h3 id=244-环境测试代码>2.4.4 环境测试代码<a class=anchor href=#244-%e7%8e%af%e5%a2%83%e6%b5%8b%e8%af%95%e4%bb%a3%e7%a0%81>#</a></h3><p>详见：<code>code/chapter02_traditional_cv/test_environment.py</code></p><p><strong>运行测试</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nb>cd</span> chapter02/code
</span></span><span class=line><span class=cl>python test_environment.py</span></span></code></pre></div><p><strong>预期输出</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>========================================
</span></span><span class=line><span class=cl>环境测试开始
</span></span><span class=line><span class=cl>========================================
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[测试1] PyTorch安装
</span></span><span class=line><span class=cl>  ✓ PyTorch版本: 2.1.0+cu118
</span></span><span class=line><span class=cl>  ✓ CUDA可用: True
</span></span><span class=line><span class=cl>  ✓ GPU设备: NVIDIA GeForce RTX 3080
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[测试2] 张量操作
</span></span><span class=line><span class=cl>  ✓ CPU张量创建成功
</span></span><span class=line><span class=cl>  ✓ GPU张量创建成功
</span></span><span class=line><span class=cl>  ✓ 张量运算正确
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[测试3] 图像处理库
</span></span><span class=line><span class=cl>  ✓ OpenCV版本: 4.8.0
</span></span><span class=line><span class=cl>  ✓ scikit-image可用
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>[测试4] 数据加载
</span></span><span class=line><span class=cl>  ✓ MNIST数据集加载成功
</span></span><span class=line><span class=cl>  ✓ 数据形状: torch.Size([1, 28, 28])
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>========================================
</span></span><span class=line><span class=cl>所有测试通过！环境配置成功。
</span></span><span class=line><span class=cl>========================================</span></span></code></pre></div><h2 id=25-第一个深度学习示例>2.5 第一个深度学习示例<a class=anchor href=#25-%e7%ac%ac%e4%b8%80%e4%b8%aa%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%a4%ba%e4%be%8b>#</a></h2><h3 id=简单的神经网络>简单的神经网络<a class=anchor href=#%e7%ae%80%e5%8d%95%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c>#</a></h3><p>为了对比传统方法和深度学习，我们用一个简单的神经网络重新实现MNIST分类。</p><p><strong>代码示例</strong>（概览，详细代码见<code>code/chapter02_traditional_cv/simple_nn_mnist.py</code>）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 定义简单的全连接神经网络</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>SimpleNN</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>(</span><span class=n>SimpleNN</span><span class=p>,</span> <span class=bp>self</span><span class=p>)</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span><span class=p>,</span> <span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>relu</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ReLU</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>128</span><span class=p>,</span> <span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=mi>28</span> <span class=o>*</span> <span class=mi>28</span><span class=p>)</span>  <span class=c1># 展平</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc1</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>fc2</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>SimpleNN</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>criterion</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>CrossEntropyLoss</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练循环（简化版）</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>epoch</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>images</span><span class=p>,</span> <span class=n>labels</span> <span class=ow>in</span> <span class=n>train_loader</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>criterion</span><span class=p>(</span><span class=n>outputs</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>zero_grad</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span></span></span></code></pre></div><p><strong>性能对比</strong>：</p><table><thead><tr><th>方法</th><th>准确率</th><th>训练时间</th></tr></thead><tbody><tr><td>Logistic Regression</td><td>~92%</td><td>快</td></tr><tr><td>Random Forest</td><td>~97%</td><td>中</td></tr><tr><td>简单神经网络</td><td>~98%</td><td>中（GPU加速）</td></tr><tr><td>CNN（下一篇）</td><td>~99%+</td><td>快（GPU加速）</td></tr></tbody></table><h2 id=本章小结-1>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93-1>#</a></h2><h3 id=核心知识点>核心知识点<a class=anchor href=#%e6%a0%b8%e5%bf%83%e7%9f%a5%e8%af%86%e7%82%b9>#</a></h3><ol><li><p><strong>传统特征方法</strong>：</p><ul><li>SIFT：尺度和旋转不变，用于图像匹配</li><li>HOG：梯度方向直方图，用于物体检测</li><li>优势：可解释、高效、特定任务表现好</li><li>局限：需要人工设计、泛化能力有限</li></ul></li><li><p><strong>深度学习的优势</strong>：</p><ul><li>自动特征学习，端到端训练</li><li>强大的表达能力和层次化特征</li><li>在大数据集上性能优越</li><li>支持迁移学习</li></ul></li><li><p><strong>环境准备</strong>：</p><ul><li>PyTorch是本教程的主要框架</li><li>配置GPU加速（推荐）</li><li>验证环境安装成功</li></ul></li></ol><h3 id=从传统到深度学习的转变>从传统到深度学习的转变<a class=anchor href=#%e4%bb%8e%e4%bc%a0%e7%bb%9f%e5%88%b0%e6%b7%b1%e5%ba%a6%e5%ad%a6%e4%b9%a0%e7%9a%84%e8%bd%ac%e5%8f%98>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>传统计算机视觉流程：
</span></span><span class=line><span class=cl>  图像 → 预处理 → 特征提取(手工) → 分类器 → 结果
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>深度学习流程：
</span></span><span class=line><span class=cl>  图像 → 神经网络(端到端) → 结果
</span></span><span class=line><span class=cl>           ↓
</span></span><span class=line><span class=cl>      自动学习特征</span></span></code></pre></div><h3 id=下一步学习>下一步学习<a class=anchor href=#%e4%b8%8b%e4%b8%80%e6%ad%a5%e5%ad%a6%e4%b9%a0>#</a></h3><p>完成本章后，你已经：</p><ul><li>✓ 理解了传统图像特征方法</li><li>✓ 明白了为什么需要深度学习</li><li>✓ 配置好了深度学习环境</li></ul><p><strong>第二篇预告</strong>：深度学习基础</p><ul><li>神经网络基础</li><li>反向传播算法</li><li>卷积神经网络（CNN）</li><li>经典CNN架构</li></ul><h2 id=扩展阅读-1>扩展阅读<a class=anchor href=#%e6%89%a9%e5%b1%95%e9%98%85%e8%af%bb-1>#</a></h2><ol><li><strong>SIFT原始论文</strong>：Lowe, D. G. (2004). &ldquo;Distinctive Image Features from Scale-Invariant Keypoints&rdquo;</li><li><strong>HOG原始论文</strong>：Dalal, N., & Triggs, B. (2005). &ldquo;Histograms of oriented gradients for human detection&rdquo;</li><li><strong>PyTorch官方教程</strong>：https://pytorch.org/tutorials/</li><li><strong>Deep Learning Book</strong>：http://www.deeplearningbook.org/</li></ol><h2 id=练习题-1>练习题<a class=anchor href=#%e7%bb%83%e4%b9%a0%e9%a2%98-1>#</a></h2><ol><li><strong>实践</strong>：运行<code>traditional_features.py</code>，比较SIFT和HOG在不同图像上的表现</li><li><strong>实验</strong>：使用HOG特征+SVM训练MNIST分类器，对比第1章的结果</li><li><strong>环境</strong>：确保<code>test_environment.py</code>所有测试通过</li><li><strong>思考</strong>：为什么SIFT适合图像匹配，而HOG适合物体检测？</li></ol><hr><p><strong>下一篇</strong>：<a href=../../part2_dl_basics/README.md>第二篇：深度学习基础</a></p><hr></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>fasta2a</span>
</a></span><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/ class="flex align-center"><span>第二篇 深度学习基础</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#篇章概述>篇章概述</a></li><li><a href=#章节结构>章节结构</a><ul><li><a href=#第1章机器学习核心概念>第1章：机器学习核心概念</a></li><li><a href=#第2章从传统特征到深度学习>第2章：从传统特征到深度学习</a></li></ul></li><li><a href=#学习路径>学习路径</a></li><li><a href=#学习建议>学习建议</a></li><li><a href=#环境要求>环境要求</a></li><li><a href=#预计学习时间>预计学习时间</a></li><li><a href=#后续安排>后续安排</a></li></ul><ul><li><a href=#本章概述>本章概述</a></li><li><a href=#11-机器学习基本分类>1.1 机器学习基本分类</a><ul><li><a href=#监督学习supervised-learning>监督学习（Supervised Learning）</a></li><li><a href=#无监督学习unsupervised-learning>无监督学习（Unsupervised Learning）</a></li><li><a href=#对比总结>对比总结</a></li></ul></li><li><a href=#12-损失函数与优化器>1.2 损失函数与优化器</a><ul><li><a href=#损失函数loss-function>损失函数（Loss Function）</a><ul><li><a href=#1-均方误差mse--回归任务>1. 均方误差（MSE）- 回归任务</a></li><li><a href=#2-交叉熵cross-entropy--分类任务>2. 交叉熵（Cross-Entropy）- 分类任务</a></li></ul></li><li><a href=#优化器optimizer>优化器（Optimizer）</a><ul><li><a href=#梯度下降gradient-descent>梯度下降（Gradient Descent）</a></li><li><a href=#常见优化器>常见优化器</a></li></ul></li></ul></li><li><a href=#13-过拟合与正则化>1.3 过拟合与正则化</a><ul><li><a href=#过拟合overfitting>过拟合（Overfitting）</a></li><li><a href=#欠拟合underfitting>欠拟合（Underfitting）</a></li><li><a href=#正则化regularization>正则化（Regularization）</a><ul><li><a href=#1-l1正则化lasso>1. L1正则化（Lasso）</a></li><li><a href=#2-l2正则化ridge>2. L2正则化（Ridge）</a></li><li><a href=#3-elastic-netl1--l2>3. Elastic Net（L1 + L2）</a></li><li><a href=#其他防止过拟合的方法>其他防止过拟合的方法</a></li></ul></li></ul></li><li><a href=#14-实战手写数字分类sklearn>1.4 实战：手写数字分类（sklearn）</a><ul><li><a href=#项目概述>项目概述</a></li><li><a href=#完整代码>完整代码</a></li><li><a href=#运行步骤>运行步骤</a></li><li><a href=#预期输出>预期输出</a></li><li><a href=#代码详解>代码详解</a><ul><li><a href=#1-数据加载>1. 数据加载</a></li><li><a href=#2-数据预处理>2. 数据预处理</a></li><li><a href=#3-模型训练>3. 模型训练</a></li><li><a href=#4-模型评估>4. 模型评估</a></li></ul></li><li><a href=#实验结果分析>实验结果分析</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心概念回顾>核心概念回顾</a></li><li><a href=#实战经验>实战经验</a></li><li><a href=#下一章预告>下一章预告</a></li></ul></li><li><a href=#扩展阅读>扩展阅读</a></li><li><a href=#练习题>练习题</a></li></ul><ul><li><a href=#本章概述-1>本章概述</a></li><li><a href=#21-传统图像特征>2.1 传统图像特征</a><ul><li><a href=#什么是特征>什么是特征？</a></li><li><a href=#211-siftscale-invariant-feature-transform>2.1.1 SIFT（Scale-Invariant Feature Transform）</a></li><li><a href=#212-hoghistogram-of-oriented-gradients>2.1.2 HOG（Histogram of Oriented Gradients）</a></li><li><a href=#213-其他传统特征>2.1.3 其他传统特征</a></li><li><a href=#214-传统特征的优势>2.1.4 传统特征的优势</a></li></ul></li><li><a href=#22-传统方法的局限性>2.2 传统方法的局限性</a><ul><li><a href=#221-特征工程的困境>2.2.1 特征工程的困境</a></li><li><a href=#222-复杂场景下的失效>2.2.2 复杂场景下的失效</a></li><li><a href=#223-性能瓶颈>2.2.3 性能瓶颈</a></li></ul></li><li><a href=#23-为什么需要深度学习>2.3 为什么需要深度学习？</a><ul><li><a href=#231-自动特征学习>2.3.1 自动特征学习</a></li><li><a href=#232-表达能力强大>2.3.2 表达能力强大</a></li><li><a href=#233-可扩展性>2.3.3 可扩展性</a></li><li><a href=#234-迁移学习能力>2.3.4 迁移学习能力</a></li><li><a href=#235-深度学习的优势总结>2.3.5 深度学习的优势总结</a></li></ul></li><li><a href=#24-环境准备>2.4 环境准备</a><ul><li><a href=#241-pytorch环境配置>2.4.1 PyTorch环境配置</a></li><li><a href=#242-tensorflow环境配置可选>2.4.2 TensorFlow环境配置（可选）</a></li><li><a href=#243-完整环境配置脚本>2.4.3 完整环境配置脚本</a></li><li><a href=#244-环境测试代码>2.4.4 环境测试代码</a></li></ul></li><li><a href=#25-第一个深度学习示例>2.5 第一个深度学习示例</a><ul><li><a href=#简单的神经网络>简单的神经网络</a></li></ul></li><li><a href=#本章小结-1>本章小结</a><ul><li><a href=#核心知识点>核心知识点</a></li><li><a href=#从传统到深度学习的转变>从传统到深度学习的转变</a></li><li><a href=#下一步学习>下一步学习</a></li></ul></li><li><a href=#扩展阅读-1>扩展阅读</a></li><li><a href=#练习题-1>练习题</a></li></ul></nav></div></aside></main></body></html>