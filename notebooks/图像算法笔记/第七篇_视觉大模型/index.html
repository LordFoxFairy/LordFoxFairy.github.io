<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第七篇:视觉大模型时代# 从多模态基础模型到视觉AGI的演进之路
篇章概述# 视觉大模型(Vision-Language Model, VLM)是2023-2024年计算机视觉领域最重要的技术突破。本篇深入讲解:
多模态基础模型(CLIP、BLIP、LLaVA) 前沿视觉大模型(Florence-2、GPT-4V、Gemini) 3D视觉与视频理解新进展 为什么学习视觉大模型?# 范式转变: 从单一任务模型到统一多模态模型 零样本能力: 无需训练即可完成新任务 产业应用: 正在重塑计算机视觉应用格局 技术前沿: 是通向AGI的重要路径 章节组织# 第16章:多模态基础模型# 核心主题: CLIP、BLIP、LLaVA三大基础模型
16.1 CLIP:视觉-语言对比学习
对比学习原理与双编码器架构 零样本分类、图像检索 transformers库实战 16.2 BLIP系列:视觉问答
BLIP-2架构:Q-Former设计 图像描述、VQA任务 量化优化与部署 16.3 LLaVA:大语言模型+视觉
视觉指令微调方法 多模态对话系统 LLaVA 1.5/1.6新特性 16.4 实战:多模态理解应用
商品图像搜索 智能客服机器人 图像内容审核 技术栈: transformers, torch, PIL, accelerate
代码文件:
code/clip_zero_shot.py - CLIP零样本分类 code/blip2_vqa.py - BLIP-2视觉问答 code/llava_chat.py - LLaVA多模态对话 code/multimodal_app.py - 综合应用示例 第17章:视觉大模型前沿# 核心主题: 工业级VLM与商业API
17.1 Florence-2:微软视觉基础模型
统一提示词范式 支持10+视觉任务 开源可商用(MIT协议) 17.2 GPT-4V/GPT-4o:多模态GPT
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第七篇 视觉大模型"><meta property="og:description" content="第七篇:视觉大模型时代# 从多模态基础模型到视觉AGI的演进之路
篇章概述# 视觉大模型(Vision-Language Model, VLM)是2023-2024年计算机视觉领域最重要的技术突破。本篇深入讲解:
多模态基础模型(CLIP、BLIP、LLaVA) 前沿视觉大模型(Florence-2、GPT-4V、Gemini) 3D视觉与视频理解新进展 为什么学习视觉大模型?# 范式转变: 从单一任务模型到统一多模态模型 零样本能力: 无需训练即可完成新任务 产业应用: 正在重塑计算机视觉应用格局 技术前沿: 是通向AGI的重要路径 章节组织# 第16章:多模态基础模型# 核心主题: CLIP、BLIP、LLaVA三大基础模型
16.1 CLIP:视觉-语言对比学习
对比学习原理与双编码器架构 零样本分类、图像检索 transformers库实战 16.2 BLIP系列:视觉问答
BLIP-2架构:Q-Former设计 图像描述、VQA任务 量化优化与部署 16.3 LLaVA:大语言模型+视觉
视觉指令微调方法 多模态对话系统 LLaVA 1.5/1.6新特性 16.4 实战:多模态理解应用
商品图像搜索 智能客服机器人 图像内容审核 技术栈: transformers, torch, PIL, accelerate
代码文件:
code/clip_zero_shot.py - CLIP零样本分类 code/blip2_vqa.py - BLIP-2视觉问答 code/llava_chat.py - LLaVA多模态对话 code/multimodal_app.py - 综合应用示例 第17章:视觉大模型前沿# 核心主题: 工业级VLM与商业API
17.1 Florence-2:微软视觉基础模型
统一提示词范式 支持10+视觉任务 开源可商用(MIT协议) 17.2 GPT-4V/GPT-4o:多模态GPT"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第七篇 视觉大模型"><meta itemprop=description content="第七篇:视觉大模型时代# 从多模态基础模型到视觉AGI的演进之路
篇章概述# 视觉大模型(Vision-Language Model, VLM)是2023-2024年计算机视觉领域最重要的技术突破。本篇深入讲解:
多模态基础模型(CLIP、BLIP、LLaVA) 前沿视觉大模型(Florence-2、GPT-4V、Gemini) 3D视觉与视频理解新进展 为什么学习视觉大模型?# 范式转变: 从单一任务模型到统一多模态模型 零样本能力: 无需训练即可完成新任务 产业应用: 正在重塑计算机视觉应用格局 技术前沿: 是通向AGI的重要路径 章节组织# 第16章:多模态基础模型# 核心主题: CLIP、BLIP、LLaVA三大基础模型
16.1 CLIP:视觉-语言对比学习
对比学习原理与双编码器架构 零样本分类、图像检索 transformers库实战 16.2 BLIP系列:视觉问答
BLIP-2架构:Q-Former设计 图像描述、VQA任务 量化优化与部署 16.3 LLaVA:大语言模型+视觉
视觉指令微调方法 多模态对话系统 LLaVA 1.5/1.6新特性 16.4 实战:多模态理解应用
商品图像搜索 智能客服机器人 图像内容审核 技术栈: transformers, torch, PIL, accelerate
代码文件:
code/clip_zero_shot.py - CLIP零样本分类 code/blip2_vqa.py - BLIP-2视觉问答 code/llava_chat.py - LLaVA多模态对话 code/multimodal_app.py - 综合应用示例 第17章:视觉大模型前沿# 核心主题: 工业级VLM与商业API
17.1 Florence-2:微软视觉基础模型
统一提示词范式 支持10+视觉任务 开源可商用(MIT协议) 17.2 GPT-4V/GPT-4o:多模态GPT"><meta itemprop=wordCount content="5119"><title>第七篇 视觉大模型 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle checked>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/ class=active>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第七篇 视觉大模型</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#篇章概述>篇章概述</a><ul><li><a href=#为什么学习视觉大模型>为什么学习视觉大模型?</a></li></ul></li><li><a href=#章节组织>章节组织</a><ul><li><a href=#第16章多模态基础模型>第16章:多模态基础模型</a></li><li><a href=#第17章视觉大模型前沿>第17章:视觉大模型前沿</a></li><li><a href=#第18章3d视觉与视频理解>第18章:3D视觉与视频理解</a></li></ul></li><li><a href=#技术路线图>技术路线图</a></li><li><a href=#环境配置>环境配置</a><ul><li><a href=#基础依赖>基础依赖</a></li><li><a href=#gpu要求>GPU要求</a></li></ul></li><li><a href=#学习建议>学习建议</a><ul><li><a href=#学习路径>学习路径</a></li><li><a href=#实践项目推荐>实践项目推荐</a></li></ul></li><li><a href=#参考资源>参考资源</a><ul><li><a href=#论文必读>论文必读</a></li><li><a href=#开源项目>开源项目</a></li><li><a href=#在线资源>在线资源</a></li></ul></li><li><a href=#关键技术对比>关键技术对比</a><ul><li><a href=#vlm模型选型指南>VLM模型选型指南</a></li><li><a href=#应用场景匹配>应用场景匹配</a></li></ul></li><li><a href=#本篇特色>本篇特色</a></li></ul><ul><li><a href=#本章概述>本章概述</a></li><li><a href=#161-clip视觉-语言对比学习>16.1 CLIP:视觉-语言对比学习</a><ul><li><a href=#核心思想>核心思想</a></li><li><a href=#模型架构>模型架构</a></li><li><a href=#使用transformers库>使用transformers库</a></li><li><a href=#零样本分类原理>零样本分类原理</a></li><li><a href=#性能表现>性能表现</a></li><li><a href=#应用场景>应用场景</a></li><li><a href=#代码实战>代码实战</a></li></ul></li><li><a href=#162-blip系列视觉问答>16.2 BLIP系列:视觉问答</a><ul><li><a href=#blip-2架构>BLIP-2架构</a></li><li><a href=#模型规格>模型规格</a></li><li><a href=#使用示例>使用示例</a></li><li><a href=#量化优化>量化优化</a></li><li><a href=#性能基准>性能基准</a></li><li><a href=#代码实战-1>代码实战</a></li></ul></li><li><a href=#163-llava大语言模型视觉>16.3 LLaVA:大语言模型+视觉</a><ul><li><a href=#模型概述>模型概述</a></li><li><a href=#架构设计>架构设计</a></li><li><a href=#训练流程>训练流程</a></li><li><a href=#使用transformers库-1>使用transformers库</a></li><li><a href=#llava-15-vs-16-对比>LLaVA 1.5 vs 1.6 对比</a></li><li><a href=#4-bit量化部署>4-bit量化部署</a></li><li><a href=#性能基准-1>性能基准</a></li><li><a href=#应用示例>应用示例</a></li><li><a href=#代码实战-2>代码实战</a></li></ul></li><li><a href=#164-实战多模态理解应用>16.4 实战:多模态理解应用</a><ul><li><a href=#项目1-商品图像搜索引擎>项目1: 商品图像搜索引擎</a></li><li><a href=#项目2-智能客服机器人>项目2: 智能客服机器人</a></li><li><a href=#项目3-图像内容审核系统>项目3: 图像内容审核系统</a></li><li><a href=#关键技术点>关键技术点</a></li><li><a href=#部署建议>部署建议</a></li></ul></li><li><a href=#本章总结>本章总结</a><ul><li><a href=#核心要点>核心要点</a></li><li><a href=#技术选型建议>技术选型建议</a></li><li><a href=#学习路径-1>学习路径</a></li><li><a href=#扩展资源>扩展资源</a></li></ul></li></ul><ul><li><a href=#本章概述-1>本章概述</a></li><li><a href=#171-florence-2微软视觉基础模型>17.1 Florence-2:微软视觉基础模型</a><ul><li><a href=#1711-核心特性>17.1.1 核心特性</a></li><li><a href=#1712-模型变体>17.1.2 模型变体</a></li><li><a href=#1713-支持的任务与提示词>17.1.3 支持的任务与提示词</a></li><li><a href=#1714-完整使用示例>17.1.4 完整使用示例</a></li><li><a href=#1715-结果可视化>17.1.5 结果可视化</a></li><li><a href=#1716-性能基准>17.1.6 性能基准</a></li><li><a href=#1717-实战应用场景>17.1.7 实战应用场景</a></li></ul></li><li><a href=#172-gpt-4o多模态gpt>17.2 GPT-4o:多模态GPT</a><ul><li><a href=#1721-核心特性>17.2.1 核心特性</a></li><li><a href=#1722-基础使用>17.2.2 基础使用</a></li><li><a href=#1723-多图像分析>17.2.3 多图像分析</a></li><li><a href=#1724-图像细节控制>17.2.4 图像细节控制</a></li><li><a href=#1725-结构化输出>17.2.5 结构化输出</a></li><li><a href=#1726-已知限制>17.2.6 已知限制</a></li><li><a href=#1727-成本优化策略>17.2.7 成本优化策略</a></li></ul></li><li><a href=#173-gemini-vision>17.3 Gemini Vision</a><ul><li><a href=#1731-模型系列>17.3.1 模型系列</a></li><li><a href=#1732-基础使用>17.3.2 基础使用</a></li><li><a href=#1733-使用file-api大文件>17.3.3 使用File API(大文件)</a></li><li><a href=#1734-多图像分析>17.3.4 多图像分析</a></li><li><a href=#1735-视频理解gemini独有优势>17.3.5 视频理解(Gemini独有优势)</a></li><li><a href=#1736-高级功能目标检测与分割>17.3.6 高级功能:目标检测与分割</a></li><li><a href=#1737-成本与token计算>17.3.7 成本与Token计算</a></li></ul></li><li><a href=#174-实战vlm-api调用与应用>17.4 实战:VLM API调用与应用</a><ul><li><a href=#1741-统一接口封装>17.4.1 统一接口封装</a></li><li><a href=#1742-文档理解应用>17.4.2 文档理解应用</a></li><li><a href=#1743-视频分析应用gemini>17.4.3 视频分析应用(Gemini)</a></li><li><a href=#1744-vlm性能对比>17.4.4 VLM性能对比</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心要点-1>核心要点</a></li><li><a href=#模型选择指南>模型选择指南</a></li><li><a href=#最佳实践>最佳实践</a></li><li><a href=#参考资源-1>参考资源</a></li></ul></li></ul><ul><li><a href=#本章概述-2>本章概述</a></li><li><a href=#181-nerf神经辐射场>18.1 NeRF:神经辐射场</a><ul><li><a href=#1811-核心原理>18.1.1 核心原理</a></li><li><a href=#1812-网络架构>18.1.2 网络架构</a></li><li><a href=#1813-位置编码positional-encoding>18.1.3 位置编码(Positional Encoding)</a></li><li><a href=#1814-使用nerfstudio>18.1.4 使用Nerfstudio</a></li><li><a href=#1815-instant-ngp1000倍加速>18.1.5 Instant-NGP:1000倍加速</a></li><li><a href=#1816-nerf的局限性>18.1.6 NeRF的局限性</a></li></ul></li><li><a href=#182-3d-gaussian-splatting>18.2 3D Gaussian Splatting</a><ul><li><a href=#1821-核心思想>18.2.1 核心思想</a></li><li><a href=#1822-渲染流程>18.2.2 渲染流程</a></li><li><a href=#1823-训练流程>18.2.3 训练流程</a></li><li><a href=#1824-安装与使用>18.2.4 安装与使用</a></li><li><a href=#1825-python-api使用>18.2.5 Python API使用</a></li><li><a href=#1826-3dgs-vs-nerf对比>18.2.6 3DGS vs NeRF对比</a></li><li><a href=#1827-3dgs扩展与应用>18.2.7 3DGS扩展与应用</a></li></ul></li><li><a href=#183-视频理解video-understanding>18.3 视频理解(Video Understanding)</a><ul><li><a href=#1831-视频理解任务>18.3.1 视频理解任务</a></li><li><a href=#1832-videomae视频自监督学习>18.3.2 VideoMAE:视频自监督学习</a></li><li><a href=#1833-timesformer时空transformer>18.3.3 TimeSformer:时空Transformer</a></li><li><a href=#1834-video-llava视频语言模型>18.3.4 Video-LLaVA:视频语言模型</a></li><li><a href=#1835-视频分析最佳实践>18.3.5 视频分析最佳实践</a></li></ul></li><li><a href=#184-实战3d重建项目>18.4 实战:3D重建项目</a><ul><li><a href=#1841-完整3d重建流程>18.4.1 完整3D重建流程</a></li><li><a href=#1842-数据采集指南>18.4.2 数据采集指南</a></li><li><a href=#1843-使用colmap进行sfm>18.4.3 使用COLMAP进行SfM</a></li><li><a href=#1844-3dgs训练脚本>18.4.4 3DGS训练脚本</a></li><li><a href=#1845-web可视化>18.4.5 Web可视化</a></li><li><a href=#1846-导出与部署>18.4.6 导出与部署</a></li></ul></li><li><a href=#本章小结-1>本章小结</a><ul><li><a href=#核心知识点>核心知识点</a></li><li><a href=#技术对比>技术对比</a></li><li><a href=#实践建议>实践建议</a></li><li><a href=#参考资源-2>参考资源</a></li></ul></li><li><a href=#第七篇总结>第七篇总结</a><ul><li><a href=#学习成果>学习成果</a></li><li><a href=#技术栈总结>技术栈总结</a></li><li><a href=#下一步>下一步</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第七篇视觉大模型时代>第七篇:视觉大模型时代<a class=anchor href=#%e7%ac%ac%e4%b8%83%e7%af%87%e8%a7%86%e8%a7%89%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%97%b6%e4%bb%a3>#</a></h1><blockquote class=book-hint><p>从多模态基础模型到视觉AGI的演进之路</p></blockquote><h2 id=篇章概述>篇章概述<a class=anchor href=#%e7%af%87%e7%ab%a0%e6%a6%82%e8%bf%b0>#</a></h2><p>视觉大模型(Vision-Language Model, VLM)是2023-2024年计算机视觉领域最重要的技术突破。本篇深入讲解:</p><ul><li>多模态基础模型(CLIP、BLIP、LLaVA)</li><li>前沿视觉大模型(Florence-2、GPT-4V、Gemini)</li><li>3D视觉与视频理解新进展</li></ul><h3 id=为什么学习视觉大模型>为什么学习视觉大模型?<a class=anchor href=#%e4%b8%ba%e4%bb%80%e4%b9%88%e5%ad%a6%e4%b9%a0%e8%a7%86%e8%a7%89%e5%a4%a7%e6%a8%a1%e5%9e%8b>#</a></h3><ol><li><strong>范式转变</strong>: 从单一任务模型到统一多模态模型</li><li><strong>零样本能力</strong>: 无需训练即可完成新任务</li><li><strong>产业应用</strong>: 正在重塑计算机视觉应用格局</li><li><strong>技术前沿</strong>: 是通向AGI的重要路径</li></ol><h2 id=章节组织>章节组织<a class=anchor href=#%e7%ab%a0%e8%8a%82%e7%bb%84%e7%bb%87>#</a></h2><h3 id=第16章多模态基础模型><a href=chapter16/README.md>第16章:多模态基础模型</a><a class=anchor href=#%e7%ac%ac16%e7%ab%a0%e5%a4%9a%e6%a8%a1%e6%80%81%e5%9f%ba%e7%a1%80%e6%a8%a1%e5%9e%8b>#</a></h3><p><strong>核心主题</strong>: CLIP、BLIP、LLaVA三大基础模型</p><ul><li><p><strong>16.1 CLIP:视觉-语言对比学习</strong></p><ul><li>对比学习原理与双编码器架构</li><li>零样本分类、图像检索</li><li>transformers库实战</li></ul></li><li><p><strong>16.2 BLIP系列:视觉问答</strong></p><ul><li>BLIP-2架构:Q-Former设计</li><li>图像描述、VQA任务</li><li>量化优化与部署</li></ul></li><li><p><strong>16.3 LLaVA:大语言模型+视觉</strong></p><ul><li>视觉指令微调方法</li><li>多模态对话系统</li><li>LLaVA 1.5/1.6新特性</li></ul></li><li><p><strong>16.4 实战:多模态理解应用</strong></p><ul><li>商品图像搜索</li><li>智能客服机器人</li><li>图像内容审核</li></ul></li></ul><p><strong>技术栈</strong>: <code>transformers</code>, <code>torch</code>, <code>PIL</code>, <code>accelerate</code></p><p><strong>代码文件</strong>:</p><ul><li><code>code/clip_zero_shot.py</code> - CLIP零样本分类</li><li><code>code/blip2_vqa.py</code> - BLIP-2视觉问答</li><li><code>code/llava_chat.py</code> - LLaVA多模态对话</li><li><code>code/multimodal_app.py</code> - 综合应用示例</li></ul><h3 id=第17章视觉大模型前沿><a href=chapter17/README.md>第17章:视觉大模型前沿</a><a class=anchor href=#%e7%ac%ac17%e7%ab%a0%e8%a7%86%e8%a7%89%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%89%8d%e6%b2%bf>#</a></h3><p><strong>核心主题</strong>: 工业级VLM与商业API</p><ul><li><p><strong>17.1 Florence-2:微软视觉基础模型</strong></p><ul><li>统一提示词范式</li><li>支持10+视觉任务</li><li>开源可商用(MIT协议)</li></ul></li><li><p><strong>17.2 GPT-4V/GPT-4o:多模态GPT</strong></p><ul><li>Vision API调用方法</li><li>提示词工程技巧</li><li>实际应用案例</li></ul></li><li><p><strong>17.3 Gemini Vision:Google多模态</strong></p><ul><li>Gemini 1.5/2.0对比</li><li>原生多模态能力</li><li>视频理解特性</li></ul></li><li><p><strong>17.4 实战:VLM API调用与应用</strong></p><ul><li>文档理解与OCR</li><li>视频分析应用</li><li>成本优化策略</li></ul></li></ul><p><strong>技术栈</strong>: <code>openai</code>, <code>google-generativeai</code>, <code>anthropic</code></p><p><strong>代码文件</strong>:</p><ul><li><code>code/florence2_demo.py</code> - Florence-2多任务演示</li><li><code>code/gpt4v_api.py</code> - GPT-4V API调用</li><li><code>code/gemini_vision.py</code> - Gemini Vision使用</li><li><code>code/vlm_comparison.py</code> - VLM性能对比</li></ul><h3 id=第18章3d视觉与视频理解><a href=chapter18/README.md>第18章:3D视觉与视频理解</a><a class=anchor href=#%e7%ac%ac18%e7%ab%a03d%e8%a7%86%e8%a7%89%e4%b8%8e%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3>#</a></h3><p><strong>核心主题</strong>: 从2D到3D/4D的扩展</p><ul><li><p><strong>18.1 NeRF:神经辐射场</strong></p><ul><li>隐式3D表示</li><li>体渲染原理</li><li>Instant-NGP加速</li></ul></li><li><p><strong>18.2 Gaussian Splatting:3D重建新范式</strong></p><ul><li>显式3D高斯表示</li><li>实时渲染能力</li><li>与NeRF对比</li></ul></li><li><p><strong>18.3 Video Understanding:视频分类与检测</strong></p><ul><li>TimeSformer、VideoMAE</li><li>视频VLM(Video-LLaVA)</li><li>时序动作检测</li></ul></li><li><p><strong>18.4 实战:3D重建项目</strong></p><ul><li>手机拍摄到3D模型</li><li>场景重建流程</li><li>Web可视化展示</li></ul></li></ul><p><strong>技术栈</strong>: <code>torch</code>, <code>trimesh</code>, <code>open3d</code>, <code>gradio</code></p><p><strong>代码文件</strong>:</p><ul><li><code>code/nerf_basic.py</code> - NeRF基础实现</li><li><code>code/gaussian_splatting.py</code> - 3DGS演示</li><li><code>code/video_vlm.py</code> - 视频理解模型</li><li><code>code/3d_reconstruction.py</code> - 3D重建流程</li></ul><h2 id=技术路线图>技术路线图<a class=anchor href=#%e6%8a%80%e6%9c%af%e8%b7%af%e7%ba%bf%e5%9b%be>#</a></h2><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>传统CV              多模态基础           视觉大模型              未来方向
</span></span><span class=line><span class=cl>  |                    |                    |                      |
</span></span><span class=line><span class=cl>ImageNet          CLIP(2021)         Florence-2(2024)      视觉AGI
</span></span><span class=line><span class=cl>ResNet            BLIP(2022)         GPT-4V(2023)          具身智能
</span></span><span class=line><span class=cl>Detection    --&gt;  LLaVA(2023)   --&gt;  Gemini(2024)    --&gt;   世界模型
</span></span><span class=line><span class=cl>Segmentation      BLIP-2(2023)       GPT-4o(2024)          多模态推理</span></span></code></pre></div><h2 id=环境配置>环境配置<a class=anchor href=#%e7%8e%af%e5%a2%83%e9%85%8d%e7%bd%ae>#</a></h2><h3 id=基础依赖>基础依赖<a class=anchor href=#%e5%9f%ba%e7%a1%80%e4%be%9d%e8%b5%96>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 核心库</span>
</span></span><span class=line><span class=cl>pip install transformers&gt;<span class=o>=</span>4.35.0 torch torchvision
</span></span><span class=line><span class=cl>pip install accelerate bitsandbytes  <span class=c1># 量化加速</span>
</span></span><span class=line><span class=cl>pip install pillow requests datasets
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># API客户端</span>
</span></span><span class=line><span class=cl>pip install openai&gt;<span class=o>=</span>1.0.0
</span></span><span class=line><span class=cl>pip install google-generativeai
</span></span><span class=line><span class=cl>pip install anthropic
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3D/视频</span>
</span></span><span class=line><span class=cl>pip install open3d trimesh
</span></span><span class=line><span class=cl>pip install opencv-python decord</span></span></code></pre></div><h3 id=gpu要求>GPU要求<a class=anchor href=#gpu%e8%a6%81%e6%b1%82>#</a></h3><table><thead><tr><th>模型</th><th>最小显存</th><th>推荐显存</th><th>量化方案</th></tr></thead><tbody><tr><td>CLIP</td><td>2GB</td><td>4GB</td><td>-</td></tr><tr><td>BLIP-2</td><td>6GB</td><td>12GB</td><td>int8/int4</td></tr><tr><td>LLaVA-7B</td><td>14GB</td><td>24GB</td><td>4bit量化</td></tr><tr><td>Florence-2</td><td>4GB</td><td>8GB</td><td>float16</td></tr></tbody></table><h2 id=学习建议>学习建议<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e5%bb%ba%e8%ae%ae>#</a></h2><h3 id=学习路径>学习路径<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84>#</a></h3><ol><li><p><strong>Week 1-2</strong>: 第16章多模态基础</p><ul><li>理解对比学习原理</li><li>掌握CLIP、BLIP使用</li><li>完成零样本分类实验</li></ul></li><li><p><strong>Week 3</strong>: 第17章前沿VLM</p><ul><li>学习Florence-2统一范式</li><li>实践商业API调用</li><li>对比不同VLM性能</li></ul></li><li><p><strong>Week 4</strong>: 第18章3D/视频</p><ul><li>理解NeRF/3DGS原理</li><li>尝试3D重建项目</li><li>探索视频VLM应用</li></ul></li></ol><h3 id=实践项目推荐>实践项目推荐<a class=anchor href=#%e5%ae%9e%e8%b7%b5%e9%a1%b9%e7%9b%ae%e6%8e%a8%e8%8d%90>#</a></h3><ol><li><strong>初级</strong>: CLIP图像搜索引擎</li><li><strong>中级</strong>: LLaVA多模态客服</li><li><strong>高级</strong>: Florence-2通用视觉助手</li><li><strong>进阶</strong>: 3D场景重建系统</li></ol><h2 id=参考资源>参考资源<a class=anchor href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%ba%90>#</a></h2><h3 id=论文必读>论文必读<a class=anchor href=#%e8%ae%ba%e6%96%87%e5%bf%85%e8%af%bb>#</a></h3><ul><li><strong>CLIP</strong>: <a href=https://arxiv.org/abs/2103.00020>Learning Transferable Visual Models From Natural Language Supervision</a> (ICML 2021)</li><li><strong>BLIP-2</strong>: <a href=https://arxiv.org/abs/2301.12597>Bootstrapping Language-Image Pre-training</a> (ICML 2023)</li><li><strong>LLaVA</strong>: <a href=https://arxiv.org/abs/2304.08485>Visual Instruction Tuning</a> (NeurIPS 2023)</li><li><strong>Florence-2</strong>: <a href=https://arxiv.org/abs/2311.06242>Advancing a Unified Representation</a> (CVPR 2024)</li><li><strong>NeRF</strong>: <a href=https://arxiv.org/abs/2003.08934>Representing Scenes as Neural Radiance Fields</a> (ECCV 2020)</li><li><strong>3DGS</strong>: <a href=https://arxiv.org/abs/2308.04079>3D Gaussian Splatting</a> (SIGGRAPH 2023)</li></ul><h3 id=开源项目>开源项目<a class=anchor href=#%e5%bc%80%e6%ba%90%e9%a1%b9%e7%9b%ae>#</a></h3><ul><li><a href=https://github.com/huggingface/transformers>Hugging Face Transformers</a> - VLM统一接口</li><li><a href=https://github.com/haotian-liu/LLaVA>LLaVA Official</a> - 视觉指令微调</li><li><a href=https://huggingface.co/microsoft/Florence-2-large>Florence-2 Demo</a> - 微软官方模型</li><li><a href=https://github.com/nerfstudio-project/nerfstudio>Nerfstudio</a> - NeRF工具箱</li><li><a href=https://github.com/graphdeco-inria/gaussian-splatting>Gaussian Splatting</a> - 官方实现</li></ul><h3 id=在线资源>在线资源<a class=anchor href=#%e5%9c%a8%e7%ba%bf%e8%b5%84%e6%ba%90>#</a></h3><ul><li><a href=https://platform.openai.com/docs/guides/vision>OpenAI Vision Guide</a></li><li><a href=https://ai.google.dev/docs>Google AI Gemini</a></li><li><a href=https://huggingface.co/spaces/opencompass/open_vlm_leaderboard>Hugging Face VLM排行榜</a></li></ul><h2 id=关键技术对比>关键技术对比<a class=anchor href=#%e5%85%b3%e9%94%ae%e6%8a%80%e6%9c%af%e5%af%b9%e6%af%94>#</a></h2><h3 id=vlm模型选型指南>VLM模型选型指南<a class=anchor href=#vlm%e6%a8%a1%e5%9e%8b%e9%80%89%e5%9e%8b%e6%8c%87%e5%8d%97>#</a></h3><table><thead><tr><th>模型</th><th>开源</th><th>参数量</th><th>优势</th><th>适用场景</th></tr></thead><tbody><tr><td>CLIP</td><td>✅</td><td>0.4B</td><td>零样本分类强</td><td>图像搜索、检索</td></tr><tr><td>BLIP-2</td><td>✅</td><td>4B</td><td>VQA性能优秀</td><td>视觉问答、描述生成</td></tr><tr><td>LLaVA</td><td>✅</td><td>7-13B</td><td>对话能力强</td><td>多模态助手</td></tr><tr><td>Florence-2</td><td>✅</td><td>0.77B</td><td>统一多任务</td><td>通用视觉API</td></tr><tr><td>GPT-4V</td><td>❌</td><td>-</td><td>综合能力最强</td><td>复杂推理、文档理解</td></tr><tr><td>Gemini</td><td>❌</td><td>-</td><td>原生多模态、视频理解</td><td>长视频分析、多模态生成</td></tr></tbody></table><h3 id=应用场景匹配>应用场景匹配<a class=anchor href=#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af%e5%8c%b9%e9%85%8d>#</a></h3><ul><li><strong>电商搜索</strong>: CLIP(以图搜图) + Florence-2(商品属性提取)</li><li><strong>智能客服</strong>: LLaVA(多轮对话) + GPT-4V(复杂问题)</li><li><strong>内容审核</strong>: Florence-2(快速检测) + Gemini(视频审核)</li><li><strong>文档理解</strong>: GPT-4V(表格/图表) + Florence-2(OCR)</li><li><strong>3D重建</strong>: NeRF/3DGS(场景重建) + VLM(语义理解)</li></ul><h2 id=本篇特色>本篇特色<a class=anchor href=#%e6%9c%ac%e7%af%87%e7%89%b9%e8%89%b2>#</a></h2><ol><li><strong>全栈覆盖</strong>: 从开源模型到商业API</li><li><strong>代码可运行</strong>: 所有示例基于最新版本</li><li><strong>实战导向</strong>: 每章包含完整应用案例</li><li><strong>性能对比</strong>: 详细评测数据与成本分析</li><li><strong>前沿跟踪</strong>: 涵盖2024年最新进展</li></ol><hr><p><strong>学习提示</strong>:</p><ul><li>视觉大模型是快速发展的领域,建议关注Hugging Face和ArXiv最新论文</li><li>商业API(GPT-4V/Gemini)需要付费,可先用开源模型学习</li><li>3D视觉部分计算密集,建议在GPU环境运行</li></ul><p><strong>下一步</strong>: 开始学习<a href=chapter16/README.md>第16章:多模态基础模型</a>,掌握CLIP、BLIP、LLaVA核心技术!</p><hr><h1 id=第16章多模态基础模型-1>第16章:多模态基础模型<a class=anchor href=#%e7%ac%ac16%e7%ab%a0%e5%a4%9a%e6%a8%a1%e6%80%81%e5%9f%ba%e7%a1%80%e6%a8%a1%e5%9e%8b-1>#</a></h1><blockquote class=book-hint><p>CLIP、BLIP、LLaVA - 连接视觉与语言的桥梁</p></blockquote><h2 id=本章概述>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0>#</a></h2><p>多模态基础模型是视觉大模型时代的基石。本章深入讲解三个里程碑式的模型:</p><ul><li><strong>CLIP</strong>: OpenAI的对比学习范式,开启零样本视觉新时代</li><li><strong>BLIP系列</strong>: Salesforce的视觉问答专家</li><li><strong>LLaVA</strong>: 将大语言模型与视觉完美结合的开创者</li></ul><p>通过本章学习,你将掌握多模态模型的核心原理、使用方法和实际应用。</p><h2 id=161-clip视觉-语言对比学习>16.1 CLIP:视觉-语言对比学习<a class=anchor href=#161-clip%e8%a7%86%e8%a7%89-%e8%af%ad%e8%a8%80%e5%af%b9%e6%af%94%e5%ad%a6%e4%b9%a0>#</a></h2><h3 id=核心思想>核心思想<a class=anchor href=#%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3>#</a></h3><p>CLIP(Contrastive Language-Image Pre-training)通过对比学习将图像和文本映射到同一语义空间,实现零样本分类。</p><p><strong>关键创新</strong>:</p><ol><li>在4亿图像-文本对上训练</li><li>双编码器架构(Image Encoder + Text Encoder)</li><li>对比损失函数建立视觉-语言对齐</li></ol><h3 id=模型架构>模型架构<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Image Input                Text Input
</span></span><span class=line><span class=cl>     |                          |
</span></span><span class=line><span class=cl>Image Encoder              Text Encoder
</span></span><span class=line><span class=cl>(ViT-L/14)                (Transformer)
</span></span><span class=line><span class=cl>     |                          |
</span></span><span class=line><span class=cl>  Image                      Text
</span></span><span class=line><span class=cl>Embedding                 Embedding
</span></span><span class=line><span class=cl>     |                          |
</span></span><span class=line><span class=cl>     +--------Cosine Sim--------+
</span></span><span class=line><span class=cl>              (Similarity Score)</span></span></code></pre></div><p><strong>技术细节</strong>:</p><ul><li><strong>Image Encoder</strong>: Vision Transformer (ViT-L/14, 400M参数)</li><li><strong>Text Encoder</strong>: Transformer with masked self-attention</li><li><strong>训练目标</strong>: InfoNCE对比损失</li><li><strong>输出维度</strong>: 768维特征向量</li></ul><h3 id=使用transformers库>使用transformers库<a class=anchor href=#%e4%bd%bf%e7%94%a8transformers%e5%ba%93>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>CLIPProcessor</span><span class=p>,</span> <span class=n>CLIPModel</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型(自动下载)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>CLIPModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;openai/clip-vit-large-patch14&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>CLIPProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;openai/clip-vit-large-patch14&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 准备输入</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;image.jpg&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>text_candidates</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;a photo of a cat&#34;</span><span class=p>,</span> <span class=s2>&#34;a photo of a dog&#34;</span><span class=p>,</span> <span class=s2>&#34;a photo of a bird&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 编码</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=o>=</span><span class=n>text_candidates</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>padding</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logits_per_image</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>logits_per_image</span>  <span class=c1># (1, 3)</span>
</span></span><span class=line><span class=cl>    <span class=n>probs</span> <span class=o>=</span> <span class=n>logits_per_image</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># (1, 3)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 结果</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;概率分布: </span><span class=si>{</span><span class=n>probs</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>tolist</span><span class=p>()</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>predicted_label</span> <span class=o>=</span> <span class=n>text_candidates</span><span class=p>[</span><span class=n>probs</span><span class=o>.</span><span class=n>argmax</span><span class=p>()]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;预测类别: </span><span class=si>{</span><span class=n>predicted_label</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=零样本分类原理>零样本分类原理<a class=anchor href=#%e9%9b%b6%e6%a0%b7%e6%9c%ac%e5%88%86%e7%b1%bb%e5%8e%9f%e7%90%86>#</a></h3><p>CLIP无需任何训练即可对新类别分类:</p><ol><li><p><strong>文本提示工程</strong>: 将类别转换为描述性文本</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 基础提示</span>
</span></span><span class=line><span class=cl><span class=n>texts</span> <span class=o>=</span> <span class=p>[</span><span class=sa>f</span><span class=s2>&#34;a photo of a </span><span class=si>{</span><span class=n>label</span><span class=si>}</span><span class=s2>&#34;</span> <span class=k>for</span> <span class=n>label</span> <span class=ow>in</span> <span class=n>class_names</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 高级提示(提升性能)</span>
</span></span><span class=line><span class=cl><span class=n>templates</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a photo of a </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a rendering of a </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a cropped photo of a </span><span class=si>{}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=c1># ... 80个模板集成</span>
</span></span><span class=line><span class=cl><span class=p>]</span></span></span></code></pre></div></li><li><p><strong>相似度计算</strong>: 图像与所有文本的余弦相似度</p></li><li><p><strong>Softmax归一化</strong>: 得到概率分布</p></li></ol><h3 id=性能表现>性能表现<a class=anchor href=#%e6%80%a7%e8%83%bd%e8%a1%a8%e7%8e%b0>#</a></h3><table><thead><tr><th>数据集</th><th>准确率</th><th>备注</th></tr></thead><tbody><tr><td>ImageNet</td><td>76.2%</td><td>零样本(top-1)</td></tr><tr><td>CIFAR-10</td><td>94.9%</td><td>零样本</td></tr><tr><td>CIFAR-100</td><td>77.4%</td><td>零样本</td></tr><tr><td>Oxford-Pets</td><td>93.8%</td><td>零样本</td></tr></tbody></table><p><strong>对比</strong>: ResNet-50在ImageNet上需要100万标注样本才能达到76%。</p><h3 id=应用场景>应用场景<a class=anchor href=#%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h3><ol><li><strong>以图搜图</strong>: 将图像和商品描述对齐</li><li><strong>内容审核</strong>: 零样本检测不适内容</li><li><strong>图像标注</strong>: 自动生成标签</li><li><strong>跨模态检索</strong>: 文本搜索图像或反之</li></ol><h3 id=代码实战>代码实战<a class=anchor href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e6%88%98>#</a></h3><p>参见 <code>code/chapter16_multimodal/clip_zero_shot.py</code> - 完整的零样本分类示例,包括:</p><ul><li>多类别分类</li><li>自定义提示模板</li><li>批量图像处理</li><li>可视化结果</li></ul><hr><h2 id=162-blip系列视觉问答>16.2 BLIP系列:视觉问答<a class=anchor href=#162-blip%e7%b3%bb%e5%88%97%e8%a7%86%e8%a7%89%e9%97%ae%e7%ad%94>#</a></h2><h3 id=blip-2架构>BLIP-2架构<a class=anchor href=#blip-2%e6%9e%b6%e6%9e%84>#</a></h3><p>BLIP-2(Bootstrapping Language-Image Pre-training v2)是Salesforce在2023年推出的视觉-语言模型。</p><p><strong>核心创新: Q-Former</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Frozen Image       Q-Former        Frozen LLM
</span></span><span class=line><span class=cl>Encoder          (Learnable)      (OPT-2.7B)
</span></span><span class=line><span class=cl>   |                 |                 |
</span></span><span class=line><span class=cl> ViT-g      32个Query Tokens      Language
</span></span><span class=line><span class=cl>(1.4B)           (762M)            Model
</span></span><span class=line><span class=cl>   |                 |                 |
</span></span><span class=line><span class=cl>   +-------Cross Attention---------+
</span></span><span class=line><span class=cl>                     |
</span></span><span class=line><span class=cl>                Text Output</span></span></code></pre></div><p><strong>三大优势</strong>:</p><ol><li><strong>参数高效</strong>: 只训练Q-Former(762M),冻结图像/文本编码器</li><li><strong>任务通用</strong>: 支持图像描述、VQA、对话</li><li><strong>性能强大</strong>: 在多个基准上超越Flamingo(80B参数)</li></ol><h3 id=模型规格>模型规格<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e8%a7%84%e6%a0%bc>#</a></h3><table><thead><tr><th>模型变体</th><th>参数量</th><th>LLM基座</th><th>显存需求</th></tr></thead><tbody><tr><td>blip2-opt-2.7b</td><td>4B</td><td>OPT-2.7B</td><td>14GB</td></tr><tr><td>blip2-flan-t5-xl</td><td>4B</td><td>Flan-T5</td><td>15GB</td></tr><tr><td>blip2-opt-6.7b</td><td>8B</td><td>OPT-6.7B</td><td>26GB</td></tr></tbody></table><h3 id=使用示例>使用示例<a class=anchor href=#%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b>#</a></h3><p><strong>图像描述生成</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>Blip2Processor</span><span class=p>,</span> <span class=n>Blip2ForConditionalGeneration</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型(推荐float16)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>Blip2Processor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;Salesforce/blip2-opt-2.7b&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Blip2ForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Salesforce/blip2-opt-2.7b&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成描述</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;image.jpg&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>50</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>caption</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;图像描述: </span><span class=si>{</span><span class=n>caption</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>视觉问答(VQA)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 提问</span>
</span></span><span class=line><span class=cl><span class=n>question</span> <span class=o>=</span> <span class=s2>&#34;What is the color of the car?&#34;</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>question</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成答案</span>
</span></span><span class=line><span class=cl><span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>20</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>answer</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;回答: </span><span class=si>{</span><span class=n>answer</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=量化优化>量化优化<a class=anchor href=#%e9%87%8f%e5%8c%96%e4%bc%98%e5%8c%96>#</a></h3><p><strong>8-bit量化</strong>(显存减半):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Blip2ForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Salesforce/blip2-opt-2.7b&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>load_in_8bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 显存: 14GB -&gt; 7GB</span></span></span></code></pre></div><p><strong>4-bit量化</strong>(显存1/4):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>BitsAndBytesConfig</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>quantization_config</span> <span class=o>=</span> <span class=n>BitsAndBytesConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_compute_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>Blip2ForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Salesforce/blip2-opt-2.7b&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>quantization_config</span><span class=o>=</span><span class=n>quantization_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 显存: 14GB -&gt; 3.5GB</span></span></span></code></pre></div><h3 id=性能基准>性能基准<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%9f%ba%e5%87%86>#</a></h3><table><thead><tr><th>任务</th><th>数据集</th><th>BLIP-2</th><th>Flamingo-80B</th></tr></thead><tbody><tr><td>VQA</td><td>VQAv2</td><td>82.2</td><td>82.0</td></tr><tr><td>图像描述</td><td>COCO</td><td>144.5</td><td>138.1</td></tr><tr><td>视觉推理</td><td>NLVR2</td><td>85.3</td><td>84.0</td></tr></tbody></table><h3 id=代码实战-1>代码实战<a class=anchor href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e6%88%98-1>#</a></h3><p>参见 <code>code/chapter16_multimodal/blip2_vqa.py</code> - BLIP-2视觉问答完整示例:</p><ul><li>图像描述生成</li><li>多轮问答对话</li><li>量化加载与性能对比</li><li>批量处理优化</li></ul><hr><h2 id=163-llava大语言模型视觉>16.3 LLaVA:大语言模型+视觉<a class=anchor href=#163-llava%e5%a4%a7%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b%e8%a7%86%e8%a7%89>#</a></h2><h3 id=模型概述>模型概述<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e6%a6%82%e8%bf%b0>#</a></h3><p>LLaVA(Large Language and Vision Assistant)是威斯康星大学在2023年提出的开源视觉对话模型。</p><p><strong>核心思想</strong>: 将视觉编码器与大语言模型通过简单的线性层连接,在GPT-4生成的多模态指令数据上微调。</p><h3 id=架构设计>架构设计<a class=anchor href=#%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>Image Input
</span></span><span class=line><span class=cl>    |
</span></span><span class=line><span class=cl>Vision Encoder ────────&gt; Projection Layer ────&gt; LLM
</span></span><span class=line><span class=cl>(CLIP ViT-L/14)         (Linear Layer)      (Vicuna-7B/13B)
</span></span><span class=line><span class=cl>    |                         |                    |
</span></span><span class=line><span class=cl>768D Embedding  ────&gt;  4096D Embedding  ──&gt; Text Generation</span></span></code></pre></div><p><strong>关键组件</strong>:</p><ol><li><strong>Vision Encoder</strong>: 预训练CLIP ViT-L/14(冻结)</li><li><strong>Projection Layer</strong>: 简单线性层(768→4096),唯一训练的连接层</li><li><strong>LLM</strong>: Vicuna-7B/13B(LoRA微调)</li></ol><h3 id=训练流程>训练流程<a class=anchor href=#%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b>#</a></h3><p><strong>两阶段训练</strong>:</p><ol><li><p><strong>Stage 1: 特征对齐</strong> (预训练)</p><ul><li>数据: 595K图像-文本对(CC3M过滤)</li><li>训练: 只训练Projection Layer</li><li>目标: 将视觉特征映射到LLM空间</li></ul></li><li><p><strong>Stage 2: 指令微调</strong></p><ul><li>数据: 158K多模态指令(GPT-4生成)</li><li>训练: Projection + LLM(LoRA)</li><li>目标: 提升对话和推理能力</li></ul></li></ol><h3 id=使用transformers库-1>使用transformers库<a class=anchor href=#%e4%bd%bf%e7%94%a8transformers%e5%ba%93-1>#</a></h3><p><strong>LLaVA 1.5官方模型</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoProcessor</span><span class=p>,</span> <span class=n>LlavaForConditionalGeneration</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;llava-hf/llava-1.5-7b-hf&#34;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LlavaForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建对话</span>
</span></span><span class=line><span class=cl><span class=n>conversation</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;描述这张图片中的内容。&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成回复</span>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>conversation</span><span class=p>,</span> <span class=n>add_generation_prompt</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span> <span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=p>)</span></span></span></code></pre></div><h3 id=llava-15-vs-16-对比>LLaVA 1.5 vs 1.6 对比<a class=anchor href=#llava-15-vs-16-%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>特性</th><th>LLaVA 1.5</th><th>LLaVA 1.6 (Next)</th></tr></thead><tbody><tr><td>发布时间</td><td>2023年10月</td><td>2024年1月</td></tr><tr><td>基座LLM</td><td>Vicuna</td><td>Mistral/Nous</td></tr><tr><td>图像分辨率</td><td>336×336</td><td>672×672</td></tr><tr><td>多图支持</td><td>❌</td><td>✅</td></tr><tr><td>性能(MMBench)</td><td>67.7</td><td>72.3</td></tr></tbody></table><p><strong>推荐</strong>: 生产环境使用LLaVA 1.5(更稳定),研究尝试1.6。</p><h3 id=4-bit量化部署>4-bit量化部署<a class=anchor href=#4-bit%e9%87%8f%e5%8c%96%e9%83%a8%e7%bd%b2>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>BitsAndBytesConfig</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 配置4-bit量化</span>
</span></span><span class=line><span class=cl><span class=n>bnb_config</span> <span class=o>=</span> <span class=n>BitsAndBytesConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_quant_type</span><span class=o>=</span><span class=s2>&#34;nf4&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_compute_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载量化模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LlavaForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;llava-hf/llava-1.5-7b-hf&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>quantization_config</span><span class=o>=</span><span class=n>bnb_config</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 显存: 28GB -&gt; 5GB (减少82%)</span></span></span></code></pre></div><h3 id=性能基准-1>性能基准<a class=anchor href=#%e6%80%a7%e8%83%bd%e5%9f%ba%e5%87%86-1>#</a></h3><table><thead><tr><th>任务</th><th>数据集</th><th>LLaVA 1.5</th><th>GPT-4V</th></tr></thead><tbody><tr><td>视觉问答</td><td>VQAv2</td><td>78.5</td><td>77.2</td></tr><tr><td>视觉推理</td><td>GQA</td><td>62.0</td><td>-</td></tr><tr><td>多模态基准</td><td>MMBench</td><td>67.7</td><td>75.1</td></tr><tr><td>OCR</td><td>TextVQA</td><td>58.2</td><td>78.0</td></tr></tbody></table><p><strong>亮点</strong>: 作为开源模型,LLaVA在某些任务上接近甚至超过闭源GPT-4V。</p><h3 id=应用示例>应用示例<a class=anchor href=#%e5%ba%94%e7%94%a8%e7%a4%ba%e4%be%8b>#</a></h3><ol><li><p><strong>智能图像助手</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>questions</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;图片中有什么物体?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;这些物体的位置关系是什么?&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;根据图片内容,这可能是什么场景?&#34;</span>
</span></span><span class=line><span class=cl><span class=p>]</span></span></span></code></pre></div></li><li><p><strong>视觉内容审核</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;请判断这张图片是否包含不适内容,并说明原因。&#34;</span></span></span></code></pre></div></li><li><p><strong>教育辅助</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;这是一道数学题的图片,请解答并说明步骤。&#34;</span></span></span></code></pre></div></li></ol><h3 id=代码实战-2>代码实战<a class=anchor href=#%e4%bb%a3%e7%a0%81%e5%ae%9e%e6%88%98-2>#</a></h3><p>参见 <code>code/chapter16_multimodal/llava_chat.py</code> - LLaVA多模态对话系统:</p><ul><li>单轮/多轮对话</li><li>图像理解与推理</li><li>量化部署方案</li><li>Gradio界面集成</li></ul><hr><h2 id=164-实战多模态理解应用>16.4 实战:多模态理解应用<a class=anchor href=#164-%e5%ae%9e%e6%88%98%e5%a4%9a%e6%a8%a1%e6%80%81%e7%90%86%e8%a7%a3%e5%ba%94%e7%94%a8>#</a></h2><h3 id=项目1-商品图像搜索引擎>项目1: 商品图像搜索引擎<a class=anchor href=#%e9%a1%b9%e7%9b%ae1-%e5%95%86%e5%93%81%e5%9b%be%e5%83%8f%e6%90%9c%e7%b4%a2%e5%bc%95%e6%93%8e>#</a></h3><p><strong>需求</strong>: 用户上传商品图片,搜索相似商品。</p><p><strong>技术方案</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 1. 使用CLIP构建图像索引</span>
</span></span><span class=line><span class=cl><span class=n>image_features</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>get_image_features</span><span class=p>(</span><span class=n>pixel_values</span><span class=o>=</span><span class=n>images</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 存入向量数据库(FAISS/Milvus)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 查询时编码并检索</span>
</span></span><span class=line><span class=cl><span class=n>query_features</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>get_image_features</span><span class=p>(</span><span class=n>pixel_values</span><span class=o>=</span><span class=n>query_image</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>similar_indices</span> <span class=o>=</span> <span class=n>faiss_index</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>query_features</span><span class=p>,</span> <span class=n>k</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. BLIP-2生成商品描述</span>
</span></span><span class=line><span class=cl><span class=n>description</span> <span class=o>=</span> <span class=n>blip2_model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=n>query_image</span><span class=p>)</span></span></span></code></pre></div><p><strong>完整代码</strong>: <code>code/chapter16_multimodal/multimodal_app.py</code></p><h3 id=项目2-智能客服机器人>项目2: 智能客服机器人<a class=anchor href=#%e9%a1%b9%e7%9b%ae2-%e6%99%ba%e8%83%bd%e5%ae%a2%e6%9c%8d%e6%9c%ba%e5%99%a8%e4%ba%ba>#</a></h3><p><strong>需求</strong>: 用户发送商品图片+文字问题,AI回答。</p><p><strong>技术方案</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用LLaVA处理多模态输入</span>
</span></span><span class=line><span class=cl><span class=n>conversation</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=s2>&#34;这个商品如何使用?&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>llava_model</span><span class=o>.</span><span class=n>chat</span><span class=p>(</span><span class=n>conversation</span><span class=p>)</span></span></span></code></pre></div><p><strong>增强功能</strong>:</p><ul><li>多轮对话记忆</li><li>商品知识库检索(RAG)</li><li>情感分析与意图识别</li></ul><h3 id=项目3-图像内容审核系统>项目3: 图像内容审核系统<a class=anchor href=#%e9%a1%b9%e7%9b%ae3-%e5%9b%be%e5%83%8f%e5%86%85%e5%ae%b9%e5%ae%a1%e6%a0%b8%e7%b3%bb%e7%bb%9f>#</a></h3><p><strong>需求</strong>: 自动检测不适内容(暴力、色情、政治敏感)。</p><p><strong>多模型集成</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 1. CLIP快速初筛(零样本)</span>
</span></span><span class=line><span class=cl><span class=n>labels</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;正常内容&#34;</span><span class=p>,</span> <span class=s2>&#34;暴力内容&#34;</span><span class=p>,</span> <span class=s2>&#34;色情内容&#34;</span><span class=p>,</span> <span class=s2>&#34;政治敏感&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>probs</span> <span class=o>=</span> <span class=n>clip_classify</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 高置信度直接通过/拒绝</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=n>probs</span><span class=o>.</span><span class=n>max</span><span class=p>()</span> <span class=o>&gt;</span> <span class=mf>0.95</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>probs</span><span class=o>.</span><span class=n>argmax</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 低置信度用LLaVA详细分析</span>
</span></span><span class=line><span class=cl><span class=n>analysis</span> <span class=o>=</span> <span class=n>llava_analyze</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;请详细分析这张图片是否包含不适内容。&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>性能优化</strong>:</p><ul><li>CLIP处理: 10ms/张(GPU)</li><li>LLaVA处理: 500ms/张(仅5%需要)</li><li>平均延迟: ~30ms/张</li></ul><h3 id=关键技术点>关键技术点<a class=anchor href=#%e5%85%b3%e9%94%ae%e6%8a%80%e6%9c%af%e7%82%b9>#</a></h3><p><strong>1. 批量处理</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># CLIP批量推理(提升10x)</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>texts</span><span class=p>,</span> <span class=n>images</span><span class=o>=</span><span class=n>images</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span></span></span></code></pre></div><p><strong>2. 特征缓存</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 预计算文本特征(类别固定时)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>text_features</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>get_text_features</span><span class=p>(</span><span class=o>**</span><span class=n>text_inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 缓存,后续只需计算图像特征</span></span></span></code></pre></div><p><strong>3. 混合精度</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 使用torch.autocast加速</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>autocast</span><span class=p>(</span><span class=n>device_type</span><span class=o>=</span><span class=s1>&#39;cuda&#39;</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span></span></span></code></pre></div><h3 id=部署建议>部署建议<a class=anchor href=#%e9%83%a8%e7%bd%b2%e5%bb%ba%e8%ae%ae>#</a></h3><table><thead><tr><th>场景</th><th>推荐模型</th><th>硬件配置</th><th>并发能力</th></tr></thead><tbody><tr><td>图像搜索</td><td>CLIP</td><td>1×T4(16GB)</td><td>100 QPS</td></tr><tr><td>视觉问答</td><td>BLIP-2 (4bit)</td><td>1×A10(24GB)</td><td>10 QPS</td></tr><tr><td>对话系统</td><td>LLaVA (4bit)</td><td>1×A100(40GB)</td><td>5 QPS</td></tr><tr><td>高并发场景</td><td>CLIP + API</td><td>Serverless</td><td>1000+ QPS</td></tr></tbody></table><p><strong>成本对比</strong>:</p><ul><li>自建GPU: $1-3/小时(云服务器)</li><li>OpenAI GPT-4V: $0.01-0.03/图像</li><li>Google Gemini: $0.0025-0.01/图像</li></ul><hr><h2 id=本章总结>本章总结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%80%bb%e7%bb%93>#</a></h2><h3 id=核心要点>核心要点<a class=anchor href=#%e6%a0%b8%e5%bf%83%e8%a6%81%e7%82%b9>#</a></h3><ol><li><strong>CLIP</strong>: 零样本分类的开创者,适合快速原型和图像检索</li><li><strong>BLIP-2</strong>: VQA专家,Q-Former架构实现参数高效训练</li><li><strong>LLaVA</strong>: 开源对话模型,接近闭源GPT-4V性能</li></ol><h3 id=技术选型建议>技术选型建议<a class=anchor href=#%e6%8a%80%e6%9c%af%e9%80%89%e5%9e%8b%e5%bb%ba%e8%ae%ae>#</a></h3><table><thead><tr><th>需求</th><th>推荐模型</th><th>理由</th></tr></thead><tbody><tr><td>零样本分类</td><td>CLIP</td><td>快速、简单、效果好</td></tr><tr><td>图像描述生成</td><td>BLIP-2</td><td>专门优化,生成质量高</td></tr><tr><td>复杂视觉推理</td><td>LLaVA</td><td>强大的LLM推理能力</td></tr><tr><td>生产环境(性能优先)</td><td>CLIP + API</td><td>自建CLIP + 调用GPT-4V</td></tr><tr><td>生产环境(成本优先)</td><td>LLaVA 4bit</td><td>开源可控,显存需求低</td></tr></tbody></table><h3 id=学习路径-1>学习路径<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e8%b7%af%e5%be%84-1>#</a></h3><ol><li><strong>初学者</strong>: 从CLIP零样本分类开始,理解对比学习</li><li><strong>进阶</strong>: 尝试BLIP-2的VQA任务,掌握量化技术</li><li><strong>高级</strong>: 部署LLaVA对话系统,优化推理性能</li></ol><h3 id=扩展资源>扩展资源<a class=anchor href=#%e6%89%a9%e5%b1%95%e8%b5%84%e6%ba%90>#</a></h3><ul><li><strong>CLIP论文</strong>: <a href=https://arxiv.org/abs/2103.00020>https://arxiv.org/abs/2103.00020</a></li><li><strong>BLIP-2论文</strong>: <a href=https://arxiv.org/abs/2301.12597>https://arxiv.org/abs/2301.12597</a></li><li><strong>LLaVA项目</strong>: <a href=https://github.com/haotian-liu/LLaVA>https://github.com/haotian-liu/LLaVA</a></li><li><strong>Hugging Face模型库</strong>: <a href="https://huggingface.co/models?pipeline_tag=image-text-to-text">https://huggingface.co/models?pipeline_tag=image-text-to-text</a></li></ul><hr><p><strong>下一章预告</strong>: <a href=../chapter17/README.md>第17章:视觉大模型前沿</a> - 探索Florence-2、GPT-4V、Gemini等前沿VLM,学习商业API调用与提示词工程!</p><hr><h1 id=第17章视觉大模型前沿-1>第17章:视觉大模型前沿<a class=anchor href=#%e7%ac%ac17%e7%ab%a0%e8%a7%86%e8%a7%89%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%89%8d%e6%b2%bf-1>#</a></h1><blockquote class=book-hint><p>Florence-2、GPT-4o、Gemini - 工业级VLM的巅峰之作</p></blockquote><h2 id=本章概述-1>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0-1>#</a></h2><p>本章深入讲解2024-2025年最前沿的视觉大模型:</p><ul><li><strong>Florence-2</strong>: 微软开源的统一视觉基础模型</li><li><strong>GPT-4o</strong>: OpenAI的原生多模态GPT</li><li><strong>Gemini</strong>: Google的原生多模态模型</li></ul><p>这些模型代表了当前VLM的最高水平,掌握它们的使用方法对于实际应用至关重要。</p><h2 id=171-florence-2微软视觉基础模型>17.1 Florence-2:微软视觉基础模型<a class=anchor href=#171-florence-2%e5%be%ae%e8%bd%af%e8%a7%86%e8%a7%89%e5%9f%ba%e7%a1%80%e6%a8%a1%e5%9e%8b>#</a></h2><p>Florence-2是微软2024年发布的开源视觉基础模型,采用统一的提示词范式处理10+视觉任务。</p><h3 id=1711-核心特性>17.1.1 核心特性<a class=anchor href=#1711-%e6%a0%b8%e5%bf%83%e7%89%b9%e6%80%a7>#</a></h3><p><strong>关键优势</strong>:</p><ul><li><strong>MIT开源协议</strong>: 可商用,无license限制</li><li><strong>统一任务范式</strong>: 一个模型完成所有视觉任务</li><li><strong>提示词驱动</strong>: 通过不同prompt切换任务</li><li><strong>高效参数</strong>: 0.77B参数,性能优异</li></ul><h3 id=1712-模型变体>17.1.2 模型变体<a class=anchor href=#1712-%e6%a8%a1%e5%9e%8b%e5%8f%98%e4%bd%93>#</a></h3><table><thead><tr><th>模型</th><th>参数量</th><th>用途</th><th>推荐场景</th></tr></thead><tbody><tr><td>Florence-2-base</td><td>0.23B</td><td>预训练基础</td><td>资源受限环境</td></tr><tr><td>Florence-2-large</td><td>0.77B</td><td>预训练基础</td><td>通用场景</td></tr><tr><td>Florence-2-base-ft</td><td>0.23B</td><td>任务微调版</td><td>快速部署</td></tr><tr><td>Florence-2-large-ft</td><td>0.77B</td><td>任务微调版</td><td>最佳性能</td></tr></tbody></table><h3 id=1713-支持的任务与提示词>17.1.3 支持的任务与提示词<a class=anchor href=#1713-%e6%94%af%e6%8c%81%e7%9a%84%e4%bb%bb%e5%8a%a1%e4%b8%8e%e6%8f%90%e7%a4%ba%e8%af%8d>#</a></h3><p><strong>视觉理解任务</strong>:</p><table><thead><tr><th>任务提示词</th><th>功能</th><th>输出格式</th><th>示例用途</th></tr></thead><tbody><tr><td><code>&lt;CAPTION></code></td><td>基础描述</td><td>文本</td><td>图像标注</td></tr><tr><td><code>&lt;DETAILED_CAPTION></code></td><td>详细描述</td><td>文本</td><td>内容分析</td></tr><tr><td><code>&lt;MORE_DETAILED_CAPTION></code></td><td>全面分析</td><td>文本</td><td>深度理解</td></tr><tr><td><code>&lt;OD></code></td><td>目标检测</td><td>bbox + 类别</td><td>物体定位</td></tr><tr><td><code>&lt;DENSE_REGION_CAPTION></code></td><td>区域级描述</td><td>区域+描述</td><td>细粒度分析</td></tr><tr><td><code>&lt;REGION_PROPOSAL></code></td><td>候选区域</td><td>bbox列表</td><td>检测预处理</td></tr></tbody></table><p><strong>定位与文字识别任务</strong>:</p><table><thead><tr><th>任务提示词</th><th>功能</th><th>输出格式</th><th>示例用途</th></tr></thead><tbody><tr><td><code>&lt;CAPTION_TO_PHRASE_GROUNDING></code></td><td>短语定位</td><td>文本→bbox</td><td>视觉定位</td></tr><tr><td><code>&lt;OCR></code></td><td>文字识别</td><td>文本</td><td>文档OCR</td></tr><tr><td><code>&lt;OCR_WITH_REGION></code></td><td>OCR+位置</td><td>文本+四边形</td><td>票据识别</td></tr><tr><td><code>&lt;REFERRING_EXPRESSION_SEGMENTATION></code></td><td>指称分割</td><td>mask</td><td>交互分割</td></tr><tr><td><code>&lt;OPEN_VOCABULARY_DETECTION></code></td><td>开放词汇检测</td><td>bbox</td><td>灵活检测</td></tr></tbody></table><h3 id=1714-完整使用示例>17.1.4 完整使用示例<a class=anchor href=#1714-%e5%ae%8c%e6%95%b4%e4%bd%bf%e7%94%a8%e7%a4%ba%e4%be%8b>#</a></h3><p><strong>基础设置</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoProcessor</span><span class=p>,</span> <span class=n>AutoModelForCausalLM</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型(推荐使用large-ft版本)</span>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;microsoft/Florence-2-large-ft&#34;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>,</span> <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>task_prompt</span><span class=p>,</span> <span class=n>text_input</span><span class=o>=</span><span class=kc>None</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;通用Florence-2推理函数&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>text_input</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt</span> <span class=o>=</span> <span class=n>task_prompt</span> <span class=o>+</span> <span class=n>text_input</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt</span> <span class=o>=</span> <span class=n>task_prompt</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span> <span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>input_ids</span><span class=o>=</span><span class=n>inputs</span><span class=p>[</span><span class=s2>&#34;input_ids&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>pixel_values</span><span class=o>=</span><span class=n>inputs</span><span class=p>[</span><span class=s2>&#34;pixel_values&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>num_beams</span><span class=o>=</span><span class=mi>3</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>generated_text</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>False</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>parsed_result</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>post_process_generation</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>generated_text</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>task</span><span class=o>=</span><span class=n>task_prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>image_size</span><span class=o>=</span><span class=p>(</span><span class=n>image</span><span class=o>.</span><span class=n>width</span><span class=p>,</span> <span class=n>image</span><span class=o>.</span><span class=n>height</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>parsed_result</span></span></span></code></pre></div><p><strong>任务示例</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=s2>&#34;example.jpg&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 图像描述</span>
</span></span><span class=line><span class=cl><span class=n>caption</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;CAPTION&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;基础描述: </span><span class=si>{</span><span class=n>caption</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 输出: {&#39;&lt;CAPTION&gt;&#39;: &#39;A cat sitting on a red sofa in a living room.&#39;}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>detailed</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;DETAILED_CAPTION&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;详细描述: </span><span class=si>{</span><span class=n>detailed</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 目标检测</span>
</span></span><span class=line><span class=cl><span class=n>detection</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OD&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;检测结果: </span><span class=si>{</span><span class=n>detection</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 输出: {&#39;&lt;OD&gt;&#39;: {&#39;bboxes&#39;: [[x1, y1, x2, y2], ...], &#39;labels&#39;: [&#39;cat&#39;, &#39;sofa&#39;, ...]}}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. OCR文字识别</span>
</span></span><span class=line><span class=cl><span class=n>ocr_result</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OCR&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;识别文字: </span><span class=si>{</span><span class=n>ocr_result</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. OCR带位置</span>
</span></span><span class=line><span class=cl><span class=n>ocr_with_region</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OCR_WITH_REGION&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;文字+位置: </span><span class=si>{</span><span class=n>ocr_with_region</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 短语定位(Grounding)</span>
</span></span><span class=line><span class=cl><span class=n>grounding</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;CAPTION_TO_PHRASE_GROUNDING&gt;&#34;</span><span class=p>,</span> <span class=s2>&#34;a cat&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;定位结果: </span><span class=si>{</span><span class=n>grounding</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. 开放词汇检测</span>
</span></span><span class=line><span class=cl><span class=n>open_det</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OPEN_VOCABULARY_DETECTION&gt;&#34;</span><span class=p>,</span> <span class=s2>&#34;cat, dog, person&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;开放检测: </span><span class=si>{</span><span class=n>open_det</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 7. 区域级描述</span>
</span></span><span class=line><span class=cl><span class=n>dense_caption</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;DENSE_REGION_CAPTION&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;区域描述: </span><span class=si>{</span><span class=n>dense_caption</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1715-结果可视化>17.1.5 结果可视化<a class=anchor href=#1715-%e7%bb%93%e6%9e%9c%e5%8f%af%e8%a7%86%e5%8c%96>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.pyplot</span> <span class=k>as</span> <span class=nn>plt</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>matplotlib.patches</span> <span class=k>as</span> <span class=nn>patches</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>visualize_detection</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>result</span><span class=p>,</span> <span class=n>task</span><span class=o>=</span><span class=s2>&#34;&lt;OD&gt;&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;可视化检测结果&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>fig</span><span class=p>,</span> <span class=n>ax</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>subplots</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=n>figsize</span><span class=o>=</span><span class=p>(</span><span class=mi>12</span><span class=p>,</span> <span class=mi>8</span><span class=p>))</span>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>imshow</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>data</span> <span class=o>=</span> <span class=n>result</span><span class=p>[</span><span class=n>task</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>bboxes</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;bboxes&#39;</span><span class=p>,</span> <span class=p>[])</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>data</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s1>&#39;labels&#39;</span><span class=p>,</span> <span class=p>[])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>colors</span> <span class=o>=</span> <span class=n>plt</span><span class=o>.</span><span class=n>cm</span><span class=o>.</span><span class=n>Set3</span><span class=p>(</span><span class=nb>range</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>bboxes</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>bbox</span><span class=p>,</span> <span class=n>label</span><span class=p>,</span> <span class=n>color</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>bboxes</span><span class=p>,</span> <span class=n>labels</span><span class=p>,</span> <span class=n>colors</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>,</span> <span class=n>x2</span><span class=p>,</span> <span class=n>y2</span> <span class=o>=</span> <span class=n>bbox</span>
</span></span><span class=line><span class=cl>        <span class=n>rect</span> <span class=o>=</span> <span class=n>patches</span><span class=o>.</span><span class=n>Rectangle</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=p>),</span> <span class=n>x2</span><span class=o>-</span><span class=n>x1</span><span class=p>,</span> <span class=n>y2</span><span class=o>-</span><span class=n>y1</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>linewidth</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>edgecolor</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> <span class=n>facecolor</span><span class=o>=</span><span class=s1>&#39;none&#39;</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>add_patch</span><span class=p>(</span><span class=n>rect</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ax</span><span class=o>.</span><span class=n>text</span><span class=p>(</span><span class=n>x1</span><span class=p>,</span> <span class=n>y1</span><span class=o>-</span><span class=mi>5</span><span class=p>,</span> <span class=n>label</span><span class=p>,</span> <span class=n>fontsize</span><span class=o>=</span><span class=mi>10</span><span class=p>,</span> <span class=n>color</span><span class=o>=</span><span class=s1>&#39;white&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=n>bbox</span><span class=o>=</span><span class=nb>dict</span><span class=p>(</span><span class=n>boxstyle</span><span class=o>=</span><span class=s1>&#39;round&#39;</span><span class=p>,</span> <span class=n>facecolor</span><span class=o>=</span><span class=n>color</span><span class=p>,</span> <span class=n>alpha</span><span class=o>=</span><span class=mf>0.8</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>ax</span><span class=o>.</span><span class=n>axis</span><span class=p>(</span><span class=s1>&#39;off&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>tight_layout</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>savefig</span><span class=p>(</span><span class=s1>&#39;detection_result.png&#39;</span><span class=p>,</span> <span class=n>dpi</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span> <span class=n>bbox_inches</span><span class=o>=</span><span class=s1>&#39;tight&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>plt</span><span class=o>.</span><span class=n>show</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>detection_result</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OD&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>visualize_detection</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>detection_result</span><span class=p>)</span></span></span></code></pre></div><h3 id=1716-性能基准>17.1.6 性能基准<a class=anchor href=#1716-%e6%80%a7%e8%83%bd%e5%9f%ba%e5%87%86>#</a></h3><table><thead><tr><th>任务</th><th>数据集</th><th>Florence-2-L</th><th>对比模型</th></tr></thead><tbody><tr><td>图像描述</td><td>COCO</td><td>135.6 CIDEr</td><td>BLIP-2: 144.5</td></tr><tr><td>目标检测</td><td>COCO</td><td>37.5 mAP</td><td>-</td></tr><tr><td>VQA</td><td>VQAv2</td><td>81.7% (ft)</td><td>LLaVA: 78.5%</td></tr><tr><td>OCR</td><td>TextVQA</td><td>63.0%</td><td>-</td></tr></tbody></table><p><strong>优势</strong>: 单一模型实现多任务,部署简单,资源需求低。</p><h3 id=1717-实战应用场景>17.1.7 实战应用场景<a class=anchor href=#1717-%e5%ae%9e%e6%88%98%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h3><p><strong>1. 智能文档处理</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_document</span><span class=p>(</span><span class=n>image_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;文档智能处理流程&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># OCR识别</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OCR&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 带位置的OCR(用于表格等)</span>
</span></span><span class=line><span class=cl>    <span class=n>ocr_regions</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OCR_WITH_REGION&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 图表/图像检测</span>
</span></span><span class=line><span class=cl>    <span class=n>objects</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OD&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>text</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;regions&#34;</span><span class=p>:</span> <span class=n>ocr_regions</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;objects&#34;</span><span class=p>:</span> <span class=n>objects</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span></span></span></code></pre></div><p><strong>2. 电商图像分析</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_product_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;电商商品图分析&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 商品描述</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;DETAILED_CAPTION&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 检测商品主体</span>
</span></span><span class=line><span class=cl>    <span class=n>detection</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OD&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 提取商品上的文字(品牌、规格等)</span>
</span></span><span class=line><span class=cl>    <span class=n>text_info</span> <span class=o>=</span> <span class=n>run_florence</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;&lt;OCR&gt;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;description&#34;</span><span class=p>:</span> <span class=n>description</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;objects&#34;</span><span class=p>:</span> <span class=n>detection</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>text_info</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span></span></span></code></pre></div><hr><h2 id=172-gpt-4o多模态gpt>17.2 GPT-4o:多模态GPT<a class=anchor href=#172-gpt-4o%e5%a4%9a%e6%a8%a1%e6%80%81gpt>#</a></h2><p>GPT-4o(omni)是OpenAI于2024年5月发布的原生多模态模型,将文本、视觉、音频能力融合到单一模型中。</p><h3 id=1721-核心特性>17.2.1 核心特性<a class=anchor href=#1721-%e6%a0%b8%e5%bf%83%e7%89%b9%e6%80%a7>#</a></h3><p><strong>相比GPT-4V的改进</strong>:</p><ul><li><strong>速度</strong>: 响应速度提升2倍</li><li><strong>成本</strong>: API价格降低50%</li><li><strong>能力</strong>: 视觉理解能力显著提升</li><li><strong>多模态</strong>: 原生支持文本+图像+音频</li></ul><p><strong>模型选择</strong>:</p><table><thead><tr><th>模型</th><th>特点</th><th>成本</th><th>推荐场景</th></tr></thead><tbody><tr><td>gpt-4o</td><td>最强能力</td><td>$5/1M tokens</td><td>复杂推理</td></tr><tr><td>gpt-4o-mini</td><td>性价比高</td><td>$0.15/1M tokens</td><td>日常任务</td></tr><tr><td>gpt-4-turbo</td><td>旧版本</td><td>$10/1M tokens</td><td>兼容需求</td></tr></tbody></table><h3 id=1722-基础使用>17.2.2 基础使用<a class=anchor href=#1722-%e5%9f%ba%e7%a1%80%e4%bd%bf%e7%94%a8>#</a></h3><p><strong>方式1: URL图像</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;OPENAI_API_KEY&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_image_url</span><span class=p>(</span><span class=n>image_url</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用URL分析图像&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=n>image_url</span><span class=p>}</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>500</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>analyze_image_url</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;https://example.com/image.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;请详细描述这张图片中的内容&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span></span></span></code></pre></div><p><strong>方式2: Base64编码图像</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>base64</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将本地图像编码为base64&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s2>&#34;rb&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_local_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;分析本地图像&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>base64_image</span> <span class=o>=</span> <span class=n>encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 自动检测图像格式</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>image_path</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>endswith</span><span class=p>(</span><span class=s1>&#39;.png&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>media_type</span> <span class=o>=</span> <span class=s2>&#34;image/png&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>image_path</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>endswith</span><span class=p>(</span><span class=s1>&#39;.gif&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>media_type</span> <span class=o>=</span> <span class=s2>&#34;image/gif&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>image_path</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>endswith</span><span class=p>(</span><span class=s1>&#39;.webp&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>media_type</span> <span class=o>=</span> <span class=s2>&#34;image/webp&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>media_type</span> <span class=o>=</span> <span class=s2>&#34;image/jpeg&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:</span><span class=si>{</span><span class=n>media_type</span><span class=si>}</span><span class=s2>;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>                        <span class=p>}</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1000</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>analyze_local_image</span><span class=p>(</span><span class=s2>&#34;product.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;这个商品的主要特点是什么?&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1723-多图像分析>17.2.3 多图像分析<a class=anchor href=#1723-%e5%a4%9a%e5%9b%be%e5%83%8f%e5%88%86%e6%9e%90>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compare_images</span><span class=p>(</span><span class=n>image_paths</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;多图像对比分析&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>content</span> <span class=o>=</span> <span class=p>[{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>}]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>path</span> <span class=ow>in</span> <span class=n>image_paths</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>base64_image</span> <span class=o>=</span> <span class=n>encode_image</span><span class=p>(</span><span class=n>path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>content</span><span class=p>}],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1500</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 对比两张图片</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>compare_images</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;before.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;after.jpg&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;请对比这两张图片的差异,描述发生了什么变化&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=1724-图像细节控制>17.2.4 图像细节控制<a class=anchor href=#1724-%e5%9b%be%e5%83%8f%e7%bb%86%e8%8a%82%e6%8e%a7%e5%88%b6>#</a></h3><p>GPT-4o支持控制图像处理的精细度:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_with_detail</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>question</span><span class=p>,</span> <span class=n>detail</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    控制图像分析精度
</span></span></span><span class=line><span class=cl><span class=s2>    detail参数:
</span></span></span><span class=line><span class=cl><span class=s2>    - &#34;low&#34;: 512x512固定,65 tokens,快速便宜
</span></span></span><span class=line><span class=cl><span class=s2>    - &#34;high&#34;: 最高2048x2048,详细分析,更多tokens
</span></span></span><span class=line><span class=cl><span class=s2>    - &#34;auto&#34;: 自动选择(默认)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>base64_image</span> <span class=o>=</span> <span class=n>encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;detail&#34;</span><span class=p>:</span> <span class=n>detail</span>  <span class=c1># &#34;low&#34;, &#34;high&#34;, &#34;auto&#34;</span>
</span></span><span class=line><span class=cl>                        <span class=p>}</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1000</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 快速预览(省钱)</span>
</span></span><span class=line><span class=cl><span class=n>quick_result</span> <span class=o>=</span> <span class=n>analyze_with_detail</span><span class=p>(</span><span class=s2>&#34;doc.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;这是什么文档?&#34;</span><span class=p>,</span> <span class=n>detail</span><span class=o>=</span><span class=s2>&#34;low&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 详细分析(精确)</span>
</span></span><span class=line><span class=cl><span class=n>detailed_result</span> <span class=o>=</span> <span class=n>analyze_with_detail</span><span class=p>(</span><span class=s2>&#34;doc.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;请提取文档中的所有文字&#34;</span><span class=p>,</span> <span class=n>detail</span><span class=o>=</span><span class=s2>&#34;high&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1725-结构化输出>17.2.5 结构化输出<a class=anchor href=#1725-%e7%bb%93%e6%9e%84%e5%8c%96%e8%be%93%e5%87%ba>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_structured_info</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>schema_description</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;提取结构化信息&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>base64_image</span> <span class=o>=</span> <span class=n>encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;分析这张图片,按照以下格式返回JSON:
</span></span></span><span class=line><span class=cl><span class=si>{</span><span class=n>schema_description</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>只返回JSON,不要其他内容。&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>response_format</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;json_object&#34;</span><span class=p>}</span>  <span class=c1># 强制JSON输出</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 提取商品信息</span>
</span></span><span class=line><span class=cl><span class=n>schema</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>{
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;product_name&#34;: &#34;商品名称&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;brand&#34;: &#34;品牌&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;price&#34;: &#34;价格(如果可见)&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;features&#34;: [&#34;特点1&#34;, &#34;特点2&#34;],
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;category&#34;: &#34;类别&#34;
</span></span></span><span class=line><span class=cl><span class=s2>}
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=n>product_info</span> <span class=o>=</span> <span class=n>extract_structured_info</span><span class=p>(</span><span class=s2>&#34;product.jpg&#34;</span><span class=p>,</span> <span class=n>schema</span><span class=p>)</span></span></span></code></pre></div><h3 id=1726-已知限制>17.2.6 已知限制<a class=anchor href=#1726-%e5%b7%b2%e7%9f%a5%e9%99%90%e5%88%b6>#</a></h3><p>GPT-4o Vision的局限性:</p><ol><li><strong>空间推理</strong>: 复杂位置关系可能出错</li><li><strong>计数</strong>: 大量物体计数不准确</li><li><strong>细小文字</strong>: 图像中的小字体可能识别不清</li><li><strong>医疗图像</strong>: 不应用于医疗诊断</li><li><strong>CAPTCHA</strong>: 明确拒绝处理验证码</li></ol><h3 id=1727-成本优化策略>17.2.7 成本优化策略<a class=anchor href=#1727-%e6%88%90%e6%9c%ac%e4%bc%98%e5%8c%96%e7%ad%96%e7%95%a5>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>GPT4VisionOptimizer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;GPT-4o Vision成本优化器&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>preprocess_image</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>,</span> <span class=n>max_size</span><span class=o>=</span><span class=mi>1024</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;预处理图像以减少tokens&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 调整大小</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>max</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>size</span><span class=p>)</span> <span class=o>&gt;</span> <span class=n>max_size</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>ratio</span> <span class=o>=</span> <span class=n>max_size</span> <span class=o>/</span> <span class=nb>max</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>new_size</span> <span class=o>=</span> <span class=p>(</span><span class=nb>int</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>width</span> <span class=o>*</span> <span class=n>ratio</span><span class=p>),</span> <span class=nb>int</span><span class=p>(</span><span class=n>img</span><span class=o>.</span><span class=n>height</span> <span class=o>*</span> <span class=n>ratio</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>img</span> <span class=o>=</span> <span class=n>img</span><span class=o>.</span><span class=n>resize</span><span class=p>(</span><span class=n>new_size</span><span class=p>,</span> <span class=n>Image</span><span class=o>.</span><span class=n>LANCZOS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 转换为JPEG(通常更小)</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>io</span>
</span></span><span class=line><span class=cl>        <span class=n>buffer</span> <span class=o>=</span> <span class=n>io</span><span class=o>.</span><span class=n>BytesIO</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s1>&#39;RGB&#39;</span><span class=p>)</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=n>buffer</span><span class=p>,</span> <span class=nb>format</span><span class=o>=</span><span class=s1>&#39;JPEG&#39;</span><span class=p>,</span> <span class=n>quality</span><span class=o>=</span><span class=mi>85</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>buffer</span><span class=o>.</span><span class=n>getvalue</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>smart_analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>,</span> <span class=n>question</span><span class=p>,</span> <span class=n>use_mini</span><span class=o>=</span><span class=kc>True</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;智能分析,根据任务选择模型&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 简单任务用mini</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span> <span class=o>=</span> <span class=s2>&#34;gpt-4o-mini&#34;</span> <span class=k>if</span> <span class=n>use_mini</span> <span class=k>else</span> <span class=s2>&#34;gpt-4o&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>base64_image</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>preprocess_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=n>model</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                        <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                        <span class=p>{</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                                <span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                <span class=s2>&#34;detail&#34;</span><span class=p>:</span> <span class=s2>&#34;low&#34;</span>  <span class=c1># 先用低精度</span>
</span></span><span class=line><span class=cl>                            <span class=p>}</span>
</span></span><span class=line><span class=cl>                        <span class=p>}</span>
</span></span><span class=line><span class=cl>                    <span class=p>]</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>],</span>
</span></span><span class=line><span class=cl>            <span class=n>max_tokens</span><span class=o>=</span><span class=mi>300</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>optimizer</span> <span class=o>=</span> <span class=n>GPT4VisionOptimizer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>optimizer</span><span class=o>.</span><span class=n>smart_analyze</span><span class=p>(</span><span class=s2>&#34;image.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;图片中有什么?&#34;</span><span class=p>,</span> <span class=n>use_mini</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span></span></span></code></pre></div><hr><h2 id=173-gemini-vision>17.3 Gemini Vision<a class=anchor href=#173-gemini-vision>#</a></h2><p>Gemini是Google于2023年底发布的原生多模态模型,在视频理解方面具有独特优势。</p><h3 id=1731-模型系列>17.3.1 模型系列<a class=anchor href=#1731-%e6%a8%a1%e5%9e%8b%e7%b3%bb%e5%88%97>#</a></h3><table><thead><tr><th>模型</th><th>特点</th><th>上下文窗口</th><th>推荐场景</th></tr></thead><tbody><tr><td>gemini-2.5-flash</td><td>最新快速版</td><td>1M tokens</td><td>日常任务</td></tr><tr><td>gemini-2.5-pro</td><td>最强推理</td><td>1M tokens</td><td>复杂分析</td></tr><tr><td>gemini-2.0-flash</td><td>平衡版</td><td>1M tokens</td><td>通用场景</td></tr><tr><td>gemini-1.5-pro</td><td>稳定版</td><td>2M tokens</td><td>超长上下文</td></tr></tbody></table><h3 id=1732-基础使用>17.3.2 基础使用<a class=anchor href=#1732-%e5%9f%ba%e7%a1%80%e4%bd%bf%e7%94%a8>#</a></h3><p><strong>安装与配置</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install google-generativeai</span></span></code></pre></div><p><strong>基础图像分析</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>google</span> <span class=kn>import</span> <span class=n>genai</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>google.genai</span> <span class=kn>import</span> <span class=n>types</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初始化客户端</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>genai</span><span class=o>.</span><span class=n>Client</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>os</span><span class=o>.</span><span class=n>environ</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;GOOGLE_API_KEY&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_image_gemini</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用Gemini分析图像&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>image_bytes</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 检测MIME类型</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>image_path</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>endswith</span><span class=p>(</span><span class=s1>&#39;.png&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>mime_type</span> <span class=o>=</span> <span class=s1>&#39;image/png&#39;</span>
</span></span><span class=line><span class=cl>    <span class=k>elif</span> <span class=n>image_path</span><span class=o>.</span><span class=n>lower</span><span class=p>()</span><span class=o>.</span><span class=n>endswith</span><span class=p>(</span><span class=s1>&#39;.webp&#39;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>mime_type</span> <span class=o>=</span> <span class=s1>&#39;image/webp&#39;</span>
</span></span><span class=line><span class=cl>    <span class=k>else</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>mime_type</span> <span class=o>=</span> <span class=s1>&#39;image/jpeg&#39;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s1>&#39;gemini-2.5-flash&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>types</span><span class=o>.</span><span class=n>Part</span><span class=o>.</span><span class=n>from_bytes</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>image_bytes</span><span class=p>,</span> <span class=n>mime_type</span><span class=o>=</span><span class=n>mime_type</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>analyze_image_gemini</span><span class=p>(</span><span class=s2>&#34;photo.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;描述这张照片中的场景&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span></span></span></code></pre></div><h3 id=1733-使用file-api大文件>17.3.3 使用File API(大文件)<a class=anchor href=#1733-%e4%bd%bf%e7%94%a8file-api%e5%a4%a7%e6%96%87%e4%bb%b6>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_large_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用File API处理大文件(推荐)&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 上传文件</span>
</span></span><span class=line><span class=cl>    <span class=n>uploaded_file</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>upload</span><span class=p>(</span><span class=n>file</span><span class=o>=</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 等待处理完成</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>uploaded_file</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>name</span> <span class=o>==</span> <span class=s2>&#34;PROCESSING&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>uploaded_file</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>uploaded_file</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 生成内容</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gemini-2.5-flash&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>uploaded_file</span><span class=p>,</span> <span class=n>prompt</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 可选:删除上传的文件</span>
</span></span><span class=line><span class=cl>    <span class=c1># client.files.delete(name=uploaded_file.name)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>analyze_large_image</span><span class=p>(</span><span class=s2>&#34;high_res_image.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;详细分析这张图片&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1734-多图像分析>17.3.4 多图像分析<a class=anchor href=#1734-%e5%a4%9a%e5%9b%be%e5%83%8f%e5%88%86%e6%9e%90>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>compare_images_gemini</span><span class=p>(</span><span class=n>image_paths</span><span class=p>,</span> <span class=n>prompt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;多图像对比分析&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>contents</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>path</span> <span class=ow>in</span> <span class=n>image_paths</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>path</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>image_bytes</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>types</span><span class=o>.</span><span class=n>Part</span><span class=o>.</span><span class=n>from_bytes</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>image_bytes</span><span class=p>,</span> <span class=n>mime_type</span><span class=o>=</span><span class=s1>&#39;image/jpeg&#39;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>contents</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s1>&#39;gemini-2.5-flash&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>=</span><span class=n>contents</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>compare_images_gemini</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=p>[</span><span class=s2>&#34;img1.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;img2.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;img3.jpg&#34;</span><span class=p>],</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;比较这三张图片的异同点&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=1735-视频理解gemini独有优势>17.3.5 视频理解(Gemini独有优势)<a class=anchor href=#1735-%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3gemini%e7%8b%ac%e6%9c%89%e4%bc%98%e5%8a%bf>#</a></h3><p>Gemini原生支持视频理解,这是其独特优势:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_video</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;分析视频内容&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 上传视频</span>
</span></span><span class=line><span class=cl>    <span class=n>video_file</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>upload</span><span class=p>(</span><span class=n>file</span><span class=o>=</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 等待处理</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>video_file</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>name</span> <span class=o>==</span> <span class=s2>&#34;PROCESSING&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>video_file</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>video_file</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>video_file</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>name</span> <span class=o>==</span> <span class=s2>&#34;FAILED&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;视频处理失败&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 分析视频</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gemini-2.5-flash&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>video_file</span><span class=p>,</span> <span class=n>prompt</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>analyze_video</span><span class=p>(</span><span class=s2>&#34;demo.mp4&#34;</span><span class=p>,</span> <span class=s2>&#34;总结这个视频的主要内容&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>result</span><span class=p>)</span></span></span></code></pre></div><p><strong>视频时间戳查询</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>query_video_timestamp</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;查询视频特定时间点的内容&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>video_file</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>upload</span><span class=p>(</span><span class=n>file</span><span class=o>=</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 等待处理</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>video_file</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>name</span> <span class=o>==</span> <span class=s2>&#34;PROCESSING&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>video_file</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>video_file</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;观看这个视频并回答问题。
</span></span></span><span class=line><span class=cl><span class=s2>如果问题涉及特定场景,请指出大概的时间点。
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>问题: </span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gemini-2.5-flash&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>video_file</span><span class=p>,</span> <span class=n>prompt</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>query_video_timestamp</span><span class=p>(</span><span class=s2>&#34;lecture.mp4&#34;</span><span class=p>,</span> <span class=s2>&#34;讲师什么时候开始讲解神经网络?&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1736-高级功能目标检测与分割>17.3.6 高级功能:目标检测与分割<a class=anchor href=#1736-%e9%ab%98%e7%ba%a7%e5%8a%9f%e8%83%bd%e7%9b%ae%e6%a0%87%e6%a3%80%e6%b5%8b%e4%b8%8e%e5%88%86%e5%89%b2>#</a></h3><p>Gemini 2.0+支持目标检测,Gemini 2.5+支持分割:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>detect_objects_gemini</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>objects_to_detect</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用Gemini进行目标检测&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>image_bytes</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;检测图片中的以下物体: </span><span class=si>{</span><span class=n>objects_to_detect</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>返回每个检测到的物体的边界框坐标,格式为:
</span></span></span><span class=line><span class=cl><span class=s2>物体名称: [x_min, y_min, x_max, y_max] (归一化到0-1000)&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s1>&#39;gemini-2.5-flash&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>contents</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>types</span><span class=o>.</span><span class=n>Part</span><span class=o>.</span><span class=n>from_bytes</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>image_bytes</span><span class=p>,</span> <span class=n>mime_type</span><span class=o>=</span><span class=s1>&#39;image/jpeg&#39;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>prompt</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>result</span> <span class=o>=</span> <span class=n>detect_objects_gemini</span><span class=p>(</span><span class=s2>&#34;street.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;人, 车, 红绿灯&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1737-成本与token计算>17.3.7 成本与Token计算<a class=anchor href=#1737-%e6%88%90%e6%9c%ac%e4%b8%8etoken%e8%ae%a1%e7%ae%97>#</a></h3><p><strong>图像Token计算规则</strong>:</p><ul><li>图像 ≤384px(两边): 258 tokens</li><li>更大图像: 按768×768 tiles切分,每tile 258 tokens</li></ul><p><strong>视频Token计算</strong>:</p><ul><li>每秒视频约263 tokens(1fps采样)</li><li>1分钟视频 ≈ 15,780 tokens</li></ul><p><strong>价格对比(2024年)</strong>:</p><table><thead><tr><th>模型</th><th>输入价格</th><th>输出价格</th></tr></thead><tbody><tr><td>Gemini 2.5 Flash</td><td>$0.075/1M</td><td>$0.30/1M</td></tr><tr><td>Gemini 2.5 Pro</td><td>$1.25/1M</td><td>$10/1M</td></tr><tr><td>GPT-4o</td><td>$2.50/1M</td><td>$10/1M</td></tr><tr><td>GPT-4o-mini</td><td>$0.15/1M</td><td>$0.60/1M</td></tr></tbody></table><p><strong>结论</strong>: Gemini在图像/视频处理上比GPT-4o便宜约60-70%。</p><hr><h2 id=174-实战vlm-api调用与应用>17.4 实战:VLM API调用与应用<a class=anchor href=#174-%e5%ae%9e%e6%88%98vlm-api%e8%b0%83%e7%94%a8%e4%b8%8e%e5%ba%94%e7%94%a8>#</a></h2><h3 id=1741-统一接口封装>17.4.1 统一接口封装<a class=anchor href=#1741-%e7%bb%9f%e4%b8%80%e6%8e%a5%e5%8f%a3%e5%b0%81%e8%a3%85>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>abc</span> <span class=kn>import</span> <span class=n>ABC</span><span class=p>,</span> <span class=n>abstractmethod</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>base64</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>io</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>VLMInterface</span><span class=p>(</span><span class=n>ABC</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;VLM统一接口&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nd>@abstractmethod</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>pass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_encode_image</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>GPT4oVLM</span><span class=p>(</span><span class=n>VLMInterface</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>api_key</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>api_key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>base64_image</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>messages</span><span class=o>=</span><span class=p>[{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>prompt</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span> <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span><span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>}}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}],</span>
</span></span><span class=line><span class=cl>            <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1000</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>GeminiVLM</span><span class=p>(</span><span class=n>VLMInterface</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>api_key</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>google</span> <span class=kn>import</span> <span class=n>genai</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>client</span> <span class=o>=</span> <span class=n>genai</span><span class=o>.</span><span class=n>Client</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>api_key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>google.genai</span> <span class=kn>import</span> <span class=n>types</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s1>&#39;rb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>image_bytes</span> <span class=o>=</span> <span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=s1>&#39;gemini-2.5-flash&#39;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>types</span><span class=o>.</span><span class=n>Part</span><span class=o>.</span><span class=n>from_bytes</span><span class=p>(</span><span class=n>data</span><span class=o>=</span><span class=n>image_bytes</span><span class=p>,</span> <span class=n>mime_type</span><span class=o>=</span><span class=s1>&#39;image/jpeg&#39;</span><span class=p>),</span> <span class=n>prompt</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>Florence2VLM</span><span class=p>(</span><span class=n>VLMInterface</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoProcessor</span><span class=p>,</span> <span class=n>AutoModelForCausalLM</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;microsoft/Florence-2-large-ft&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;microsoft/Florence-2-large-ft&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>analyze</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span> <span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>output</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=o>.</span><span class=n>batch_decode</span><span class=p>(</span><span class=n>output</span><span class=p>,</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_with_fallback</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>,</span> <span class=n>vlm_list</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;带fallback的分析&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>vlm</span> <span class=ow>in</span> <span class=n>vlm_list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>return</span> <span class=n>vlm</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>vlm</span><span class=o>.</span><span class=vm>__class__</span><span class=o>.</span><span class=vm>__name__</span><span class=si>}</span><span class=s2> 失败: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>    <span class=k>raise</span> <span class=ne>RuntimeError</span><span class=p>(</span><span class=s2>&#34;所有VLM都失败了&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1742-文档理解应用>17.4.2 文档理解应用<a class=anchor href=#1742-%e6%96%87%e6%a1%a3%e7%90%86%e8%a7%a3%e5%ba%94%e7%94%a8>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>DocumentAnalyzer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;文档智能分析器&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vlm</span><span class=p>:</span> <span class=n>VLMInterface</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>vlm</span> <span class=o>=</span> <span class=n>vlm</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>extract_text</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;提取文档中的文字&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;提取图片中的所有文字,保持原有格式和布局&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>vlm</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>analyze_table</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;分析表格内容&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;分析图片中的表格,返回JSON格式:
</span></span></span><span class=line><span class=cl><span class=s2>{
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;headers&#34;: [&#34;列1&#34;, &#34;列2&#34;, ...],
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;rows&#34;: [[&#34;数据1&#34;, &#34;数据2&#34;, ...], ...]
</span></span></span><span class=line><span class=cl><span class=s2>}
</span></span></span><span class=line><span class=cl><span class=s2>只返回JSON,不要其他内容。&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>vlm</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>summarize_document</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;文档摘要&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;分析这份文档,返回JSON格式:
</span></span></span><span class=line><span class=cl><span class=s2>{
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;type&#34;: &#34;文档类型(如:发票/合同/报告)&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;title&#34;: &#34;文档标题&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;date&#34;: &#34;日期(如果有)&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;summary&#34;: &#34;主要内容摘要(100字以内)&#34;,
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;key_info&#34;: [&#34;关键信息1&#34;, &#34;关键信息2&#34;, ...]
</span></span></span><span class=line><span class=cl><span class=s2>}&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>result</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>vlm</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>vlm</span> <span class=o>=</span> <span class=n>GPT4oVLM</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;your-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>analyzer</span> <span class=o>=</span> <span class=n>DocumentAnalyzer</span><span class=p>(</span><span class=n>vlm</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 分析发票</span>
</span></span><span class=line><span class=cl><span class=n>invoice_info</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>summarize_document</span><span class=p>(</span><span class=s2>&#34;invoice.jpg&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>invoice_info</span><span class=p>)</span></span></span></code></pre></div><h3 id=1743-视频分析应用gemini>17.4.3 视频分析应用(Gemini)<a class=anchor href=#1743-%e8%a7%86%e9%a2%91%e5%88%86%e6%9e%90%e5%ba%94%e7%94%a8gemini>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>VideoAnalyzer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;视频智能分析器(仅支持Gemini)&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>api_key</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=kn>from</span> <span class=nn>google</span> <span class=kn>import</span> <span class=n>genai</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>client</span> <span class=o>=</span> <span class=n>genai</span><span class=o>.</span><span class=n>Client</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=n>api_key</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_upload_video</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>video_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;上传并等待视频处理完成&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>        <span class=n>video_file</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>upload</span><span class=p>(</span><span class=n>file</span><span class=o>=</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>while</span> <span class=n>video_file</span><span class=o>.</span><span class=n>state</span><span class=o>.</span><span class=n>name</span> <span class=o>==</span> <span class=s2>&#34;PROCESSING&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>time</span><span class=o>.</span><span class=n>sleep</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>video_file</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>files</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>video_file</span><span class=o>.</span><span class=n>name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>video_file</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>generate_summary</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>video_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;生成视频摘要&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>video_file</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_upload_video</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gemini-2.5-flash&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>video_file</span><span class=p>,</span> <span class=s2>&#34;生成这个视频的详细摘要,包括主要内容、关键场景和结论&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>extract_key_frames</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>video_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;提取关键帧描述&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>video_file</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_upload_video</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;分析视频中的关键场景,返回JSON格式:
</span></span></span><span class=line><span class=cl><span class=s2>[
</span></span></span><span class=line><span class=cl><span class=s2>    {&#34;timestamp&#34;: &#34;MM:SS&#34;, &#34;description&#34;: &#34;场景描述&#34;},
</span></span></span><span class=line><span class=cl><span class=s2>    ...
</span></span></span><span class=line><span class=cl><span class=s2>]
</span></span></span><span class=line><span class=cl><span class=s2>只返回JSON列表。&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gemini-2.5-flash&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>video_file</span><span class=p>,</span> <span class=n>prompt</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>answer_question</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>video_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>question</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;视频问答&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>video_file</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>_upload_video</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>response</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>client</span><span class=o>.</span><span class=n>models</span><span class=o>.</span><span class=n>generate_content</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gemini-2.5-flash&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>contents</span><span class=o>=</span><span class=p>[</span><span class=n>video_file</span><span class=p>,</span> <span class=sa>f</span><span class=s2>&#34;观看视频并回答问题: </span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>text</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>analyzer</span> <span class=o>=</span> <span class=n>VideoAnalyzer</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;your-google-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>summary</span> <span class=o>=</span> <span class=n>analyzer</span><span class=o>.</span><span class=n>generate_summary</span><span class=p>(</span><span class=s2>&#34;lecture.mp4&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>summary</span><span class=p>)</span></span></span></code></pre></div><h3 id=1744-vlm性能对比>17.4.4 VLM性能对比<a class=anchor href=#1744-vlm%e6%80%a7%e8%83%bd%e5%af%b9%e6%af%94>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>benchmark_vlms</span><span class=p>(</span><span class=n>image_path</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>prompt</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>vlms</span><span class=p>:</span> <span class=nb>dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;VLM性能基准测试&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>{}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>vlm</span> <span class=ow>in</span> <span class=n>vlms</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>start</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=n>response</span> <span class=o>=</span> <span class=n>vlm</span><span class=o>.</span><span class=n>analyze</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>prompt</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>latency</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=n>results</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;success&#34;</span><span class=p>:</span> <span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;latency&#34;</span><span class=p>:</span> <span class=nb>round</span><span class=p>(</span><span class=n>latency</span><span class=p>,</span> <span class=mi>2</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;response_length&#34;</span><span class=p>:</span> <span class=nb>len</span><span class=p>(</span><span class=n>response</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;response_preview&#34;</span><span class=p>:</span> <span class=n>response</span><span class=p>[:</span><span class=mi>200</span><span class=p>]</span> <span class=o>+</span> <span class=s2>&#34;...&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span><span class=p>[</span><span class=n>name</span><span class=p>]</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;success&#34;</span><span class=p>:</span> <span class=kc>False</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;error&#34;</span><span class=p>:</span> <span class=nb>str</span><span class=p>(</span><span class=n>e</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 运行基准测试</span>
</span></span><span class=line><span class=cl><span class=n>vlms</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;GPT-4o&#34;</span><span class=p>:</span> <span class=n>GPT4oVLM</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;...&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Gemini&#34;</span><span class=p>:</span> <span class=n>GeminiVLM</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;...&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;Florence-2&#34;</span><span class=p>:</span> <span class=n>Florence2VLM</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>results</span> <span class=o>=</span> <span class=n>benchmark_vlms</span><span class=p>(</span><span class=s2>&#34;test_image.jpg&#34;</span><span class=p>,</span> <span class=s2>&#34;描述这张图片&#34;</span><span class=p>,</span> <span class=n>vlms</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>name</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=n>results</span><span class=o>.</span><span class=n>items</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>name</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>result</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><hr><h2 id=本章小结>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>#</a></h2><h3 id=核心要点-1>核心要点<a class=anchor href=#%e6%a0%b8%e5%bf%83%e8%a6%81%e7%82%b9-1>#</a></h3><ol><li><strong>Florence-2</strong>: 开源统一视觉模型,通过提示词切换10+任务,适合部署和定制</li><li><strong>GPT-4o</strong>: 综合能力最强,适合复杂推理和高精度需求</li><li><strong>Gemini</strong>: 视频理解独特优势,成本最低,超长上下文</li></ol><h3 id=模型选择指南>模型选择指南<a class=anchor href=#%e6%a8%a1%e5%9e%8b%e9%80%89%e6%8b%a9%e6%8c%87%e5%8d%97>#</a></h3><table><thead><tr><th>需求</th><th>推荐模型</th><th>理由</th></tr></thead><tbody><tr><td>开源可控</td><td>Florence-2</td><td>MIT协议,可商用</td></tr><tr><td>最强推理</td><td>GPT-4o</td><td>综合能力最佳</td></tr><tr><td>视频分析</td><td>Gemini</td><td>原生视频支持</td></tr><tr><td>成本敏感</td><td>Gemini Flash</td><td>最便宜</td></tr><tr><td>快速原型</td><td>GPT-4o-mini</td><td>性价比高</td></tr><tr><td>本地部署</td><td>Florence-2</td><td>无API依赖</td></tr></tbody></table><h3 id=最佳实践>最佳实践<a class=anchor href=#%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5>#</a></h3><ol><li><strong>成本优化</strong>: 简单任务用mini模型,复杂任务用标准模型</li><li><strong>图像预处理</strong>: 压缩图像减少tokens消耗</li><li><strong>批量处理</strong>: 使用异步调用提升吞吐</li><li><strong>Fallback策略</strong>: 主模型失败时切换备用模型</li><li><strong>结果缓存</strong>: 相同图像+prompt缓存结果</li></ol><h3 id=参考资源-1>参考资源<a class=anchor href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%ba%90-1>#</a></h3><ul><li><a href=https://huggingface.co/microsoft/Florence-2-large>Florence-2 Hugging Face</a></li><li><a href=https://platform.openai.com/docs/guides/vision>OpenAI Vision Guide</a></li><li><a href=https://ai.google.dev/docs>Google AI Gemini</a></li><li><a href=https://huggingface.co/spaces/opencompass/open_vlm_leaderboard>Hugging Face VLM排行榜</a></li></ul><hr><h1 id=第18章3d视觉与视频理解-1>第18章:3D视觉与视频理解<a class=anchor href=#%e7%ac%ac18%e7%ab%a03d%e8%a7%86%e8%a7%89%e4%b8%8e%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3-1>#</a></h1><blockquote class=book-hint><p>从2D到3D/4D的视觉扩展</p></blockquote><h2 id=本章概述-2>本章概述<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e6%a6%82%e8%bf%b0-2>#</a></h2><p>本章探索计算机视觉的前沿方向:</p><ul><li><strong>NeRF</strong>: 神经辐射场,隐式3D表示</li><li><strong>3D Gaussian Splatting</strong>: 显式3D重建新范式,实时渲染</li><li><strong>Video Understanding</strong>: 视频分类与理解</li><li><strong>Video VLM</strong>: 视频版大语言模型</li></ul><p>这些技术代表了CV从2D向3D/4D演进的重要方向。</p><hr><h2 id=181-nerf神经辐射场>18.1 NeRF:神经辐射场<a class=anchor href=#181-nerf%e7%a5%9e%e7%bb%8f%e8%be%90%e5%b0%84%e5%9c%ba>#</a></h2><p>NeRF(Neural Radiance Fields)是2020年ECCV提出的突破性工作,通过神经网络隐式表示3D场景,并获得了ECCV 2020最佳论文荣誉提名。</p><h3 id=1811-核心原理>18.1.1 核心原理<a class=anchor href=#1811-%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86>#</a></h3><p><strong>基本思想</strong>:
用一个神经网络学习从5D输入(3D位置 + 2D视角方向)到颜色和密度的映射。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入: (x, y, z, θ, φ) - 空间位置 + 观察方向
</span></span><span class=line><span class=cl>       ↓
</span></span><span class=line><span class=cl>    MLP网络
</span></span><span class=line><span class=cl>       ↓
</span></span><span class=line><span class=cl>输出: (r, g, b, σ) - 颜色 + 密度</span></span></code></pre></div><p><strong>体渲染(Volume Rendering)</strong>:
沿着每条射线积分颜色和密度,生成最终像素值:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>C(r) = ∫ T(t) · σ(r(t)) · c(r(t), d) dt
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中:
</span></span><span class=line><span class=cl>- T(t): 透射率,光线到达t点的概率
</span></span><span class=line><span class=cl>- σ: 体积密度
</span></span><span class=line><span class=cl>- c: 颜色
</span></span><span class=line><span class=cl>- d: 视角方向</span></span></code></pre></div><h3 id=1812-网络架构>18.1.2 网络架构<a class=anchor href=#1812-%e7%bd%91%e7%bb%9c%e6%9e%b6%e6%9e%84>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>NeRF</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;简化版NeRF网络&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>D</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span> <span class=n>W</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span> <span class=n>input_ch</span><span class=o>=</span><span class=mi>63</span><span class=p>,</span> <span class=n>input_ch_views</span><span class=o>=</span><span class=mi>27</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            D: 网络深度
</span></span></span><span class=line><span class=cl><span class=s2>            W: 隐藏层宽度
</span></span></span><span class=line><span class=cl><span class=s2>            input_ch: 位置编码后的位置维度
</span></span></span><span class=line><span class=cl><span class=s2>            input_ch_views: 位置编码后的方向维度
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>D</span> <span class=o>=</span> <span class=n>D</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>W</span> <span class=o>=</span> <span class=n>W</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_ch</span> <span class=o>=</span> <span class=n>input_ch</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>input_ch_views</span> <span class=o>=</span> <span class=n>input_ch_views</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 位置编码后的位置输入 -&gt; 特征</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pts_linears</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_ch</span><span class=p>,</span> <span class=n>W</span><span class=p>)]</span> <span class=o>+</span>
</span></span><span class=line><span class=cl>            <span class=p>[</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>W</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span> <span class=k>if</span> <span class=n>i</span> <span class=o>!=</span> <span class=mi>4</span> <span class=k>else</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>W</span> <span class=o>+</span> <span class=n>input_ch</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl>             <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>D</span> <span class=o>-</span> <span class=mi>1</span><span class=p>)]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 方向相关的颜色预测</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>views_linears</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span><span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>input_ch_views</span> <span class=o>+</span> <span class=n>W</span><span class=p>,</span> <span class=n>W</span> <span class=o>//</span> <span class=mi>2</span><span class=p>)])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 输出层</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>feature_linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>W</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>alpha_linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>W</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>  <span class=c1># 密度</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>rgb_linear</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>W</span> <span class=o>//</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>  <span class=c1># 颜色</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 分离位置和方向</span>
</span></span><span class=line><span class=cl>        <span class=n>input_pts</span><span class=p>,</span> <span class=n>input_views</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>split</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>x</span><span class=p>,</span> <span class=p>[</span><span class=bp>self</span><span class=o>.</span><span class=n>input_ch</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>input_ch_views</span><span class=p>],</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>h</span> <span class=o>=</span> <span class=n>input_pts</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>layer</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>pts_linears</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>4</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>h</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>input_pts</span><span class=p>,</span> <span class=n>h</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 密度输出(与视角无关)</span>
</span></span><span class=line><span class=cl>        <span class=n>alpha</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>alpha_linear</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 颜色输出(与视角相关)</span>
</span></span><span class=line><span class=cl>        <span class=n>feature</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>feature_linear</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>h</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>feature</span><span class=p>,</span> <span class=n>input_views</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>views_linears</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>h</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>relu</span><span class=p>(</span><span class=n>h</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>rgb</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>sigmoid</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>rgb_linear</span><span class=p>(</span><span class=n>h</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>rgb</span><span class=p>,</span> <span class=n>alpha</span><span class=p>],</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></div><h3 id=1813-位置编码positional-encoding>18.1.3 位置编码(Positional Encoding)<a class=anchor href=#1813-%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81positional-encoding>#</a></h3><p>NeRF使用位置编码帮助网络学习高频细节:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PositionalEncoding</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;位置编码:将低维输入映射到高维空间&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>L</span><span class=o>=</span><span class=mi>10</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            L: 编码频率数量
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>L</span> <span class=o>=</span> <span class=n>L</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>freq_bands</span> <span class=o>=</span> <span class=mf>2.0</span> <span class=o>**</span> <span class=n>torch</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>L</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>L</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            x: 输入坐标 [..., C]
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            编码后的坐标 [..., C * (2L + 1)]
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>out</span> <span class=o>=</span> <span class=p>[</span><span class=n>x</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>freq</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>freq_bands</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>out</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>sin</span><span class=p>(</span><span class=n>freq</span> <span class=o>*</span> <span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=n>out</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>cos</span><span class=p>(</span><span class=n>freq</span> <span class=o>*</span> <span class=n>x</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>out</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=n>pos_encoder</span> <span class=o>=</span> <span class=n>PositionalEncoding</span><span class=p>(</span><span class=n>L</span><span class=o>=</span><span class=mi>10</span><span class=p>)</span>  <span class=c1># 位置用L=10</span>
</span></span><span class=line><span class=cl><span class=n>dir_encoder</span> <span class=o>=</span> <span class=n>PositionalEncoding</span><span class=p>(</span><span class=n>L</span><span class=o>=</span><span class=mi>4</span><span class=p>)</span>   <span class=c1># 方向用L=4</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3D位置: 3 -&gt; 3*(2*10+1) = 63</span>
</span></span><span class=line><span class=cl><span class=c1># 2D方向: 3 -&gt; 3*(2*4+1) = 27</span></span></span></code></pre></div><h3 id=1814-使用nerfstudio>18.1.4 使用Nerfstudio<a class=anchor href=#1814-%e4%bd%bf%e7%94%a8nerfstudio>#</a></h3><p>Nerfstudio是最流行的NeRF工具箱,提供了统一的训练和可视化接口:</p><p><strong>安装</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install nerfstudio
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或从源码安装(获取最新功能)</span>
</span></span><span class=line><span class=cl>git clone https://github.com/nerfstudio-project/nerfstudio.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> nerfstudio
</span></span><span class=line><span class=cl>pip install -e .</span></span></code></pre></div><p><strong>数据准备</strong>(使用COLMAP):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 从视频提取帧并估计相机位姿</span>
</span></span><span class=line><span class=cl>ns-process-data video --data ./input_video.mp4 --output-dir ./data/my_scene
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或从图像文件夹处理</span>
</span></span><span class=line><span class=cl>ns-process-data images --data ./images/ --output-dir ./data/my_scene</span></span></code></pre></div><p><strong>训练</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 训练Nerfacto模型(推荐)</span>
</span></span><span class=line><span class=cl>ns-train nerfacto --data ./data/my_scene
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练Instant-NGP(更快)</span>
</span></span><span class=line><span class=cl>ns-train instant-ngp --data ./data/my_scene
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 指定输出目录</span>
</span></span><span class=line><span class=cl>ns-train nerfacto --data ./data/my_scene --output-dir ./outputs/</span></span></code></pre></div><p><strong>可视化</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 启动交互式查看器</span>
</span></span><span class=line><span class=cl>ns-viewer --load-config outputs/my_scene/nerfacto/config.yml
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 渲染视频</span>
</span></span><span class=line><span class=cl>ns-render camera-path --load-config outputs/my_scene/nerfacto/config.yml <span class=se>\
</span></span></span><span class=line><span class=cl>    --camera-path-filename camera_path.json <span class=se>\
</span></span></span><span class=line><span class=cl>    --output-path renders/output.mp4</span></span></code></pre></div><h3 id=1815-instant-ngp1000倍加速>18.1.5 Instant-NGP:1000倍加速<a class=anchor href=#1815-instant-ngp1000%e5%80%8d%e5%8a%a0%e9%80%9f>#</a></h3><p>NVIDIA的Instant-NGP使用多分辨率哈希编码,将NeRF训练从小时级缩短到分钟级:</p><p><strong>核心创新</strong>:</p><ol><li><strong>多分辨率哈希编码</strong>: 用哈希表替代大型MLP,大幅加速查询</li><li><strong>小型MLP</strong>: 只需要2层MLP(原版需要8层)</li><li><strong>CUDA优化</strong>: 高度优化的CUDA实现</li></ol><p><strong>使用方式</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 下载并解压Instant-NGP</span>
</span></span><span class=line><span class=cl><span class=c1># 从 https://github.com/NVlabs/instant-ngp/releases 下载</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动GUI</span>
</span></span><span class=line><span class=cl>./instant-ngp
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 拖拽数据文件夹到窗口即可开始训练</span>
</span></span><span class=line><span class=cl><span class=c1># 或使用命令行</span>
</span></span><span class=line><span class=cl>./instant-ngp ./data/nerf/fox</span></span></code></pre></div><p><strong>性能对比</strong>:</p><table><thead><tr><th>方法</th><th>训练时间</th><th>渲染FPS</th><th>质量(PSNR)</th></tr></thead><tbody><tr><td>原版NeRF</td><td>1-2天</td><td>0.03</td><td>31.0</td></tr><tr><td>Instant-NGP</td><td>5分钟</td><td>60+</td><td>33.0</td></tr><tr><td>Nerfacto</td><td>30分钟</td><td>1-5</td><td>32.5</td></tr></tbody></table><h3 id=1816-nerf的局限性>18.1.6 NeRF的局限性<a class=anchor href=#1816-nerf%e7%9a%84%e5%b1%80%e9%99%90%e6%80%a7>#</a></h3><ol><li><strong>训练慢</strong>: 即使Instant-NGP也需要几分钟</li><li><strong>渲染慢</strong>: 体渲染计算密集(除了Instant-NGP)</li><li><strong>静态场景</strong>: 原版只能处理静态场景</li><li><strong>采集要求</strong>: 需要高质量的多视角图像</li></ol><hr><h2 id=182-3d-gaussian-splatting>18.2 3D Gaussian Splatting<a class=anchor href=#182-3d-gaussian-splatting>#</a></h2><p>3D Gaussian Splatting(3DGS)是2023年SIGGRAPH的突破性工作,实现了高质量实时3D重建。</p><h3 id=1821-核心思想>18.2.1 核心思想<a class=anchor href=#1821-%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3>#</a></h3><p>与NeRF的隐式表示不同,3DGS使用显式的3D高斯点云表示场景:</p><p><strong>每个高斯的属性</strong>:</p><ul><li><strong>位置</strong>: 3D中心点 (x, y, z)</li><li><strong>协方差</strong>: 3×3矩阵,定义高斯的形状和方向</li><li><strong>不透明度</strong>: α值</li><li><strong>球谐系数</strong>: 表示视角相关的颜色</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>场景 = {G₁, G₂, ..., Gₙ}
</span></span><span class=line><span class=cl>Gᵢ = (μᵢ, Σᵢ, αᵢ, SHᵢ)
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>其中:
</span></span><span class=line><span class=cl>- μ: 位置 (3D)
</span></span><span class=line><span class=cl>- Σ: 协方差矩阵 (表示为缩放+旋转)
</span></span><span class=line><span class=cl>- α: 不透明度
</span></span><span class=line><span class=cl>- SH: 球谐系数 (颜色)</span></span></code></pre></div><h3 id=1822-渲染流程>18.2.2 渲染流程<a class=anchor href=#1822-%e6%b8%b2%e6%9f%93%e6%b5%81%e7%a8%8b>#</a></h3><p>3DGS使用可微分光栅化而非体渲染:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 伪代码:3DGS渲染流程</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>render_gaussians</span><span class=p>(</span><span class=n>gaussians</span><span class=p>,</span> <span class=n>camera</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    1. 将3D高斯投影到2D
</span></span></span><span class=line><span class=cl><span class=s2>    2. 按深度排序
</span></span></span><span class=line><span class=cl><span class=s2>    3. Alpha混合
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 投影</span>
</span></span><span class=line><span class=cl>    <span class=n>projected_2d</span> <span class=o>=</span> <span class=n>project_to_2d</span><span class=p>(</span><span class=n>gaussians</span><span class=p>,</span> <span class=n>camera</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 排序(按深度)</span>
</span></span><span class=line><span class=cl>    <span class=n>sorted_gaussians</span> <span class=o>=</span> <span class=n>sort_by_depth</span><span class=p>(</span><span class=n>projected_2d</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 光栅化(Alpha混合)</span>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>gaussian</span> <span class=ow>in</span> <span class=n>sorted_gaussians</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>contribution</span> <span class=o>=</span> <span class=n>gaussian</span><span class=o>.</span><span class=n>alpha</span> <span class=o>*</span> <span class=n>gaussian</span><span class=o>.</span><span class=n>color</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span> <span class=o>=</span> <span class=n>image</span> <span class=o>*</span> <span class=p>(</span><span class=mi>1</span> <span class=o>-</span> <span class=n>gaussian</span><span class=o>.</span><span class=n>alpha</span><span class=p>)</span> <span class=o>+</span> <span class=n>contribution</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>image</span></span></span></code></pre></div><h3 id=1823-训练流程>18.2.3 训练流程<a class=anchor href=#1823-%e8%ae%ad%e7%bb%83%e6%b5%81%e7%a8%8b>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 伪代码:3DGS训练流程</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_3dgs</span><span class=p>(</span><span class=n>images</span><span class=p>,</span> <span class=n>cameras</span><span class=p>,</span> <span class=n>sfm_points</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        images: 训练图像
</span></span></span><span class=line><span class=cl><span class=s2>        cameras: 相机参数
</span></span></span><span class=line><span class=cl><span class=s2>        sfm_points: SfM稀疏点云(初始化)
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 初始化高斯点</span>
</span></span><span class=line><span class=cl>    <span class=n>gaussians</span> <span class=o>=</span> <span class=n>initialize_from_sfm</span><span class=p>(</span><span class=n>sfm_points</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>optimizer</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>optim</span><span class=o>.</span><span class=n>Adam</span><span class=p>(</span><span class=n>gaussians</span><span class=o>.</span><span class=n>parameters</span><span class=p>(),</span> <span class=n>lr</span><span class=o>=</span><span class=mf>0.001</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>iteration</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>30000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 随机选择视角</span>
</span></span><span class=line><span class=cl>        <span class=n>camera</span> <span class=o>=</span> <span class=n>random</span><span class=o>.</span><span class=n>choice</span><span class=p>(</span><span class=n>cameras</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>gt_image</span> <span class=o>=</span> <span class=n>images</span><span class=p>[</span><span class=n>camera</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 前向渲染</span>
</span></span><span class=line><span class=cl>        <span class=n>rendered</span> <span class=o>=</span> <span class=n>render_gaussians</span><span class=p>(</span><span class=n>gaussians</span><span class=p>,</span> <span class=n>camera</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 计算损失</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span> <span class=o>=</span> <span class=n>l1_loss</span><span class=p>(</span><span class=n>rendered</span><span class=p>,</span> <span class=n>gt_image</span><span class=p>)</span> <span class=o>+</span> <span class=n>ssim_loss</span><span class=p>(</span><span class=n>rendered</span><span class=p>,</span> <span class=n>gt_image</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 反向传播</span>
</span></span><span class=line><span class=cl>        <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>optimizer</span><span class=o>.</span><span class=n>step</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 自适应密度控制(关键!)</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>iteration</span> <span class=o>%</span> <span class=mi>100</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>densify_and_prune</span><span class=p>(</span><span class=n>gaussians</span><span class=p>)</span>  <span class=c1># 分裂/克隆/删除高斯</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>gaussians</span></span></span></code></pre></div><h3 id=1824-安装与使用>18.2.4 安装与使用<a class=anchor href=#1824-%e5%ae%89%e8%a3%85%e4%b8%8e%e4%bd%bf%e7%94%a8>#</a></h3><p><strong>环境要求</strong>:</p><ul><li>CUDA 11.0+</li><li>Python 3.8+</li><li>PyTorch 2.0+</li></ul><p><strong>安装</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 克隆仓库(注意递归克隆)</span>
</span></span><span class=line><span class=cl>git clone https://github.com/graphdeco-inria/gaussian-splatting --recursive
</span></span><span class=line><span class=cl><span class=nb>cd</span> gaussian-splatting
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 安装依赖</span>
</span></span><span class=line><span class=cl>pip install -r requirements.txt
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 安装子模块</span>
</span></span><span class=line><span class=cl>pip install submodules/diff-gaussian-rasterization
</span></span><span class=line><span class=cl>pip install submodules/simple-knn</span></span></code></pre></div><p><strong>数据准备</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 使用COLMAP处理数据</span>
</span></span><span class=line><span class=cl><span class=c1># 需要:images/文件夹下的图像</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>python convert.py -s ./data/my_scene</span></span></code></pre></div><p><strong>训练</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 基础训练</span>
</span></span><span class=line><span class=cl>python train.py -s ./data/my_scene
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 指定输出和迭代次数</span>
</span></span><span class=line><span class=cl>python train.py -s ./data/my_scene -m ./output/my_scene --iterations <span class=m>30000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用稀疏Adam优化器(2.7倍加速)</span>
</span></span><span class=line><span class=cl>python train.py -s ./data/my_scene --optimizer_type sparse_adam</span></span></code></pre></div><p><strong>渲染</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 渲染训练视角</span>
</span></span><span class=line><span class=cl>python render.py -m ./output/my_scene
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 交互式查看器</span>
</span></span><span class=line><span class=cl><span class=c1># 需要安装SIBR viewer</span>
</span></span><span class=line><span class=cl>./SIBR_viewers/install/bin/SIBR_gaussianViewer_app -m ./output/my_scene</span></span></code></pre></div><h3 id=1825-python-api使用>18.2.5 Python API使用<a class=anchor href=#1825-python-api%e4%bd%bf%e7%94%a8>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>scene</span> <span class=kn>import</span> <span class=n>Scene</span><span class=p>,</span> <span class=n>GaussianModel</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>gaussian_renderer</span> <span class=kn>import</span> <span class=n>render</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载训练好的模型</span>
</span></span><span class=line><span class=cl><span class=n>gaussians</span> <span class=o>=</span> <span class=n>GaussianModel</span><span class=p>(</span><span class=mi>3</span><span class=p>)</span>  <span class=c1># sh_degree=3</span>
</span></span><span class=line><span class=cl><span class=n>gaussians</span><span class=o>.</span><span class=n>load_ply</span><span class=p>(</span><span class=s2>&#34;output/my_scene/point_cloud/iteration_30000/point_cloud.ply&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 设置相机</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>utils.graphics_utils</span> <span class=kn>import</span> <span class=n>getProjectionMatrix</span><span class=p>,</span> <span class=n>getWorld2View2</span>
</span></span><span class=line><span class=cl><span class=n>viewpoint_camera</span> <span class=o>=</span> <span class=n>create_camera</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>  <span class=c1># 创建相机对象</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 渲染</span>
</span></span><span class=line><span class=cl><span class=n>rendering</span> <span class=o>=</span> <span class=n>render</span><span class=p>(</span><span class=n>viewpoint_camera</span><span class=p>,</span> <span class=n>gaussians</span><span class=p>,</span> <span class=n>pipe</span><span class=p>,</span> <span class=n>background</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>rendering</span><span class=p>[</span><span class=s2>&#34;render&#34;</span><span class=p>]</span>  <span class=c1># [3, H, W]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 保存图像</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>torchvision.utils</span> <span class=kn>import</span> <span class=n>save_image</span>
</span></span><span class=line><span class=cl><span class=n>save_image</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=s2>&#34;rendered.png&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=1826-3dgs-vs-nerf对比>18.2.6 3DGS vs NeRF对比<a class=anchor href=#1826-3dgs-vs-nerf%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>特性</th><th>NeRF</th><th>3D Gaussian Splatting</th></tr></thead><tbody><tr><td><strong>表示方式</strong></td><td>隐式(MLP)</td><td>显式(点云)</td></tr><tr><td><strong>渲染方法</strong></td><td>体渲染(射线采样)</td><td>光栅化(Splatting)</td></tr><tr><td><strong>训练时间</strong></td><td>小时级</td><td>分钟级(~30min)</td></tr><tr><td><strong>渲染速度</strong></td><td>慢(~0.1 FPS)</td><td>实时(100+ FPS)</td></tr><tr><td><strong>质量</strong></td><td>高</td><td>更高</td></tr><tr><td><strong>编辑性</strong></td><td>困难</td><td>容易(点云操作)</td></tr><tr><td><strong>存储大小</strong></td><td>小(~5MB)</td><td>大(~100MB+)</td></tr><tr><td><strong>动态场景</strong></td><td>需要扩展</td><td>需要扩展</td></tr></tbody></table><p><strong>选择建议</strong>:</p><ul><li>需要实时渲染 → 3DGS</li><li>存储空间有限 → NeRF</li><li>需要编辑场景 → 3DGS</li><li>研究/学习目的 → 两者都尝试</li></ul><h3 id=1827-3dgs扩展与应用>18.2.7 3DGS扩展与应用<a class=anchor href=#1827-3dgs%e6%89%a9%e5%b1%95%e4%b8%8e%e5%ba%94%e7%94%a8>#</a></h3><p><strong>1. Dynamic 3DGS(动态场景)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 动态高斯:每个高斯有时间相关属性</span>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>DynamicGaussian</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>position</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=o>...</span><span class=p>)</span>  <span class=c1># 基础位置</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>deformation</span> <span class=o>=</span> <span class=n>DeformationNetwork</span><span class=p>()</span>  <span class=c1># 变形网络</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>get_position</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>time</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 根据时间获取当前位置</span>
</span></span><span class=line><span class=cl>        <span class=n>delta</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>deformation</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>position</span><span class=p>,</span> <span class=n>time</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>position</span> <span class=o>+</span> <span class=n>delta</span></span></span></code></pre></div><p><strong>2. SuGaR(网格提取)</strong>:
从3DGS中提取可编辑的网格:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 安装SuGaR</span>
</span></span><span class=line><span class=cl>git clone https://github.com/Anttwo/SuGaR
</span></span><span class=line><span class=cl><span class=nb>cd</span> SuGaR
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练并提取网格</span>
</span></span><span class=line><span class=cl>python train.py -s ./data/my_scene -r <span class=s2>&#34;density&#34;</span> --export_obj</span></span></code></pre></div><p><strong>3. GaussianEditor(场景编辑)</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 删除特定区域的高斯</span>
</span></span><span class=line><span class=cl><span class=n>mask</span> <span class=o>=</span> <span class=n>create_mask_from_text</span><span class=p>(</span><span class=s2>&#34;remove the car&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>gaussians</span><span class=o>.</span><span class=n>prune_by_mask</span><span class=p>(</span><span class=n>mask</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 复制高斯</span>
</span></span><span class=line><span class=cl><span class=n>new_gaussians</span> <span class=o>=</span> <span class=n>gaussians</span><span class=o>.</span><span class=n>clone</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>new_gaussians</span><span class=o>.</span><span class=n>translate</span><span class=p>([</span><span class=mi>1</span><span class=p>,</span> <span class=mi>0</span><span class=p>,</span> <span class=mi>0</span><span class=p>])</span>  <span class=c1># 移动</span></span></span></code></pre></div><hr><h2 id=183-视频理解video-understanding>18.3 视频理解(Video Understanding)<a class=anchor href=#183-%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3video-understanding>#</a></h2><p>视频理解是将VLM能力扩展到时序数据的重要方向。</p><h3 id=1831-视频理解任务>18.3.1 视频理解任务<a class=anchor href=#1831-%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3%e4%bb%bb%e5%8a%a1>#</a></h3><table><thead><tr><th>任务</th><th>描述</th><th>输出</th></tr></thead><tbody><tr><td>视频分类</td><td>识别视频类别</td><td>类别标签</td></tr><tr><td>动作识别</td><td>识别人体动作</td><td>动作类别</td></tr><tr><td>时序动作检测</td><td>检测动作起止时间</td><td>时间段+类别</td></tr><tr><td>视频描述</td><td>生成视频描述</td><td>文本</td></tr><tr><td>视频问答</td><td>回答关于视频的问题</td><td>文本</td></tr><tr><td>视频摘要</td><td>提取关键片段</td><td>视频片段</td></tr></tbody></table><h3 id=1832-videomae视频自监督学习>18.3.2 VideoMAE:视频自监督学习<a class=anchor href=#1832-videomae%e8%a7%86%e9%a2%91%e8%87%aa%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0>#</a></h3><p>VideoMAE是视频版的MAE,通过掩码自编码学习视频表示:</p><p><strong>安装</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install transformers decord av</span></span></code></pre></div><p><strong>视频分类</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>VideoMAEForVideoClassification</span><span class=p>,</span> <span class=n>VideoMAEImageProcessor</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>av</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>read_video_pyav</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用PyAV读取视频帧&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>container</span> <span class=o>=</span> <span class=n>av</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>stream</span> <span class=o>=</span> <span class=n>container</span><span class=o>.</span><span class=n>streams</span><span class=o>.</span><span class=n>video</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算采样间隔</span>
</span></span><span class=line><span class=cl>    <span class=n>total_frames</span> <span class=o>=</span> <span class=n>stream</span><span class=o>.</span><span class=n>frames</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>total_frames</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>num_frames</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>frames</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>frame</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>container</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>video</span><span class=o>=</span><span class=mi>0</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>frames</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame</span><span class=o>.</span><span class=n>to_ndarray</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s2>&#34;rgb24&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>frames</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=n>num_frames</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>frames</span><span class=p>)</span>  <span class=c1># [T, H, W, C]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model_name</span> <span class=o>=</span> <span class=s2>&#34;MCG-NJU/videomae-base-finetuned-kinetics&#34;</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>VideoMAEImageProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>VideoMAEForVideoClassification</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 读取视频</span>
</span></span><span class=line><span class=cl><span class=n>video</span> <span class=o>=</span> <span class=n>read_video_pyav</span><span class=p>(</span><span class=s2>&#34;video.mp4&#34;</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预处理</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>video</span><span class=p>),</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 推理</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>logits</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>logits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 获取预测类别</span>
</span></span><span class=line><span class=cl><span class=n>predicted_class_idx</span> <span class=o>=</span> <span class=n>logits</span><span class=o>.</span><span class=n>argmax</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>)</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;预测类别: </span><span class=si>{</span><span class=n>model</span><span class=o>.</span><span class=n>config</span><span class=o>.</span><span class=n>id2label</span><span class=p>[</span><span class=n>predicted_class_idx</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>VideoMAE性能</strong>:</p><table><thead><tr><th>模型</th><th>Kinetics-400</th><th>Something-Something V2</th></tr></thead><tbody><tr><td>videomae-base</td><td>81.5%</td><td>70.8%</td></tr><tr><td>videomae-large</td><td>85.2%</td><td>75.3%</td></tr><tr><td>videomae-huge</td><td>86.6%</td><td>77.4%</td></tr></tbody></table><h3 id=1833-timesformer时空transformer>18.3.3 TimeSformer:时空Transformer<a class=anchor href=#1833-timesformer%e6%97%b6%e7%a9%batransformer>#</a></h3><p>TimeSformer将ViT扩展到视频,使用分离的时空注意力:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>TimesformerModel</span><span class=p>,</span> <span class=n>AutoImageProcessor</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoImageProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;facebook/timesformer-base-finetuned-k400&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>TimesformerModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=s2>&#34;facebook/timesformer-base-finetuned-k400&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 准备视频(假设已读取为numpy数组)</span>
</span></span><span class=line><span class=cl><span class=c1># video: [T, H, W, C], T通常为8或16帧</span>
</span></span><span class=line><span class=cl><span class=n>video_frames</span> <span class=o>=</span> <span class=n>read_video_pyav</span><span class=p>(</span><span class=s2>&#34;video.mp4&#34;</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预处理</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=nb>list</span><span class=p>(</span><span class=n>video_frames</span><span class=p>),</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 特征提取</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>features</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>last_hidden_state</span>  <span class=c1># [B, T*patches+1, D]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用CLS token作为视频表示</span>
</span></span><span class=line><span class=cl><span class=n>video_embedding</span> <span class=o>=</span> <span class=n>features</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>  <span class=c1># [B, D]</span></span></span></code></pre></div><h3 id=1834-video-llava视频语言模型>18.3.4 Video-LLaVA:视频语言模型<a class=anchor href=#1834-video-llava%e8%a7%86%e9%a2%91%e8%af%ad%e8%a8%80%e6%a8%a1%e5%9e%8b>#</a></h3><p>Video-LLaVA是LLaVA的视频版本,支持视频问答和描述:</p><p><strong>安装</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install transformers accelerate</span></span></code></pre></div><p><strong>使用示例</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>VideoLlavaProcessor</span><span class=p>,</span> <span class=n>VideoLlavaForConditionalGeneration</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>av</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>read_video_for_llava</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;为Video-LLaVA读取视频&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>container</span> <span class=o>=</span> <span class=n>av</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>stream</span> <span class=o>=</span> <span class=n>container</span><span class=o>.</span><span class=n>streams</span><span class=o>.</span><span class=n>video</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>    <span class=n>total_frames</span> <span class=o>=</span> <span class=n>stream</span><span class=o>.</span><span class=n>frames</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>total_frames</span> <span class=o>-</span> <span class=mi>1</span><span class=p>,</span> <span class=n>num_frames</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>frames</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>container</span><span class=o>.</span><span class=n>seek</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>frame</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>container</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>video</span><span class=o>=</span><span class=mi>0</span><span class=p>)):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>i</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>frames</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame</span><span class=o>.</span><span class=n>to_ndarray</span><span class=p>(</span><span class=nb>format</span><span class=o>=</span><span class=s2>&#34;rgb24&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>frames</span><span class=p>)</span> <span class=o>&gt;=</span> <span class=n>num_frames</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>np</span><span class=o>.</span><span class=n>stack</span><span class=p>(</span><span class=n>frames</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;LanguageBind/Video-LLaVA-7B-hf&#34;</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>VideoLlavaProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>VideoLlavaForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 读取视频</span>
</span></span><span class=line><span class=cl><span class=n>video</span> <span class=o>=</span> <span class=n>read_video_for_llava</span><span class=p>(</span><span class=s2>&#34;demo.mp4&#34;</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 构建对话</span>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;USER: &lt;video&gt;请详细描述这个视频的内容。 ASSISTANT:&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 处理输入</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>videos</span><span class=o>=</span><span class=n>video</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 生成</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=o>**</span><span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>256</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>do_sample</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 解码</span>
</span></span><span class=line><span class=cl><span class=n>response</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;ASSISTANT:&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>())</span></span></span></code></pre></div><p><strong>视频问答</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>video_qa</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;视频问答&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>video</span> <span class=o>=</span> <span class=n>read_video_for_llava</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;USER: &lt;video&gt;</span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2> ASSISTANT:&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>videos</span><span class=o>=</span><span class=n>video</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>model</span><span class=o>.</span><span class=n>device</span><span class=p>,</span> <span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>128</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>output</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;ASSISTANT:&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用</span>
</span></span><span class=line><span class=cl><span class=n>answer</span> <span class=o>=</span> <span class=n>video_qa</span><span class=p>(</span><span class=s2>&#34;cooking.mp4&#34;</span><span class=p>,</span> <span class=s2>&#34;视频中的人在做什么菜?用了哪些食材?&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>answer</span><span class=p>)</span></span></span></code></pre></div><h3 id=1835-视频分析最佳实践>18.3.5 视频分析最佳实践<a class=anchor href=#1835-%e8%a7%86%e9%a2%91%e5%88%86%e6%9e%90%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5>#</a></h3><p><strong>1. 帧采样策略</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>uniform_sample</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;均匀采样&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 最常用,适合大多数任务</span>
</span></span><span class=line><span class=cl>    <span class=k>pass</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>keyframe_sample</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;关键帧采样&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 适合快速变化的视频</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl>    <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>frames</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>prev_frame</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=n>cap</span><span class=o>.</span><span class=n>isOpened</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>prev_frame</span> <span class=ow>is</span> <span class=ow>not</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 计算帧差</span>
</span></span><span class=line><span class=cl>            <span class=n>diff</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>absdiff</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>prev_frame</span><span class=p>)</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=n>diff</span> <span class=o>&gt;</span> <span class=n>threshold</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=n>frames</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>prev_frame</span> <span class=o>=</span> <span class=n>frame</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>select_frames</span><span class=p>(</span><span class=n>frames</span><span class=p>,</span> <span class=n>num_frames</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>scene_based_sample</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>16</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;场景切换采样&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 适合包含多个场景的视频</span>
</span></span><span class=line><span class=cl>    <span class=k>pass</span></span></span></code></pre></div><p><strong>2. 长视频处理</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_long_video</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>chunk_duration</span><span class=o>=</span><span class=mi>30</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;分块处理长视频&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>av</span>
</span></span><span class=line><span class=cl>    <span class=n>container</span> <span class=o>=</span> <span class=n>av</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>duration</span> <span class=o>=</span> <span class=n>container</span><span class=o>.</span><span class=n>duration</span> <span class=o>/</span> <span class=mi>1000000</span>  <span class=c1># 秒</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>start</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>int</span><span class=p>(</span><span class=n>duration</span><span class=p>),</span> <span class=n>chunk_duration</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>end</span> <span class=o>=</span> <span class=nb>min</span><span class=p>(</span><span class=n>start</span> <span class=o>+</span> <span class=n>chunk_duration</span><span class=p>,</span> <span class=n>duration</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk</span> <span class=o>=</span> <span class=n>extract_chunk</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>start</span><span class=p>,</span> <span class=n>end</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 处理每个块</span>
</span></span><span class=line><span class=cl>        <span class=n>chunk_result</span> <span class=o>=</span> <span class=n>analyze_video_chunk</span><span class=p>(</span><span class=n>chunk</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;start&#34;</span><span class=p>:</span> <span class=n>start</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;end&#34;</span><span class=p>:</span> <span class=n>end</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;result&#34;</span><span class=p>:</span> <span class=n>chunk_result</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 合并结果</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>merge_results</span><span class=p>(</span><span class=n>results</span><span class=p>)</span></span></span></code></pre></div><p><strong>3. 批量推理</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>batch_video_inference</span><span class=p>(</span><span class=n>video_paths</span><span class=p>,</span> <span class=n>batch_size</span><span class=o>=</span><span class=mi>4</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;批量视频推理&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=n>video_paths</span><span class=p>),</span> <span class=n>batch_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_paths</span> <span class=o>=</span> <span class=n>video_paths</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span> <span class=o>+</span> <span class=n>batch_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_videos</span> <span class=o>=</span> <span class=p>[</span><span class=n>read_video</span><span class=p>(</span><span class=n>p</span><span class=p>)</span> <span class=k>for</span> <span class=n>p</span> <span class=ow>in</span> <span class=n>batch_paths</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 批量处理</span>
</span></span><span class=line><span class=cl>        <span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>videos</span><span class=o>=</span><span class=n>batch_videos</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>padding</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>process_outputs</span><span class=p>(</span><span class=n>outputs</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span></span></span></code></pre></div><hr><h2 id=184-实战3d重建项目>18.4 实战:3D重建项目<a class=anchor href=#184-%e5%ae%9e%e6%88%983d%e9%87%8d%e5%bb%ba%e9%a1%b9%e7%9b%ae>#</a></h2><h3 id=1841-完整3d重建流程>18.4.1 完整3D重建流程<a class=anchor href=#1841-%e5%ae%8c%e6%95%b43d%e9%87%8d%e5%bb%ba%e6%b5%81%e7%a8%8b>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>手机拍摄 → 图像预处理 → SfM位姿估计 → 3DGS/NeRF训练 → 渲染/导出</span></span></code></pre></div><h3 id=1842-数据采集指南>18.4.2 数据采集指南<a class=anchor href=#1842-%e6%95%b0%e6%8d%ae%e9%87%87%e9%9b%86%e6%8c%87%e5%8d%97>#</a></h3><p><strong>拍摄技巧</strong>:</p><ol><li><strong>覆盖全面</strong>: 围绕物体/场景拍摄,覆盖所有角度</li><li><strong>重叠率高</strong>: 相邻图像重叠70%以上</li><li><strong>光照一致</strong>: 避免强烈阴影和高光</li><li><strong>稳定清晰</strong>: 避免运动模糊</li><li><strong>数量适中</strong>: 50-150张图像为佳</li></ol><p><strong>使用手机</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 使用Record3D(iOS)直接导出</span>
</span></span><span class=line><span class=cl><span class=c1># 支持LiDAR深度数据</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或使用Polycam等App</span></span></span></code></pre></div><h3 id=1843-使用colmap进行sfm>18.4.3 使用COLMAP进行SfM<a class=anchor href=#1843-%e4%bd%bf%e7%94%a8colmap%e8%bf%9b%e8%a1%8csfm>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 安装COLMAP</span>
</span></span><span class=line><span class=cl><span class=c1># macOS</span>
</span></span><span class=line><span class=cl>brew install colmap
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Ubuntu</span>
</span></span><span class=line><span class=cl>sudo apt install colmap
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 或下载预编译版本</span></span></span></code></pre></div><p><strong>自动流程</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 自动重建流程</span>
</span></span><span class=line><span class=cl>colmap automatic_reconstructor <span class=se>\
</span></span></span><span class=line><span class=cl>    --workspace_path ./workspace <span class=se>\
</span></span></span><span class=line><span class=cl>    --image_path ./images <span class=se>\
</span></span></span><span class=line><span class=cl>    --camera_model OPENCV <span class=se>\
</span></span></span><span class=line><span class=cl>    --single_camera <span class=m>1</span></span></span></code></pre></div><p><strong>分步流程</strong>(更多控制):</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. 特征提取</span>
</span></span><span class=line><span class=cl>colmap feature_extractor <span class=se>\
</span></span></span><span class=line><span class=cl>    --database_path ./database.db <span class=se>\
</span></span></span><span class=line><span class=cl>    --image_path ./images <span class=se>\
</span></span></span><span class=line><span class=cl>    --ImageReader.camera_model OPENCV <span class=se>\
</span></span></span><span class=line><span class=cl>    --ImageReader.single_camera <span class=m>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 特征匹配</span>
</span></span><span class=line><span class=cl>colmap exhaustive_matcher <span class=se>\
</span></span></span><span class=line><span class=cl>    --database_path ./database.db
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 稀疏重建</span>
</span></span><span class=line><span class=cl>mkdir sparse
</span></span><span class=line><span class=cl>colmap mapper <span class=se>\
</span></span></span><span class=line><span class=cl>    --database_path ./database.db <span class=se>\
</span></span></span><span class=line><span class=cl>    --image_path ./images <span class=se>\
</span></span></span><span class=line><span class=cl>    --output_path ./sparse
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 导出为文本格式(用于3DGS)</span>
</span></span><span class=line><span class=cl>colmap model_converter <span class=se>\
</span></span></span><span class=line><span class=cl>    --input_path ./sparse/0 <span class=se>\
</span></span></span><span class=line><span class=cl>    --output_path ./sparse_txt <span class=se>\
</span></span></span><span class=line><span class=cl>    --output_type TXT</span></span></code></pre></div><h3 id=1844-3dgs训练脚本>18.4.4 3DGS训练脚本<a class=anchor href=#1844-3dgs%e8%ae%ad%e7%bb%83%e8%84%9a%e6%9c%ac>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># train_3dgs.py</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>subprocess</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>argparse</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>prepare_data</span><span class=p>(</span><span class=n>image_folder</span><span class=p>,</span> <span class=n>output_folder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用COLMAP准备数据&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>os</span><span class=o>.</span><span class=n>makedirs</span><span class=p>(</span><span class=n>output_folder</span><span class=p>,</span> <span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 运行COLMAP</span>
</span></span><span class=line><span class=cl>    <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;colmap&#34;</span><span class=p>,</span> <span class=s2>&#34;automatic_reconstructor&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--workspace_path&#34;</span><span class=p>,</span> <span class=n>output_folder</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--image_path&#34;</span><span class=p>,</span> <span class=n>image_folder</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--camera_model&#34;</span><span class=p>,</span> <span class=s2>&#34;OPENCV&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--single_camera&#34;</span><span class=p>,</span> <span class=s2>&#34;1&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>train_gaussians</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=n>output_path</span><span class=p>,</span> <span class=n>iterations</span><span class=o>=</span><span class=mi>30000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;训练3D Gaussian Splatting&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;python&#34;</span><span class=p>,</span> <span class=s2>&#34;train.py&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;-s&#34;</span><span class=p>,</span> <span class=n>data_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;-m&#34;</span><span class=p>,</span> <span class=n>output_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--iterations&#34;</span><span class=p>,</span> <span class=nb>str</span><span class=p>(</span><span class=n>iterations</span><span class=p>),</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--save_iterations&#34;</span><span class=p>,</span> <span class=s2>&#34;7000&#34;</span><span class=p>,</span> <span class=s2>&#34;15000&#34;</span><span class=p>,</span> <span class=s2>&#34;30000&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>render_video</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>output_video</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;渲染视频&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>subprocess</span><span class=o>.</span><span class=n>run</span><span class=p>([</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;python&#34;</span><span class=p>,</span> <span class=s2>&#34;render.py&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;-m&#34;</span><span class=p>,</span> <span class=n>model_path</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--skip_train&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;--skip_test&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>main</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span> <span class=o>=</span> <span class=n>argparse</span><span class=o>.</span><span class=n>ArgumentParser</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--images&#34;</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;图像文件夹路径&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--output&#34;</span><span class=p>,</span> <span class=n>required</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>help</span><span class=o>=</span><span class=s2>&#34;输出路径&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>parser</span><span class=o>.</span><span class=n>add_argument</span><span class=p>(</span><span class=s2>&#34;--iterations&#34;</span><span class=p>,</span> <span class=nb>type</span><span class=o>=</span><span class=nb>int</span><span class=p>,</span> <span class=n>default</span><span class=o>=</span><span class=mi>30000</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>args</span> <span class=o>=</span> <span class=n>parser</span><span class=o>.</span><span class=n>parse_args</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 准备数据</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;步骤1: 准备数据...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>data_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>output</span><span class=p>,</span> <span class=s2>&#34;data&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prepare_data</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>images</span><span class=p>,</span> <span class=n>data_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 训练</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;步骤2: 训练3DGS...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>model_path</span> <span class=o>=</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>output</span><span class=p>,</span> <span class=s2>&#34;model&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>train_gaussians</span><span class=p>(</span><span class=n>data_path</span><span class=p>,</span> <span class=n>model_path</span><span class=p>,</span> <span class=n>args</span><span class=o>.</span><span class=n>iterations</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 渲染</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;步骤3: 渲染结果...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>render_video</span><span class=p>(</span><span class=n>model_path</span><span class=p>,</span> <span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>args</span><span class=o>.</span><span class=n>output</span><span class=p>,</span> <span class=s2>&#34;video.mp4&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;完成! 结果保存在: </span><span class=si>{</span><span class=n>args</span><span class=o>.</span><span class=n>output</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>main</span><span class=p>()</span></span></span></code></pre></div><h3 id=1845-web可视化>18.4.5 Web可视化<a class=anchor href=#1845-web%e5%8f%af%e8%a7%86%e5%8c%96>#</a></h3><p>使用Three.js展示3DGS结果:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-html data-lang=html><span class=line><span class=cl><span class=c>&lt;!-- index.html --&gt;</span>
</span></span><span class=line><span class=cl><span class=cp>&lt;!DOCTYPE html&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>html</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>head</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=p>&lt;</span><span class=nt>title</span><span class=p>&gt;</span>3D Gaussian Splatting Viewer<span class=p>&lt;/</span><span class=nt>title</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=p>&lt;</span><span class=nt>script</span> <span class=na>src</span><span class=o>=</span><span class=s>&#34;https://cdn.jsdelivr.net/npm/three@0.150.0/build/three.min.js&#34;</span><span class=p>&gt;&lt;/</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=p>&lt;</span><span class=nt>script</span> <span class=na>src</span><span class=o>=</span><span class=s>&#34;https://cdn.jsdelivr.net/npm/three@0.150.0/examples/js/controls/OrbitControls.js&#34;</span><span class=p>&gt;&lt;/</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;/</span><span class=nt>head</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;</span><span class=nt>body</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=p>&lt;</span><span class=nt>canvas</span> <span class=na>id</span><span class=o>=</span><span class=s>&#34;canvas&#34;</span><span class=p>&gt;&lt;/</span><span class=nt>canvas</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>    <span class=p>&lt;</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl>        <span class=c1>// 初始化场景
</span></span></span><span class=line><span class=cl>        <span class=kr>const</span> <span class=nx>scene</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>Scene</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=kr>const</span> <span class=nx>camera</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>PerspectiveCamera</span><span class=p>(</span><span class=mi>75</span><span class=p>,</span> <span class=nb>window</span><span class=p>.</span><span class=nx>innerWidth</span> <span class=o>/</span> <span class=nb>window</span><span class=p>.</span><span class=nx>innerHeight</span><span class=p>,</span> <span class=mf>0.1</span><span class=p>,</span> <span class=mi>1000</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=kr>const</span> <span class=nx>renderer</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>WebGLRenderer</span><span class=p>({</span><span class=nx>canvas</span><span class=o>:</span> <span class=nb>document</span><span class=p>.</span><span class=nx>getElementById</span><span class=p>(</span><span class=s1>&#39;canvas&#39;</span><span class=p>)});</span>
</span></span><span class=line><span class=cl>        <span class=nx>renderer</span><span class=p>.</span><span class=nx>setSize</span><span class=p>(</span><span class=nb>window</span><span class=p>.</span><span class=nx>innerWidth</span><span class=p>,</span> <span class=nb>window</span><span class=p>.</span><span class=nx>innerHeight</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// 控制器
</span></span></span><span class=line><span class=cl>        <span class=kr>const</span> <span class=nx>controls</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>OrbitControls</span><span class=p>(</span><span class=nx>camera</span><span class=p>,</span> <span class=nx>renderer</span><span class=p>.</span><span class=nx>domElement</span><span class=p>);</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// 加载PLY点云(简化版本)
</span></span></span><span class=line><span class=cl>        <span class=kr>const</span> <span class=nx>loader</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>PLYLoader</span><span class=p>();</span>
</span></span><span class=line><span class=cl>        <span class=nx>loader</span><span class=p>.</span><span class=nx>load</span><span class=p>(</span><span class=s1>&#39;point_cloud.ply&#39;</span><span class=p>,</span> <span class=kd>function</span><span class=p>(</span><span class=nx>geometry</span><span class=p>)</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=kr>const</span> <span class=nx>material</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>PointsMaterial</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=nx>size</span><span class=o>:</span> <span class=mf>0.01</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=nx>vertexColors</span><span class=o>:</span> <span class=kc>true</span>
</span></span><span class=line><span class=cl>            <span class=p>});</span>
</span></span><span class=line><span class=cl>            <span class=kr>const</span> <span class=nx>points</span> <span class=o>=</span> <span class=k>new</span> <span class=nx>THREE</span><span class=p>.</span><span class=nx>Points</span><span class=p>(</span><span class=nx>geometry</span><span class=p>,</span> <span class=nx>material</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=nx>scene</span><span class=p>.</span><span class=nx>add</span><span class=p>(</span><span class=nx>points</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>});</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nx>camera</span><span class=p>.</span><span class=nx>position</span><span class=p>.</span><span class=nx>z</span> <span class=o>=</span> <span class=mi>5</span><span class=p>;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1>// 渲染循环
</span></span></span><span class=line><span class=cl>        <span class=kd>function</span> <span class=nx>animate</span><span class=p>()</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nx>requestAnimationFrame</span><span class=p>(</span><span class=nx>animate</span><span class=p>);</span>
</span></span><span class=line><span class=cl>            <span class=nx>controls</span><span class=p>.</span><span class=nx>update</span><span class=p>();</span>
</span></span><span class=line><span class=cl>            <span class=nx>renderer</span><span class=p>.</span><span class=nx>render</span><span class=p>(</span><span class=nx>scene</span><span class=p>,</span> <span class=nx>camera</span><span class=p>);</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=nx>animate</span><span class=p>();</span>
</span></span><span class=line><span class=cl>    <span class=p>&lt;/</span><span class=nt>script</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;/</span><span class=nt>body</span><span class=p>&gt;</span>
</span></span><span class=line><span class=cl><span class=p>&lt;/</span><span class=nt>html</span><span class=p>&gt;</span></span></span></code></pre></div><p><strong>使用专业查看器</strong>:</p><ul><li><a href=https://playcanvas.com/supersplat/editor>SuperSplat</a> - 在线编辑器</li><li><a href=https://lumalabs.ai/interactive-scenes>Luma AI</a> - 在线查看</li><li><a href=https://github.com/graphdeco-inria/gaussian-splatting>SIBR Viewer</a> - 官方查看器</li></ul><h3 id=1846-导出与部署>18.4.6 导出与部署<a class=anchor href=#1846-%e5%af%bc%e5%87%ba%e4%b8%8e%e9%83%a8%e7%bd%b2>#</a></h3><p><strong>导出为网页格式</strong>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 导出为压缩的.splat格式</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>export_splat</span><span class=p>(</span><span class=n>gaussians</span><span class=p>,</span> <span class=n>output_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;导出为Web友好的格式&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>    <span class=kn>import</span> <span class=nn>struct</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 提取高斯属性</span>
</span></span><span class=line><span class=cl>    <span class=n>positions</span> <span class=o>=</span> <span class=n>gaussians</span><span class=o>.</span><span class=n>get_xyz</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>colors</span> <span class=o>=</span> <span class=n>gaussians</span><span class=o>.</span><span class=n>get_features</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>opacities</span> <span class=o>=</span> <span class=n>gaussians</span><span class=o>.</span><span class=n>get_opacity</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>scales</span> <span class=o>=</span> <span class=n>gaussians</span><span class=o>.</span><span class=n>get_scaling</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>rotations</span> <span class=o>=</span> <span class=n>gaussians</span><span class=o>.</span><span class=n>get_rotation</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 按不透明度排序</span>
</span></span><span class=line><span class=cl>    <span class=n>sorted_indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>argsort</span><span class=p>(</span><span class=o>-</span><span class=n>opacities</span><span class=o>.</span><span class=n>flatten</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 写入二进制文件</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>output_path</span><span class=p>,</span> <span class=s1>&#39;wb&#39;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>sorted_indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># 位置 (float32 x 3)</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>struct</span><span class=o>.</span><span class=n>pack</span><span class=p>(</span><span class=s1>&#39;fff&#39;</span><span class=p>,</span> <span class=o>*</span><span class=n>positions</span><span class=p>[</span><span class=n>idx</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 缩放 (float32 x 3)</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>struct</span><span class=o>.</span><span class=n>pack</span><span class=p>(</span><span class=s1>&#39;fff&#39;</span><span class=p>,</span> <span class=o>*</span><span class=n>scales</span><span class=p>[</span><span class=n>idx</span><span class=p>]))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 颜色 (uint8 x 4)</span>
</span></span><span class=line><span class=cl>            <span class=n>rgb</span> <span class=o>=</span> <span class=p>(</span><span class=n>colors</span><span class=p>[</span><span class=n>idx</span><span class=p>,</span> <span class=p>:</span><span class=mi>3</span><span class=p>]</span> <span class=o>*</span> <span class=mi>255</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>alpha</span> <span class=o>=</span> <span class=p>(</span><span class=n>opacities</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>*</span> <span class=mi>255</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>uint8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>struct</span><span class=o>.</span><span class=n>pack</span><span class=p>(</span><span class=s1>&#39;BBBB&#39;</span><span class=p>,</span> <span class=o>*</span><span class=n>rgb</span><span class=p>,</span> <span class=n>alpha</span><span class=p>))</span>
</span></span><span class=line><span class=cl>            <span class=c1># 旋转 (int8 x 4)</span>
</span></span><span class=line><span class=cl>            <span class=n>rot</span> <span class=o>=</span> <span class=p>(</span><span class=n>rotations</span><span class=p>[</span><span class=n>idx</span><span class=p>]</span> <span class=o>*</span> <span class=mi>127</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=n>np</span><span class=o>.</span><span class=n>int8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>f</span><span class=o>.</span><span class=n>write</span><span class=p>(</span><span class=n>struct</span><span class=o>.</span><span class=n>pack</span><span class=p>(</span><span class=s1>&#39;bbbb&#39;</span><span class=p>,</span> <span class=o>*</span><span class=n>rot</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;导出完成: </span><span class=si>{</span><span class=n>output_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><hr><h2 id=本章小结-1>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93-1>#</a></h2><h3 id=核心知识点>核心知识点<a class=anchor href=#%e6%a0%b8%e5%bf%83%e7%9f%a5%e8%af%86%e7%82%b9>#</a></h3><ol><li><strong>NeRF</strong>: 隐式3D表示,体渲染,Instant-NGP加速</li><li><strong>3DGS</strong>: 显式高斯表示,实时渲染,可编辑</li><li><strong>VideoMAE</strong>: 视频自监督学习,掩码自编码</li><li><strong>Video-LLaVA</strong>: 视频语言模型,问答和描述</li></ol><h3 id=技术对比>技术对比<a class=anchor href=#%e6%8a%80%e6%9c%af%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>技术</th><th>优势</th><th>劣势</th><th>适用场景</th></tr></thead><tbody><tr><td>NeRF</td><td>高质量,存储小</td><td>训练慢,渲染慢</td><td>高质量重建</td></tr><tr><td>3DGS</td><td>实时渲染,可编辑</td><td>存储大</td><td>实时应用</td></tr><tr><td>VideoMAE</td><td>自监督,预训练</td><td>仅分类</td><td>视频分类</td></tr><tr><td>Video-LLaVA</td><td>视频理解</td><td>资源需求大</td><td>视频问答</td></tr></tbody></table><h3 id=实践建议>实践建议<a class=anchor href=#%e5%ae%9e%e8%b7%b5%e5%bb%ba%e8%ae%ae>#</a></h3><ol><li><p><strong>3D重建</strong>:</p><ul><li>新手先用Nerfstudio</li><li>需要实时渲染用3DGS</li><li>注意数据采集质量</li></ul></li><li><p><strong>视频理解</strong>:</p><ul><li>分类任务用VideoMAE</li><li>问答描述用Video-LLaVA</li><li>长视频分块处理</li></ul></li></ol><h3 id=参考资源-2>参考资源<a class=anchor href=#%e5%8f%82%e8%80%83%e8%b5%84%e6%ba%90-2>#</a></h3><ul><li><a href=https://arxiv.org/abs/2003.08934>NeRF论文</a></li><li><a href=https://arxiv.org/abs/2308.04079>3DGS论文</a></li><li><a href=https://docs.nerf.studio/>Nerfstudio文档</a></li><li><a href=https://github.com/graphdeco-inria/gaussian-splatting>3DGS官方仓库</a></li><li><a href=https://huggingface.co/docs/transformers/en/model_doc/videomae>VideoMAE</a></li><li><a href=https://github.com/PKU-YuanGroup/Video-LLaVA>Video-LLaVA</a></li></ul><hr><h2 id=第七篇总结>第七篇总结<a class=anchor href=#%e7%ac%ac%e4%b8%83%e7%af%87%e6%80%bb%e7%bb%93>#</a></h2><h3 id=学习成果>学习成果<a class=anchor href=#%e5%ad%a6%e4%b9%a0%e6%88%90%e6%9e%9c>#</a></h3><p>通过本篇学习,你已掌握:</p><ol><li><strong>多模态基础模型</strong>: CLIP、BLIP、LLaVA的原理和使用</li><li><strong>前沿VLM</strong>: Florence-2、GPT-4o、Gemini的API调用</li><li><strong>3D视觉</strong>: NeRF和3DGS的原理与实践</li><li><strong>视频理解</strong>: VideoMAE和Video-LLaVA的应用</li></ol><h3 id=技术栈总结>技术栈总结<a class=anchor href=#%e6%8a%80%e6%9c%af%e6%a0%88%e6%80%bb%e7%bb%93>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像理解: CLIP → BLIP → LLaVA → GPT-4o/Gemini
</span></span><span class=line><span class=cl>3D重建:  COLMAP → NeRF/3DGS → 渲染/导出
</span></span><span class=line><span class=cl>视频理解: VideoMAE → Video-LLaVA → Gemini Video</span></span></code></pre></div><h3 id=下一步>下一步<a class=anchor href=#%e4%b8%8b%e4%b8%80%e6%ad%a5>#</a></h3><ul><li>深入研究特定领域(医疗、自动驾驶)的VLM应用</li><li>探索多模态生成(图像+视频生成)</li><li>关注具身智能(Embodied AI)的发展</li><li>学习第八篇:生产实践与工程化</li></ul></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第六篇 生成模型</span>
</a></span><span><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/ class="flex align-center"><span>第八篇 生产实践</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#篇章概述>篇章概述</a><ul><li><a href=#为什么学习视觉大模型>为什么学习视觉大模型?</a></li></ul></li><li><a href=#章节组织>章节组织</a><ul><li><a href=#第16章多模态基础模型>第16章:多模态基础模型</a></li><li><a href=#第17章视觉大模型前沿>第17章:视觉大模型前沿</a></li><li><a href=#第18章3d视觉与视频理解>第18章:3D视觉与视频理解</a></li></ul></li><li><a href=#技术路线图>技术路线图</a></li><li><a href=#环境配置>环境配置</a><ul><li><a href=#基础依赖>基础依赖</a></li><li><a href=#gpu要求>GPU要求</a></li></ul></li><li><a href=#学习建议>学习建议</a><ul><li><a href=#学习路径>学习路径</a></li><li><a href=#实践项目推荐>实践项目推荐</a></li></ul></li><li><a href=#参考资源>参考资源</a><ul><li><a href=#论文必读>论文必读</a></li><li><a href=#开源项目>开源项目</a></li><li><a href=#在线资源>在线资源</a></li></ul></li><li><a href=#关键技术对比>关键技术对比</a><ul><li><a href=#vlm模型选型指南>VLM模型选型指南</a></li><li><a href=#应用场景匹配>应用场景匹配</a></li></ul></li><li><a href=#本篇特色>本篇特色</a></li></ul><ul><li><a href=#本章概述>本章概述</a></li><li><a href=#161-clip视觉-语言对比学习>16.1 CLIP:视觉-语言对比学习</a><ul><li><a href=#核心思想>核心思想</a></li><li><a href=#模型架构>模型架构</a></li><li><a href=#使用transformers库>使用transformers库</a></li><li><a href=#零样本分类原理>零样本分类原理</a></li><li><a href=#性能表现>性能表现</a></li><li><a href=#应用场景>应用场景</a></li><li><a href=#代码实战>代码实战</a></li></ul></li><li><a href=#162-blip系列视觉问答>16.2 BLIP系列:视觉问答</a><ul><li><a href=#blip-2架构>BLIP-2架构</a></li><li><a href=#模型规格>模型规格</a></li><li><a href=#使用示例>使用示例</a></li><li><a href=#量化优化>量化优化</a></li><li><a href=#性能基准>性能基准</a></li><li><a href=#代码实战-1>代码实战</a></li></ul></li><li><a href=#163-llava大语言模型视觉>16.3 LLaVA:大语言模型+视觉</a><ul><li><a href=#模型概述>模型概述</a></li><li><a href=#架构设计>架构设计</a></li><li><a href=#训练流程>训练流程</a></li><li><a href=#使用transformers库-1>使用transformers库</a></li><li><a href=#llava-15-vs-16-对比>LLaVA 1.5 vs 1.6 对比</a></li><li><a href=#4-bit量化部署>4-bit量化部署</a></li><li><a href=#性能基准-1>性能基准</a></li><li><a href=#应用示例>应用示例</a></li><li><a href=#代码实战-2>代码实战</a></li></ul></li><li><a href=#164-实战多模态理解应用>16.4 实战:多模态理解应用</a><ul><li><a href=#项目1-商品图像搜索引擎>项目1: 商品图像搜索引擎</a></li><li><a href=#项目2-智能客服机器人>项目2: 智能客服机器人</a></li><li><a href=#项目3-图像内容审核系统>项目3: 图像内容审核系统</a></li><li><a href=#关键技术点>关键技术点</a></li><li><a href=#部署建议>部署建议</a></li></ul></li><li><a href=#本章总结>本章总结</a><ul><li><a href=#核心要点>核心要点</a></li><li><a href=#技术选型建议>技术选型建议</a></li><li><a href=#学习路径-1>学习路径</a></li><li><a href=#扩展资源>扩展资源</a></li></ul></li></ul><ul><li><a href=#本章概述-1>本章概述</a></li><li><a href=#171-florence-2微软视觉基础模型>17.1 Florence-2:微软视觉基础模型</a><ul><li><a href=#1711-核心特性>17.1.1 核心特性</a></li><li><a href=#1712-模型变体>17.1.2 模型变体</a></li><li><a href=#1713-支持的任务与提示词>17.1.3 支持的任务与提示词</a></li><li><a href=#1714-完整使用示例>17.1.4 完整使用示例</a></li><li><a href=#1715-结果可视化>17.1.5 结果可视化</a></li><li><a href=#1716-性能基准>17.1.6 性能基准</a></li><li><a href=#1717-实战应用场景>17.1.7 实战应用场景</a></li></ul></li><li><a href=#172-gpt-4o多模态gpt>17.2 GPT-4o:多模态GPT</a><ul><li><a href=#1721-核心特性>17.2.1 核心特性</a></li><li><a href=#1722-基础使用>17.2.2 基础使用</a></li><li><a href=#1723-多图像分析>17.2.3 多图像分析</a></li><li><a href=#1724-图像细节控制>17.2.4 图像细节控制</a></li><li><a href=#1725-结构化输出>17.2.5 结构化输出</a></li><li><a href=#1726-已知限制>17.2.6 已知限制</a></li><li><a href=#1727-成本优化策略>17.2.7 成本优化策略</a></li></ul></li><li><a href=#173-gemini-vision>17.3 Gemini Vision</a><ul><li><a href=#1731-模型系列>17.3.1 模型系列</a></li><li><a href=#1732-基础使用>17.3.2 基础使用</a></li><li><a href=#1733-使用file-api大文件>17.3.3 使用File API(大文件)</a></li><li><a href=#1734-多图像分析>17.3.4 多图像分析</a></li><li><a href=#1735-视频理解gemini独有优势>17.3.5 视频理解(Gemini独有优势)</a></li><li><a href=#1736-高级功能目标检测与分割>17.3.6 高级功能:目标检测与分割</a></li><li><a href=#1737-成本与token计算>17.3.7 成本与Token计算</a></li></ul></li><li><a href=#174-实战vlm-api调用与应用>17.4 实战:VLM API调用与应用</a><ul><li><a href=#1741-统一接口封装>17.4.1 统一接口封装</a></li><li><a href=#1742-文档理解应用>17.4.2 文档理解应用</a></li><li><a href=#1743-视频分析应用gemini>17.4.3 视频分析应用(Gemini)</a></li><li><a href=#1744-vlm性能对比>17.4.4 VLM性能对比</a></li></ul></li><li><a href=#本章小结>本章小结</a><ul><li><a href=#核心要点-1>核心要点</a></li><li><a href=#模型选择指南>模型选择指南</a></li><li><a href=#最佳实践>最佳实践</a></li><li><a href=#参考资源-1>参考资源</a></li></ul></li></ul><ul><li><a href=#本章概述-2>本章概述</a></li><li><a href=#181-nerf神经辐射场>18.1 NeRF:神经辐射场</a><ul><li><a href=#1811-核心原理>18.1.1 核心原理</a></li><li><a href=#1812-网络架构>18.1.2 网络架构</a></li><li><a href=#1813-位置编码positional-encoding>18.1.3 位置编码(Positional Encoding)</a></li><li><a href=#1814-使用nerfstudio>18.1.4 使用Nerfstudio</a></li><li><a href=#1815-instant-ngp1000倍加速>18.1.5 Instant-NGP:1000倍加速</a></li><li><a href=#1816-nerf的局限性>18.1.6 NeRF的局限性</a></li></ul></li><li><a href=#182-3d-gaussian-splatting>18.2 3D Gaussian Splatting</a><ul><li><a href=#1821-核心思想>18.2.1 核心思想</a></li><li><a href=#1822-渲染流程>18.2.2 渲染流程</a></li><li><a href=#1823-训练流程>18.2.3 训练流程</a></li><li><a href=#1824-安装与使用>18.2.4 安装与使用</a></li><li><a href=#1825-python-api使用>18.2.5 Python API使用</a></li><li><a href=#1826-3dgs-vs-nerf对比>18.2.6 3DGS vs NeRF对比</a></li><li><a href=#1827-3dgs扩展与应用>18.2.7 3DGS扩展与应用</a></li></ul></li><li><a href=#183-视频理解video-understanding>18.3 视频理解(Video Understanding)</a><ul><li><a href=#1831-视频理解任务>18.3.1 视频理解任务</a></li><li><a href=#1832-videomae视频自监督学习>18.3.2 VideoMAE:视频自监督学习</a></li><li><a href=#1833-timesformer时空transformer>18.3.3 TimeSformer:时空Transformer</a></li><li><a href=#1834-video-llava视频语言模型>18.3.4 Video-LLaVA:视频语言模型</a></li><li><a href=#1835-视频分析最佳实践>18.3.5 视频分析最佳实践</a></li></ul></li><li><a href=#184-实战3d重建项目>18.4 实战:3D重建项目</a><ul><li><a href=#1841-完整3d重建流程>18.4.1 完整3D重建流程</a></li><li><a href=#1842-数据采集指南>18.4.2 数据采集指南</a></li><li><a href=#1843-使用colmap进行sfm>18.4.3 使用COLMAP进行SfM</a></li><li><a href=#1844-3dgs训练脚本>18.4.4 3DGS训练脚本</a></li><li><a href=#1845-web可视化>18.4.5 Web可视化</a></li><li><a href=#1846-导出与部署>18.4.6 导出与部署</a></li></ul></li><li><a href=#本章小结-1>本章小结</a><ul><li><a href=#核心知识点>核心知识点</a></li><li><a href=#技术对比>技术对比</a></li><li><a href=#实践建议>实践建议</a></li><li><a href=#参考资源-2>参考资源</a></li></ul></li><li><a href=#第七篇总结>第七篇总结</a><ul><li><a href=#学习成果>学习成果</a></li><li><a href=#技术栈总结>技术栈总结</a></li><li><a href=#下一步>下一步</a></li></ul></li></ul></nav></div></aside></main></body></html>