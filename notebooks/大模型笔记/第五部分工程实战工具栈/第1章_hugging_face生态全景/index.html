<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='第1章：Hugging Face 生态全景 (The Complete Guide)# 本章定位：这是构建 LLM 应用的基石。我们将深入 Hugging Face 生态的五大核心组件：Transformers, Datasets, Tokenizers, Accelerate, Hub。不仅覆盖基础 API，更包含量化加载、词表扩充、断点续训、分布式配置等工业级实战技巧。
目录# 1. Transformers：模型加载与推理 1.1 Pipeline：极速验证 1.2 AutoClass：底层控制与 Flash Attention 1.3 Quantization：4-bit/8-bit 量化加载 2. Datasets：海量数据工程 2.1 流式加载 (Streaming) 与 混合 (Interleave) 2.2 并行处理 (Map) 与 数据分片 (Sharding) 2.3 自定义数据集加载脚本 3. Tokenizers：分词器的艺术与陷阱 3.1 Chat Template 原理：如何避免"答非所问" 3.2 Padding Side：左补齐 vs 右补齐 3.3 实战：扩充中文词表 (Add Tokens) 4. Training：训练与分布式 4.1 Trainer API：Callbacks 与 断点续训 4.2 Accelerate + DeepSpeed：分布式配置详解 5. Hub：模型管理与版本控制 5.1 模型上传与 Revision 锁定 5.2 Model Card 编写规范 本章小结：开发流 CheckList 1. Transformers：模型加载与推理# 1.1 Pipeline：极速验证# 适合快速测试模型能力。
'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第1章 Hugging Face生态全景"><meta property="og:description" content='第1章：Hugging Face 生态全景 (The Complete Guide)# 本章定位：这是构建 LLM 应用的基石。我们将深入 Hugging Face 生态的五大核心组件：Transformers, Datasets, Tokenizers, Accelerate, Hub。不仅覆盖基础 API，更包含量化加载、词表扩充、断点续训、分布式配置等工业级实战技巧。
目录# 1. Transformers：模型加载与推理 1.1 Pipeline：极速验证 1.2 AutoClass：底层控制与 Flash Attention 1.3 Quantization：4-bit/8-bit 量化加载 2. Datasets：海量数据工程 2.1 流式加载 (Streaming) 与 混合 (Interleave) 2.2 并行处理 (Map) 与 数据分片 (Sharding) 2.3 自定义数据集加载脚本 3. Tokenizers：分词器的艺术与陷阱 3.1 Chat Template 原理：如何避免"答非所问" 3.2 Padding Side：左补齐 vs 右补齐 3.3 实战：扩充中文词表 (Add Tokens) 4. Training：训练与分布式 4.1 Trainer API：Callbacks 与 断点续训 4.2 Accelerate + DeepSpeed：分布式配置详解 5. Hub：模型管理与版本控制 5.1 模型上传与 Revision 锁定 5.2 Model Card 编写规范 本章小结：开发流 CheckList 1. Transformers：模型加载与推理# 1.1 Pipeline：极速验证# 适合快速测试模型能力。'><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第1章 Hugging Face生态全景"><meta itemprop=description content='第1章：Hugging Face 生态全景 (The Complete Guide)# 本章定位：这是构建 LLM 应用的基石。我们将深入 Hugging Face 生态的五大核心组件：Transformers, Datasets, Tokenizers, Accelerate, Hub。不仅覆盖基础 API，更包含量化加载、词表扩充、断点续训、分布式配置等工业级实战技巧。
目录# 1. Transformers：模型加载与推理 1.1 Pipeline：极速验证 1.2 AutoClass：底层控制与 Flash Attention 1.3 Quantization：4-bit/8-bit 量化加载 2. Datasets：海量数据工程 2.1 流式加载 (Streaming) 与 混合 (Interleave) 2.2 并行处理 (Map) 与 数据分片 (Sharding) 2.3 自定义数据集加载脚本 3. Tokenizers：分词器的艺术与陷阱 3.1 Chat Template 原理：如何避免"答非所问" 3.2 Padding Side：左补齐 vs 右补齐 3.3 实战：扩充中文词表 (Add Tokens) 4. Training：训练与分布式 4.1 Trainer API：Callbacks 与 断点续训 4.2 Accelerate + DeepSpeed：分布式配置详解 5. Hub：模型管理与版本控制 5.1 模型上传与 Revision 锁定 5.2 Model Card 编写规范 本章小结：开发流 CheckList 1. Transformers：模型加载与推理# 1.1 Pipeline：极速验证# 适合快速测试模型能力。'><meta itemprop=wordCount content="760"><title>第1章 Hugging Face生态全景 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle checked>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle checked>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/ class=active>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第1章 Hugging Face生态全景</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#1-transformers模型加载与推理>1. Transformers：模型加载与推理</a><ul><li><a href=#11-pipeline极速验证>1.1 Pipeline：极速验证</a></li><li><a href=#12-autoclass底层控制与-flash-attention>1.2 AutoClass：底层控制与 Flash Attention</a></li><li><a href=#13-quantization4-bit8-bit-量化加载>1.3 Quantization：4-bit/8-bit 量化加载</a></li></ul></li><li><a href=#2-datasets海量数据工程>2. Datasets：海量数据工程</a><ul><li><a href=#21-流式加载-streaming-与-混合-interleave>2.1 流式加载 (Streaming) 与 混合 (Interleave)</a></li><li><a href=#22-并行处理-map-与-数据分片-sharding>2.2 并行处理 (Map) 与 数据分片 (Sharding)</a></li><li><a href=#23-自定义数据集加载脚本>2.3 自定义数据集加载脚本</a></li></ul></li><li><a href=#3-tokenizers分词器的艺术与陷阱>3. Tokenizers：分词器的艺术与陷阱</a><ul><li><a href=#31-chat-template-的原理与陷阱>3.1 Chat Template 的原理与陷阱</a></li><li><a href=#32-padding-side左补齐-vs-右补齐>3.2 Padding Side：左补齐 vs 右补齐</a></li><li><a href=#33-实战扩充中文词表-add-tokens>3.3 实战：扩充中文词表 (Add Tokens)</a></li></ul></li><li><a href=#4-training训练与分布式>4. Training：训练与分布式</a><ul><li><a href=#41-trainer-apicallbacks-与-断点续训>4.1 Trainer API：Callbacks 与 断点续训</a></li><li><a href=#42-accelerate--deepspeed分布式配置详解>4.2 Accelerate + DeepSpeed：分布式配置详解</a></li></ul></li><li><a href=#5-hub模型管理与版本控制>5. Hub：模型管理与版本控制</a><ul><li><a href=#51-模型上传与-revision-锁定>5.1 模型上传与 Revision 锁定</a></li><li><a href=#52-model-card-编写规范>5.2 Model Card 编写规范</a></li></ul></li><li><a href=#本章小结开发流-checklist>本章小结：开发流 CheckList</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第1章hugging-face-生态全景-the-complete-guide>第1章：Hugging Face 生态全景 (The Complete Guide)<a class=anchor href=#%e7%ac%ac1%e7%ab%a0hugging-face-%e7%94%9f%e6%80%81%e5%85%a8%e6%99%af-the-complete-guide>#</a></h1><blockquote class=book-hint><p><strong>本章定位</strong>：这是构建 LLM 应用的基石。我们将深入 Hugging Face 生态的五大核心组件：<code>Transformers</code>, <code>Datasets</code>, <code>Tokenizers</code>, <code>Accelerate</code>, <code>Hub</code>。不仅覆盖基础 API，更包含<strong>量化加载</strong>、<strong>词表扩充</strong>、<strong>断点续训</strong>、<strong>分布式配置</strong>等工业级实战技巧。</p></blockquote><hr><h2 id=目录>目录<a class=anchor href=#%e7%9b%ae%e5%bd%95>#</a></h2><ul><li><a href=#1-transformers%e6%a8%a1%e5%9e%8b%e5%8a%a0%e8%bd%bd%e4%b8%8e%e6%8e%a8%e7%90%86>1. Transformers：模型加载与推理</a><ul><li><a href=#11-pipeline%e6%9e%81%e9%80%9f%e9%aa%8c%e8%af%81>1.1 Pipeline：极速验证</a></li><li><a href=#12-autoclass%e5%ba%95%e5%b1%82%e6%8e%a7%e5%88%b6%e4%b8%8e-flash-attention>1.2 AutoClass：底层控制与 Flash Attention</a></li><li><a href=#13-quantization4-bit8-bit-%e9%87%8f%e5%8c%96%e5%8a%a0%e8%bd%bd>1.3 Quantization：4-bit/8-bit 量化加载</a></li></ul></li><li><a href=#2-datasets%e6%b5%b7%e9%87%8f%e6%95%b0%e6%8d%ae%e5%b7%a5%e7%a8%8b>2. Datasets：海量数据工程</a><ul><li><a href=#21-%e6%b5%81%e5%bc%8f%e5%8a%a0%e8%bd%bd-streaming-%e4%b8%8e-%e6%b7%b7%e5%90%88-interleave>2.1 流式加载 (Streaming) 与 混合 (Interleave)</a></li><li><a href=#22-%e5%b9%b6%e8%a1%8c%e5%a4%84%e7%90%86-map-%e4%b8%8e-%e6%95%b0%e6%8d%ae%e5%88%86%e7%89%87-sharding>2.2 并行处理 (Map) 与 数据分片 (Sharding)</a></li><li><a href=#23-%e8%87%aa%e5%ae%9a%e4%b9%89%e6%95%b0%e6%8d%ae%e9%9b%86%e5%8a%a0%e8%bd%bd%e8%84%9a%e6%9c%ac>2.3 自定义数据集加载脚本</a></li></ul></li><li><a href=#3-tokenizers%e5%88%86%e8%af%8d%e5%99%a8%e7%9a%84%e8%89%ba%e6%9c%af%e4%b8%8e%e9%99%b7%e9%98%b1>3. Tokenizers：分词器的艺术与陷阱</a><ul><li><a href=#31-chat-template-%e5%8e%9f%e7%90%86%e5%a6%82%e4%bd%95%e9%81%bf%e5%85%8d%e7%ad%94%e9%9d%9e%e6%89%80%e9%97%ae>3.1 Chat Template 原理：如何避免"答非所问"</a></li><li><a href=#32-padding-side%e5%b7%a6%e8%a1%a5%e9%bd%90-vs-%e5%8f%b3%e8%a1%a5%e9%bd%90>3.2 Padding Side：左补齐 vs 右补齐</a></li><li><a href=#33-%e5%ae%9e%e6%88%98%e6%89%a9%e5%85%85%e4%b8%ad%e6%96%87%e8%af%8d%e8%a1%a8-add-tokens>3.3 实战：扩充中文词表 (Add Tokens)</a></li></ul></li><li><a href=#4-training%e8%ae%ad%e7%bb%83%e4%b8%8e%e5%88%86%e5%b8%83%e5%bc%8f>4. Training：训练与分布式</a><ul><li><a href=#41-trainer-api-callbacks-%e4%b8%8e-%e6%96%ad%e7%82%b9%e7%bb%ad%e8%ae%ad>4.1 Trainer API：Callbacks 与 断点续训</a></li><li><a href=#42-accelerate--deepspeed%e5%88%86%e5%b8%83%e5%bc%8f%e9%85%8d%e7%bd%ae%e8%af%a6%e8%a7%a3>4.2 Accelerate + DeepSpeed：分布式配置详解</a></li></ul></li><li><a href=#5-hub%e6%a8%a1%e5%9e%8b%e7%ae%a1%e7%90%86%e4%b8%8e%e7%89%88%e6%9c%ac%e6%8e%a7%e5%88%b6>5. Hub：模型管理与版本控制</a><ul><li><a href=#51-%e6%a8%a1%e5%9e%8b%e4%b8%8a%e4%bc%a0%e4%b8%8e-revision-%e9%94%81%e5%ae%9a>5.1 模型上传与 Revision 锁定</a></li><li><a href=#52-model-card-%e7%bc%96%e5%86%99%e8%a7%84%e8%8c%83>5.2 Model Card 编写规范</a></li></ul></li><li><a href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93%e5%bc%80%e5%8f%91%e6%b5%81-checklist>本章小结：开发流 CheckList</a></li></ul><hr><h2 id=1-transformers模型加载与推理>1. Transformers：模型加载与推理<a class=anchor href=#1-transformers%e6%a8%a1%e5%9e%8b%e5%8a%a0%e8%bd%bd%e4%b8%8e%e6%8e%a8%e7%90%86>#</a></h2><h3 id=11-pipeline极速验证>1.1 Pipeline：极速验证<a class=anchor href=#11-pipeline%e6%9e%81%e9%80%9f%e9%aa%8c%e8%af%81>#</a></h3><p>适合快速测试模型能力。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>pipeline</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 自动推断设备，默认使用 bfloat16 (推荐 Ampere 架构 GPU 使用)</span>
</span></span><span class=line><span class=cl><span class=n>pipe</span> <span class=o>=</span> <span class=n>pipeline</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;text-generation&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=o>=</span><span class=s2>&#34;meta-llama/Llama-3-8B-Instruct&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Batch Inference (提升吞吐量的关键)</span>
</span></span><span class=line><span class=cl><span class=n>prompts</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;Explain AI.&#34;</span><span class=p>,</span> <span class=s2>&#34;Write a poem.&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>pipe</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>prompts</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>128</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>do_sample</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=12-autoclass底层控制与-flash-attention>1.2 AutoClass：底层控制与 Flash Attention<a class=anchor href=#12-autoclass%e5%ba%95%e5%b1%82%e6%8e%a7%e5%88%b6%e4%b8%8e-flash-attention>#</a></h3><p>生产环境通常使用 <code>AutoModel</code> + <code>AutoTokenizer</code>。</p><p><strong>Flash Attention 2 加速</strong>：
这是现代 LLM 推理/训练的必备加速技术。</p><ul><li><strong>前提</strong>：安装 <code>flash-attn</code> 库 (<code>pip install flash-attn --no-build-isolation</code>) + 兼容的 GPU (A100, A10, RTX 3090/4090)。</li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoTokenizer</span><span class=p>,</span> <span class=n>AutoModelForCausalLM</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;meta-llama/Llama-3-8B-Instruct&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 加载 Tokenizer</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span> <span class=o>=</span> <span class=n>AutoTokenizer</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>,</span> <span class=n>padding_side</span><span class=o>=</span><span class=s2>&#34;left&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>tokenizer</span><span class=o>.</span><span class=n>pad_token</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>eos_token</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 加载 Model (开启 FA2)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>attn_implementation</span><span class=o>=</span><span class=s2>&#34;flash_attention_2&#34;</span>  <span class=c1># 关键加速参数</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=13-quantization4-bit8-bit-量化加载>1.3 Quantization：4-bit/8-bit 量化加载<a class=anchor href=#13-quantization4-bit8-bit-%e9%87%8f%e5%8c%96%e5%8a%a0%e8%bd%bd>#</a></h3><p>在显存有限的设备（如单卡 24G 跑 70B 模型）上，量化是刚需。HF 通过 <code>bitsandbytes</code> (bnb) 库实现了原生集成。</p><p><strong>依赖</strong>：<code>pip install bitsandbytes</code></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>BitsAndBytesConfig</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># NF4 (Normal Float 4) 配置：精度损失极小的 4bit 量化</span>
</span></span><span class=line><span class=cl><span class=n>bnb_config</span> <span class=o>=</span> <span class=n>BitsAndBytesConfig</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>load_in_4bit</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_quant_type</span><span class=o>=</span><span class=s2>&#34;nf4&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_compute_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>bfloat16</span><span class=p>,</span>  <span class=c1># 计算时还原为 bf16</span>
</span></span><span class=line><span class=cl>    <span class=n>bnb_4bit_use_double_quant</span><span class=o>=</span><span class=kc>True</span>          <span class=c1># 二次量化，进一步节省显存</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModelForCausalLM</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>quantization_config</span><span class=o>=</span><span class=n>bnb_config</span><span class=p>,</span>         <span class=c1># 传入量化配置</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 显存对比 (Llama-3-8B):</span>
</span></span><span class=line><span class=cl><span class=c1># fp16: ~16GB</span>
</span></span><span class=line><span class=cl><span class=c1># 4bit: ~6GB</span></span></span></code></pre></div><hr><h2 id=2-datasets海量数据工程>2. Datasets：海量数据工程<a class=anchor href=#2-datasets%e6%b5%b7%e9%87%8f%e6%95%b0%e6%8d%ae%e5%b7%a5%e7%a8%8b>#</a></h2><h3 id=21-流式加载-streaming-与-混合-interleave>2.1 流式加载 (Streaming) 与 混合 (Interleave)<a class=anchor href=#21-%e6%b5%81%e5%bc%8f%e5%8a%a0%e8%bd%bd-streaming-%e4%b8%8e-%e6%b7%b7%e5%90%88-interleave>#</a></h3><p>处理 TB 级数据集（如 C4, WanJuan）时，无法全部下载。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>datasets</span> <span class=kn>import</span> <span class=n>load_dataset</span><span class=p>,</span> <span class=n>interleave_datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. Streaming 模式</span>
</span></span><span class=line><span class=cl><span class=n>ds_en</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;c4&#34;</span><span class=p>,</span> <span class=s2>&#34;en&#34;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>,</span> <span class=n>streaming</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>ds_zh</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;wanjuan&#34;</span><span class=p>,</span> <span class=s2>&#34;zh&#34;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>,</span> <span class=n>streaming</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 数据混合 (80% 英文, 20% 中文) -&gt; 预训练常用 trick</span>
</span></span><span class=line><span class=cl><span class=n>ds_mixed</span> <span class=o>=</span> <span class=n>interleave_datasets</span><span class=p>([</span><span class=n>ds_en</span><span class=p>,</span> <span class=n>ds_zh</span><span class=p>],</span> <span class=n>probabilities</span><span class=o>=</span><span class=p>[</span><span class=mf>0.8</span><span class=p>,</span> <span class=mf>0.2</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 迭代查看</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>example</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>ds_mixed</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=n>example</span><span class=p>[</span><span class=s1>&#39;text&#39;</span><span class=p>][:</span><span class=mi>50</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>if</span> <span class=n>i</span> <span class=o>==</span> <span class=mi>5</span><span class=p>:</span> <span class=k>break</span></span></span></code></pre></div><h3 id=22-并行处理-map-与-数据分片-sharding>2.2 并行处理 (Map) 与 数据分片 (Sharding)<a class=anchor href=#22-%e5%b9%b6%e8%a1%8c%e5%a4%84%e7%90%86-map-%e4%b8%8e-%e6%95%b0%e6%8d%ae%e5%88%86%e7%89%87-sharding>#</a></h3><p><strong>Map 并行化</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ds</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;imdb&#34;</span><span class=p>,</span> <span class=n>split</span><span class=o>=</span><span class=s2>&#34;train&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>process_fn</span><span class=p>(</span><span class=n>examples</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=c1># 支持 batch 处理</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>tokenizer</span><span class=p>(</span><span class=n>examples</span><span class=p>[</span><span class=s2>&#34;text&#34;</span><span class=p>],</span> <span class=n>truncation</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=n>max_length</span><span class=o>=</span><span class=mi>512</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>tokenized_ds</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>map</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>process_fn</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batched</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_size</span><span class=o>=</span><span class=mi>1000</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>num_proc</span><span class=o>=</span><span class=mi>8</span><span class=p>,</span>        <span class=c1># 多进程加速</span>
</span></span><span class=line><span class=cl>    <span class=n>remove_columns</span><span class=o>=</span><span class=n>ds</span><span class=o>.</span><span class=n>column_names</span> <span class=c1># 移除原始文本列，节省 RAM</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>Sharding (分片)</strong>：
分布式训练时，需要把大数据集切分成小块分发给不同节点。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 将数据集切分为 100 份，取第 0 份</span>
</span></span><span class=line><span class=cl><span class=n>shard_0</span> <span class=o>=</span> <span class=n>ds</span><span class=o>.</span><span class=n>shard</span><span class=p>(</span><span class=n>num_shards</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=mi>0</span><span class=p>)</span></span></span></code></pre></div><h3 id=23-自定义数据集加载脚本>2.3 自定义数据集加载脚本<a class=anchor href=#23-%e8%87%aa%e5%ae%9a%e4%b9%89%e6%95%b0%e6%8d%ae%e9%9b%86%e5%8a%a0%e8%bd%bd%e8%84%9a%e6%9c%ac>#</a></h3><p>当数据格式复杂（如 JSONL 嵌套、特殊 CSV），或者是私有数据时，编写加载脚本比手动解析更高效。</p><p>创建 <code>my_dataset.py</code>:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>datasets</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>MyDataset</span><span class=p>(</span><span class=n>datasets</span><span class=o>.</span><span class=n>GeneratorBasedBuilder</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_info</span><span class=p>(</span><span class=bp>self</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>datasets</span><span class=o>.</span><span class=n>DatasetInfo</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>features</span><span class=o>=</span><span class=n>datasets</span><span class=o>.</span><span class=n>Features</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>datasets</span><span class=o>.</span><span class=n>Value</span><span class=p>(</span><span class=s2>&#34;string&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;label&#34;</span><span class=p>:</span> <span class=n>datasets</span><span class=o>.</span><span class=n>Value</span><span class=p>(</span><span class=s2>&#34;int32&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=p>})</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_split_generators</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>dl_manager</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=n>datasets</span><span class=o>.</span><span class=n>SplitGenerator</span><span class=p>(</span><span class=n>name</span><span class=o>=</span><span class=n>datasets</span><span class=o>.</span><span class=n>Split</span><span class=o>.</span><span class=n>TRAIN</span><span class=p>,</span> <span class=n>gen_kwargs</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;filepath&#34;</span><span class=p>:</span> <span class=s2>&#34;train.jsonl&#34;</span><span class=p>}),</span>
</span></span><span class=line><span class=cl>        <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>_generate_examples</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>filepath</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>filepath</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>id_</span><span class=p>,</span> <span class=n>line</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>f</span><span class=p>):</span>
</span></span><span class=line><span class=cl>                <span class=c1># 自定义解析逻辑</span>
</span></span><span class=line><span class=cl>                <span class=k>yield</span> <span class=n>id_</span><span class=p>,</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>line</span><span class=p>)</span></span></span></code></pre></div><p>使用：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>ds</span> <span class=o>=</span> <span class=n>load_dataset</span><span class=p>(</span><span class=s2>&#34;./my_dataset.py&#34;</span><span class=p>)</span></span></span></code></pre></div><hr><h2 id=3-tokenizers分词器的艺术与陷阱>3. Tokenizers：分词器的艺术与陷阱<a class=anchor href=#3-tokenizers%e5%88%86%e8%af%8d%e5%99%a8%e7%9a%84%e8%89%ba%e6%9c%af%e4%b8%8e%e9%99%b7%e9%98%b1>#</a></h2><h3 id=31-chat-template-的原理与陷阱>3.1 Chat Template 的原理与陷阱<a class=anchor href=#31-chat-template-%e7%9a%84%e5%8e%9f%e7%90%86%e4%b8%8e%e9%99%b7%e9%98%b1>#</a></h3><p>微调后的 Chat 模型（Llama-3, Qwen-2）对 Prompt 格式极其敏感。少一个空格或换行都可能导致模型“变傻”。</p><p><strong>原理</strong>：Tokenizer 配置中的 <code>chat_template</code> 字段定义了 Jinja2 模板。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>chat</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Hello&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>    <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;Hi there!&#34;</span><span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 自动渲染 (推荐)</span>
</span></span><span class=line><span class=cl><span class=n>text</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>apply_chat_template</span><span class=p>(</span><span class=n>chat</span><span class=p>,</span> <span class=n>tokenize</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>text</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># Llama-3 输出: &lt;|begin_of_text|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\nHello&lt;|eot_id|&gt;...</span></span></span></code></pre></div><p><strong>陷阱</strong>：
如果手动拼接字符串（如 <code>f"User: {msg}"</code>），不仅格式可能错，还会导致特殊 Token（如 <code>&lt;|eot_id|></code>）被当作普通文本编码，模型无法识别停止信号。</p><h3 id=32-padding-side左补齐-vs-右补齐>3.2 Padding Side：左补齐 vs 右补齐<a class=anchor href=#32-padding-side%e5%b7%a6%e8%a1%a5%e9%bd%90-vs-%e5%8f%b3%e8%a1%a5%e9%bd%90>#</a></h3><table><thead><tr><th>场景</th><th>Padding Side</th><th>原因</th></tr></thead><tbody><tr><td><strong>训练 (Training)</strong></td><td><code>right</code></td><td>配合 Attention Mask，通常在序列末尾补齐效率最高。</td></tr><tr><td><strong>推理 (Generation)</strong></td><td><code>left</code></td><td><strong>必须向左补齐！</strong> 因为生成是自回归的，如果右侧有 Pad，模型会根据 Pad 去预测下一个词，导致输出乱码。</td></tr></tbody></table><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>tokenizer</span><span class=o>.</span><span class=n>padding_side</span> <span class=o>=</span> <span class=s2>&#34;left&#34;</span>  <span class=c1># 推理时务必设置</span></span></span></code></pre></div><h3 id=33-实战扩充中文词表-add-tokens>3.3 实战：扩充中文词表 (Add Tokens)<a class=anchor href=#33-%e5%ae%9e%e6%88%98%e6%89%a9%e5%85%85%e4%b8%ad%e6%96%87%e8%af%8d%e8%a1%a8-add-tokens>#</a></h3><p>Llama-3 原生词表对中文支持一般（一个汉字可能被切成 3 个 token）。微调时常需扩充词表。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 1. 添加新词</span>
</span></span><span class=line><span class=cl><span class=n>new_tokens</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;你好&#34;</span><span class=p>,</span> <span class=s2>&#34;人工智能&#34;</span><span class=p>,</span> <span class=s2>&#34;大模型&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl><span class=n>num_added</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>add_tokens</span><span class=p>(</span><span class=n>new_tokens</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 调整模型 Embedding 层大小 (这也是必须要做的！)</span>
</span></span><span class=line><span class=cl><span class=c1># 模型原本 vocab_size 是 128256，现在变大了，Embedding 矩阵也要变大</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>resize_token_embeddings</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Added </span><span class=si>{</span><span class=n>num_added</span><span class=si>}</span><span class=s2> tokens. New vocab size: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>tokenizer</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 注意：新加入的 Token 初始 Embedding 是随机的，需要经过 Fine-tuning 才能有语义。</span></span></span></code></pre></div><hr><h2 id=4-training训练与分布式>4. Training：训练与分布式<a class=anchor href=#4-training%e8%ae%ad%e7%bb%83%e4%b8%8e%e5%88%86%e5%b8%83%e5%bc%8f>#</a></h2><h3 id=41-trainer-apicallbacks-与-断点续训>4.1 Trainer API：Callbacks 与 断点续训<a class=anchor href=#41-trainer-apicallbacks-%e4%b8%8e-%e6%96%ad%e7%82%b9%e7%bb%ad%e8%ae%ad>#</a></h3><p><code>Trainer</code> 是 HF 生态的核心训练器。</p><p><strong>WandB 集成与 Callbacks</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>TrainerCallback</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>LogCallback</span><span class=p>(</span><span class=n>TrainerCallback</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>on_step_end</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>args</span><span class=p>,</span> <span class=n>state</span><span class=p>,</span> <span class=n>control</span><span class=p>,</span> <span class=o>**</span><span class=n>kwargs</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>state</span><span class=o>.</span><span class=n>global_step</span> <span class=o>%</span> <span class=mi>10</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Step </span><span class=si>{</span><span class=n>state</span><span class=o>.</span><span class=n>global_step</span><span class=si>}</span><span class=s2> finished.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 配置参数</span>
</span></span><span class=line><span class=cl><span class=n>args</span> <span class=o>=</span> <span class=n>TrainingArguments</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>output_dir</span><span class=o>=</span><span class=s2>&#34;./checkpoints&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>report_to</span><span class=o>=</span><span class=s2>&#34;wandb&#34;</span><span class=p>,</span>  <span class=c1># 自动集成 Weights &amp; Biases</span>
</span></span><span class=line><span class=cl>    <span class=n>run_name</span><span class=o>=</span><span class=s2>&#34;llama3-finetune-v1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_strategy</span><span class=o>=</span><span class=s2>&#34;steps&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>save_steps</span><span class=o>=</span><span class=mi>500</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>load_best_model_at_end</span><span class=o>=</span><span class=kc>True</span><span class=p>,</span> <span class=c1># 训练结束加载验证集最好的模型</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><p><strong>断点续训 (Resume Training)</strong>：
训练大模型动辄几天，中断是常态。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>trainer</span><span class=o>.</span><span class=n>train</span><span class=p>(</span><span class=n>resume_from_checkpoint</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=c1># 或者指定具体路径</span>
</span></span><span class=line><span class=cl><span class=c1># trainer.train(resume_from_checkpoint=&#34;./checkpoints/checkpoint-5000&#34;)</span></span></span></code></pre></div><h3 id=42-accelerate--deepspeed分布式配置详解>4.2 Accelerate + DeepSpeed：分布式配置详解<a class=anchor href=#42-accelerate--deepspeed%e5%88%86%e5%b8%83%e5%bc%8f%e9%85%8d%e7%bd%ae%e8%af%a6%e8%a7%a3>#</a></h3><p>不使用 Trainer 时，Accelerate 是手动写训练循环的最佳伴侣。它完美集成了 DeepSpeed。</p><p><strong>配置 DeepSpeed</strong>：
运行 <code>accelerate config</code>，选择 DeepSpeed，然后选择 ZeRO Stage (0/1/2/3)。</p><ul><li><strong>ZeRO-2</strong>：切分优化器状态 + 梯度（及格线，适合单机多卡）。</li><li><strong>ZeRO-3</strong>：切分模型参数（显存占用最小，适合超大模型）。</li><li><strong>Offload</strong>：将参数卸载到 CPU 内存（速度慢，但能跑更大的模型）。</li></ul><p><strong>代码集成</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>accelerate</span> <span class=kn>import</span> <span class=n>Accelerator</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初始化时会自动读取 accelerate config 的配置</span>
</span></span><span class=line><span class=cl><span class=n>accelerator</span> <span class=o>=</span> <span class=n>Accelerator</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 准备</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>train_dataloader</span><span class=p>,</span> <span class=n>lr_scheduler</span> <span class=o>=</span> <span class=n>accelerator</span><span class=o>.</span><span class=n>prepare</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span><span class=p>,</span> <span class=n>optimizer</span><span class=p>,</span> <span class=n>train_dataloader</span><span class=p>,</span> <span class=n>lr_scheduler</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 训练步</span>
</span></span><span class=line><span class=cl><span class=n>accelerator</span><span class=o>.</span><span class=n>backward</span><span class=p>(</span><span class=n>loss</span><span class=p>)</span> <span class=c1># 替代 loss.backward()</span></span></span></code></pre></div><hr><h2 id=5-hub模型管理与版本控制>5. Hub：模型管理与版本控制<a class=anchor href=#5-hub%e6%a8%a1%e5%9e%8b%e7%ae%a1%e7%90%86%e4%b8%8e%e7%89%88%e6%9c%ac%e6%8e%a7%e5%88%b6>#</a></h2><h3 id=51-模型上传与-revision-锁定>5.1 模型上传与 Revision 锁定<a class=anchor href=#51-%e6%a8%a1%e5%9e%8b%e4%b8%8a%e4%bc%a0%e4%b8%8e-revision-%e9%94%81%e5%ae%9a>#</a></h3><p>不要只 push 到 <code>main</code>。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 上传时打标签</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>push_to_hub</span><span class=p>(</span><span class=s2>&#34;my-model&#34;</span><span class=p>,</span> <span class=n>revision</span><span class=o>=</span><span class=s2>&#34;v1.0&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 加载时锁定版本 (生产环境铁律)</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>AutoModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;username/my-model&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>revision</span><span class=o>=</span><span class=s2>&#34;d4e5f6...&#34;</span><span class=p>,</span> <span class=c1># Commit Hash 或 Tag</span>
</span></span><span class=line><span class=cl>    <span class=n>trust_remote_code</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl><span class=p>)</span></span></span></code></pre></div><h3 id=52-model-card-编写规范>5.2 Model Card 编写规范<a class=anchor href=#52-model-card-%e7%bc%96%e5%86%99%e8%a7%84%e8%8c%83>#</a></h3><p>一个好的 <code>README.md</code> (Model Card) 应包含：</p><ol><li><strong>Model Details</strong>: 基础架构、参数量、训练数据来源。</li><li><strong>Usage</strong>: 几行可运行的 Python 代码示例。</li><li><strong>Evaluation</strong>: 在 MTEB 或 OpenCompass 上的评测分数。</li><li><strong>Bias & Limitations</strong>: 模型的局限性和偏见声明。</li></ol><hr><h2 id=本章小结开发流-checklist>本章小结：开发流 CheckList<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93%e5%bc%80%e5%8f%91%e6%b5%81-checklist>#</a></h2><p>在开始下一章（微调实战）之前，请自查是否掌握了以下 <strong>Engineering</strong> 细节：</p><ol><li>✅ <strong>推理加速</strong>：是否开启了 <code>Flash Attention 2</code> 和 <code>bfloat16</code>？</li><li>✅ <strong>显存优化</strong>：是否会用 <code>bitsandbytes</code> 进行 4-bit 量化加载？</li><li>✅ <strong>数据处理</strong>：面对 TB 级数据，是否会用 <code>Streaming</code> 和 <code>Interleave</code>？</li><li>✅ <strong>分词避坑</strong>：推理时是否将 padding 设为了 <code>left</code>？是否使用了正确的 <code>Chat Template</code>？</li><li>✅ <strong>训练稳健性</strong>：是否配置了 <code>save_limit</code> 防止硬盘撑爆？是否知道如何 <code>resume_from_checkpoint</code>？</li></ol><p>掌握了这些，你就不再是 API 调包侠，而是具备了 <strong>LLM 工程化落地</strong> 的能力。</p><p>下一章，我们将介绍 <strong>LLaMA-Factory</strong>——它将上述所有（Trainer, DeepSpeed, Quantization, FlashAttn）封装成了一个 WebUI 界面，让你体验“零代码微调”的快感。</p></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第4章 多模态大模型原理</span>
</a></span><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/ class="flex align-center"><span>第2章 LLaMA-Factory微调工厂</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#1-transformers模型加载与推理>1. Transformers：模型加载与推理</a><ul><li><a href=#11-pipeline极速验证>1.1 Pipeline：极速验证</a></li><li><a href=#12-autoclass底层控制与-flash-attention>1.2 AutoClass：底层控制与 Flash Attention</a></li><li><a href=#13-quantization4-bit8-bit-量化加载>1.3 Quantization：4-bit/8-bit 量化加载</a></li></ul></li><li><a href=#2-datasets海量数据工程>2. Datasets：海量数据工程</a><ul><li><a href=#21-流式加载-streaming-与-混合-interleave>2.1 流式加载 (Streaming) 与 混合 (Interleave)</a></li><li><a href=#22-并行处理-map-与-数据分片-sharding>2.2 并行处理 (Map) 与 数据分片 (Sharding)</a></li><li><a href=#23-自定义数据集加载脚本>2.3 自定义数据集加载脚本</a></li></ul></li><li><a href=#3-tokenizers分词器的艺术与陷阱>3. Tokenizers：分词器的艺术与陷阱</a><ul><li><a href=#31-chat-template-的原理与陷阱>3.1 Chat Template 的原理与陷阱</a></li><li><a href=#32-padding-side左补齐-vs-右补齐>3.2 Padding Side：左补齐 vs 右补齐</a></li><li><a href=#33-实战扩充中文词表-add-tokens>3.3 实战：扩充中文词表 (Add Tokens)</a></li></ul></li><li><a href=#4-training训练与分布式>4. Training：训练与分布式</a><ul><li><a href=#41-trainer-apicallbacks-与-断点续训>4.1 Trainer API：Callbacks 与 断点续训</a></li><li><a href=#42-accelerate--deepspeed分布式配置详解>4.2 Accelerate + DeepSpeed：分布式配置详解</a></li></ul></li><li><a href=#5-hub模型管理与版本控制>5. Hub：模型管理与版本控制</a><ul><li><a href=#51-模型上传与-revision-锁定>5.1 模型上传与 Revision 锁定</a></li><li><a href=#52-model-card-编写规范>5.2 Model Card 编写规范</a></li></ul></li><li><a href=#本章小结开发流-checklist>本章小结：开发流 CheckList</a></li></ul></nav></div></aside></main></body></html>