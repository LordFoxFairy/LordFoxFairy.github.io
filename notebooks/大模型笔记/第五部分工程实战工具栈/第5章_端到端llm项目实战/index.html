<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='第5章：端到端项目：LawGLM 法律咨询助手# 本章定位：综合大作业。串联前4章知识，从零构建一个垂直领域的法律问答助手。
目录# 项目目标 技术栈 1. Step 1: 数据准备 (Data Engineering) 2. Step 2: 微调训练 (Fine-tuning) 3. Step 3: 模型合并与量化 4. Step 4: 服务API开发 5. Step 5: 前端交互与评估 本章小结 项目目标# 构建一个能够回答中国法律问题、辅助撰写法律文书的 LLM。
技术栈# 数据：Pandas, Datasets 微调：LLaMA-Factory (LoRA + ZeRO-2) 评估：LLM-as-a-Judge (GPT-4 打分) 部署：vLLM 1. Step 1: 数据准备 (Data Engineering)# 我们需要构建三类数据：法律条文知识注入、判例问答对 和 法律咨询对话。
1.1 数据源规划# 数据来源： 1. 法律条文：中国裁判文书网、法律法规数据库 2. 判例分析：最高人民法院公报案例 3. 咨询问答：Legal Advice Reddit、知乎法律话题（经人工清洗） 目标数据量： - 训练集：10,000+ 条高质量问答对 - 验证集：500 条 - 测试集：500 条（用于 GPT-4 评估）1.2 数据清洗脚本# 1.2.1 法律条文处理# import json import re from pathlib import Path def extract_law_articles(text: str, law_name: str) -> list: """ 从法律条文中提取结构化数据 Args: text: 原始法律条文 law_name: 法律名称（如"民法典"） Returns: list: 结构化的问答对 """ # 正则匹配 "第X条" 格式 pattern = r&#39;第([零一二三四五六七八九十百千万\d]+)条\s+(.*?)(?=第[零一二三四五六七八九十百千万\d]+条|$)&#39; matches = re.findall(pattern, text, re.DOTALL) results = [] for article_num, content in matches: content = content.strip() if len(content) < 10: # 过滤过短的条文 continue # 生成多种问法（数据增强） results.extend([ { "instruction": f"请解释《{law_name}》第{article_num}条的内容。", "input": "", "output": content }, { "instruction": f"《{law_name}》第{article_num}条规定了什么？", "input": "", "output": content }, { "instruction": "法律问题咨询", "input": f"请帮我查询《{law_name}》第{article_num}条", "output": f"《{law_name}》第{article_num}条规定：{content}" } ]) return results # 示例：处理民法典 civil_code_text = """ 第一条 为了保护民事主体的合法权益，调整民事关系，维护社会和经济秩序，适应中国特色社会主义发展要求，弘扬社会主义核心价值观，根据宪法，制定本法。 第二条 民法调整平等主体的自然人、法人和非法人组织之间的人身关系和财产关系。 第三条 民事主体的人身权利、财产权利以及其他合法权益受法律保护，任何组织或者个人不得侵犯。 """ law_data = extract_law_articles(civil_code_text, "民法典") print(f"提取了 {len(law_data)} 条法律知识")1.2.2 判例问答对构造# def create_case_qa(case_dict: dict) -> dict: """ 将判例转换为问答格式 Args: case_dict: 包含 case_title, facts, judgment 等字段的判例 Returns: dict: Alpaca 格式的问答对 """ return { "instruction": "请分析以下案件，并给出法律意见。", "input": f"案件：{case_dict[&#39;case_title&#39;]}\n事实：{case_dict[&#39;facts&#39;]}", "output": f"法律分析：\n{case_dict[&#39;legal_analysis&#39;]}\n\n判决结果：\n{case_dict[&#39;judgment&#39;]}" } # 示例数据 sample_case = { "case_title": "张某诉李某房屋租赁合同纠纷案", "facts": "原告张某与被告李某签订房屋租赁合同，约定租期一年，租金每月3000元。租期届满后，被告拒不退还押金5000元，理由是房屋内设施损坏。", "legal_analysis": "根据《民法典》第704条，租赁期限届满，承租人应当返还租赁物。因承租人原因导致租赁物毁损的，出租人可以扣除相应押金。但本案中，被告未能提供充分证据证明设施损坏系原告造成，且损坏价值未经评估。", "judgment": "判决被告李某于判决生效之日起十日内返还原告张某押金5000元。" } case_qa = create_case_qa(sample_case) print(json.dumps(case_qa, ensure_ascii=False, indent=2))1.2.3 数据质量控制# def validate_data_quality(data_list: list) -> list: """ 过滤低质量数据 """ filtered = [] for item in data_list: # 1. 长度检查 if len(item["output"]) < 20 or len(item["output"]) > 2048: continue # 2. 关键词检查（避免包含敏感内容） sensitive_keywords = ["暴力", "色情", "赌博"] if any(kw in item["output"] for kw in sensitive_keywords): continue # 3. 格式规范检查 if not item["instruction"] or not item["output"]: continue filtered.append(item) return filtered # 合并所有数据 all_data = law_data + [case_qa] # 实际项目中添加更多数据 clean_data = validate_data_quality(all_data) # 保存为 Alpaca 格式 output_path = Path("data/law_glm_train.json") output_path.parent.mkdir(exist_ok=True) with open(output_path, "w", encoding="utf-8") as f: json.dump(clean_data, f, ensure_ascii=False, indent=2) print(f"✓ 数据清洗完成，保存了 {len(clean_data)} 条数据到 {output_path}")1.2 数据注册# 在 LLaMA-Factory 的 data/dataset_info.json 中注册：
'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第5章 端到端LLM项目实战"><meta property="og:description" content='第5章：端到端项目：LawGLM 法律咨询助手# 本章定位：综合大作业。串联前4章知识，从零构建一个垂直领域的法律问答助手。
目录# 项目目标 技术栈 1. Step 1: 数据准备 (Data Engineering) 2. Step 2: 微调训练 (Fine-tuning) 3. Step 3: 模型合并与量化 4. Step 4: 服务API开发 5. Step 5: 前端交互与评估 本章小结 项目目标# 构建一个能够回答中国法律问题、辅助撰写法律文书的 LLM。
技术栈# 数据：Pandas, Datasets 微调：LLaMA-Factory (LoRA + ZeRO-2) 评估：LLM-as-a-Judge (GPT-4 打分) 部署：vLLM 1. Step 1: 数据准备 (Data Engineering)# 我们需要构建三类数据：法律条文知识注入、判例问答对 和 法律咨询对话。
1.1 数据源规划# 数据来源： 1. 法律条文：中国裁判文书网、法律法规数据库 2. 判例分析：最高人民法院公报案例 3. 咨询问答：Legal Advice Reddit、知乎法律话题（经人工清洗） 目标数据量： - 训练集：10,000+ 条高质量问答对 - 验证集：500 条 - 测试集：500 条（用于 GPT-4 评估）1.2 数据清洗脚本# 1.2.1 法律条文处理# import json import re from pathlib import Path def extract_law_articles(text: str, law_name: str) -> list: """ 从法律条文中提取结构化数据 Args: text: 原始法律条文 law_name: 法律名称（如"民法典"） Returns: list: 结构化的问答对 """ # 正则匹配 "第X条" 格式 pattern = r&#39;第([零一二三四五六七八九十百千万\d]+)条\s+(.*?)(?=第[零一二三四五六七八九十百千万\d]+条|$)&#39; matches = re.findall(pattern, text, re.DOTALL) results = [] for article_num, content in matches: content = content.strip() if len(content) < 10: # 过滤过短的条文 continue # 生成多种问法（数据增强） results.extend([ { "instruction": f"请解释《{law_name}》第{article_num}条的内容。", "input": "", "output": content }, { "instruction": f"《{law_name}》第{article_num}条规定了什么？", "input": "", "output": content }, { "instruction": "法律问题咨询", "input": f"请帮我查询《{law_name}》第{article_num}条", "output": f"《{law_name}》第{article_num}条规定：{content}" } ]) return results # 示例：处理民法典 civil_code_text = """ 第一条 为了保护民事主体的合法权益，调整民事关系，维护社会和经济秩序，适应中国特色社会主义发展要求，弘扬社会主义核心价值观，根据宪法，制定本法。 第二条 民法调整平等主体的自然人、法人和非法人组织之间的人身关系和财产关系。 第三条 民事主体的人身权利、财产权利以及其他合法权益受法律保护，任何组织或者个人不得侵犯。 """ law_data = extract_law_articles(civil_code_text, "民法典") print(f"提取了 {len(law_data)} 条法律知识")1.2.2 判例问答对构造# def create_case_qa(case_dict: dict) -> dict: """ 将判例转换为问答格式 Args: case_dict: 包含 case_title, facts, judgment 等字段的判例 Returns: dict: Alpaca 格式的问答对 """ return { "instruction": "请分析以下案件，并给出法律意见。", "input": f"案件：{case_dict[&#39;case_title&#39;]}\n事实：{case_dict[&#39;facts&#39;]}", "output": f"法律分析：\n{case_dict[&#39;legal_analysis&#39;]}\n\n判决结果：\n{case_dict[&#39;judgment&#39;]}" } # 示例数据 sample_case = { "case_title": "张某诉李某房屋租赁合同纠纷案", "facts": "原告张某与被告李某签订房屋租赁合同，约定租期一年，租金每月3000元。租期届满后，被告拒不退还押金5000元，理由是房屋内设施损坏。", "legal_analysis": "根据《民法典》第704条，租赁期限届满，承租人应当返还租赁物。因承租人原因导致租赁物毁损的，出租人可以扣除相应押金。但本案中，被告未能提供充分证据证明设施损坏系原告造成，且损坏价值未经评估。", "judgment": "判决被告李某于判决生效之日起十日内返还原告张某押金5000元。" } case_qa = create_case_qa(sample_case) print(json.dumps(case_qa, ensure_ascii=False, indent=2))1.2.3 数据质量控制# def validate_data_quality(data_list: list) -> list: """ 过滤低质量数据 """ filtered = [] for item in data_list: # 1. 长度检查 if len(item["output"]) < 20 or len(item["output"]) > 2048: continue # 2. 关键词检查（避免包含敏感内容） sensitive_keywords = ["暴力", "色情", "赌博"] if any(kw in item["output"] for kw in sensitive_keywords): continue # 3. 格式规范检查 if not item["instruction"] or not item["output"]: continue filtered.append(item) return filtered # 合并所有数据 all_data = law_data + [case_qa] # 实际项目中添加更多数据 clean_data = validate_data_quality(all_data) # 保存为 Alpaca 格式 output_path = Path("data/law_glm_train.json") output_path.parent.mkdir(exist_ok=True) with open(output_path, "w", encoding="utf-8") as f: json.dump(clean_data, f, ensure_ascii=False, indent=2) print(f"✓ 数据清洗完成，保存了 {len(clean_data)} 条数据到 {output_path}")1.2 数据注册# 在 LLaMA-Factory 的 data/dataset_info.json 中注册：'><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第5章 端到端LLM项目实战"><meta itemprop=description content='第5章：端到端项目：LawGLM 法律咨询助手# 本章定位：综合大作业。串联前4章知识，从零构建一个垂直领域的法律问答助手。
目录# 项目目标 技术栈 1. Step 1: 数据准备 (Data Engineering) 2. Step 2: 微调训练 (Fine-tuning) 3. Step 3: 模型合并与量化 4. Step 4: 服务API开发 5. Step 5: 前端交互与评估 本章小结 项目目标# 构建一个能够回答中国法律问题、辅助撰写法律文书的 LLM。
技术栈# 数据：Pandas, Datasets 微调：LLaMA-Factory (LoRA + ZeRO-2) 评估：LLM-as-a-Judge (GPT-4 打分) 部署：vLLM 1. Step 1: 数据准备 (Data Engineering)# 我们需要构建三类数据：法律条文知识注入、判例问答对 和 法律咨询对话。
1.1 数据源规划# 数据来源： 1. 法律条文：中国裁判文书网、法律法规数据库 2. 判例分析：最高人民法院公报案例 3. 咨询问答：Legal Advice Reddit、知乎法律话题（经人工清洗） 目标数据量： - 训练集：10,000+ 条高质量问答对 - 验证集：500 条 - 测试集：500 条（用于 GPT-4 评估）1.2 数据清洗脚本# 1.2.1 法律条文处理# import json import re from pathlib import Path def extract_law_articles(text: str, law_name: str) -> list: """ 从法律条文中提取结构化数据 Args: text: 原始法律条文 law_name: 法律名称（如"民法典"） Returns: list: 结构化的问答对 """ # 正则匹配 "第X条" 格式 pattern = r&#39;第([零一二三四五六七八九十百千万\d]+)条\s+(.*?)(?=第[零一二三四五六七八九十百千万\d]+条|$)&#39; matches = re.findall(pattern, text, re.DOTALL) results = [] for article_num, content in matches: content = content.strip() if len(content) < 10: # 过滤过短的条文 continue # 生成多种问法（数据增强） results.extend([ { "instruction": f"请解释《{law_name}》第{article_num}条的内容。", "input": "", "output": content }, { "instruction": f"《{law_name}》第{article_num}条规定了什么？", "input": "", "output": content }, { "instruction": "法律问题咨询", "input": f"请帮我查询《{law_name}》第{article_num}条", "output": f"《{law_name}》第{article_num}条规定：{content}" } ]) return results # 示例：处理民法典 civil_code_text = """ 第一条 为了保护民事主体的合法权益，调整民事关系，维护社会和经济秩序，适应中国特色社会主义发展要求，弘扬社会主义核心价值观，根据宪法，制定本法。 第二条 民法调整平等主体的自然人、法人和非法人组织之间的人身关系和财产关系。 第三条 民事主体的人身权利、财产权利以及其他合法权益受法律保护，任何组织或者个人不得侵犯。 """ law_data = extract_law_articles(civil_code_text, "民法典") print(f"提取了 {len(law_data)} 条法律知识")1.2.2 判例问答对构造# def create_case_qa(case_dict: dict) -> dict: """ 将判例转换为问答格式 Args: case_dict: 包含 case_title, facts, judgment 等字段的判例 Returns: dict: Alpaca 格式的问答对 """ return { "instruction": "请分析以下案件，并给出法律意见。", "input": f"案件：{case_dict[&#39;case_title&#39;]}\n事实：{case_dict[&#39;facts&#39;]}", "output": f"法律分析：\n{case_dict[&#39;legal_analysis&#39;]}\n\n判决结果：\n{case_dict[&#39;judgment&#39;]}" } # 示例数据 sample_case = { "case_title": "张某诉李某房屋租赁合同纠纷案", "facts": "原告张某与被告李某签订房屋租赁合同，约定租期一年，租金每月3000元。租期届满后，被告拒不退还押金5000元，理由是房屋内设施损坏。", "legal_analysis": "根据《民法典》第704条，租赁期限届满，承租人应当返还租赁物。因承租人原因导致租赁物毁损的，出租人可以扣除相应押金。但本案中，被告未能提供充分证据证明设施损坏系原告造成，且损坏价值未经评估。", "judgment": "判决被告李某于判决生效之日起十日内返还原告张某押金5000元。" } case_qa = create_case_qa(sample_case) print(json.dumps(case_qa, ensure_ascii=False, indent=2))1.2.3 数据质量控制# def validate_data_quality(data_list: list) -> list: """ 过滤低质量数据 """ filtered = [] for item in data_list: # 1. 长度检查 if len(item["output"]) < 20 or len(item["output"]) > 2048: continue # 2. 关键词检查（避免包含敏感内容） sensitive_keywords = ["暴力", "色情", "赌博"] if any(kw in item["output"] for kw in sensitive_keywords): continue # 3. 格式规范检查 if not item["instruction"] or not item["output"]: continue filtered.append(item) return filtered # 合并所有数据 all_data = law_data + [case_qa] # 实际项目中添加更多数据 clean_data = validate_data_quality(all_data) # 保存为 Alpaca 格式 output_path = Path("data/law_glm_train.json") output_path.parent.mkdir(exist_ok=True) with open(output_path, "w", encoding="utf-8") as f: json.dump(clean_data, f, ensure_ascii=False, indent=2) print(f"✓ 数据清洗完成，保存了 {len(clean_data)} 条数据到 {output_path}")1.2 数据注册# 在 LLaMA-Factory 的 data/dataset_info.json 中注册：'><meta itemprop=wordCount content="1542"><title>第5章 端到端LLM项目实战 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle checked>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle checked>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/ class=active>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第5章 端到端LLM项目实战</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#项目目标>项目目标</a></li><li><a href=#技术栈>技术栈</a></li><li><a href=#1-step-1-数据准备-data-engineering>1. Step 1: 数据准备 (Data Engineering)</a><ul><li><a href=#11-数据源规划>1.1 数据源规划</a></li><li><a href=#12-数据清洗脚本>1.2 数据清洗脚本</a><ul><li><a href=#121-法律条文处理>1.2.1 法律条文处理</a></li><li><a href=#122-判例问答对构造>1.2.2 判例问答对构造</a></li><li><a href=#123-数据质量控制>1.2.3 数据质量控制</a></li></ul></li><li><a href=#12-数据注册>1.2 数据注册</a></li></ul></li><li><a href=#2-step-2-模型微调-qlora-sft>2. Step 2: 模型微调 (QLoRA SFT)</a><ul><li><a href=#21-配置文件-law_finetuneyaml>2.1 配置文件 <code>law_finetune.yaml</code></a></li><li><a href=#22-启动训练>2.2 启动训练</a></li><li><a href=#23-训练监控>2.3 训练监控</a></li></ul></li><li><a href=#3-step-3-合并与导出>3. Step 3: 合并与导出</a></li><li><a href=#4-step-4-性能评估-llm-as-a-judge>4. Step 4: 性能评估 (LLM-as-a-Judge)</a><ul><li><a href=#41-评估维度设计>4.1 评估维度设计</a></li><li><a href=#42-完整评估脚本>4.2 完整评估脚本</a></li><li><a href=#43-预期结果示例>4.3 预期结果示例</a></li></ul></li><li><a href=#5-step-5-生产级部署-vllm>5. Step 5: 生产级部署 (vLLM)</a><ul><li><a href=#51-安装-vllm>5.1 安装 vLLM</a></li><li><a href=#52-启动-api-server>5.2 启动 API Server</a></li><li><a href=#53-性能基准测试>5.3 性能基准测试</a></li><li><a href=#54-python-客户端调用>5.4 Python 客户端调用</a></li><li><a href=#55-流式输出streaming>5.5 流式输出（Streaming）</a></li><li><a href=#56-docker-容器化部署>5.6 Docker 容器化部署</a></li></ul></li><li><a href=#6-本章小结工程化最佳实践>6. 本章小结：工程化最佳实践</a><ul><li><a href=#61-技术栈总结>6.1 技术栈总结</a></li><li><a href=#62-核心经验总结>6.2 核心经验总结</a></li><li><a href=#63-生产环境检查清单>6.3 生产环境检查清单</a></li><li><a href=#64-下一步优化方向>6.4 下一步优化方向</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第5章端到端项目lawglm-法律咨询助手>第5章：端到端项目：LawGLM 法律咨询助手<a class=anchor href=#%e7%ac%ac5%e7%ab%a0%e7%ab%af%e5%88%b0%e7%ab%af%e9%a1%b9%e7%9b%aelawglm-%e6%b3%95%e5%be%8b%e5%92%a8%e8%af%a2%e5%8a%a9%e6%89%8b>#</a></h1><blockquote class=book-hint><p><strong>本章定位</strong>：综合大作业。串联前4章知识，从零构建一个垂直领域的法律问答助手。</p></blockquote><hr><h2 id=目录>目录<a class=anchor href=#%e7%9b%ae%e5%bd%95>#</a></h2><ul><li><a href=#%e9%a1%b9%e7%9b%ae%e7%9b%ae%e6%a0%87>项目目标</a></li><li><a href=#%e6%8a%80%e6%9c%af%e6%a0%88>技术栈</a></li><li><a href=#1-step-1-%e6%95%b0%e6%8d%ae%e5%87%86%e5%a4%87-data-engineering>1. Step 1: 数据准备 (Data Engineering)</a></li><li><a href=#2-step-2-%e5%be%ae%e8%b0%83%e8%ae%ad%e7%bb%83-fine-tuning>2. Step 2: 微调训练 (Fine-tuning)</a></li><li><a href=#3-step-3-%e6%a8%a1%e5%9e%8b%e5%90%88%e5%b9%b6%e4%b8%8e%e9%87%8f%e5%8c%96>3. Step 3: 模型合并与量化</a></li><li><a href=#4-step-4-%e6%9c%8d%e5%8a%a1api%e5%bc%80%e5%8f%91>4. Step 4: 服务API开发</a></li><li><a href=#5-step-5-%e5%89%8d%e7%ab%af%e4%ba%a4%e4%ba%92%e4%b8%8e%e8%af%84%e4%bc%b0>5. Step 5: 前端交互与评估</a></li><li><a href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>本章小结</a></li></ul><hr><h2 id=项目目标>项目目标<a class=anchor href=#%e9%a1%b9%e7%9b%ae%e7%9b%ae%e6%a0%87>#</a></h2><p>构建一个能够回答中国法律问题、辅助撰写法律文书的 LLM。</p><h2 id=技术栈>技术栈<a class=anchor href=#%e6%8a%80%e6%9c%af%e6%a0%88>#</a></h2><ul><li><strong>数据</strong>：Pandas, Datasets</li><li><strong>微调</strong>：LLaMA-Factory (LoRA + ZeRO-2)</li><li><strong>评估</strong>：LLM-as-a-Judge (GPT-4 打分)</li><li><strong>部署</strong>：vLLM</li></ul><hr><h2 id=1-step-1-数据准备-data-engineering>1. Step 1: 数据准备 (Data Engineering)<a class=anchor href=#1-step-1-%e6%95%b0%e6%8d%ae%e5%87%86%e5%a4%87-data-engineering>#</a></h2><p>我们需要构建三类数据：<strong>法律条文知识注入</strong>、<strong>判例问答对</strong> 和 <strong>法律咨询对话</strong>。</p><h3 id=11-数据源规划>1.1 数据源规划<a class=anchor href=#11-%e6%95%b0%e6%8d%ae%e6%ba%90%e8%a7%84%e5%88%92>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>数据来源：
</span></span><span class=line><span class=cl>1. 法律条文：中国裁判文书网、法律法规数据库
</span></span><span class=line><span class=cl>2. 判例分析：最高人民法院公报案例
</span></span><span class=line><span class=cl>3. 咨询问答：Legal Advice Reddit、知乎法律话题（经人工清洗）
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>目标数据量：
</span></span><span class=line><span class=cl>- 训练集：10,000+ 条高质量问答对
</span></span><span class=line><span class=cl>- 验证集：500 条
</span></span><span class=line><span class=cl>- 测试集：500 条（用于 GPT-4 评估）</span></span></code></pre></div><h3 id=12-数据清洗脚本>1.2 数据清洗脚本<a class=anchor href=#12-%e6%95%b0%e6%8d%ae%e6%b8%85%e6%b4%97%e8%84%9a%e6%9c%ac>#</a></h3><h4 id=121-法律条文处理>1.2.1 法律条文处理<a class=anchor href=#121-%e6%b3%95%e5%be%8b%e6%9d%a1%e6%96%87%e5%a4%84%e7%90%86>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>re</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>extract_law_articles</span><span class=p>(</span><span class=n>text</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>law_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    从法律条文中提取结构化数据
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        text: 原始法律条文
</span></span></span><span class=line><span class=cl><span class=s2>        law_name: 法律名称（如&#34;民法典&#34;）
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        list: 结构化的问答对
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 正则匹配 &#34;第X条&#34; 格式</span>
</span></span><span class=line><span class=cl>    <span class=n>pattern</span> <span class=o>=</span> <span class=sa>r</span><span class=s1>&#39;第([零一二三四五六七八九十百千万\d]+)条\s+(.*?)(?=第[零一二三四五六七八九十百千万\d]+条|$)&#39;</span>
</span></span><span class=line><span class=cl>    <span class=n>matches</span> <span class=o>=</span> <span class=n>re</span><span class=o>.</span><span class=n>findall</span><span class=p>(</span><span class=n>pattern</span><span class=p>,</span> <span class=n>text</span><span class=p>,</span> <span class=n>re</span><span class=o>.</span><span class=n>DOTALL</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>article_num</span><span class=p>,</span> <span class=n>content</span> <span class=ow>in</span> <span class=n>matches</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>content</span> <span class=o>=</span> <span class=n>content</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>content</span><span class=p>)</span> <span class=o>&lt;</span> <span class=mi>10</span><span class=p>:</span>  <span class=c1># 过滤过短的条文</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 生成多种问法（数据增强）</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>extend</span><span class=p>([</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;instruction&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;请解释《</span><span class=si>{</span><span class=n>law_name</span><span class=si>}</span><span class=s2>》第</span><span class=si>{</span><span class=n>article_num</span><span class=si>}</span><span class=s2>条的内容。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;input&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;output&#34;</span><span class=p>:</span> <span class=n>content</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;instruction&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;《</span><span class=si>{</span><span class=n>law_name</span><span class=si>}</span><span class=s2>》第</span><span class=si>{</span><span class=n>article_num</span><span class=si>}</span><span class=s2>条规定了什么？&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;input&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;output&#34;</span><span class=p>:</span> <span class=n>content</span>
</span></span><span class=line><span class=cl>            <span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;法律问题咨询&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;input&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;请帮我查询《</span><span class=si>{</span><span class=n>law_name</span><span class=si>}</span><span class=s2>》第</span><span class=si>{</span><span class=n>article_num</span><span class=si>}</span><span class=s2>条&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;output&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;《</span><span class=si>{</span><span class=n>law_name</span><span class=si>}</span><span class=s2>》第</span><span class=si>{</span><span class=n>article_num</span><span class=si>}</span><span class=s2>条规定：</span><span class=si>{</span><span class=n>content</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 示例：处理民法典</span>
</span></span><span class=line><span class=cl><span class=n>civil_code_text</span> <span class=o>=</span> <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>第一条 为了保护民事主体的合法权益，调整民事关系，维护社会和经济秩序，适应中国特色社会主义发展要求，弘扬社会主义核心价值观，根据宪法，制定本法。
</span></span></span><span class=line><span class=cl><span class=s2>第二条 民法调整平等主体的自然人、法人和非法人组织之间的人身关系和财产关系。
</span></span></span><span class=line><span class=cl><span class=s2>第三条 民事主体的人身权利、财产权利以及其他合法权益受法律保护，任何组织或者个人不得侵犯。
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>law_data</span> <span class=o>=</span> <span class=n>extract_law_articles</span><span class=p>(</span><span class=n>civil_code_text</span><span class=p>,</span> <span class=s2>&#34;民法典&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;提取了 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>law_data</span><span class=p>)</span><span class=si>}</span><span class=s2> 条法律知识&#34;</span><span class=p>)</span></span></span></code></pre></div><h4 id=122-判例问答对构造>1.2.2 判例问答对构造<a class=anchor href=#122-%e5%88%a4%e4%be%8b%e9%97%ae%e7%ad%94%e5%af%b9%e6%9e%84%e9%80%a0>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>create_case_qa</span><span class=p>(</span><span class=n>case_dict</span><span class=p>:</span> <span class=nb>dict</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    将判例转换为问答格式
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        case_dict: 包含 case_title, facts, judgment 等字段的判例
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        dict: Alpaca 格式的问答对
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;请分析以下案件，并给出法律意见。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;input&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;案件：</span><span class=si>{</span><span class=n>case_dict</span><span class=p>[</span><span class=s1>&#39;case_title&#39;</span><span class=p>]</span><span class=si>}</span><span class=se>\n</span><span class=s2>事实：</span><span class=si>{</span><span class=n>case_dict</span><span class=p>[</span><span class=s1>&#39;facts&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;output&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;法律分析：</span><span class=se>\n</span><span class=si>{</span><span class=n>case_dict</span><span class=p>[</span><span class=s1>&#39;legal_analysis&#39;</span><span class=p>]</span><span class=si>}</span><span class=se>\n\n</span><span class=s2>判决结果：</span><span class=se>\n</span><span class=si>{</span><span class=n>case_dict</span><span class=p>[</span><span class=s1>&#39;judgment&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 示例数据</span>
</span></span><span class=line><span class=cl><span class=n>sample_case</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;case_title&#34;</span><span class=p>:</span> <span class=s2>&#34;张某诉李某房屋租赁合同纠纷案&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;facts&#34;</span><span class=p>:</span> <span class=s2>&#34;原告张某与被告李某签订房屋租赁合同，约定租期一年，租金每月3000元。租期届满后，被告拒不退还押金5000元，理由是房屋内设施损坏。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;legal_analysis&#34;</span><span class=p>:</span> <span class=s2>&#34;根据《民法典》第704条，租赁期限届满，承租人应当返还租赁物。因承租人原因导致租赁物毁损的，出租人可以扣除相应押金。但本案中，被告未能提供充分证据证明设施损坏系原告造成，且损坏价值未经评估。&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;judgment&#34;</span><span class=p>:</span> <span class=s2>&#34;判决被告李某于判决生效之日起十日内返还原告张某押金5000元。&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>case_qa</span> <span class=o>=</span> <span class=n>create_case_qa</span><span class=p>(</span><span class=n>sample_case</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=n>json</span><span class=o>.</span><span class=n>dumps</span><span class=p>(</span><span class=n>case_qa</span><span class=p>,</span> <span class=n>ensure_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>))</span></span></span></code></pre></div><h4 id=123-数据质量控制>1.2.3 数据质量控制<a class=anchor href=#123-%e6%95%b0%e6%8d%ae%e8%b4%a8%e9%87%8f%e6%8e%a7%e5%88%b6>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>validate_data_quality</span><span class=p>(</span><span class=n>data_list</span><span class=p>:</span> <span class=nb>list</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    过滤低质量数据
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>filtered</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>data_list</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 长度检查</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>len</span><span class=p>(</span><span class=n>item</span><span class=p>[</span><span class=s2>&#34;output&#34;</span><span class=p>])</span> <span class=o>&lt;</span> <span class=mi>20</span> <span class=ow>or</span> <span class=nb>len</span><span class=p>(</span><span class=n>item</span><span class=p>[</span><span class=s2>&#34;output&#34;</span><span class=p>])</span> <span class=o>&gt;</span> <span class=mi>2048</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. 关键词检查（避免包含敏感内容）</span>
</span></span><span class=line><span class=cl>        <span class=n>sensitive_keywords</span> <span class=o>=</span> <span class=p>[</span><span class=s2>&#34;暴力&#34;</span><span class=p>,</span> <span class=s2>&#34;色情&#34;</span><span class=p>,</span> <span class=s2>&#34;赌博&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=nb>any</span><span class=p>(</span><span class=n>kw</span> <span class=ow>in</span> <span class=n>item</span><span class=p>[</span><span class=s2>&#34;output&#34;</span><span class=p>]</span> <span class=k>for</span> <span class=n>kw</span> <span class=ow>in</span> <span class=n>sensitive_keywords</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. 格式规范检查</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>item</span><span class=p>[</span><span class=s2>&#34;instruction&#34;</span><span class=p>]</span> <span class=ow>or</span> <span class=ow>not</span> <span class=n>item</span><span class=p>[</span><span class=s2>&#34;output&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>            <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>filtered</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>item</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>filtered</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 合并所有数据</span>
</span></span><span class=line><span class=cl><span class=n>all_data</span> <span class=o>=</span> <span class=n>law_data</span> <span class=o>+</span> <span class=p>[</span><span class=n>case_qa</span><span class=p>]</span>  <span class=c1># 实际项目中添加更多数据</span>
</span></span><span class=line><span class=cl><span class=n>clean_data</span> <span class=o>=</span> <span class=n>validate_data_quality</span><span class=p>(</span><span class=n>all_data</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 保存为 Alpaca 格式</span>
</span></span><span class=line><span class=cl><span class=n>output_path</span> <span class=o>=</span> <span class=n>Path</span><span class=p>(</span><span class=s2>&#34;data/law_glm_train.json&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>output_path</span><span class=o>.</span><span class=n>parent</span><span class=o>.</span><span class=n>mkdir</span><span class=p>(</span><span class=n>exist_ok</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>output_path</span><span class=p>,</span> <span class=s2>&#34;w&#34;</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>json</span><span class=o>.</span><span class=n>dump</span><span class=p>(</span><span class=n>clean_data</span><span class=p>,</span> <span class=n>f</span><span class=p>,</span> <span class=n>ensure_ascii</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>indent</span><span class=o>=</span><span class=mi>2</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;✓ 数据清洗完成，保存了 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>clean_data</span><span class=p>)</span><span class=si>}</span><span class=s2> 条数据到 </span><span class=si>{</span><span class=n>output_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=12-数据注册>1.2 数据注册<a class=anchor href=#12-%e6%95%b0%e6%8d%ae%e6%b3%a8%e5%86%8c>#</a></h3><p>在 LLaMA-Factory 的 <code>data/dataset_info.json</code> 中注册：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=s2>&#34;law_glm_sft&#34;</span><span class=err>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;file_name&#34;</span><span class=p>:</span> <span class=s2>&#34;law_data.json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;columns&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;prompt&#34;</span><span class=p>:</span> <span class=s2>&#34;instruction&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;query&#34;</span><span class=p>:</span> <span class=s2>&#34;input&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;response&#34;</span><span class=p>:</span> <span class=s2>&#34;output&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><hr><h2 id=2-step-2-模型微调-qlora-sft>2. Step 2: 模型微调 (QLoRA SFT)<a class=anchor href=#2-step-2-%e6%a8%a1%e5%9e%8b%e5%be%ae%e8%b0%83-qlora-sft>#</a></h2><p>使用 LLaMA-Factory 进行 <strong>QLoRA</strong> 微调（4-bit 量化），在单张 24GB 显卡上训练 7B 模型。</p><h3 id=21-配置文件-law_finetuneyaml>2.1 配置文件 <code>law_finetune.yaml</code><a class=anchor href=#21-%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6-law_finetuneyaml>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c># ===== 模型配置 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>model_name_or_path</span><span class=p>:</span><span class=w> </span><span class=l>deepseek-ai/DeepSeek-Coder-V2-Lite-Instruct </span><span class=w> </span><span class=c># 或 meta-llama/Llama-3-8B-Instruct</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>trust_remote_code</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 微调方法 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>stage</span><span class=p>:</span><span class=w> </span><span class=l>sft</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>do_train</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>finetuning_type</span><span class=p>:</span><span class=w> </span><span class=l>lora</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lora_target</span><span class=p>:</span><span class=w> </span><span class=l>all          </span><span class=w> </span><span class=c># 挂载所有线性层</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lora_rank</span><span class=p>:</span><span class=w> </span><span class=m>64</span><span class=w>              </span><span class=c># 法律领域建议 rank=64（提升容量）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lora_alpha</span><span class=p>:</span><span class=w> </span><span class=m>128</span><span class=w>            </span><span class=c># alpha = 2 * rank</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lora_dropout</span><span class=p>:</span><span class=w> </span><span class=m>0.05</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 量化配置（QLoRA 关键）=====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>quantization_bit</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>        </span><span class=c># 4-bit 量化</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>quantization_type</span><span class=p>:</span><span class=w> </span><span class=l>nf4    </span><span class=w> </span><span class=c># NormalFloat4（推荐）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>double_quantization</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>  </span><span class=c># 二次量化，进一步节省显存</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 数据配置 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>dataset</span><span class=p>:</span><span class=w> </span><span class=l>law_glm_train    </span><span class=w> </span><span class=c># 需在 dataset_info.json 中注册</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>template</span><span class=p>:</span><span class=w> </span><span class=l>llama3          </span><span class=w> </span><span class=c># 根据选择的基座模型调整</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>cutoff_len</span><span class=p>:</span><span class=w> </span><span class=m>2048</span><span class=w>           </span><span class=c># 法律文本通常较长</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>max_samples</span><span class=p>:</span><span class=w> </span><span class=m>50000</span><span class=w>         </span><span class=c># 限制训练样本数（可选）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>overwrite_cache</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>preprocessing_num_workers</span><span class=p>:</span><span class=w> </span><span class=m>16</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 训练参数 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>output_dir</span><span class=p>:</span><span class=w> </span><span class=l>outputs/LawGLM-7B-QLoRA</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>logging_steps</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>save_steps</span><span class=p>:</span><span class=w> </span><span class=m>500</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>save_total_limit</span><span class=p>:</span><span class=w> </span><span class=m>3</span><span class=w>        </span><span class=c># 只保留最新3个 checkpoint</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>plot_loss</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>overwrite_output_dir</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>per_device_train_batch_size</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>gradient_accumulation_steps</span><span class=p>:</span><span class=w> </span><span class=m>8</span><span class=w>  </span><span class=c># 等效 batch_size = 2 * 8 * num_gpus</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>learning_rate</span><span class=p>:</span><span class=w> </span><span class=m>1e-4</span><span class=w>             </span><span class=c># QLoRA 学习率通常比 LoRA 高</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>num_train_epochs</span><span class=p>:</span><span class=w> </span><span class=m>3.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lr_scheduler_type</span><span class=p>:</span><span class=w> </span><span class=l>cosine</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>warmup_ratio</span><span class=p>:</span><span class=w> </span><span class=m>0.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>weight_decay</span><span class=p>:</span><span class=w> </span><span class=m>0.01</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 显存优化 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>fp16</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>                      </span><span class=c># 混合精度训练</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>gradient_checkpointing</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>    </span><span class=c># 梯度检查点（必开，节省显存）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>flash_attn</span><span class=p>:</span><span class=w> </span><span class=l>fa2                </span><span class=w> </span><span class=c># FlashAttention-2 加速</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 验证配置 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>val_size</span><span class=p>:</span><span class=w> </span><span class=m>0.05</span><span class=w>                  </span><span class=c># 5% 数据用于验证</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>evaluation_strategy</span><span class=p>:</span><span class=w> </span><span class=l>steps</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>eval_steps</span><span class=p>:</span><span class=w> </span><span class=m>500</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>per_device_eval_batch_size</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c># ===== 其他 =====</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>report_to</span><span class=p>:</span><span class=w> </span><span class=l>wandb               </span><span class=w> </span><span class=c># 实验记录（需安装 wandb）</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>logging_first_step</span><span class=p>:</span><span class=w> </span><span class=kc>true</span></span></span></code></pre></div><h3 id=22-启动训练>2.2 启动训练<a class=anchor href=#22-%e5%90%af%e5%8a%a8%e8%ae%ad%e7%bb%83>#</a></h3><p><strong>单卡训练</strong>（24GB 显存即可）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>llamafactory-cli train law_finetune.yaml</span></span></code></pre></div><p><strong>多卡训练</strong>（使用 DeepSpeed ZeRO-2）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 先创建 DeepSpeed 配置（ds_config.json）</span>
</span></span><span class=line><span class=cl>cat &gt; ds_zero2.json <span class=s>&lt;&lt;EOF
</span></span></span><span class=line><span class=cl><span class=s>{
</span></span></span><span class=line><span class=cl><span class=s>  &#34;train_batch_size&#34;: &#34;auto&#34;,
</span></span></span><span class=line><span class=cl><span class=s>  &#34;gradient_accumulation_steps&#34;: &#34;auto&#34;,
</span></span></span><span class=line><span class=cl><span class=s>  &#34;zero_optimization&#34;: {
</span></span></span><span class=line><span class=cl><span class=s>    &#34;stage&#34;: 2
</span></span></span><span class=line><span class=cl><span class=s>  },
</span></span></span><span class=line><span class=cl><span class=s>  &#34;fp16&#34;: { &#34;enabled&#34;: true }
</span></span></span><span class=line><span class=cl><span class=s>}
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 在 YAML 中添加：</span>
</span></span><span class=line><span class=cl><span class=c1># deepspeed: ds_zero2.json</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动训练</span>
</span></span><span class=line><span class=cl><span class=nv>CUDA_VISIBLE_DEVICES</span><span class=o>=</span>0,1,2,3 llamafactory-cli train law_finetune.yaml</span></span></code></pre></div><h3 id=23-训练监控>2.3 训练监控<a class=anchor href=#23-%e8%ae%ad%e7%bb%83%e7%9b%91%e6%8e%a7>#</a></h3><p><strong>实时查看 Loss 曲线</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 方法1：使用 LLaMA-Factory 自带的图表</span>
</span></span><span class=line><span class=cl><span class=c1># 训练完成后会自动生成 loss.png</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方法2：使用 wandb（推荐）</span>
</span></span><span class=line><span class=cl>wandb login  <span class=c1># 首次使用需登录</span>
</span></span><span class=line><span class=cl><span class=c1># 在浏览器中打开 wandb 项目页面，实时查看</span></span></span></code></pre></div><p><strong>预期指标</strong>：</p><ul><li><strong>训练 Loss</strong>：从 ~1.5 降至 ~0.3（收敛良好）</li><li><strong>验证 Loss</strong>：不应持续上升（避免过拟合）</li><li><strong>训练时间</strong>：单卡约 8-12 小时（10k 样本，3 epochs）</li></ul><hr><h2 id=3-step-3-合并与导出>3. Step 3: 合并与导出<a class=anchor href=#3-step-3-%e5%90%88%e5%b9%b6%e4%b8%8e%e5%af%bc%e5%87%ba>#</a></h2><p>为了提高推理速度，我们将 LoRA 权重合并回基座模型。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>llamafactory-cli <span class=nb>export</span> <span class=se>\
</span></span></span><span class=line><span class=cl>    --model_name_or_path Qwen/Qwen1.5-7B-Chat <span class=se>\
</span></span></span><span class=line><span class=cl>    --adapter_name_or_path saves/Qwen1.5-7B/law-lora <span class=se>\
</span></span></span><span class=line><span class=cl>    --template qwen <span class=se>\
</span></span></span><span class=line><span class=cl>    --finetuning_type lora <span class=se>\
</span></span></span><span class=line><span class=cl>    --export_dir models/LawGLM-7B <span class=se>\
</span></span></span><span class=line><span class=cl>    --export_size <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl>    --export_legacy_format false</span></span></code></pre></div><p>现在，<code>models/LawGLM-7B</code> 目录就是一个完整的、可独立运行的模型了。</p><hr><h2 id=4-step-4-性能评估-llm-as-a-judge>4. Step 4: 性能评估 (LLM-as-a-Judge)<a class=anchor href=#4-step-4-%e6%80%a7%e8%83%bd%e8%af%84%e4%bc%b0-llm-as-a-judge>#</a></h2><p>使用 <strong>GPT-4 作为评委</strong>，对 LawGLM 的回答进行多维度打分。</p><h3 id=41-评估维度设计>4.1 评估维度设计<a class=anchor href=#41-%e8%af%84%e4%bc%b0%e7%bb%b4%e5%ba%a6%e8%ae%be%e8%ae%a1>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>EVALUATION_CRITERIA</span> <span class=o>=</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;准确性 (Accuracy)&#34;</span><span class=p>:</span> <span class=s2>&#34;法律条文引用是否准确，法律逻辑是否严谨&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;完整性 (Completeness)&#34;</span><span class=p>:</span> <span class=s2>&#34;是否涵盖问题的所有关键点&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;专业性 (Professionalism)&#34;</span><span class=p>:</span> <span class=s2>&#34;用词是否专业，表述是否规范&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;安全性 (Safety)&#34;</span><span class=p>:</span> <span class=s2>&#34;是否避免给出危险或违法建议&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;可理解性 (Clarity)&#34;</span><span class=p>:</span> <span class=s2>&#34;非法律专业人士是否容易理解&#34;</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><h3 id=42-完整评估脚本>4.2 完整评估脚本<a class=anchor href=#42-%e5%ae%8c%e6%95%b4%e8%af%84%e4%bc%b0%e8%84%9a%e6%9c%ac>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>json</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>pathlib</span> <span class=kn>import</span> <span class=n>Path</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>tqdm</span> <span class=kn>import</span> <span class=n>tqdm</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>pandas</span> <span class=k>as</span> <span class=nn>pd</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初始化 OpenAI 客户端</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;your-api-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>evaluate_with_gpt4</span><span class=p>(</span><span class=n>question</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>model_answer</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>reference_answer</span><span class=p>:</span> <span class=nb>str</span> <span class=o>=</span> <span class=kc>None</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>dict</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    使用 GPT-4 对模型回答进行评分
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Returns:
</span></span></span><span class=line><span class=cl><span class=s2>        dict: {
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;准确性&#34;: 9,
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;完整性&#34;: 8,
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;专业性&#34;: 9,
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;安全性&#34;: 10,
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;可理解性&#34;: 8,
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;总分&#34;: 44,
</span></span></span><span class=line><span class=cl><span class=s2>            &#34;评语&#34;: &#34;...&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        }
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 构造评审 Prompt</span>
</span></span><span class=line><span class=cl>    <span class=n>evaluation_prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>你是一位资深法律专家，负责评估 AI 法律助手的回答质量。
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>【问题】
</span></span></span><span class=line><span class=cl><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>【AI 回答】
</span></span></span><span class=line><span class=cl><span class=si>{</span><span class=n>model_answer</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=si>{</span><span class=s1>&#39;【参考答案】&#39;</span> <span class=k>if</span> <span class=n>reference_answer</span> <span class=k>else</span> <span class=s1>&#39;&#39;</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=si>{</span><span class=n>reference_answer</span> <span class=ow>or</span> <span class=s1>&#39;（无参考答案，请基于专业知识评估）&#39;</span><span class=si>}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>【评分标准】
</span></span></span><span class=line><span class=cl><span class=s2>请从以下5个维度打分（每项1-10分）：
</span></span></span><span class=line><span class=cl><span class=s2>1. 准确性：法律条文引用准确，法律逻辑严谨
</span></span></span><span class=line><span class=cl><span class=s2>2. 完整性：涵盖问题的所有关键点
</span></span></span><span class=line><span class=cl><span class=s2>3. 专业性：用词专业，表述规范
</span></span></span><span class=line><span class=cl><span class=s2>4. 安全性：避免危险或违法建议
</span></span></span><span class=line><span class=cl><span class=s2>5. 可理解性：非法律专业人士易于理解
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>【输出格式】（严格按 JSON 格式）
</span></span></span><span class=line><span class=cl><span class=se>{{</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;准确性&#34;: 9,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;完整性&#34;: 8,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;专业性&#34;: 9,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;安全性&#34;: 10,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;可理解性&#34;: 8,
</span></span></span><span class=line><span class=cl><span class=s2>  &#34;评语&#34;: &#34;详细评价...&#34;
</span></span></span><span class=line><span class=cl><span class=se>}}</span><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>  <span class=c1># 或 gpt-4-turbo</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;你是一位严谨的法律评审专家。&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>evaluation_prompt</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.3</span><span class=p>,</span>  <span class=c1># 降低随机性，提高一致性</span>
</span></span><span class=line><span class=cl>        <span class=n>response_format</span><span class=o>=</span><span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;json_object&#34;</span><span class=p>}</span>  <span class=c1># 强制 JSON 输出</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>result</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>loads</span><span class=p>(</span><span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>result</span><span class=p>[</span><span class=s2>&#34;总分&#34;</span><span class=p>]</span> <span class=o>=</span> <span class=nb>sum</span><span class=p>([</span><span class=n>v</span> <span class=k>for</span> <span class=n>k</span><span class=p>,</span> <span class=n>v</span> <span class=ow>in</span> <span class=n>result</span><span class=o>.</span><span class=n>items</span><span class=p>()</span> <span class=k>if</span> <span class=n>k</span> <span class=o>!=</span> <span class=s2>&#34;评语&#34;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>result</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>batch_evaluate</span><span class=p>(</span><span class=n>test_file</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>output_file</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    批量评估测试集
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 加载测试数据</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>test_file</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>test_data</span> <span class=o>=</span> <span class=n>json</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>f</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>item</span> <span class=ow>in</span> <span class=n>tqdm</span><span class=p>(</span><span class=n>test_data</span><span class=p>[:</span><span class=mi>100</span><span class=p>],</span> <span class=n>desc</span><span class=o>=</span><span class=sa>f</span><span class=s2>&#34;评估 </span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>):</span>  <span class=c1># 限制100条节省成本</span>
</span></span><span class=line><span class=cl>        <span class=n>question</span> <span class=o>=</span> <span class=n>item</span><span class=p>[</span><span class=s2>&#34;instruction&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;input&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>question</span> <span class=o>+=</span> <span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=n>item</span><span class=p>[</span><span class=s1>&#39;input&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 获取模型回答（这里需要调用你部署的 LawGLM API）</span>
</span></span><span class=line><span class=cl>        <span class=n>model_answer</span> <span class=o>=</span> <span class=n>get_model_response</span><span class=p>(</span><span class=n>question</span><span class=p>,</span> <span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># GPT-4 评分</span>
</span></span><span class=line><span class=cl>        <span class=n>score</span> <span class=o>=</span> <span class=n>evaluate_with_gpt4</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>question</span><span class=o>=</span><span class=n>question</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>model_answer</span><span class=o>=</span><span class=n>model_answer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>reference_answer</span><span class=o>=</span><span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;output&#34;</span><span class=p>)</span>  <span class=c1># 如果有参考答案</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;model_answer&#34;</span><span class=p>:</span> <span class=n>model_answer</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;reference&#34;</span><span class=p>:</span> <span class=n>item</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=s2>&#34;output&#34;</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=o>**</span><span class=n>score</span>
</span></span><span class=line><span class=cl>        <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 保存结果</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span> <span class=o>=</span> <span class=n>pd</span><span class=o>.</span><span class=n>DataFrame</span><span class=p>(</span><span class=n>results</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>df</span><span class=o>.</span><span class=n>to_csv</span><span class=p>(</span><span class=n>output_file</span><span class=p>,</span> <span class=n>index</span><span class=o>=</span><span class=kc>False</span><span class=p>,</span> <span class=n>encoding</span><span class=o>=</span><span class=s2>&#34;utf-8-sig&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 打印统计</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>50</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;模型：</span><span class=si>{</span><span class=n>model_name</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>50</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>metric</span> <span class=ow>in</span> <span class=p>[</span><span class=s2>&#34;准确性&#34;</span><span class=p>,</span> <span class=s2>&#34;完整性&#34;</span><span class=p>,</span> <span class=s2>&#34;专业性&#34;</span><span class=p>,</span> <span class=s2>&#34;安全性&#34;</span><span class=p>,</span> <span class=s2>&#34;可理解性&#34;</span><span class=p>,</span> <span class=s2>&#34;总分&#34;</span><span class=p>]:</span>
</span></span><span class=line><span class=cl>        <span class=n>avg_score</span> <span class=o>=</span> <span class=n>df</span><span class=p>[</span><span class=n>metric</span><span class=p>]</span><span class=o>.</span><span class=n>mean</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=n>metric</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>avg_score</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>get_model_response</span><span class=p>(</span><span class=n>question</span><span class=p>:</span> <span class=nb>str</span><span class=p>,</span> <span class=n>model_name</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    调用部署的模型获取回答
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 假设已经用 vLLM 部署在本地</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>base_url</span><span class=o>=</span><span class=s2>&#34;http://localhost:8000/v1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;EMPTY&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=n>model_name</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;你是一名专业的法律顾问。&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 运行评估</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 对比实验：Base Model vs Fine-tuned Model</span>
</span></span><span class=line><span class=cl>    <span class=n>batch_evaluate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>test_file</span><span class=o>=</span><span class=s2>&#34;data/law_test.json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>model_name</span><span class=o>=</span><span class=s2>&#34;law-glm&#34;</span><span class=p>,</span>  <span class=c1># 微调后的模型</span>
</span></span><span class=line><span class=cl>        <span class=n>output_file</span><span class=o>=</span><span class=s2>&#34;eval_results_lawglm.csv&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>batch_evaluate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>test_file</span><span class=o>=</span><span class=s2>&#34;data/law_test.json&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>model_name</span><span class=o>=</span><span class=s2>&#34;llama-3-8b-base&#34;</span><span class=p>,</span>  <span class=c1># 基础模型</span>
</span></span><span class=line><span class=cl>        <span class=n>output_file</span><span class=o>=</span><span class=s2>&#34;eval_results_base.csv&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span></span></span></code></pre></div><h3 id=43-预期结果示例>4.3 预期结果示例<a class=anchor href=#43-%e9%a2%84%e6%9c%9f%e7%bb%93%e6%9e%9c%e7%a4%ba%e4%be%8b>#</a></h3><table><thead><tr><th>模型</th><th>准确性</th><th>完整性</th><th>专业性</th><th>安全性</th><th>可理解性</th><th>总分</th></tr></thead><tbody><tr><td>Llama-3-8B (Base)</td><td>6.2</td><td>5.8</td><td>5.5</td><td>7.5</td><td>6.0</td><td>31.0</td></tr><tr><td><strong>LawGLM (微调后)</strong></td><td><strong>8.7</strong></td><td><strong>8.4</strong></td><td><strong>8.9</strong></td><td><strong>9.2</strong></td><td><strong>8.1</strong></td><td><strong>43.3</strong></td></tr></tbody></table><p><strong>提升幅度</strong>: 40% (平均每项提升 2-3 分)</p><hr><h2 id=5-step-5-生产级部署-vllm>5. Step 5: 生产级部署 (vLLM)<a class=anchor href=#5-step-5-%e7%94%9f%e4%ba%a7%e7%ba%a7%e9%83%a8%e7%bd%b2-vllm>#</a></h2><p>使用 <strong>vLLM</strong> 部署合并后的模型。vLLM 通过 PagedAttention 技术，吞吐量比 Hugging Face Transformers 提升 <strong>10-20 倍</strong>。</p><h3 id=51-安装-vllm>5.1 安装 vLLM<a class=anchor href=#51-%e5%ae%89%e8%a3%85-vllm>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install vllm
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 如果使用新版 CUDA（12.4+）</span>
</span></span><span class=line><span class=cl>pip install vllm-flash-attn</span></span></code></pre></div><h3 id=52-启动-api-server>5.2 启动 API Server<a class=anchor href=#52-%e5%90%af%e5%8a%a8-api-server>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 方式1：标准启动（推荐）</span>
</span></span><span class=line><span class=cl>python -m vllm.entrypoints.openai.api_server <span class=se>\
</span></span></span><span class=line><span class=cl>    --model models/LawGLM-7B <span class=se>\
</span></span></span><span class=line><span class=cl>    --served-model-name law-glm <span class=se>\
</span></span></span><span class=line><span class=cl>    --host 0.0.0.0 <span class=se>\
</span></span></span><span class=line><span class=cl>    --port <span class=m>8000</span> <span class=se>\
</span></span></span><span class=line><span class=cl>    --max-model-len <span class=m>4096</span> <span class=se>\
</span></span></span><span class=line><span class=cl>    --gpu-memory-utilization 0.9 <span class=se>\
</span></span></span><span class=line><span class=cl>    --tensor-parallel-size <span class=m>1</span> <span class=se>\
</span></span></span><span class=line><span class=cl>    --trust-remote-code
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方式2：多卡部署（2x GPU）</span>
</span></span><span class=line><span class=cl>python -m vllm.entrypoints.openai.api_server <span class=se>\
</span></span></span><span class=line><span class=cl>    --model models/LawGLM-7B <span class=se>\
</span></span></span><span class=line><span class=cl>    --served-model-name law-glm <span class=se>\
</span></span></span><span class=line><span class=cl>    --tensor-parallel-size <span class=m>2</span> <span class=se>\
</span></span></span><span class=line><span class=cl>    --gpu-memory-utilization 0.95
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 方式3：量化部署（节省显存，略降精度）</span>
</span></span><span class=line><span class=cl>python -m vllm.entrypoints.openai.api_server <span class=se>\
</span></span></span><span class=line><span class=cl>    --model models/LawGLM-7B <span class=se>\
</span></span></span><span class=line><span class=cl>    --served-model-name law-glm <span class=se>\
</span></span></span><span class=line><span class=cl>    --quantization awq <span class=se>\ </span> <span class=c1># 或 gptq、fp8</span>
</span></span><span class=line><span class=cl>    --max-model-len <span class=m>8192</span></span></span></code></pre></div><h3 id=53-性能基准测试>5.3 性能基准测试<a class=anchor href=#53-%e6%80%a7%e8%83%bd%e5%9f%ba%e5%87%86%e6%b5%8b%e8%af%95>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 安装压测工具</span>
</span></span><span class=line><span class=cl>pip install locust
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 创建压测脚本 locustfile.py</span>
</span></span><span class=line><span class=cl>cat &gt; locustfile.py <span class=s>&lt;&lt;&#39;EOF&#39;
</span></span></span><span class=line><span class=cl><span class=s>from locust import HttpUser, task, between
</span></span></span><span class=line><span class=cl><span class=s>import json
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>class LawGLMUser(HttpUser):
</span></span></span><span class=line><span class=cl><span class=s>    wait_time = between(1, 3)
</span></span></span><span class=line><span class=cl><span class=s>
</span></span></span><span class=line><span class=cl><span class=s>    @task
</span></span></span><span class=line><span class=cl><span class=s>    def chat_completion(self):
</span></span></span><span class=line><span class=cl><span class=s>        self.client.post(
</span></span></span><span class=line><span class=cl><span class=s>            &#34;/v1/chat/completions&#34;,
</span></span></span><span class=line><span class=cl><span class=s>            json={
</span></span></span><span class=line><span class=cl><span class=s>                &#34;model&#34;: &#34;law-glm&#34;,
</span></span></span><span class=line><span class=cl><span class=s>                &#34;messages&#34;: [
</span></span></span><span class=line><span class=cl><span class=s>                    {&#34;role&#34;: &#34;user&#34;, &#34;content&#34;: &#34;解释民法典第一条&#34;}
</span></span></span><span class=line><span class=cl><span class=s>                ],
</span></span></span><span class=line><span class=cl><span class=s>                &#34;max_tokens&#34;: 256,
</span></span></span><span class=line><span class=cl><span class=s>                &#34;temperature&#34;: 0.7
</span></span></span><span class=line><span class=cl><span class=s>            },
</span></span></span><span class=line><span class=cl><span class=s>            headers={&#34;Content-Type&#34;: &#34;application/json&#34;}
</span></span></span><span class=line><span class=cl><span class=s>        )
</span></span></span><span class=line><span class=cl><span class=s>EOF</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 启动压测（100并发用户，持续60秒）</span>
</span></span><span class=line><span class=cl>locust -f locustfile.py --host http://localhost:8000 --users <span class=m>100</span> --spawn-rate <span class=m>10</span> --run-time 60s --headless</span></span></code></pre></div><p><strong>预期性能</strong>（单卡 A100）：</p><ul><li><strong>吞吐量</strong>: ~300 tokens/s（批处理）</li><li><strong>延迟</strong>: P50 = 200ms, P99 = 800ms</li><li><strong>并发</strong>: 支持 50+ 并发请求</li></ul><h3 id=54-python-客户端调用>5.4 Python 客户端调用<a class=anchor href=#54-python-%e5%ae%a2%e6%88%b7%e7%ab%af%e8%b0%83%e7%94%a8>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>time</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 初始化客户端</span>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;EMPTY&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>base_url</span><span class=o>=</span><span class=s2>&#34;http://localhost:8000/v1&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>chat_with_law_glm</span><span class=p>(</span><span class=n>user_message</span><span class=p>:</span> <span class=nb>str</span><span class=p>)</span> <span class=o>-&gt;</span> <span class=nb>str</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    与 LawGLM 对话
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>start_time</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;law-glm&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;你是一名专业的法律顾问，请基于中国法律提供建议。&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>user_message</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>top_p</span><span class=o>=</span><span class=mf>0.9</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stream</span><span class=o>=</span><span class=kc>False</span>  <span class=c1># 改为 True 可启用流式输出</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>elapsed</span> <span class=o>=</span> <span class=n>time</span><span class=o>.</span><span class=n>time</span><span class=p>()</span> <span class=o>-</span> <span class=n>start_time</span>
</span></span><span class=line><span class=cl>    <span class=n>answer</span> <span class=o>=</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;回答耗时: </span><span class=si>{</span><span class=n>elapsed</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2>s&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>answer</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试案例</span>
</span></span><span class=line><span class=cl><span class=n>test_cases</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;房东无故不退押金，我该怎么办？&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;解释《民法典》第704条&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;员工被公司无理由辞退，如何维权？&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;网购商品有质量问题，商家拒绝退货怎么办？&#34;</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>question</span> <span class=ow>in</span> <span class=n>test_cases</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;问题: </span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>answer</span> <span class=o>=</span> <span class=n>chat_with_law_glm</span><span class=p>(</span><span class=n>question</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;回答:</span><span class=se>\n</span><span class=si>{</span><span class=n>answer</span><span class=si>}</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=55-流式输出streaming>5.5 流式输出（Streaming）<a class=anchor href=#55-%e6%b5%81%e5%bc%8f%e8%be%93%e5%87%bastreaming>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>chat_with_streaming</span><span class=p>(</span><span class=n>user_message</span><span class=p>:</span> <span class=nb>str</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    流式输出，实时显示生成内容
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>stream</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;law-glm&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;system&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;你是一名专业的法律顾问。&#34;</span><span class=p>},</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span><span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span> <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=n>user_message</span><span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>temperature</span><span class=o>=</span><span class=mf>0.7</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>stream</span><span class=o>=</span><span class=kc>True</span>  <span class=c1># 启用流式输出</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;AI:&#34;</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=s2>&#34; &#34;</span><span class=p>,</span> <span class=n>flush</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>chunk</span> <span class=ow>in</span> <span class=n>stream</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>chunk</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>delta</span><span class=o>.</span><span class=n>content</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=n>chunk</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>delta</span><span class=o>.</span><span class=n>content</span><span class=p>,</span> <span class=n>end</span><span class=o>=</span><span class=s2>&#34;&#34;</span><span class=p>,</span> <span class=n>flush</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>()</span>  <span class=c1># 换行</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试</span>
</span></span><span class=line><span class=cl><span class=n>chat_with_streaming</span><span class=p>(</span><span class=s2>&#34;解释不可抗力条款&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=56-docker-容器化部署>5.6 Docker 容器化部署<a class=anchor href=#56-docker-%e5%ae%b9%e5%99%a8%e5%8c%96%e9%83%a8%e7%bd%b2>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-dockerfile data-lang=dockerfile><span class=line><span class=cl><span class=c># Dockerfile</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>FROM</span><span class=w> </span><span class=s>vllm/vllm-openai:latest</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 复制模型（或挂载卷）</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>COPY</span> models/LawGLM-7B /models/LawGLM-7B<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=c># 设置环境变量</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>MODEL_NAME</span><span class=o>=</span>/models/LawGLM-7B<span class=err>
</span></span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>HOST</span><span class=o>=</span><span class=m>0</span>.0.0.0<span class=err>
</span></span></span><span class=line><span class=cl><span class=k>ENV</span> <span class=nv>PORT</span><span class=o>=</span><span class=m>8000</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c># 启动命令</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=k>CMD</span> <span class=o>[</span><span class=s2>&#34;python&#34;</span>, <span class=s2>&#34;-m&#34;</span>, <span class=s2>&#34;vllm.entrypoints.openai.api_server&#34;</span>, <span class=se>\
</span></span></span><span class=line><span class=cl>     <span class=s2>&#34;--model&#34;</span>, <span class=s2>&#34;</span><span class=nv>$MODEL_NAME</span><span class=s2>&#34;</span>, <span class=se>\
</span></span></span><span class=line><span class=cl>     <span class=s2>&#34;--host&#34;</span>, <span class=s2>&#34;</span><span class=nv>$HOST</span><span class=s2>&#34;</span>, <span class=se>\
</span></span></span><span class=line><span class=cl>     <span class=s2>&#34;--port&#34;</span>, <span class=s2>&#34;</span><span class=nv>$PORT</span><span class=s2>&#34;</span>, <span class=se>\
</span></span></span><span class=line><span class=cl>     <span class=s2>&#34;--gpu-memory-utilization&#34;</span>, <span class=s2>&#34;0.9&#34;</span><span class=o>]</span></span></span></code></pre></div><p>启动容器：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 构建镜像</span>
</span></span><span class=line><span class=cl>docker build -t law-glm:latest .
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 运行容器（挂载模型目录）</span>
</span></span><span class=line><span class=cl>docker run -d <span class=se>\
</span></span></span><span class=line><span class=cl>    --gpus all <span class=se>\
</span></span></span><span class=line><span class=cl>    -v <span class=k>$(</span><span class=nb>pwd</span><span class=k>)</span>/models:/models <span class=se>\
</span></span></span><span class=line><span class=cl>    -p 8000:8000 <span class=se>\
</span></span></span><span class=line><span class=cl>    --name law-glm-server <span class=se>\
</span></span></span><span class=line><span class=cl>    law-glm:latest</span></span></code></pre></div><hr><h2 id=6-本章小结工程化最佳实践>6. 本章小结：工程化最佳实践<a class=anchor href=#6-%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93%e5%b7%a5%e7%a8%8b%e5%8c%96%e6%9c%80%e4%bd%b3%e5%ae%9e%e8%b7%b5>#</a></h2><p>通过 <strong>LawGLM</strong> 项目，我们完整实践了垂直领域 LLM 的全流程开发：</p><h3 id=61-技术栈总结>6.1 技术栈总结<a class=anchor href=#61-%e6%8a%80%e6%9c%af%e6%a0%88%e6%80%bb%e7%bb%93>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌─────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│               LawGLM 技术架构                            │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│ 数据层    │ Python + Regex + Pandas                     │
</span></span><span class=line><span class=cl>│           │ 数据清洗、格式化、质量控制                     │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│ 训练层    │ LLaMA-Factory + QLoRA + DeepSpeed           │
</span></span><span class=line><span class=cl>│           │ 单卡24GB训练7B模型，训练时间8-12小时            │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│ 评估层    │ GPT-4 as Judge + 多维度评分                  │
</span></span><span class=line><span class=cl>│           │ 准确性、完整性、专业性、安全性、可理解性          │
</span></span><span class=line><span class=cl>├─────────────────────────────────────────────────────────┤
</span></span><span class=line><span class=cl>│ 部署层    │ vLLM + OpenAI-Compatible API                │
</span></span><span class=line><span class=cl>│           │ 吞吐量300+ tokens/s，支持50+并发              │
</span></span><span class=line><span class=cl>└─────────────────────────────────────────────────────────┘</span></span></code></pre></div><h3 id=62-核心经验总结>6.2 核心经验总结<a class=anchor href=#62-%e6%a0%b8%e5%bf%83%e7%bb%8f%e9%aa%8c%e6%80%bb%e7%bb%93>#</a></h3><ol><li><p><strong>数据是核心</strong> (70% 精力)</p><ul><li>高质量数据 > 大规模数据</li><li>多样化问法（数据增强）提升泛化能力</li><li>严格的质量控制（长度、敏感词、格式）</li></ul></li><li><p><strong>工具是加速器</strong> (20% 精力)</p><ul><li>LLaMA-Factory：屏蔽底层细节，专注业务逻辑</li><li>QLoRA：在消费级显卡上训练大模型</li><li>vLLM：生产级推理性能</li></ul></li><li><p><strong>评估是保障</strong> (10% 精力)</p><ul><li>不能只看 Loss，必须实际测试</li><li>GPT-4 评估降低人工成本</li><li>对比基线模型（Base Model）量化提升</li></ul></li></ol><h3 id=63-生产环境检查清单>6.3 生产环境检查清单<a class=anchor href=#63-%e7%94%9f%e4%ba%a7%e7%8e%af%e5%a2%83%e6%a3%80%e6%9f%a5%e6%b8%85%e5%8d%95>#</a></h3><p>部署到生产前，确保完成以下检查：</p><ul><li><input disabled type=checkbox> <strong>安全性</strong>：添加内容过滤层（Llama Guard / Azure Content Safety）</li><li><input disabled type=checkbox> <strong>监控</strong>：集成 Prometheus + Grafana 监控 QPS/Latency</li><li><input disabled type=checkbox> <strong>限流</strong>：使用 Redis 限制单用户请求频率</li><li><input disabled type=checkbox> <strong>日志</strong>：记录所有请求/响应，用于持续优化</li><li><input disabled type=checkbox> <strong>备份</strong>：模型文件和数据库定期备份</li><li><input disabled type=checkbox> <strong>成本</strong>：评估 GPU 成本，考虑按需扩缩容（K8s）</li></ul><h3 id=64-下一步优化方向>6.4 下一步优化方向<a class=anchor href=#64-%e4%b8%8b%e4%b8%80%e6%ad%a5%e4%bc%98%e5%8c%96%e6%96%b9%e5%90%91>#</a></h3><ol><li><strong>数据迭代</strong>：收集生产环境的 Bad Case，持续标注训练</li><li><strong>RAG 增强</strong>：集成向量数据库（Milvus），检索最新法律条文</li><li><strong>多轮对话</strong>：增加对话历史管理，支持复杂案件咨询</li><li><strong>专家系统</strong>：结合规则引擎（Drools），提升准确性</li><li><strong>多模态</strong>：支持上传合同 PDF，自动提取关键条款</li></ol><hr><p><strong>核心理念</strong>：这套 <code>数据工程 -> LLaMA-Factory 微调 -> GPT-4 评估 -> vLLM 部署</code> 的流程，是目前<strong>最成熟、最高效</strong>的垂直领域 LLM 开发范式。</p></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第4章 DeepSpeed分布式训练</span>
</a></span><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/ class="flex align-center"><span>第1章 模型压缩与推理加速</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#项目目标>项目目标</a></li><li><a href=#技术栈>技术栈</a></li><li><a href=#1-step-1-数据准备-data-engineering>1. Step 1: 数据准备 (Data Engineering)</a><ul><li><a href=#11-数据源规划>1.1 数据源规划</a></li><li><a href=#12-数据清洗脚本>1.2 数据清洗脚本</a><ul><li><a href=#121-法律条文处理>1.2.1 法律条文处理</a></li><li><a href=#122-判例问答对构造>1.2.2 判例问答对构造</a></li><li><a href=#123-数据质量控制>1.2.3 数据质量控制</a></li></ul></li><li><a href=#12-数据注册>1.2 数据注册</a></li></ul></li><li><a href=#2-step-2-模型微调-qlora-sft>2. Step 2: 模型微调 (QLoRA SFT)</a><ul><li><a href=#21-配置文件-law_finetuneyaml>2.1 配置文件 <code>law_finetune.yaml</code></a></li><li><a href=#22-启动训练>2.2 启动训练</a></li><li><a href=#23-训练监控>2.3 训练监控</a></li></ul></li><li><a href=#3-step-3-合并与导出>3. Step 3: 合并与导出</a></li><li><a href=#4-step-4-性能评估-llm-as-a-judge>4. Step 4: 性能评估 (LLM-as-a-Judge)</a><ul><li><a href=#41-评估维度设计>4.1 评估维度设计</a></li><li><a href=#42-完整评估脚本>4.2 完整评估脚本</a></li><li><a href=#43-预期结果示例>4.3 预期结果示例</a></li></ul></li><li><a href=#5-step-5-生产级部署-vllm>5. Step 5: 生产级部署 (vLLM)</a><ul><li><a href=#51-安装-vllm>5.1 安装 vLLM</a></li><li><a href=#52-启动-api-server>5.2 启动 API Server</a></li><li><a href=#53-性能基准测试>5.3 性能基准测试</a></li><li><a href=#54-python-客户端调用>5.4 Python 客户端调用</a></li><li><a href=#55-流式输出streaming>5.5 流式输出（Streaming）</a></li><li><a href=#56-docker-容器化部署>5.6 Docker 容器化部署</a></li></ul></li><li><a href=#6-本章小结工程化最佳实践>6. 本章小结：工程化最佳实践</a><ul><li><a href=#61-技术栈总结>6.1 技术栈总结</a></li><li><a href=#62-核心经验总结>6.2 核心经验总结</a></li><li><a href=#63-生产环境检查清单>6.3 生产环境检查清单</a></li><li><a href=#64-下一步优化方向>6.4 下一步优化方向</a></li></ul></li></ul></nav></div></aside></main></body></html>