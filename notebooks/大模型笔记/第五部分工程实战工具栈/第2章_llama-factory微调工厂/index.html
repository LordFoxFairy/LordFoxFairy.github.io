<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="第2章：LLaMA-Factory 微调工厂# 项目地址：https://github.com/hiyouga/LLaMA-Factory
本章定位：从手写 PyTorch 进阶到“流水线工厂”。学会利用 LLaMA-Factory 进行零代码（WebUI）和低代码（CLI）的高效微调，涵盖从 SFT 到模型导出（Merge）的全流程。
目录# 1. 为什么选择 LLaMA-Factory？ 2. 环境搭建与 Unsloth 加速 2.1 标准安装 2.2 开启 Unsloth 极速模式（推荐） 3. 数据工程：Dataset Registration 3.1 数据格式标准 (Alpaca vs ShareGPT) 3.2 注册自定义数据集 (dataset_info.json) 4. 可视化微调：WebUI 全流程 4.1 启动与界面概览 4.2 训练参数配置详解 4.3 训练监控与评估 5. 生产化：从 WebUI 到 CLI 自动化 5.1 导出 YAML 配置文件 5.2 命令行启动训练 5.3 多机多卡分布式配置 6. 模型导出与合并 本章小结 1. 为什么选择 LLaMA-Factory？# 在 LLaMA-Factory 出现之前，微调一个模型需要自己手写 PEFT 代码、处理复杂的 Padding、适配 Flash Attention。LLaMA-Factory 解决了以下核心痛点：
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第2章 LLaMA-Factory微调工厂"><meta property="og:description" content="第2章：LLaMA-Factory 微调工厂# 项目地址：https://github.com/hiyouga/LLaMA-Factory
本章定位：从手写 PyTorch 进阶到“流水线工厂”。学会利用 LLaMA-Factory 进行零代码（WebUI）和低代码（CLI）的高效微调，涵盖从 SFT 到模型导出（Merge）的全流程。
目录# 1. 为什么选择 LLaMA-Factory？ 2. 环境搭建与 Unsloth 加速 2.1 标准安装 2.2 开启 Unsloth 极速模式（推荐） 3. 数据工程：Dataset Registration 3.1 数据格式标准 (Alpaca vs ShareGPT) 3.2 注册自定义数据集 (dataset_info.json) 4. 可视化微调：WebUI 全流程 4.1 启动与界面概览 4.2 训练参数配置详解 4.3 训练监控与评估 5. 生产化：从 WebUI 到 CLI 自动化 5.1 导出 YAML 配置文件 5.2 命令行启动训练 5.3 多机多卡分布式配置 6. 模型导出与合并 本章小结 1. 为什么选择 LLaMA-Factory？# 在 LLaMA-Factory 出现之前，微调一个模型需要自己手写 PEFT 代码、处理复杂的 Padding、适配 Flash Attention。LLaMA-Factory 解决了以下核心痛点："><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第2章 LLaMA-Factory微调工厂"><meta itemprop=description content="第2章：LLaMA-Factory 微调工厂# 项目地址：https://github.com/hiyouga/LLaMA-Factory
本章定位：从手写 PyTorch 进阶到“流水线工厂”。学会利用 LLaMA-Factory 进行零代码（WebUI）和低代码（CLI）的高效微调，涵盖从 SFT 到模型导出（Merge）的全流程。
目录# 1. 为什么选择 LLaMA-Factory？ 2. 环境搭建与 Unsloth 加速 2.1 标准安装 2.2 开启 Unsloth 极速模式（推荐） 3. 数据工程：Dataset Registration 3.1 数据格式标准 (Alpaca vs ShareGPT) 3.2 注册自定义数据集 (dataset_info.json) 4. 可视化微调：WebUI 全流程 4.1 启动与界面概览 4.2 训练参数配置详解 4.3 训练监控与评估 5. 生产化：从 WebUI 到 CLI 自动化 5.1 导出 YAML 配置文件 5.2 命令行启动训练 5.3 多机多卡分布式配置 6. 模型导出与合并 本章小结 1. 为什么选择 LLaMA-Factory？# 在 LLaMA-Factory 出现之前，微调一个模型需要自己手写 PEFT 代码、处理复杂的 Padding、适配 Flash Attention。LLaMA-Factory 解决了以下核心痛点："><meta itemprop=wordCount content="616"><title>第2章 LLaMA-Factory微调工厂 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle checked>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle checked>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/ class=active>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第2章 LLaMA-Factory微调工厂</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#1-为什么选择-llama-factory>1. 为什么选择 LLaMA-Factory？</a></li><li><a href=#2-环境搭建与-unsloth-加速>2. 环境搭建与 Unsloth 加速</a><ul><li><a href=#21-标准安装>2.1 标准安装</a></li><li><a href=#22-开启-unsloth-极速模式推荐>2.2 开启 Unsloth 极速模式（推荐）</a></li></ul></li><li><a href=#3-数据工程dataset-registration>3. 数据工程：Dataset Registration</a><ul><li><a href=#31-数据格式标准-alpaca-vs-sharegpt>3.1 数据格式标准 (Alpaca vs ShareGPT)</a></li><li><a href=#32-注册自定义数据集-dataset_infojson>3.2 注册自定义数据集 (<code>dataset_info.json</code>)</a></li></ul></li><li><a href=#4-可视化微调webui-全流程>4. 可视化微调：WebUI 全流程</a><ul><li><a href=#41-启动与界面概览>4.1 启动与界面概览</a></li><li><a href=#42-训练参数配置详解>4.2 训练参数配置详解</a></li><li><a href=#43-训练监控与评估>4.3 训练监控与评估</a></li></ul></li><li><a href=#5-生产化从-webui-到-cli-自动化>5. 生产化：从 WebUI 到 CLI 自动化</a><ul><li><a href=#51-导出-yaml-配置文件>5.1 导出 YAML 配置文件</a></li><li><a href=#52-命令行启动训练>5.2 命令行启动训练</a></li><li><a href=#53-多机多卡分布式配置>5.3 多机多卡分布式配置</a></li></ul></li><li><a href=#6-模型导出与合并>6. 模型导出与合并</a></li><li><a href=#本章小结>本章小结</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第2章llama-factory-微调工厂>第2章：LLaMA-Factory 微调工厂<a class=anchor href=#%e7%ac%ac2%e7%ab%a0llama-factory-%e5%be%ae%e8%b0%83%e5%b7%a5%e5%8e%82>#</a></h1><blockquote class=book-hint><p><strong>项目地址</strong>：<a href=https://github.com/hiyouga/LLaMA-Factory>https://github.com/hiyouga/LLaMA-Factory</a></p><p><strong>本章定位</strong>：从手写 PyTorch 进阶到“流水线工厂”。学会利用 LLaMA-Factory 进行零代码（WebUI）和低代码（CLI）的高效微调，涵盖从 SFT 到模型导出（Merge）的全流程。</p></blockquote><hr><h2 id=目录>目录<a class=anchor href=#%e7%9b%ae%e5%bd%95>#</a></h2><ul><li><a href=#1-%e4%b8%ba%e4%bb%80%e4%b9%88%e9%80%89%e6%8b%a9-llama-factory>1. 为什么选择 LLaMA-Factory？</a></li><li><a href=#2-%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba%e4%b8%8e-unsloth-%e5%8a%a0%e9%80%9f>2. 环境搭建与 Unsloth 加速</a><ul><li><a href=#21-%e6%a0%87%e5%87%86%e5%ae%89%e8%a3%85>2.1 标准安装</a></li><li><a href=#22-%e5%bc%80%e5%90%af-unsloth-%e6%9e%81%e9%80%9f%e6%a8%a1%e5%bc%8f%e6%8e%a8%e8%8d%90>2.2 开启 Unsloth 极速模式（推荐）</a></li></ul></li><li><a href=#3-%e6%95%b0%e6%8d%ae%e5%b7%a5%e7%a8%8bdataset-registration>3. 数据工程：Dataset Registration</a><ul><li><a href=#31-%e6%95%b0%e6%8d%ae%e6%a0%bc%e5%bc%8f%e6%a0%87%e5%87%86-alpaca-vs-sharegpt>3.1 数据格式标准 (Alpaca vs ShareGPT)</a></li><li><a href=#32-%e6%b3%a8%e5%86%8c%e8%87%aa%e5%ae%9a%e4%b9%89%e6%95%b0%e6%8d%ae%e9%9b%86-dataset_infojson>3.2 注册自定义数据集 (<code>dataset_info.json</code>)</a></li></ul></li><li><a href=#4-%e5%8f%af%e8%a7%86%e5%8c%96%e5%be%ae%e8%b0%83webui-%e5%85%a8%e6%b5%81%e7%a8%8b>4. 可视化微调：WebUI 全流程</a><ul><li><a href=#41-%e5%90%af%e5%8a%a8%e4%b8%8e%e7%95%8c%e9%9d%a2%e6%a6%82%e8%a7%88>4.1 启动与界面概览</a></li><li><a href=#42-%e8%ae%ad%e7%bb%83%e5%8f%82%e6%95%b0%e9%85%8d%e7%bd%ae%e8%af%a6%e8%a7%a3>4.2 训练参数配置详解</a></li><li><a href=#43-%e8%ae%ad%e7%bb%83%e7%9b%91%e6%8e%a7%e4%b8%8e%e8%af%84%e4%bc%b0>4.3 训练监控与评估</a></li></ul></li><li><a href=#5-%e7%94%9f%e4%ba%a7%e5%8c%96%e4%bb%8e-webui-%e5%88%b0-cli-%e8%87%aa%e5%8a%a8%e5%8c%96>5. 生产化：从 WebUI 到 CLI 自动化</a><ul><li><a href=#51-%e5%af%bc%e5%87%ba-yaml-%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6>5.1 导出 YAML 配置文件</a></li><li><a href=#52-%e5%91%bd%e4%bb%a4%e8%a1%8c%e5%90%af%e5%8a%a8%e8%ae%ad%e7%bb%83>5.2 命令行启动训练</a></li><li><a href=#53-%e5%a4%9a%e6%9c%ba%e5%a4%9a%e5%8d%a1%e5%88%86%e5%b8%83%e5%bc%8f%e9%85%8d%e7%bd%ae>5.3 多机多卡分布式配置</a></li></ul></li><li><a href=#6-%e6%a8%a1%e5%9e%8b%e5%af%bc%e5%87%ba%e4%b8%8e%e5%90%88%e5%b9%b6>6. 模型导出与合并</a></li><li><a href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>本章小结</a></li></ul><hr><h2 id=1-为什么选择-llama-factory>1. 为什么选择 LLaMA-Factory？<a class=anchor href=#1-%e4%b8%ba%e4%bb%80%e4%b9%88%e9%80%89%e6%8b%a9-llama-factory>#</a></h2><p>在 LLaMA-Factory 出现之前，微调一个模型需要自己手写 PEFT 代码、处理复杂的 Padding、适配 Flash Attention。LLaMA-Factory 解决了以下<strong>核心痛点</strong>：</p><ol><li><strong>多模型适配</strong>：一套代码支持 Llama-3, Qwen-2, Mistral, Gemma 等 100+ 模型。</li><li><strong>多算法集成</strong>：无缝切换 Full, LoRA, QLoRA, DoRA, PPO, DPO。</li><li><strong>多硬件兼容</strong>：自动适配 DeepSpeed (ZeRO), Unsloth (Triton优化), FlashAttention-2。</li><li><strong>零代码门槛</strong>：提供 WebUI 界面，小白也能点点鼠标跑通微调。</li></ol><hr><h2 id=2-环境搭建与-unsloth-加速>2. 环境搭建与 Unsloth 加速<a class=anchor href=#2-%e7%8e%af%e5%a2%83%e6%90%ad%e5%bb%ba%e4%b8%8e-unsloth-%e5%8a%a0%e9%80%9f>#</a></h2><h3 id=21-标准安装>2.1 标准安装<a class=anchor href=#21-%e6%a0%87%e5%87%86%e5%ae%89%e8%a3%85>#</a></h3><p>推荐使用 PyTorch 2.4+ 和 CUDA 12.1+ 环境。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 1. 克隆仓库</span>
</span></span><span class=line><span class=cl>git clone --depth <span class=m>1</span> https://github.com/hiyouga/LLaMA-Factory.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> LLaMA-Factory
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 安装依赖 (推荐先创建 conda 环境)</span>
</span></span><span class=line><span class=cl><span class=c1># [metrics] 用于评估，[bitsandbytes] 用于量化</span>
</span></span><span class=line><span class=cl>pip install -e <span class=s2>&#34;.[torch,metrics,bitsandbytes]&#34;</span></span></span></code></pre></div><h3 id=22-开启-unsloth-极速模式推荐>2.2 开启 Unsloth 极速模式（推荐）<a class=anchor href=#22-%e5%bc%80%e5%90%af-unsloth-%e6%9e%81%e9%80%9f%e6%a8%a1%e5%bc%8f%e6%8e%a8%e8%8d%90>#</a></h3><p><strong>Unsloth</strong> 是当前最强的微调加速库，通过重写 Triton 内核，能实现：</p><ul><li>训练速度提升 <strong>2-5 倍</strong></li><li>显存占用减少 <strong>60%</strong> (单张 T4/4060 也能跑 Llama-3-8B)</li></ul><p>安装 Unsloth (需根据 CUDA 版本选择，以下以 CUDA 12.1 为例)：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>pip install <span class=s2>&#34;unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git&#34;</span></span></span></code></pre></div><blockquote class=book-hint><p><strong>注意</strong>：Windows 用户请参考 <a href=https://github.com/unslothai/unsloth#installation-instructions>Unsloth 官方指南</a> 使用 WSL2 安装。</p></blockquote><hr><h2 id=3-数据工程dataset-registration>3. 数据工程：Dataset Registration<a class=anchor href=#3-%e6%95%b0%e6%8d%ae%e5%b7%a5%e7%a8%8bdataset-registration>#</a></h2><p><strong>这是新手最容易卡壳的地方</strong>。LLaMA-Factory 不直接读取 raw text，必须先在 <code>dataset_info.json</code> 中注册。</p><h3 id=31-数据格式标准-alpaca-vs-sharegpt>3.1 数据格式标准 (Alpaca vs ShareGPT)<a class=anchor href=#31-%e6%95%b0%e6%8d%ae%e6%a0%bc%e5%bc%8f%e6%a0%87%e5%87%86-alpaca-vs-sharegpt>#</a></h3><p>准备你的数据 <code>my_data.json</code>，推荐以下两种格式：</p><p><strong>格式 A：Alpaca 格式（适合单轮指令）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;请解释什么是量子纠缠&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;input&#34;</span><span class=p>:</span> <span class=s2>&#34;&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;output&#34;</span><span class=p>:</span> <span class=s2>&#34;量子纠缠是量子力学中的一种现象...&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;instruction&#34;</span><span class=p>:</span> <span class=s2>&#34;将以下文本翻译成英文&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;input&#34;</span><span class=p>:</span> <span class=s2>&#34;你好，世界&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;output&#34;</span><span class=p>:</span> <span class=s2>&#34;Hello, World&#34;</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span></span></span></code></pre></div><p><strong>格式 B：ShareGPT 格式（适合多轮对话）</strong> -> <strong>推荐</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>[</span>
</span></span><span class=line><span class=cl>  <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;conversations&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span> <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;human&#34;</span><span class=p>,</span> <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;你好&#34;</span> <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span> <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;gpt&#34;</span><span class=p>,</span> <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;你好！有什么我可以帮你的吗？&#34;</span> <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span> <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;human&#34;</span><span class=p>,</span> <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;写首诗&#34;</span> <span class=p>},</span>
</span></span><span class=line><span class=cl>      <span class=p>{</span> <span class=nt>&#34;from&#34;</span><span class=p>:</span> <span class=s2>&#34;gpt&#34;</span><span class=p>,</span> <span class=nt>&#34;value&#34;</span><span class=p>:</span> <span class=s2>&#34;明月几时有...&#34;</span> <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>]</span></span></span></code></pre></div><h3 id=32-注册自定义数据集-dataset_infojson>3.2 注册自定义数据集 (<code>dataset_info.json</code>)<a class=anchor href=#32-%e6%b3%a8%e5%86%8c%e8%87%aa%e5%ae%9a%e4%b9%89%e6%95%b0%e6%8d%ae%e9%9b%86-dataset_infojson>#</a></h3><p>打开 <code>data/dataset_info.json</code>，在末尾添加你的数据集配置：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;identity&#34;</span><span class=p>:</span> <span class=p>{</span> <span class=nt>&#34;file_name&#34;</span><span class=p>:</span> <span class=s2>&#34;identity.json&#34;</span> <span class=p>},</span>
</span></span><span class=line><span class=cl>  <span class=nt>&#34;my_custom_data&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;file_name&#34;</span><span class=p>:</span> <span class=s2>&#34;my_data.json&#34;</span><span class=p>,</span> <span class=c1>// 你的文件必须放在 data/ 目录下
</span></span></span><span class=line><span class=cl>    <span class=nt>&#34;formatting&#34;</span><span class=p>:</span> <span class=s2>&#34;sharegpt&#34;</span><span class=p>,</span>     <span class=c1>// 格式：alpaca 或 sharegpt
</span></span></span><span class=line><span class=cl>    <span class=nt>&#34;columns&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>      <span class=nt>&#34;messages&#34;</span><span class=p>:</span> <span class=s2>&#34;conversations&#34;</span> <span class=c1>// 映射你的字段名
</span></span></span><span class=line><span class=cl>    <span class=p>}</span>
</span></span><span class=line><span class=cl>  <span class=p>}</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><blockquote class=book-hint><p><strong>校验技巧</strong>：如果不确定格式对不对，直接运行 WebUI，在数据预览页查看是否能正确解析。</p></blockquote><hr><h2 id=4-可视化微调webui-全流程>4. 可视化微调：WebUI 全流程<a class=anchor href=#4-%e5%8f%af%e8%a7%86%e5%8c%96%e5%be%ae%e8%b0%83webui-%e5%85%a8%e6%b5%81%e7%a8%8b>#</a></h2><p>WebUI 是调试参数的最佳场所。调试满意后，我们再导出命令去后台运行。</p><h3 id=41-启动与界面概览>4.1 启动与界面概览<a class=anchor href=#41-%e5%90%af%e5%8a%a8%e4%b8%8e%e7%95%8c%e9%9d%a2%e6%a6%82%e8%a7%88>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 启动 WebUI</span>
</span></span><span class=line><span class=cl><span class=c1># 默认端口 7860</span>
</span></span><span class=line><span class=cl>llamafactory-cli webui</span></span></code></pre></div><blockquote class=book-hint><p>📸 <strong>[截图占位]：WebUI 主界面</strong>
<em>请截取浏览器打开 <code>localhost:7860</code> 后的界面，重点框出：语言切换（ZH）、模型选择区、微调方法区。</em></p></blockquote><p><strong>核心操作步骤</strong>：</p><ol><li><strong>语言</strong>：选择 <code>zh</code> (中文)。</li><li><strong>模型名称</strong>：选择 <code>LLaMA-3-8B-Instruct</code>。</li><li><strong>微调方法</strong>：选择 <code>LoRA</code>。</li><li><strong>适配器路径</strong>：(训练时留空，合并模型时才填)。</li></ol><h3 id=42-训练参数配置详解>4.2 训练参数配置详解<a class=anchor href=#42-%e8%ae%ad%e7%bb%83%e5%8f%82%e6%95%b0%e9%85%8d%e7%bd%ae%e8%af%a6%e8%a7%a3>#</a></h3><p>进入 <strong>[Train] (训练)</strong> 选项卡。</p><blockquote class=book-hint><p>📸 <strong>[截图占位]：训练参数配置面板</strong>
<em>重点展示：数据集选择、学习率、秩(Rank)、批处理大小。</em></p></blockquote><p><strong>关键参数指南</strong>：</p><table><thead><tr><th style=text-align:left>参数项</th><th style=text-align:left>推荐值</th><th style=text-align:left>说明</th></tr></thead><tbody><tr><td style=text-align:left><strong>数据集</strong></td><td style=text-align:left><code>my_custom_data</code></td><td style=text-align:left>刚刚注册的数据集。</td></tr><tr><td style=text-align:left><strong>截断长度 (Cutoff Len)</strong></td><td style=text-align:left><code>1024</code> ~ <code>4096</code></td><td style=text-align:left>根据显存决定。超长文本会被截断。</td></tr><tr><td style=text-align:left><strong>学习率 (Learning Rate)</strong></td><td style=text-align:left><code>5e-5</code> ~ <code>1e-4</code></td><td style=text-align:left>LoRA 通常需要比全量微调大一点的 LR。</td></tr><tr><td style=text-align:left><strong>轮数 (Epochs)</strong></td><td style=text-align:left><code>3</code> ~ <code>5</code></td><td style=text-align:left>数据少就多跑几轮，数据多跑1-2轮。</td></tr><tr><td style=text-align:left><strong>批处理大小 (Batch/GPU)</strong></td><td style=text-align:left><code>4</code> ~ <code>16</code></td><td style=text-align:left>显存不够就减小，开梯度累积。</td></tr><tr><td style=text-align:left><strong>梯度累积 (Grad Accum)</strong></td><td style=text-align:left><code>4</code></td><td style=text-align:left>它可以模拟大 Batch Size 效果。</td></tr><tr><td style=text-align:left><strong>LoRA 秩 (Rank)</strong></td><td style=text-align:left><code>8</code> ~ <code>64</code></td><td style=text-align:left>越大显存占用越高，拟合能力越强。一般 <code>16</code> 或 <code>32</code> 够用。</td></tr><tr><td style=text-align:left><strong>LoRA Alpha</strong></td><td style=text-align:left><code>16</code> 或 <code>32</code></td><td style=text-align:left>通常设为 Rank 的 1倍或 2倍。</td></tr><tr><td style=text-align:left><strong>Target Modules</strong></td><td style=text-align:left><code>all</code></td><td style=text-align:left>推荐微调所有线性层 (q,k,v,o,gate,up,down)，效果最好。</td></tr></tbody></table><h3 id=43-训练监控与评估>4.3 训练监控与评估<a class=anchor href=#43-%e8%ae%ad%e7%bb%83%e7%9b%91%e6%8e%a7%e4%b8%8e%e8%af%84%e4%bc%b0>#</a></h3><p>点击 <strong>[Start] (开始)</strong> 按钮后，右侧会显示 Loss 曲线。</p><blockquote class=book-hint><p>📸 <strong>[截图占位]：训练中的 Loss 曲线图</strong>
<em>展示 Loss 随 Step 下降的趋势。</em></p></blockquote><p><strong>如何判断训练正常？</strong></p><ul><li><strong>Loss 快速下降</strong>：初期从 2.0+ 降到 1.0 左右是正常的。</li><li><strong>Loss 震荡</strong>：如果 Loss 忽高忽低，尝试减小学习率。</li><li><strong>Loss 贴地飞行 (0.01)</strong>：可能是过拟合了，或者数据太少。</li></ul><hr><h2 id=5-生产化从-webui-到-cli-自动化>5. 生产化：从 WebUI 到 CLI 自动化<a class=anchor href=#5-%e7%94%9f%e4%ba%a7%e5%8c%96%e4%bb%8e-webui-%e5%88%b0-cli-%e8%87%aa%e5%8a%a8%e5%8c%96>#</a></h2><p>WebUI 最大的价值在于**“预览命令”**。在生产环境中，我们需要用命令行（CLI）来运行，以便挂后台 (<code>nohup</code>) 或多机运行。</p><h3 id=51-导出-yaml-配置文件>5.1 导出 YAML 配置文件<a class=anchor href=#51-%e5%af%bc%e5%87%ba-yaml-%e9%85%8d%e7%bd%ae%e6%96%87%e4%bb%b6>#</a></h3><p>在 WebUI 点击 <strong>[Preview Command] (预览命令)</strong>，或者直接 <strong>[Save Arguments]</strong> 保存配置。</p><p>推荐将配置保存为 <code>examples/train_lora.yaml</code>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c>### model</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>model_name_or_path</span><span class=p>:</span><span class=w> </span><span class=l>meta-llama/Meta-Llama-3-8B-Instruct</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c>### method</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>stage</span><span class=p>:</span><span class=w> </span><span class=l>sft</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>do_train</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>finetuning_type</span><span class=p>:</span><span class=w> </span><span class=l>lora</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lora_target</span><span class=p>:</span><span class=w> </span><span class=l>all</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c>### dataset</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>dataset</span><span class=p>:</span><span class=w> </span><span class=l>my_custom_data</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>template</span><span class=p>:</span><span class=w> </span><span class=l>llama3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>cutoff_len</span><span class=p>:</span><span class=w> </span><span class=m>1024</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>overwrite_cache</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>preprocessing_num_workers</span><span class=p>:</span><span class=w> </span><span class=m>16</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c>### output</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>output_dir</span><span class=p>:</span><span class=w> </span><span class=l>saves/llama3-8b/lora/sft</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>logging_steps</span><span class=p>:</span><span class=w> </span><span class=m>10</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>save_steps</span><span class=p>:</span><span class=w> </span><span class=m>500</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>plot_loss</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>overwrite_output_dir</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c>### train</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>per_device_train_batch_size</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>gradient_accumulation_steps</span><span class=p>:</span><span class=w> </span><span class=m>4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>learning_rate</span><span class=p>:</span><span class=w> </span><span class=m>1.0e-4</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>num_train_epochs</span><span class=p>:</span><span class=w> </span><span class=m>3.0</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>lr_scheduler_type</span><span class=p>:</span><span class=w> </span><span class=l>cosine</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>warmup_ratio</span><span class=p>:</span><span class=w> </span><span class=m>0.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>bf16</span><span class=p>:</span><span class=w> </span><span class=kc>true</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>flash_attn</span><span class=p>:</span><span class=w> </span><span class=l>fa2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c>### val</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>val_size</span><span class=p>:</span><span class=w> </span><span class=m>0.1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>per_device_eval_batch_size</span><span class=p>:</span><span class=w> </span><span class=m>1</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>eval_strategy</span><span class=p>:</span><span class=w> </span><span class=l>steps</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>eval_steps</span><span class=p>:</span><span class=w> </span><span class=m>500</span></span></span></code></pre></div><h3 id=52-命令行启动训练>5.2 命令行启动训练<a class=anchor href=#52-%e5%91%bd%e4%bb%a4%e8%a1%8c%e5%90%af%e5%8a%a8%e8%ae%ad%e7%bb%83>#</a></h3><p>有了 yaml 文件，启动训练非常优雅：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=c1># 单机单卡 / 单机多卡 (自动检测)</span>
</span></span><span class=line><span class=cl>llamafactory-cli train examples/train_lora.yaml</span></span></code></pre></div><h3 id=53-多机多卡分布式配置>5.3 多机多卡分布式配置<a class=anchor href=#53-%e5%a4%9a%e6%9c%ba%e5%a4%9a%e5%8d%a1%e5%88%86%e5%b8%83%e5%bc%8f%e9%85%8d%e7%bd%ae>#</a></h3><p>如果是多台服务器，需要结合 <code>FORCE_TORCHRUN=1</code>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl><span class=nv>FORCE_TORCHRUN</span><span class=o>=</span><span class=m>1</span> <span class=nv>NNODES</span><span class=o>=</span><span class=m>2</span> <span class=nv>NODE_RANK</span><span class=o>=</span><span class=m>0</span> <span class=nv>MASTER_ADDR</span><span class=o>=</span>192.168.0.1 <span class=nv>MASTER_PORT</span><span class=o>=</span><span class=m>29500</span> <span class=se>\
</span></span></span><span class=line><span class=cl>llamafactory-cli train examples/train_lora.yaml</span></span></code></pre></div><hr><h2 id=6-模型导出与合并>6. 模型导出与合并<a class=anchor href=#6-%e6%a8%a1%e5%9e%8b%e5%af%bc%e5%87%ba%e4%b8%8e%e5%90%88%e5%b9%b6>#</a></h2><p>LoRA 训练完后，你会得到一个几十 MB 的适配器文件夹。为了部署（如 vLLM 或 Ollama），通常需要将 LoRA 权重合并回基座模型（Merge）。</p><p><strong>WebUI 操作</strong>：</p><ol><li>切换到 <strong>[Export] (导出)</strong> 选项卡。</li><li>选择 <strong>Adapter Path</strong>：你刚才训练的输出目录 <code>saves/...</code>。</li><li>选择 <strong>Export Dir</strong>：合并后模型的保存路径。</li><li>点击 <strong>[Export]</strong>。</li></ol><blockquote class=book-hint><p>📸 <strong>[截图占位]：模型导出界面</strong></p></blockquote><p><strong>CLI 操作</strong>：
创建 <code>merge.yaml</code>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-yaml data-lang=yaml><span class=line><span class=cl><span class=c>### model</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>model_name_or_path</span><span class=p>:</span><span class=w> </span><span class=l>meta-llama/Meta-Llama-3-8B-Instruct</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>adapter_name_or_path</span><span class=p>:</span><span class=w> </span><span class=l>saves/llama3-8b/lora/sft</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>template</span><span class=p>:</span><span class=w> </span><span class=l>llama3</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>finetuning_type</span><span class=p>:</span><span class=w> </span><span class=l>lora</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=w>
</span></span></span><span class=line><span class=cl><span class=c>### export</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>export_dir</span><span class=p>:</span><span class=w> </span><span class=l>models/llama3-8b-sft-merged</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>export_size</span><span class=p>:</span><span class=w> </span><span class=m>2</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>export_device</span><span class=p>:</span><span class=w> </span><span class=l>cpu</span><span class=w>
</span></span></span><span class=line><span class=cl><span class=nt>export_legacy_format</span><span class=p>:</span><span class=w> </span><span class=kc>false</span></span></span></code></pre></div><p>运行导出：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-bash data-lang=bash><span class=line><span class=cl>llamafactory-cli <span class=nb>export</span> merge.yaml</span></span></code></pre></div><hr><h2 id=本章小结>本章小结<a class=anchor href=#%e6%9c%ac%e7%ab%a0%e5%b0%8f%e7%bb%93>#</a></h2><p>LLaMA-Factory 定义了 LLM 微调的<strong>工业标准流程</strong>：</p><ol><li><strong>准备</strong>：安装 Unsloth，整理数据为 ShareGPT 格式。</li><li><strong>注册</strong>：在 <code>dataset_info.json</code> 中配置数据映射。</li><li><strong>调试</strong>：用 WebUI 快速验证超参（Rank, LR, Batch）。</li><li><strong>运行</strong>：导出 YAML，使用 <code>llamafactory-cli train</code> 挂后台训练。</li><li><strong>交付</strong>：使用 <code>export</code> 命令合并权重，交付完整模型。</li></ol><p>有了这个神器，你不再需要关心底层 PyTorch 的分布式细节，专注于数据质量和模型效果即可。下一章，我们将探讨如何利用微调后的模型进行<strong>强化学习 (RLHF/DPO)</strong>，进一步对齐人类偏好。</p></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第1章 Hugging Face生态全景</span>
</a></span><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/ class="flex align-center"><span>第3章 TRL与强化学习实战</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#1-为什么选择-llama-factory>1. 为什么选择 LLaMA-Factory？</a></li><li><a href=#2-环境搭建与-unsloth-加速>2. 环境搭建与 Unsloth 加速</a><ul><li><a href=#21-标准安装>2.1 标准安装</a></li><li><a href=#22-开启-unsloth-极速模式推荐>2.2 开启 Unsloth 极速模式（推荐）</a></li></ul></li><li><a href=#3-数据工程dataset-registration>3. 数据工程：Dataset Registration</a><ul><li><a href=#31-数据格式标准-alpaca-vs-sharegpt>3.1 数据格式标准 (Alpaca vs ShareGPT)</a></li><li><a href=#32-注册自定义数据集-dataset_infojson>3.2 注册自定义数据集 (<code>dataset_info.json</code>)</a></li></ul></li><li><a href=#4-可视化微调webui-全流程>4. 可视化微调：WebUI 全流程</a><ul><li><a href=#41-启动与界面概览>4.1 启动与界面概览</a></li><li><a href=#42-训练参数配置详解>4.2 训练参数配置详解</a></li><li><a href=#43-训练监控与评估>4.3 训练监控与评估</a></li></ul></li><li><a href=#5-生产化从-webui-到-cli-自动化>5. 生产化：从 WebUI 到 CLI 自动化</a><ul><li><a href=#51-导出-yaml-配置文件>5.1 导出 YAML 配置文件</a></li><li><a href=#52-命令行启动训练>5.2 命令行启动训练</a></li><li><a href=#53-多机多卡分布式配置>5.3 多机多卡分布式配置</a></li></ul></li><li><a href=#6-模型导出与合并>6. 模型导出与合并</a></li><li><a href=#本章小结>本章小结</a></li></ul></nav></div></aside></main></body></html>