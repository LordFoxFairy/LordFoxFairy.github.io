<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content='第4章：多模态大模型原理# 核心定位：理解文本-图像等多模态交互的核心技术（CLIP、ViT、LLaVA）
边界约束：
✅ 包含：CLIP 对比学习、ViT 架构、LLaVA 连接器、多模态推理实战 ❌ 不包含：Transformer 基础机制（已在 Part 2 第1章）、对比学习基础理论（已在 Part 3 第4章） 目录# 多模态的直觉理解：图像作为"外语" 统一 Token 化：Omni 模型的基石 视觉编码器：Vision Transformer (ViT) 图文对齐：CLIP 多模态大模型架构：LLaVA 视频理解：Video as Frames 实战：多模态理解应用 2025视角：Connector vs Native Multimodal 总结与展望 一、多模态的直觉理解：图像作为"外语"# 1.1 Token Space Alignment：为什么图像可以被视为"外语"# 想象你是一个只懂中文的语言模型（LLM）。现在，有人拿着一张图片，用一种你从未见过的语言（“图像语”）向你描述。你该怎么办？
核心挑战：LLM 只理解文本 Token，而图像是像素矩阵。就像中文和英文一样，它们是两个完全不同的"语言空间"。
解决方案：跨模态对齐（Cross-Modal Alignment）
┌─────────────┐ ┌─────────────┐ │ 图像空间 │ │ 文本空间 │ │ (像素矩阵) │ │ (Token 序列) │ │ │ │ │ │ [255, 0] │ │ "一只猫" │ │ [128, 64] │ │ "在草地上" │ │ [...] │ │ "躺着" │ └──────┬──────┘ └──────┬──────┘ │ │ │ 通过对齐训练 │ │ (CLIP、LLaVA 等) │ ▼ ▼ ┌────────────────────────────────────────────┐ │ 共享语义空间 (Shared Latent Space) │ │ │ │ "猫" ≈ [0.8, -0.3, 0.5, ...] │ │ 🐱 ≈ [0.82, -0.28, 0.51, ...] │ │ │ │ 距离很近 → 语义相似！ │ └────────────────────────────────────────────┘核心思想：
'><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="第4章 多模态大模型原理"><meta property="og:description" content='第4章：多模态大模型原理# 核心定位：理解文本-图像等多模态交互的核心技术（CLIP、ViT、LLaVA）
边界约束：
✅ 包含：CLIP 对比学习、ViT 架构、LLaVA 连接器、多模态推理实战 ❌ 不包含：Transformer 基础机制（已在 Part 2 第1章）、对比学习基础理论（已在 Part 3 第4章） 目录# 多模态的直觉理解：图像作为"外语" 统一 Token 化：Omni 模型的基石 视觉编码器：Vision Transformer (ViT) 图文对齐：CLIP 多模态大模型架构：LLaVA 视频理解：Video as Frames 实战：多模态理解应用 2025视角：Connector vs Native Multimodal 总结与展望 一、多模态的直觉理解：图像作为"外语"# 1.1 Token Space Alignment：为什么图像可以被视为"外语"# 想象你是一个只懂中文的语言模型（LLM）。现在，有人拿着一张图片，用一种你从未见过的语言（“图像语”）向你描述。你该怎么办？
核心挑战：LLM 只理解文本 Token，而图像是像素矩阵。就像中文和英文一样，它们是两个完全不同的"语言空间"。
解决方案：跨模态对齐（Cross-Modal Alignment）
┌─────────────┐ ┌─────────────┐ │ 图像空间 │ │ 文本空间 │ │ (像素矩阵) │ │ (Token 序列) │ │ │ │ │ │ [255, 0] │ │ "一只猫" │ │ [128, 64] │ │ "在草地上" │ │ [...] │ │ "躺着" │ └──────┬──────┘ └──────┬──────┘ │ │ │ 通过对齐训练 │ │ (CLIP、LLaVA 等) │ ▼ ▼ ┌────────────────────────────────────────────┐ │ 共享语义空间 (Shared Latent Space) │ │ │ │ "猫" ≈ [0.8, -0.3, 0.5, ...] │ │ 🐱 ≈ [0.82, -0.28, 0.51, ...] │ │ │ │ 距离很近 → 语义相似！ │ └────────────────────────────────────────────┘核心思想：'><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="第4章 多模态大模型原理"><meta itemprop=description content='第4章：多模态大模型原理# 核心定位：理解文本-图像等多模态交互的核心技术（CLIP、ViT、LLaVA）
边界约束：
✅ 包含：CLIP 对比学习、ViT 架构、LLaVA 连接器、多模态推理实战 ❌ 不包含：Transformer 基础机制（已在 Part 2 第1章）、对比学习基础理论（已在 Part 3 第4章） 目录# 多模态的直觉理解：图像作为"外语" 统一 Token 化：Omni 模型的基石 视觉编码器：Vision Transformer (ViT) 图文对齐：CLIP 多模态大模型架构：LLaVA 视频理解：Video as Frames 实战：多模态理解应用 2025视角：Connector vs Native Multimodal 总结与展望 一、多模态的直觉理解：图像作为"外语"# 1.1 Token Space Alignment：为什么图像可以被视为"外语"# 想象你是一个只懂中文的语言模型（LLM）。现在，有人拿着一张图片，用一种你从未见过的语言（“图像语”）向你描述。你该怎么办？
核心挑战：LLM 只理解文本 Token，而图像是像素矩阵。就像中文和英文一样，它们是两个完全不同的"语言空间"。
解决方案：跨模态对齐（Cross-Modal Alignment）
┌─────────────┐ ┌─────────────┐ │ 图像空间 │ │ 文本空间 │ │ (像素矩阵) │ │ (Token 序列) │ │ │ │ │ │ [255, 0] │ │ "一只猫" │ │ [128, 64] │ │ "在草地上" │ │ [...] │ │ "躺着" │ └──────┬──────┘ └──────┬──────┘ │ │ │ 通过对齐训练 │ │ (CLIP、LLaVA 等) │ ▼ ▼ ┌────────────────────────────────────────────┐ │ 共享语义空间 (Shared Latent Space) │ │ │ │ "猫" ≈ [0.8, -0.3, 0.5, ...] │ │ 🐱 ≈ [0.82, -0.28, 0.51, ...] │ │ │ │ 距离很近 → 语义相似！ │ └────────────────────────────────────────────┘核心思想：'><meta itemprop=wordCount content="4641"><title>第4章 多模态大模型原理 | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle checked>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle checked>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/ class=active>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>第4章 多模态大模型原理</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#一多模态的直觉理解图像作为外语>一、多模态的直觉理解：图像作为"外语"</a><ul><li><a href=#11-token-space-alignment为什么图像可以被视为外语>1.1 Token Space Alignment：为什么图像可以被视为"外语"</a></li><li><a href=#12-数学本质余弦相似度>1.2 数学本质：余弦相似度</a></li></ul></li><li><a href=#二统一-token-化omni-模型的基石>二、统一 Token 化：Omni 模型的基石</a><ul><li><a href=#21-从连续到离散为什么需要-token-化>2.1 从连续到离散：为什么需要 Token 化</a></li><li><a href=#22-视觉-token-化vq-vaevector-quantized-variational-autoencoder>2.2 视觉 Token 化：VQ-VAE（Vector Quantized Variational AutoEncoder）</a><ul><li><a href=#221-vq-vae-核心原理>2.2.1 VQ-VAE 核心原理</a></li><li><a href=#222-codebook-的工作机制>2.2.2 Codebook 的工作机制</a></li><li><a href=#223-视觉-token-化的直观理解>2.2.3 视觉 Token 化的直观理解</a></li></ul></li><li><a href=#23-音频-token-化audio-codec>2.3 音频 Token 化：Audio Codec</a><ul><li><a href=#231-常用音频-codec>2.3.1 常用音频 Codec</a></li><li><a href=#232-音频-token-化示例代码>2.3.2 音频 Token 化示例代码</a></li></ul></li><li><a href=#24-统一-token-空间omni-模型的实现>2.4 统一 Token 空间：Omni 模型的实现</a></li><li><a href=#25-实战构建简易的视觉-token-化器>2.5 实战：构建简易的视觉 Token 化器</a></li></ul></li><li><a href=#三视觉编码器vision-transformer-vit>三、视觉编码器：Vision Transformer (ViT)</a><ul><li><a href=#31-核心思想图像是-1616-的单词>3.1 核心思想：图像是 16×16 的单词</a></li><li><a href=#32-vit-代码实现>3.2 ViT 代码实现</a></li></ul></li><li><a href=#四图文对齐clip>四、图文对齐：CLIP</a><ul><li><a href=#41-核心机制对比学习contrastive-learning>4.1 核心机制：对比学习（Contrastive Learning）</a></li><li><a href=#42-clip-的实际使用>4.2 CLIP 的实际使用</a></li><li><a href=#43-clip-的应用场景>4.3 CLIP 的应用场景</a></li></ul></li><li><a href=#五多模态大模型架构llava>五、多模态大模型架构：LLaVA</a><ul><li><a href=#51-架构设计三个组件>5.1 架构设计：三个组件</a></li><li><a href=#52-projection-layertoken-space-alignment-的实现>5.2 Projection Layer：Token Space Alignment 的实现</a></li><li><a href=#53-llava-的两阶段训练>5.3 LLaVA 的两阶段训练</a><ul><li><a href=#阶段一特征对齐预训练feature-alignment-pre-training>阶段一：特征对齐预训练（Feature Alignment Pre-training）</a></li><li><a href=#阶段二视觉指令微调visual-instruction-tuning>阶段二：视觉指令微调（Visual Instruction Tuning）</a></li></ul></li><li><a href=#54-其他连接器方案perceiver-resampler-flamingoidefics>5.4 其他连接器方案：Perceiver Resampler (Flamingo/IDEFICS)</a></li></ul></li><li><a href=#六视频理解video-as-frames>六、视频理解：Video as Frames</a><ul><li><a href=#61-视频的本质时序图像序列>6.1 视频的本质：时序图像序列</a></li><li><a href=#62-视频抽帧策略>6.2 视频抽帧策略</a></li><li><a href=#63-视频-token-化两种范式>6.3 视频 Token 化：两种范式</a><ul><li><a href=#范式-1连接器方案llava-video>范式 1：连接器方案（LLaVA-Video）</a></li><li><a href=#范式-2原生统一方案gpt-4o>范式 2：原生统一方案（GPT-4o）</a></li></ul></li><li><a href=#64-实战使用-llava-video-理解视频>6.4 实战：使用 LLaVA-Video 理解视频</a></li><li><a href=#65-视频理解的挑战与优化>6.5 视频理解的挑战与优化</a></li><li><a href=#66-视频理解的应用场景>6.6 视频理解的应用场景</a></li></ul></li><li><a href=#七实战多模态理解应用>七、实战：多模态理解应用</a><ul><li><a href=#71-使用开源模型llava-图像问答>7.1 使用开源模型：LLaVA 图像问答</a></li><li><a href=#72-实战构建本地图文检索引擎>7.2 实战：构建本地图文检索引擎</a></li><li><a href=#73-实战使用-gpt-4v-进行高级视觉理解>7.3 实战：使用 GPT-4V 进行高级视觉理解</a></li></ul></li><li><a href=#八当前视角connector-vs-native-multimodal>八、当前视角：Connector vs Native Multimodal</a><ul><li><a href=#81-架构范式对比眼睛-vs-神经系统>8.1 架构范式对比：眼睛 vs 神经系统</a><ul><li><a href=#connector-方案llava外挂的眼睛>Connector 方案（LLaVA）：外挂的"眼睛"</a></li><li><a href=#native-方案gpt-4o原生的神经系统>Native 方案（GPT-4o）：原生的"神经系统"</a></li></ul></li><li><a href=#82-核心差异深入技术对比>8.2 核心差异：深入技术对比</a></li><li><a href=#83-能力对比实际场景测试>8.3 能力对比：实际场景测试</a><ul><li><a href=#场景-1细粒度视觉推理>场景 1：细粒度视觉推理</a></li><li><a href=#场景-2跨模态推理>场景 2：跨模态推理</a></li><li><a href=#场景-3视频音频理解>场景 3：视频+音频理解</a></li></ul></li><li><a href=#84-类比理解两种架构的本质>8.4 类比理解：两种架构的本质</a><ul><li><a href=#connector拼接汽车>Connector：拼接汽车</a></li><li><a href=#native原生电动车>Native：原生电动车</a></li></ul></li><li><a href=#85-未来趋势预测>8.5 未来趋势预测</a></li><li><a href=#86-选型建议最新版>8.6 选型建议（最新版）</a></li><li><a href=#87-实战对比测试两种架构>8.7 实战：对比测试两种架构</a></li></ul></li><li><a href=#九总结与展望>九、总结与展望</a><ul><li><a href=#91-核心知识点回顾>9.1 核心知识点回顾</a></li><li><a href=#92-多模态技术演进路线>9.2 多模态技术演进路线</a></li><li><a href=#93-未来趋势>9.3 未来趋势</a></li><li><a href=#94-学习资源>9.4 学习资源</a></li></ul></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=第4章多模态大模型原理>第4章：多模态大模型原理<a class=anchor href=#%e7%ac%ac4%e7%ab%a0%e5%a4%9a%e6%a8%a1%e6%80%81%e5%a4%a7%e6%a8%a1%e5%9e%8b%e5%8e%9f%e7%90%86>#</a></h1><blockquote class=book-hint><p><strong>核心定位</strong>：理解文本-图像等多模态交互的核心技术（CLIP、ViT、LLaVA）</p><p><strong>边界约束</strong>：</p><ul><li>✅ 包含：CLIP 对比学习、ViT 架构、LLaVA 连接器、多模态推理实战</li><li>❌ 不包含：Transformer 基础机制（已在 Part 2 第1章）、对比学习基础理论（已在 Part 3 第4章）</li></ul></blockquote><hr><h2 id=目录>目录<a class=anchor href=#%e7%9b%ae%e5%bd%95>#</a></h2><ol><li><a href=#%e4%b8%80%e5%a4%9a%e6%a8%a1%e6%80%81%e7%9a%84%e7%9b%b4%e8%a7%89%e7%90%86%e8%a7%a3%e5%9b%be%e5%83%8f%e4%bd%9c%e4%b8%ba%e5%a4%96%e8%af%ad>多模态的直觉理解：图像作为"外语"</a></li><li><a href=#%e4%ba%8c%e7%bb%9f%e4%b8%80-token-%e5%8c%96omni-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%9f%ba%e7%9f%b3>统一 Token 化：Omni 模型的基石</a></li><li><a href=#%e4%b8%89%e8%a7%86%e8%a7%89%e7%bc%96%e7%a0%81%e5%99%a8vision-transformer-vit>视觉编码器：Vision Transformer (ViT)</a></li><li><a href=#%e5%9b%9b%e5%9b%be%e6%96%87%e5%af%b9%e9%bd%90clip>图文对齐：CLIP</a></li><li><a href=#%e4%ba%94%e5%a4%9a%e6%a8%a1%e6%80%81%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84llava>多模态大模型架构：LLaVA</a></li><li><a href=#%e5%85%ad%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3video-as-frames>视频理解：Video as Frames</a></li><li><a href=#%e4%b8%83%e5%ae%9e%e6%88%98%e5%a4%9a%e6%a8%a1%e6%80%81%e7%90%86%e8%a7%a3%e5%ba%94%e7%94%a8>实战：多模态理解应用</a></li><li><a href=#%e5%85%ab2025%e8%a7%86%e8%a7%92connector-vs-native-multimodal>2025视角：Connector vs Native Multimodal</a></li><li><a href=#%e4%b9%9d%e6%80%bb%e7%bb%93%e4%b8%8e%e5%b1%95%e6%9c%9b>总结与展望</a></li></ol><hr><h2 id=一多模态的直觉理解图像作为外语>一、多模态的直觉理解：图像作为"外语"<a class=anchor href=#%e4%b8%80%e5%a4%9a%e6%a8%a1%e6%80%81%e7%9a%84%e7%9b%b4%e8%a7%89%e7%90%86%e8%a7%a3%e5%9b%be%e5%83%8f%e4%bd%9c%e4%b8%ba%e5%a4%96%e8%af%ad>#</a></h2><h3 id=11-token-space-alignment为什么图像可以被视为外语>1.1 Token Space Alignment：为什么图像可以被视为"外语"<a class=anchor href=#11-token-space-alignment%e4%b8%ba%e4%bb%80%e4%b9%88%e5%9b%be%e5%83%8f%e5%8f%af%e4%bb%a5%e8%a2%ab%e8%a7%86%e4%b8%ba%e5%a4%96%e8%af%ad>#</a></h3><p>想象你是一个只懂中文的语言模型（LLM）。现在，有人拿着一张图片，用一种你从未见过的语言（&ldquo;图像语&rdquo;）向你描述。你该怎么办？</p><p><strong>核心挑战</strong>：LLM 只理解文本 Token，而图像是像素矩阵。就像中文和英文一样，它们是<strong>两个完全不同的"语言空间"</strong>。</p><p><strong>解决方案：跨模态对齐（Cross-Modal Alignment）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌─────────────┐                    ┌─────────────┐
</span></span><span class=line><span class=cl>│  图像空间    │                    │  文本空间    │
</span></span><span class=line><span class=cl>│  (像素矩阵)  │                    │  (Token 序列) │
</span></span><span class=line><span class=cl>│             │                    │             │
</span></span><span class=line><span class=cl>│   [255, 0]  │                    │ &#34;一只猫&#34;     │
</span></span><span class=line><span class=cl>│   [128, 64] │                    │ &#34;在草地上&#34;   │
</span></span><span class=line><span class=cl>│   [...]     │                    │ &#34;躺着&#34;       │
</span></span><span class=line><span class=cl>└──────┬──────┘                    └──────┬──────┘
</span></span><span class=line><span class=cl>       │                                  │
</span></span><span class=line><span class=cl>       │    通过对齐训练                   │
</span></span><span class=line><span class=cl>       │    (CLIP、LLaVA 等)              │
</span></span><span class=line><span class=cl>       ▼                                  ▼
</span></span><span class=line><span class=cl>┌────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│         共享语义空间 (Shared Latent Space)   │
</span></span><span class=line><span class=cl>│                                            │
</span></span><span class=line><span class=cl>│   &#34;猫&#34; ≈ [0.8, -0.3, 0.5, ...]           │
</span></span><span class=line><span class=cl>│   🐱   ≈ [0.82, -0.28, 0.51, ...]        │
</span></span><span class=line><span class=cl>│                                            │
</span></span><span class=line><span class=cl>│   距离很近 → 语义相似！                     │
</span></span><span class=line><span class=cl>└────────────────────────────────────────────┘</span></span></code></pre></div><p><strong>核心思想</strong>：</p><ol><li><strong>图像编码器</strong>：将图像翻译成向量（就像把英文翻译成中文）</li><li><strong>文本编码器</strong>：将文本也翻译成向量</li><li><strong>对齐训练</strong>：让描述同一事物的图像和文本在向量空间中<strong>靠近</strong></li></ol><h3 id=12-数学本质余弦相似度>1.2 数学本质：余弦相似度<a class=anchor href=#12-%e6%95%b0%e5%ad%a6%e6%9c%ac%e8%b4%a8%e4%bd%99%e5%bc%a6%e7%9b%b8%e4%bc%bc%e5%ba%a6>#</a></h3><p>假设我们有一张猫的图片 $I$ 和文本 &ldquo;a photo of a cat&rdquo; $T$。</p><p><strong>编码过程</strong>：
$$
\mathbf{v}<em>{\text{image}} = E</em>{\text{vision}}(I) \in \mathbb{R}^d
$$
$$
\mathbf{v}<em>{\text{text}} = E</em>{\text{text}}(T) \in \mathbb{R}^d
$$</p><p><strong>相似度计算</strong>（余弦相似度）：
$$
\text{sim}(\mathbf{v}<em>{\text{image}}, \mathbf{v}</em>{\text{text}}) = \frac{\mathbf{v}<em>{\text{image}} \cdot \mathbf{v}</em>{\text{text}}}{|\mathbf{v}<em>{\text{image}}| |\mathbf{v}</em>{\text{text}}|} \in [-1, 1]
$$</p><ul><li><strong>接近 1</strong>：高度相关（图片确实是猫）</li><li><strong>接近 0</strong>：无关（图片可能是狗）</li><li><strong>接近 -1</strong>：负相关（实际应用中较少见）</li></ul><p><strong>直觉理解</strong>：</p><ul><li>就像在高维空间中测量两个向量的夹角</li><li>夹角越小，语义越相似</li></ul><hr><h2 id=二统一-token-化omni-模型的基石>二、统一 Token 化：Omni 模型的基石<a class=anchor href=#%e4%ba%8c%e7%bb%9f%e4%b8%80-token-%e5%8c%96omni-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%9f%ba%e7%9f%b3>#</a></h2><blockquote class=book-hint><p><strong>核心定位</strong>：理解 GPT-4o 时代的 &ldquo;Omni&rdquo; 理念 - 如何让 LLM 像处理文本一样处理图像、音频和视频。</p></blockquote><h3 id=21-从连续到离散为什么需要-token-化>2.1 从连续到离散：为什么需要 Token 化<a class=anchor href=#21-%e4%bb%8e%e8%bf%9e%e7%bb%ad%e5%88%b0%e7%a6%bb%e6%95%a3%e4%b8%ba%e4%bb%80%e4%b9%88%e9%9c%80%e8%a6%81-token-%e5%8c%96>#</a></h3><p><strong>核心问题</strong>：语言模型只理解离散的 Token（如文字），但图像、音频是连续信号。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>文本：天生离散
</span></span><span class=line><span class=cl>&#34;我爱猫&#34; → [&#34;我&#34;, &#34;爱&#34;, &#34;猫&#34;] → [101, 203, 456] (Token IDs)
</span></span><span class=line><span class=cl>         ✅ LLM 可以直接处理
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>图像：连续信号
</span></span><span class=line><span class=cl>[[[255, 0, 128], [64, 32, 200], ...]]  # 像素矩阵
</span></span><span class=line><span class=cl>❌ LLM 无法直接处理 → 需要转换为离散 Token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>音频：连续信号
</span></span><span class=line><span class=cl>[0.023, -0.145, 0.089, ...]  # 波形采样点
</span></span><span class=line><span class=cl>❌ LLM 无法直接处理 → 需要转换为离散 Token</span></span></code></pre></div><p><strong>Omni 模型的核心思想</strong>：将所有模态统一到离散 Token 空间，让 LLM 用同一套机制处理所有信息。</p><h3 id=22-视觉-token-化vq-vaevector-quantized-variational-autoencoder>2.2 视觉 Token 化：VQ-VAE（Vector Quantized Variational AutoEncoder）<a class=anchor href=#22-%e8%a7%86%e8%a7%89-token-%e5%8c%96vq-vaevector-quantized-variational-autoencoder>#</a></h3><blockquote class=book-hint><p>VQ-VAE 是将连续图像转换为离散 Token 的核心技术，广泛应用于 DALL-E、Parti 等生成模型。</p></blockquote><h4 id=221-vq-vae-核心原理>2.2.1 VQ-VAE 核心原理<a class=anchor href=#221-vq-vae-%e6%a0%b8%e5%bf%83%e5%8e%9f%e7%90%86>#</a></h4><p><strong>架构流程</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌───────────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                       VQ-VAE 架构                              │
</span></span><span class=line><span class=cl>└───────────────────────────────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>输入图像                     编码器                    量化器
</span></span><span class=line><span class=cl>[256×256×3]                                           Codebook
</span></span><span class=line><span class=cl>    │                                              ┌──────────┐
</span></span><span class=line><span class=cl>    │                                              │ e₀=[...]  │
</span></span><span class=line><span class=cl>    ▼                                              │ e₁=[...]  │
</span></span><span class=line><span class=cl>┌─────────┐        ┌──────────┐                   │ e₂=[...]  │
</span></span><span class=line><span class=cl>│         │        │          │  连续编码           │   ...     │
</span></span><span class=line><span class=cl>│  原始   │───────&gt;│  Encoder │ [32×32×256]        │ e₈₁₉₁=[..]│
</span></span><span class=line><span class=cl>│  图像   │        │   (CNN)  │      │             └─────┬────┘
</span></span><span class=line><span class=cl>│         │        │          │      │                   │
</span></span><span class=line><span class=cl>└─────────┘        └──────────┘      │                   │
</span></span><span class=line><span class=cl>                                     ▼                   ▼
</span></span><span class=line><span class=cl>                                查找最近的 Codebook 向量
</span></span><span class=line><span class=cl>                                     │
</span></span><span class=line><span class=cl>                                     ▼
</span></span><span class=line><span class=cl>                          离散 Token 序列
</span></span><span class=line><span class=cl>                          [142, 783, 45, 892, ...]
</span></span><span class=line><span class=cl>                          [1024 个 Token IDs]
</span></span><span class=line><span class=cl>                                     │
</span></span><span class=line><span class=cl>                                     ▼
</span></span><span class=line><span class=cl>                          ┌──────────────┐
</span></span><span class=line><span class=cl>                          │   Decoder    │
</span></span><span class=line><span class=cl>                          │    (CNN)     │───────&gt; 重建图像
</span></span><span class=line><span class=cl>                          └──────────────┘         [256×256×3]</span></span></code></pre></div><p><strong>工作流程</strong>：</p><ol><li><strong>Encoder</strong>：将图像 $(256 \times 256 \times 3)$ 压缩为低分辨率特征图 $(32 \times 32 \times 256)$</li><li><strong>Quantization</strong>：将每个特征向量 $(256维)$ 映射到最近的 Codebook 向量</li><li><strong>离散化</strong>：得到 $32 \times 32 = 1024$ 个离散 Token</li><li><strong>Decoder</strong>：从离散 Token 重建图像（训练时用于优化）</li></ol><h4 id=222-codebook-的工作机制>2.2.2 Codebook 的工作机制<a class=anchor href=#222-codebook-%e7%9a%84%e5%b7%a5%e4%bd%9c%e6%9c%ba%e5%88%b6>#</a></h4><p><strong>Codebook</strong>：预定义的向量字典，类似于"视觉词汇表"。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>VectorQuantizer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;VQ-VAE 的量化层&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_embeddings</span><span class=o>=</span><span class=mi>8192</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=o>=</span><span class=mi>256</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            num_embeddings: Codebook 大小（词汇表大小）
</span></span></span><span class=line><span class=cl><span class=s2>            embedding_dim: 每个向量的维度
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>num_embeddings</span> <span class=o>=</span> <span class=n>num_embeddings</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embedding_dim</span> <span class=o>=</span> <span class=n>embedding_dim</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Codebook: [8192, 256] - 8192 个 256 维的向量</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Embedding</span><span class=p>(</span><span class=n>num_embeddings</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>data</span><span class=o>.</span><span class=n>uniform_</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=o>/</span><span class=n>num_embeddings</span><span class=p>,</span> <span class=mi>1</span><span class=o>/</span><span class=n>num_embeddings</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>z</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>        Args:
</span></span></span><span class=line><span class=cl><span class=s2>            z: 编码器输出 [B, H, W, D] 例如 [B, 32, 32, 256]
</span></span></span><span class=line><span class=cl><span class=s2>        Returns:
</span></span></span><span class=line><span class=cl><span class=s2>            quantized: 量化后的特征 [B, H, W, D]
</span></span></span><span class=line><span class=cl><span class=s2>            token_ids: 离散 Token IDs [B, H, W]
</span></span></span><span class=line><span class=cl><span class=s2>        &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>B</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=n>D</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>shape</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 展平空间维度: [B, H, W, D] -&gt; [B*H*W, D]</span>
</span></span><span class=line><span class=cl>        <span class=n>z_flat</span> <span class=o>=</span> <span class=n>z</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>D</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. 计算与所有 Codebook 向量的距离</span>
</span></span><span class=line><span class=cl>        <span class=c1># |z - e|² = |z|² + |e|² - 2z·e</span>
</span></span><span class=line><span class=cl>        <span class=n>distances</span> <span class=o>=</span> <span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=n>z_flat</span><span class=o>**</span><span class=mi>2</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span> <span class=o>+</span>  <span class=c1># [B*H*W, 1]</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>sum</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>weight</span><span class=o>**</span><span class=mi>2</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span> <span class=o>-</span>  <span class=c1># [8192]</span>
</span></span><span class=line><span class=cl>            <span class=mi>2</span> <span class=o>*</span> <span class=n>torch</span><span class=o>.</span><span class=n>matmul</span><span class=p>(</span><span class=n>z_flat</span><span class=p>,</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=o>.</span><span class=n>weight</span><span class=o>.</span><span class=n>t</span><span class=p>())</span>  <span class=c1># [B*H*W, 8192]</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. 找到最近的 Codebook 向量（贪心匹配）</span>
</span></span><span class=line><span class=cl>        <span class=n>token_ids</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>argmin</span><span class=p>(</span><span class=n>distances</span><span class=p>,</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [B*H*W]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 4. 查表获取量化后的向量</span>
</span></span><span class=line><span class=cl>        <span class=n>quantized_flat</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>embedding</span><span class=p>(</span><span class=n>token_ids</span><span class=p>)</span>  <span class=c1># [B*H*W, D]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 5. 恢复空间维度</span>
</span></span><span class=line><span class=cl>        <span class=n>quantized</span> <span class=o>=</span> <span class=n>quantized_flat</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>,</span> <span class=n>D</span><span class=p>)</span>  <span class=c1># [B, H, W, D]</span>
</span></span><span class=line><span class=cl>        <span class=n>token_ids</span> <span class=o>=</span> <span class=n>token_ids</span><span class=o>.</span><span class=n>view</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=n>H</span><span class=p>,</span> <span class=n>W</span><span class=p>)</span>  <span class=c1># [B, H, W]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 6. Straight-through estimator（训练技巧）</span>
</span></span><span class=line><span class=cl>        <span class=c1># 前向传播：使用量化后的向量</span>
</span></span><span class=line><span class=cl>        <span class=c1># 反向传播：梯度直接传给编码器</span>
</span></span><span class=line><span class=cl>        <span class=n>quantized</span> <span class=o>=</span> <span class=n>z</span> <span class=o>+</span> <span class=p>(</span><span class=n>quantized</span> <span class=o>-</span> <span class=n>z</span><span class=p>)</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>quantized</span><span class=p>,</span> <span class=n>token_ids</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>vq</span> <span class=o>=</span> <span class=n>VectorQuantizer</span><span class=p>(</span><span class=n>num_embeddings</span><span class=o>=</span><span class=mi>8192</span><span class=p>,</span> <span class=n>embedding_dim</span><span class=o>=</span><span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 模拟编码器输出</span>
</span></span><span class=line><span class=cl>    <span class=n>z</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>32</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span>  <span class=c1># batch=2, 图像编码为 32×32 的特征图</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>quantized</span><span class=p>,</span> <span class=n>token_ids</span> <span class=o>=</span> <span class=n>vq</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;输入: </span><span class=si>{</span><span class=n>z</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;量化后: </span><span class=si>{</span><span class=n>quantized</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Token IDs: </span><span class=si>{</span><span class=n>token_ids</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Token 范围: [</span><span class=si>{</span><span class=n>token_ids</span><span class=o>.</span><span class=n>min</span><span class=p>()</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>token_ids</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=si>}</span><span class=s2>]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 输出:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输入: torch.Size([2, 32, 32, 256])</span>
</span></span><span class=line><span class=cl>    <span class=c1># 量化后: torch.Size([2, 32, 32, 256])</span>
</span></span><span class=line><span class=cl>    <span class=c1># Token IDs: torch.Size([2, 32, 32])</span>
</span></span><span class=line><span class=cl>    <span class=c1># Token 范围: [0, 8191]</span></span></span></code></pre></div><p><strong>为什么这样有效</strong>？</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>图像: [256×256×3] → Encoder → [32×32×256] → VQ → [32×32] Token IDs
</span></span><span class=line><span class=cl>                                 ↑
</span></span><span class=line><span class=cl>                          每个位置选择 8192 个候选中最匹配的 Token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>最终：图像被表示为 1024 个离散 Token（就像 1024 个单词！）</span></span></code></pre></div><h4 id=223-视觉-token-化的直观理解>2.2.3 视觉 Token 化的直观理解<a class=anchor href=#223-%e8%a7%86%e8%a7%89-token-%e5%8c%96%e7%9a%84%e7%9b%b4%e8%a7%82%e7%90%86%e8%a7%a3>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>原始图像                 VQ-VAE Token 化              文本类比
</span></span><span class=line><span class=cl>┌─────────────┐         ┌─────────────┐              ┌─────────────┐
</span></span><span class=line><span class=cl>│   🐱        │   →     │ [142, 783]  │   ≈         │ &#34;一只猫&#34;     │
</span></span><span class=line><span class=cl>│             │         │ [45, 892]   │              │             │
</span></span><span class=line><span class=cl>│             │         │ [234, 1023] │              │             │
</span></span><span class=line><span class=cl>└─────────────┘         └─────────────┘              └─────────────┘
</span></span><span class=line><span class=cl>  像素矩阵                 离散 Token                   文本 Token
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>现在，LLM 可以用同样的 Transformer 处理这两种 Token！</span></span></code></pre></div><h3 id=23-音频-token-化audio-codec>2.3 音频 Token 化：Audio Codec<a class=anchor href=#23-%e9%9f%b3%e9%a2%91-token-%e5%8c%96audio-codec>#</a></h3><blockquote class=book-hint><p>音频的 Token 化与图像类似，但使用专门的音频编解码器。</p></blockquote><h4 id=231-常用音频-codec>2.3.1 常用音频 Codec<a class=anchor href=#231-%e5%b8%b8%e7%94%a8%e9%9f%b3%e9%a2%91-codec>#</a></h4><p><strong>1. EnCodec（Meta，2022）</strong></p><ul><li>将音频压缩为离散 Token</li><li>支持多种码率（1.5-12 kbps）</li><li>应用：AudioLM、MusicGen</li></ul><p><strong>2. SoundStream（Google，2021）</strong></p><ul><li>高质量音频压缩</li><li>应用：AudioPaLM</li></ul><p><strong>架构流程</strong>（以 EnCodec 为例）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌────────────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                    EnCodec 音频 Token 化                        │
</span></span><span class=line><span class=cl>└────────────────────────────────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>原始音频波形                编码器                  量化器
</span></span><span class=line><span class=cl>[1秒 @ 24kHz]                                      Codebook
</span></span><span class=line><span class=cl>= 24000 采样点                                   ┌──────────┐
</span></span><span class=line><span class=cl>    │                                            │ e₀=[...]  │
</span></span><span class=line><span class=cl>    ▼                                            │ e₁=[...]  │
</span></span><span class=line><span class=cl>┌─────────┐        ┌──────────┐                 │   ...     │
</span></span><span class=line><span class=cl>│  音频   │───────&gt;│  Conv    │  压缩特征        │ e₁₀₂₃=[..]│
</span></span><span class=line><span class=cl>│  波形   │        │  Encoder │  [75, 128]      └─────┬────┘
</span></span><span class=line><span class=cl>└─────────┘        └──────────┘      │                │
</span></span><span class=line><span class=cl>                                     ▼                ▼
</span></span><span class=line><span class=cl>                              量化为离散 Token
</span></span><span class=line><span class=cl>                                     │
</span></span><span class=line><span class=cl>                                     ▼
</span></span><span class=line><span class=cl>                          [523, 12, 945, 234, ...]
</span></span><span class=line><span class=cl>                          [75 个 Token / 秒]
</span></span><span class=line><span class=cl>                                     │
</span></span><span class=line><span class=cl>                                     ▼
</span></span><span class=line><span class=cl>                          ┌──────────────┐
</span></span><span class=line><span class=cl>                          │   Decoder    │
</span></span><span class=line><span class=cl>                          │   (Conv)     │───────&gt; 重建音频
</span></span><span class=line><span class=cl>                          └──────────────┘</span></span></code></pre></div><p><strong>关键参数</strong>：</p><ul><li><strong>降采样倍率</strong>：320倍（24000 Hz → 75 Token/秒）</li><li><strong>Codebook 大小</strong>：1024（10 位）</li><li><strong>压缩率</strong>：1 秒音频 ≈ 75 个 Token</li></ul><h4 id=232-音频-token-化示例代码>2.3.2 音频 Token 化示例代码<a class=anchor href=#232-%e9%9f%b3%e9%a2%91-token-%e5%8c%96%e7%a4%ba%e4%be%8b%e4%bb%a3%e7%a0%81>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>使用 EnCodec 进行音频 Token 化
</span></span></span><span class=line><span class=cl><span class=s2>需要: pip install encodec
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchaudio</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>encodec</span> <span class=kn>import</span> <span class=n>EncodecModel</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>encodec.utils</span> <span class=kn>import</span> <span class=n>convert_audio</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 加载预训练的 EnCodec 模型</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>EncodecModel</span><span class=o>.</span><span class=n>encodec_model_24khz</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>model</span><span class=o>.</span><span class=n>set_target_bandwidth</span><span class=p>(</span><span class=mf>6.0</span><span class=p>)</span>  <span class=c1># 设置目标码率 6 kbps</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 加载音频文件</span>
</span></span><span class=line><span class=cl><span class=n>wav</span><span class=p>,</span> <span class=n>sr</span> <span class=o>=</span> <span class=n>torchaudio</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=s2>&#34;audio.wav&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 转换为模型需要的格式（24kHz, mono）</span>
</span></span><span class=line><span class=cl><span class=n>wav</span> <span class=o>=</span> <span class=n>convert_audio</span><span class=p>(</span><span class=n>wav</span><span class=p>,</span> <span class=n>sr</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>sample_rate</span><span class=p>,</span> <span class=n>model</span><span class=o>.</span><span class=n>channels</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>wav</span> <span class=o>=</span> <span class=n>wav</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># [1, channels, time]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 编码为离散 Token</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>encoded_frames</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>wav</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 提取 Token IDs</span>
</span></span><span class=line><span class=cl><span class=c1># encoded_frames 是一个列表，每个元素包含 [codes, scale]</span>
</span></span><span class=line><span class=cl><span class=c1># codes: [batch, num_quantizers, time]</span>
</span></span><span class=line><span class=cl><span class=n>codes</span> <span class=o>=</span> <span class=n>encoded_frames</span><span class=p>[</span><span class=mi>0</span><span class=p>][</span><span class=mi>0</span><span class=p>]</span>  <span class=c1># [1, num_quantizers, time]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;原始音频: </span><span class=si>{</span><span class=n>wav</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=si>}</span><span class=s2> 采样点 (</span><span class=si>{</span><span class=n>wav</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=o>/</span><span class=n>model</span><span class=o>.</span><span class=n>sample_rate</span><span class=si>:</span><span class=s2>.2f</span><span class=si>}</span><span class=s2> 秒)&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Token 序列: </span><span class=si>{</span><span class=n>codes</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;压缩率: </span><span class=si>{</span><span class=n>wav</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span> <span class=o>/</span> <span class=n>codes</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>2</span><span class=p>]</span><span class=si>:</span><span class=s2>.1f</span><span class=si>}</span><span class=s2>x&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 输出示例:</span>
</span></span><span class=line><span class=cl><span class=c1># 原始音频: 48000 采样点 (2.00 秒)</span>
</span></span><span class=line><span class=cl><span class=c1># Token 序列: torch.Size([1, 8, 150])</span>
</span></span><span class=line><span class=cl><span class=c1># 压缩率: 320.0x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. 解码回音频（验证）</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>reconstructed</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>encoded_frames</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;重建音频: </span><span class=si>{</span><span class=n>reconstructed</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><h3 id=24-统一-token-空间omni-模型的实现>2.4 统一 Token 空间：Omni 模型的实现<a class=anchor href=#24-%e7%bb%9f%e4%b8%80-token-%e7%a9%ba%e9%97%b4omni-%e6%a8%a1%e5%9e%8b%e7%9a%84%e5%ae%9e%e7%8e%b0>#</a></h3><p><strong>GPT-4o / Gemini 1.5 的推测架构</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌────────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                  Unified Token Space                       │
</span></span><span class=line><span class=cl>│                                                            │
</span></span><span class=line><span class=cl>│  ┌─────────────┐  ┌──────────────┐  ┌──────────────┐    │
</span></span><span class=line><span class=cl>│  │   文本      │  │    图像      │  │    音频      │    │
</span></span><span class=line><span class=cl>│  │  &#34;你好&#34;     │  │   🖼️         │  │   🔊         │    │
</span></span><span class=line><span class=cl>│  └──────┬──────┘  └──────┬───────┘  └──────┬───────┘    │
</span></span><span class=line><span class=cl>│         │                │                  │             │
</span></span><span class=line><span class=cl>│    Text Tokenizer   VQ-VAE Encoder    Audio Codec        │
</span></span><span class=line><span class=cl>│         │                │                  │             │
</span></span><span class=line><span class=cl>│         ▼                ▼                  ▼             │
</span></span><span class=line><span class=cl>│    [1024, 2045]    [256000+142]       [264000+523]       │
</span></span><span class=line><span class=cl>│         │                │                  │             │
</span></span><span class=line><span class=cl>│         └────────────────┴──────────────────┘             │
</span></span><span class=line><span class=cl>│                          │                                │
</span></span><span class=line><span class=cl>│                          ▼                                │
</span></span><span class=line><span class=cl>│              Unified Transformer (GPT-4o)                 │
</span></span><span class=line><span class=cl>│              - 词汇表: [0, 300000)                        │
</span></span><span class=line><span class=cl>│                [0, 256k):  文本 Token                     │
</span></span><span class=line><span class=cl>│                [256k, 264k): 视觉 Token (VQ-VAE)         │
</span></span><span class=line><span class=cl>│                [264k, 300k): 音频 Token (Codec)          │
</span></span><span class=line><span class=cl>│              - 无需投影层，原生统一处理                    │
</span></span><span class=line><span class=cl>└────────────────────────────────────────────────────────────┘</span></span></code></pre></div><p><strong>核心优势</strong>：</p><ol><li><p><strong>真正的 Any-to-Any</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入:  [文本 Token] + [图像 Token] + [音频 Token]
</span></span><span class=line><span class=cl>输出:  [文本 Token] 或 [图像 Token] 或 [音频 Token]</span></span></code></pre></div></li><li><p><strong>无信息瓶颈</strong></p><ul><li>不需要投影层（LLaVA 的瓶颈）</li><li>每层 Transformer 都能处理跨模态信息</li></ul></li><li><p><strong>统一训练范式</strong></p><ul><li>所有模态使用相同的预训练目标（Next Token Prediction）</li><li>自然支持模态间的细粒度交互</li></ul></li></ol><h3 id=25-实战构建简易的视觉-token-化器>2.5 实战：构建简易的视觉 Token 化器<a class=anchor href=#25-%e5%ae%9e%e6%88%98%e6%9e%84%e5%bb%ba%e7%ae%80%e6%98%93%e7%9a%84%e8%a7%86%e8%a7%89-token-%e5%8c%96%e5%99%a8>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>使用预训练的 VQGAN 进行图像 Token 化
</span></span></span><span class=line><span class=cl><span class=s2>需要: pip install taming-transformers-rom1504
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>omegaconf</span> <span class=kn>import</span> <span class=n>OmegaConf</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>taming.models.vqgan</span> <span class=kn>import</span> <span class=n>VQModel</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torchvision.transforms</span> <span class=k>as</span> <span class=nn>transforms</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImageTokenizer</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;图像 Token 化器（基于 VQGAN）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>config_path</span><span class=p>,</span> <span class=n>checkpoint_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># 加载配置和模型</span>
</span></span><span class=line><span class=cl>        <span class=n>config</span> <span class=o>=</span> <span class=n>OmegaConf</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>config_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>VQModel</span><span class=p>(</span><span class=o>**</span><span class=n>config</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>params</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>state_dict</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>load</span><span class=p>(</span><span class=n>checkpoint_path</span><span class=p>,</span> <span class=n>map_location</span><span class=o>=</span><span class=s2>&#34;cpu&#34;</span><span class=p>)[</span><span class=s2>&#34;state_dict&#34;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>load_state_dict</span><span class=p>(</span><span class=n>state_dict</span><span class=p>,</span> <span class=n>strict</span><span class=o>=</span><span class=kc>False</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>eval</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 图像预处理</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>transform</span> <span class=o>=</span> <span class=n>transforms</span><span class=o>.</span><span class=n>Compose</span><span class=p>([</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>Resize</span><span class=p>(</span><span class=mi>256</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>CenterCrop</span><span class=p>(</span><span class=mi>256</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>ToTensor</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>transforms</span><span class=o>.</span><span class=n>Normalize</span><span class=p>([</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>],</span> <span class=p>[</span><span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>,</span> <span class=mf>0.5</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>encode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;将图像编码为离散 Token&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 加载并预处理图像</span>
</span></span><span class=line><span class=cl>        <span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s2>&#34;RGB&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>transform</span><span class=p>(</span><span class=n>image</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>  <span class=c1># [1, 3, 256, 256]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 编码</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>z</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># 连续特征</span>
</span></span><span class=line><span class=cl>            <span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=p>[</span><span class=n>_</span><span class=p>,</span> <span class=n>_</span><span class=p>,</span> <span class=n>indices</span><span class=p>]</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>quantize</span><span class=p>(</span><span class=n>z</span><span class=p>)</span>  <span class=c1># 量化</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># indices: [1, 16*16] = [1, 256] (16x16 个 Token)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>indices</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>decode</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>token_ids</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;从 Token 重建图像&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>z_q</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>quantize</span><span class=o>.</span><span class=n>get_codebook_entry</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>torch</span><span class=o>.</span><span class=n>tensor</span><span class=p>(</span><span class=n>token_ids</span><span class=p>)</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>),</span>
</span></span><span class=line><span class=cl>                <span class=n>shape</span><span class=o>=</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>16</span><span class=p>,</span> <span class=mi>256</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>reconstructed</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>z_q</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 转为 PIL 图像</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=n>reconstructed</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>permute</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>,</span> <span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=n>img</span> <span class=o>=</span> <span class=p>((</span><span class=n>img</span> <span class=o>+</span> <span class=mi>1</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span> <span class=o>*</span> <span class=mi>255</span><span class=p>)</span><span class=o>.</span><span class=n>clip</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>255</span><span class=p>)</span><span class=o>.</span><span class=n>astype</span><span class=p>(</span><span class=s1>&#39;uint8&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>Image</span><span class=o>.</span><span class=n>fromarray</span><span class=p>(</span><span class=n>img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>tokenizer</span> <span class=o>=</span> <span class=n>ImageTokenizer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>config_path</span><span class=o>=</span><span class=s2>&#34;vqgan_config.yaml&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>checkpoint_path</span><span class=o>=</span><span class=s2>&#34;vqgan.ckpt&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 编码</span>
</span></span><span class=line><span class=cl>    <span class=n>token_ids</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>encode</span><span class=p>(</span><span class=s2>&#34;cat.jpg&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Token 序列: </span><span class=si>{</span><span class=n>token_ids</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Token 数量: </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>token_ids</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;Token 范围: [</span><span class=si>{</span><span class=n>token_ids</span><span class=o>.</span><span class=n>min</span><span class=p>()</span><span class=si>}</span><span class=s2>, </span><span class=si>{</span><span class=n>token_ids</span><span class=o>.</span><span class=n>max</span><span class=p>()</span><span class=si>}</span><span class=s2>]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 解码（验证）</span>
</span></span><span class=line><span class=cl>    <span class=n>reconstructed</span> <span class=o>=</span> <span class=n>tokenizer</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>token_ids</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>reconstructed</span><span class=o>.</span><span class=n>save</span><span class=p>(</span><span class=s2>&#34;cat_reconstructed.jpg&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>关键点</strong>：</p><ul><li>图像 $(256 \times 256)$ → $16 \times 16 = 256$ 个 Token</li><li>每个 Token 来自大小为 8192 的 Codebook</li><li>压缩率：$(256 \times 256 \times 3)$ 像素 → 256 个 Token（约 768:1）</li></ul><hr><h2 id=三视觉编码器vision-transformer-vit>三、视觉编码器：Vision Transformer (ViT)<a class=anchor href=#%e4%b8%89%e8%a7%86%e8%a7%89%e7%bc%96%e7%a0%81%e5%99%a8vision-transformer-vit>#</a></h2><blockquote class=book-hint><p>详见 [Part 2 第1章] Transformer 核心机制。本章仅讲解 ViT 如何将 Transformer 应用于图像。</p></blockquote><h3 id=31-核心思想图像是-1616-的单词>3.1 核心思想：图像是 16×16 的单词<a class=anchor href=#31-%e6%a0%b8%e5%bf%83%e6%80%9d%e6%83%b3%e5%9b%be%e5%83%8f%e6%98%af-1616-%e7%9a%84%e5%8d%95%e8%af%8d>#</a></h3><p><strong>问题</strong>：Transformer 处理一维序列，但图像是二维的 $(H \times W)$。</p><p><strong>ViT 的解决方案</strong>：把图像切成小方块（Patches），像处理单词一样处理它们。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 1. 原始图像</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=p>[</span><span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>3</span><span class=p>]</span>  <span class=c1># 高×宽×通道</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 切成 Patches (每块 16×16)</span>
</span></span><span class=line><span class=cl><span class=n>num_patches</span> <span class=o>=</span> <span class=p>(</span><span class=mi>224</span> <span class=o>//</span> <span class=mi>16</span><span class=p>)</span> <span class=o>*</span> <span class=p>(</span><span class=mi>224</span> <span class=o>//</span> <span class=mi>16</span><span class=p>)</span> <span class=o>=</span> <span class=mi>14</span> <span class=o>*</span> <span class=mi>14</span> <span class=o>=</span> <span class=mi>196</span>
</span></span><span class=line><span class=cl><span class=n>patches</span> <span class=o>=</span> <span class=n>split_image</span><span class=p>(</span><span class=n>image</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>)</span>  <span class=c1># [196, 16, 16, 3]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 展平每个 Patch</span>
</span></span><span class=line><span class=cl><span class=n>patch_vectors</span> <span class=o>=</span> <span class=n>patches</span><span class=o>.</span><span class=n>reshape</span><span class=p>(</span><span class=mi>196</span><span class=p>,</span> <span class=mi>16</span><span class=o>*</span><span class=mi>16</span><span class=o>*</span><span class=mi>3</span><span class=p>)</span>  <span class=c1># [196, 768]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 线性投影到 Embedding 维度</span>
</span></span><span class=line><span class=cl><span class=n>embeddings</span> <span class=o>=</span> <span class=n>Linear</span><span class=p>(</span><span class=mi>768</span><span class=p>,</span> <span class=mi>768</span><span class=p>)(</span><span class=n>patch_vectors</span><span class=p>)</span>  <span class=c1># [196, 768]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 加入位置编码（告诉模型每个 Patch 的位置）</span>
</span></span><span class=line><span class=cl><span class=n>position_embeddings</span> <span class=o>=</span> <span class=n>learnable_params</span><span class=p>([</span><span class=mi>196</span><span class=p>,</span> <span class=mi>768</span><span class=p>])</span>
</span></span><span class=line><span class=cl><span class=n>final_input</span> <span class=o>=</span> <span class=n>embeddings</span> <span class=o>+</span> <span class=n>position_embeddings</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. 喂给 Transformer！</span></span></span></code></pre></div><p><strong>类比</strong>：</p><ul><li><strong>NLP</strong>：一句话 = [&ldquo;我&rdquo;, &ldquo;爱&rdquo;, &ldquo;猫&rdquo;] → 3 个 Token</li><li><strong>ViT</strong>：一张图 = [Patch₁, Patch₂, &mldr;, Patch₁₉₆] → 196 个 Token</li></ul><h3 id=32-vit-代码实现>3.2 ViT 代码实现<a class=anchor href=#32-vit-%e4%bb%a3%e7%a0%81%e5%ae%9e%e7%8e%b0>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn</span> <span class=k>as</span> <span class=nn>nn</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>PatchEmbedding</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将图像切分成 Patches 并映射到 Embedding 空间&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>img_size</span><span class=o>=</span><span class=mi>224</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=n>in_channels</span><span class=o>=</span><span class=mi>3</span><span class=p>,</span> <span class=n>embed_dim</span><span class=o>=</span><span class=mi>768</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>n_patches</span> <span class=o>=</span> <span class=p>(</span><span class=n>img_size</span> <span class=o>//</span> <span class=n>patch_size</span><span class=p>)</span> <span class=o>**</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 使用卷积实现分块+投影（最高效的方式）</span>
</span></span><span class=line><span class=cl>        <span class=c1># kernel_size=patch_size, stride=patch_size 实现非重叠分块</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Conv2d</span><span class=p>(</span><span class=n>in_channels</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                              <span class=n>kernel_size</span><span class=o>=</span><span class=n>patch_size</span><span class=p>,</span> <span class=n>stride</span><span class=o>=</span><span class=n>patch_size</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># x: [batch, 3, 224, 224]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>proj</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>         <span class=c1># [batch, 768, 14, 14]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>flatten</span><span class=p>(</span><span class=mi>2</span><span class=p>)</span>         <span class=c1># [batch, 768, 196]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>2</span><span class=p>)</span>    <span class=c1># [batch, 196, 768]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>x</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>VisionTransformer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>img_size</span><span class=o>=</span><span class=mi>224</span><span class=p>,</span> <span class=n>patch_size</span><span class=o>=</span><span class=mi>16</span><span class=p>,</span> <span class=n>embed_dim</span><span class=o>=</span><span class=mi>768</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                 <span class=n>num_heads</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=mi>12</span><span class=p>,</span> <span class=n>num_classes</span><span class=o>=</span><span class=mi>1000</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 1. Patch Embedding</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>patch_embed</span> <span class=o>=</span> <span class=n>PatchEmbedding</span><span class=p>(</span><span class=n>img_size</span><span class=p>,</span> <span class=n>patch_size</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. CLS Token（类似 BERT 的 [CLS]，用于分类）</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>cls_token</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. Position Embedding</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>pos_embed</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>torch</span><span class=o>.</span><span class=n>zeros</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>1</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>patch_embed</span><span class=o>.</span><span class=n>n_patches</span><span class=p>,</span> <span class=n>embed_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 4. Transformer Encoder（详见 Part 2 第1章）</span>
</span></span><span class=line><span class=cl>        <span class=n>encoder_layer</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TransformerEncoderLayer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>d_model</span><span class=o>=</span><span class=n>embed_dim</span><span class=p>,</span> <span class=n>nhead</span><span class=o>=</span><span class=n>num_heads</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=n>activation</span><span class=o>=</span><span class=s1>&#39;gelu&#39;</span><span class=p>,</span> <span class=n>batch_first</span><span class=o>=</span><span class=kc>True</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>TransformerEncoder</span><span class=p>(</span><span class=n>encoder_layer</span><span class=p>,</span> <span class=n>num_layers</span><span class=o>=</span><span class=n>num_layers</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 5. Classification Head</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>head</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>embed_dim</span><span class=p>,</span> <span class=n>num_classes</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>x</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=n>B</span> <span class=o>=</span> <span class=n>x</span><span class=o>.</span><span class=n>shape</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Patch Embedding</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>patch_embed</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>  <span class=c1># [B, 196, 768]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 添加 CLS Token</span>
</span></span><span class=line><span class=cl>        <span class=n>cls_tokens</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>cls_token</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [B, 1, 768]</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>((</span><span class=n>cls_tokens</span><span class=p>,</span> <span class=n>x</span><span class=p>),</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>           <span class=c1># [B, 197, 768]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 添加位置编码</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=n>x</span> <span class=o>+</span> <span class=bp>self</span><span class=o>.</span><span class=n>pos_embed</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># Transformer Encoder</span>
</span></span><span class=line><span class=cl>        <span class=n>x</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>encoder</span><span class=p>(</span><span class=n>x</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 取 CLS Token 进行分类</span>
</span></span><span class=line><span class=cl>        <span class=n>cls_output</span> <span class=o>=</span> <span class=n>x</span><span class=p>[:,</span> <span class=mi>0</span><span class=p>]</span>        <span class=c1># [B, 768]</span>
</span></span><span class=line><span class=cl>        <span class=n>logits</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>head</span><span class=p>(</span><span class=n>cls_output</span><span class=p>)</span>  <span class=c1># [B, 1000]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>logits</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 测试</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>VisionTransformer</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>dummy_img</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>2</span><span class=p>,</span> <span class=mi>3</span><span class=p>,</span> <span class=mi>224</span><span class=p>,</span> <span class=mi>224</span><span class=p>)</span>  <span class=c1># 批量大小=2</span>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=n>dummy_img</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;输入: </span><span class=si>{</span><span class=n>dummy_img</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>, 输出: </span><span class=si>{</span><span class=n>output</span><span class=o>.</span><span class=n>shape</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=c1># 输入: torch.Size([2, 3, 224, 224]), 输出: torch.Size([2, 1000])</span></span></span></code></pre></div><p><strong>关键点</strong>：</p><ul><li><strong>Patch Embedding</strong>：用卷积高效实现分块</li><li><strong>CLS Token</strong>：全局特征聚合（可选，有些 ViT 用全局平均池化）</li><li><strong>位置编码</strong>：ViT 通常使用<strong>可学习</strong>的位置编码（与 Transformer 的正弦编码不同）</li></ul><hr><h2 id=四图文对齐clip>四、图文对齐：CLIP<a class=anchor href=#%e5%9b%9b%e5%9b%be%e6%96%87%e5%af%b9%e9%bd%90clip>#</a></h2><blockquote class=book-hint><p><strong>CLIP (Contrastive Language-Image Pre-training)</strong> 是 OpenAI 2021 年提出的突破性工作，通过对比学习让图像和文本在同一空间中对齐。</p></blockquote><h3 id=41-核心机制对比学习contrastive-learning>4.1 核心机制：对比学习（Contrastive Learning）<a class=anchor href=#41-%e6%a0%b8%e5%bf%83%e6%9c%ba%e5%88%b6%e5%af%b9%e6%af%94%e5%ad%a6%e4%b9%a0contrastive-learning>#</a></h3><blockquote class=book-hint><p>详见 [Part 3 第4章] 对比学习详解。本节仅讲解 CLIP 的具体实现。</p></blockquote><p><strong>训练数据</strong>：4 亿个（图像，文本）对，从互联网爬取。</p><p><strong>训练目标</strong>：</p><ul><li><strong>正样本对</strong> $(I_i, T_i)$：相似度<strong>最大化</strong></li><li><strong>负样本对</strong> $(I_i, T_j)_{i \neq j}$：相似度<strong>最小化</strong></li></ul><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch.nn.functional</span> <span class=k>as</span> <span class=nn>F</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>clip_loss</span><span class=p>(</span><span class=n>image_embeddings</span><span class=p>,</span> <span class=n>text_embeddings</span><span class=p>,</span> <span class=n>temperature</span><span class=o>=</span><span class=mf>0.07</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    CLIP 的 InfoNCE 损失
</span></span></span><span class=line><span class=cl><span class=s2>
</span></span></span><span class=line><span class=cl><span class=s2>    Args:
</span></span></span><span class=line><span class=cl><span class=s2>        image_embeddings: [N, D] - N 张图像的特征向量
</span></span></span><span class=line><span class=cl><span class=s2>        text_embeddings: [N, D] - N 个文本的特征向量
</span></span></span><span class=line><span class=cl><span class=s2>        temperature: 温度系数，控制 softmax 分布的平滑度
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 归一化（确保余弦相似度计算正确）</span>
</span></span><span class=line><span class=cl>    <span class=n>image_embeddings</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>normalize</span><span class=p>(</span><span class=n>image_embeddings</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>text_embeddings</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>normalize</span><span class=p>(</span><span class=n>text_embeddings</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 计算相似度矩阵 [N, N]</span>
</span></span><span class=line><span class=cl>    <span class=c1># logits[i, j] = sim(image_i, text_j)</span>
</span></span><span class=line><span class=cl>    <span class=n>logits</span> <span class=o>=</span> <span class=p>(</span><span class=n>image_embeddings</span> <span class=o>@</span> <span class=n>text_embeddings</span><span class=o>.</span><span class=n>T</span><span class=p>)</span> <span class=o>/</span> <span class=n>temperature</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 对角线是正样本，其余是负样本</span>
</span></span><span class=line><span class=cl>    <span class=n>labels</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>arange</span><span class=p>(</span><span class=nb>len</span><span class=p>(</span><span class=n>logits</span><span class=p>))</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=n>logits</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 4. 双向损失（图像→文本 + 文本→图像）</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_i2t</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span><span class=n>logits</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>        <span class=c1># 图像查文本</span>
</span></span><span class=line><span class=cl>    <span class=n>loss_t2i</span> <span class=o>=</span> <span class=n>F</span><span class=o>.</span><span class=n>cross_entropy</span><span class=p>(</span><span class=n>logits</span><span class=o>.</span><span class=n>T</span><span class=p>,</span> <span class=n>labels</span><span class=p>)</span>      <span class=c1># 文本查图像</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=p>(</span><span class=n>loss_i2t</span> <span class=o>+</span> <span class=n>loss_t2i</span><span class=p>)</span> <span class=o>/</span> <span class=mi>2</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>loss</span></span></span></code></pre></div><p><strong>数学表达</strong>（图像→文本方向）：
$$
\mathcal{L}<em>{i \to t} = -\log \frac{\exp(\text{sim}(I_i, T_i) / \tau)}{\sum</em>{j=1}^N \exp(\text{sim}(I_i, T_j) / \tau)}
$$</p><p><strong>直觉解释</strong>：</p><ul><li><strong>分子</strong>：正样本对的相似度（越大越好）</li><li><strong>分母</strong>：所有样本的相似度（正样本应该远大于负样本）</li><li><strong>$\tau$ (温度)</strong>：越小，模型对难负样本越敏感</li></ul><h3 id=42-clip-的实际使用>4.2 CLIP 的实际使用<a class=anchor href=#42-clip-%e7%9a%84%e5%ae%9e%e9%99%85%e4%bd%bf%e7%94%a8>#</a></h3><p><strong>零样本图像分类</strong>（Zero-shot Classification）</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>CLIPProcessor</span><span class=p>,</span> <span class=n>CLIPModel</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 加载预训练的 CLIP 模型</span>
</span></span><span class=line><span class=cl><span class=n>model_name</span> <span class=o>=</span> <span class=s2>&#34;openai/clip-vit-base-patch32&#34;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>CLIPModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>CLIPProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_name</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 准备图像</span>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;http://images.cocodataset.org/val2017/000000039769.jpg&#34;</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>,</span> <span class=n>stream</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>raw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 定义候选类别（用自然语言描述！）</span>
</span></span><span class=line><span class=cl><span class=n>candidates</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a photo of a cat&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a photo of a dog&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a photo of a bird&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;a photo of remote controls&#34;</span>  <span class=c1># 图中实际有遥控器</span>
</span></span><span class=line><span class=cl><span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 编码</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>candidates</span><span class=p>,</span> <span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                   <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span> <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 前向传播</span>
</span></span><span class=line><span class=cl><span class=n>outputs</span> <span class=o>=</span> <span class=n>model</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>logits_per_image</span> <span class=o>=</span> <span class=n>outputs</span><span class=o>.</span><span class=n>logits_per_image</span>  <span class=c1># [1, 4]</span>
</span></span><span class=line><span class=cl><span class=n>probs</span> <span class=o>=</span> <span class=n>logits_per_image</span><span class=o>.</span><span class=n>softmax</span><span class=p>(</span><span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>      <span class=c1># 转为概率</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. 输出结果</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;候选类别:&#34;</span><span class=p>,</span> <span class=n>candidates</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;匹配概率:&#34;</span><span class=p>,</span> <span class=n>probs</span><span class=o>.</span><span class=n>detach</span><span class=p>()</span><span class=o>.</span><span class=n>numpy</span><span class=p>()[</span><span class=mi>0</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预期输出（实际图片是两只猫和一些遥控器）：</span>
</span></span><span class=line><span class=cl><span class=c1># 候选类别: [&#39;a photo of a cat&#39;, &#39;a photo of a dog&#39;, &#39;a photo of a bird&#39;, &#39;a photo of remote controls&#39;]</span>
</span></span><span class=line><span class=cl><span class=c1># 匹配概率: [0.85, 0.02, 0.01, 0.12]  (猫的概率最高)</span></span></span></code></pre></div><p><strong>关键优势</strong>：</p><ul><li><strong>零样本能力</strong>：不需要专门训练分类器，直接用文本描述类别</li><li><strong>灵活性</strong>：可以随时改变候选类别，无需重新训练</li></ul><h3 id=43-clip-的应用场景>4.3 CLIP 的应用场景<a class=anchor href=#43-clip-%e7%9a%84%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h3><ol><li><strong>零样本图像分类</strong>（如上例）</li><li><strong>图文检索</strong>（详见第五节实战）</li><li><strong>多模态搜索</strong>：输入文字搜图片，或输入图片搜相似图片</li><li><strong>图像生成引导</strong>：Stable Diffusion、DALL-E 使用 CLIP 引导生成</li></ol><hr><h2 id=五多模态大模型架构llava>五、多模态大模型架构：LLaVA<a class=anchor href=#%e4%ba%94%e5%a4%9a%e6%a8%a1%e6%80%81%e5%a4%a7%e6%a8%a1%e5%9e%8b%e6%9e%b6%e6%9e%84llava>#</a></h2><blockquote class=book-hint><p><strong>LLaVA (Large Language and Vision Assistant)</strong> 是当前最流行的开源多模态大模型架构，设计理念简单优雅。</p></blockquote><h3 id=51-架构设计三个组件>5.1 架构设计：三个组件<a class=anchor href=#51-%e6%9e%b6%e6%9e%84%e8%ae%be%e8%ae%a1%e4%b8%89%e4%b8%aa%e7%bb%84%e4%bb%b6>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                                                │
</span></span><span class=line><span class=cl>│  输入: 图像 + 文本指令                          │
</span></span><span class=line><span class=cl>│  &#34;请描述这张图片&#34;                               │
</span></span><span class=line><span class=cl>│                                                │
</span></span><span class=line><span class=cl>└────────────┬───────────────────────────────────┘
</span></span><span class=line><span class=cl>             │
</span></span><span class=line><span class=cl>             ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│  1️⃣ Vision Encoder (CLIP ViT-L/14)              │
</span></span><span class=line><span class=cl>│     - 冻结参数，不训练                           │
</span></span><span class=line><span class=cl>│     - 输出: [576, 1024] 视觉 Token              │
</span></span><span class=line><span class=cl>└────────────┬────────────────────────────────────┘
</span></span><span class=line><span class=cl>             │
</span></span><span class=line><span class=cl>             ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│  2️⃣ Projection Layer (投影层)                   │
</span></span><span class=line><span class=cl>│     - 可训练的 MLP: 1024 → 4096 维              │
</span></span><span class=line><span class=cl>│     - 将视觉特征映射到 LLM 的 Token 空间         │
</span></span><span class=line><span class=cl>│     - 输出: [576, 4096] &#34;伪装&#34;成文本 Token      │
</span></span><span class=line><span class=cl>└────────────┬────────────────────────────────────┘
</span></span><span class=line><span class=cl>             │
</span></span><span class=line><span class=cl>             ▼
</span></span><span class=line><span class=cl>┌─────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│  3️⃣ LLM (Vicuna-7B / LLaMA-7B)                 │
</span></span><span class=line><span class=cl>│     - 处理: [视觉 Token] + [文本 Token]         │
</span></span><span class=line><span class=cl>│     - 生成: &#34;这张图片显示了...&#34;                  │
</span></span><span class=line><span class=cl>└─────────────────────────────────────────────────┘</span></span></code></pre></div><p><strong>核心思想</strong>：</p><ul><li><strong>Vision Encoder</strong>：提取视觉特征（使用预训练的 CLIP）</li><li><strong>Projection Layer</strong>：桥接视觉和语言空间（<strong>关键创新</strong>）</li><li><strong>LLM</strong>：理解并生成文本</li></ul><h3 id=52-projection-layertoken-space-alignment-的实现>5.2 Projection Layer：Token Space Alignment 的实现<a class=anchor href=#52-projection-layertoken-space-alignment-%e7%9a%84%e5%ae%9e%e7%8e%b0>#</a></h3><p><strong>问题</strong>：</p><ul><li>CLIP ViT 输出维度：1024</li><li>LLaMA-7B Token 维度：4096</li></ul><p><strong>解决方案</strong>：简单的 MLP</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>ProjectionLayer</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将视觉特征投影到 LLM 的 Token Embedding 空间&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vision_dim</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>llm_dim</span><span class=o>=</span><span class=mi>4096</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># 两层 MLP</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>proj</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Sequential</span><span class=p>(</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>vision_dim</span><span class=p>,</span> <span class=n>llm_dim</span><span class=p>),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>GELU</span><span class=p>(),</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=n>llm_dim</span><span class=p>,</span> <span class=n>llm_dim</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vision_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># vision_features: [B, N, 1024] (N=576 个视觉 Token)</span>
</span></span><span class=line><span class=cl>        <span class=c1># 输出: [B, N, 4096]</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=bp>self</span><span class=o>.</span><span class=n>proj</span><span class=p>(</span><span class=n>vision_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=n>proj</span> <span class=o>=</span> <span class=n>ProjectionLayer</span><span class=p>()</span>
</span></span><span class=line><span class=cl><span class=n>vision_tokens</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>576</span><span class=p>,</span> <span class=mi>1024</span><span class=p>)</span>  <span class=c1># CLIP 输出</span>
</span></span><span class=line><span class=cl><span class=n>llm_tokens</span> <span class=o>=</span> <span class=n>proj</span><span class=p>(</span><span class=n>vision_tokens</span><span class=p>)</span>           <span class=c1># [1, 576, 4096]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 现在可以与文本 Token 拼接！</span>
</span></span><span class=line><span class=cl><span class=n>text_tokens</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=mi>1</span><span class=p>,</span> <span class=mi>20</span><span class=p>,</span> <span class=mi>4096</span><span class=p>)</span>     <span class=c1># 文本 Token</span>
</span></span><span class=line><span class=cl><span class=n>combined</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>([</span><span class=n>llm_tokens</span><span class=p>,</span> <span class=n>text_tokens</span><span class=p>],</span> <span class=n>dim</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [1, 596, 4096]</span></span></span></code></pre></div><p><strong>为什么有效</strong>？</p><ul><li>视觉特征经过投影后，&ldquo;伪装"成了 LLM 可以理解的 Token</li><li>LLM 就像在处理一段"特殊语言&rdquo;（图像语），但使用相同的 Transformer 机制</li></ul><h3 id=53-llava-的两阶段训练>5.3 LLaVA 的两阶段训练<a class=anchor href=#53-llava-%e7%9a%84%e4%b8%a4%e9%98%b6%e6%ae%b5%e8%ae%ad%e7%bb%83>#</a></h3><blockquote class=book-hint><p>这种<strong>两阶段训练法</strong>已成为行业标准。</p></blockquote><h4 id=阶段一特征对齐预训练feature-alignment-pre-training>阶段一：特征对齐预训练（Feature Alignment Pre-training）<a class=anchor href=#%e9%98%b6%e6%ae%b5%e4%b8%80%e7%89%b9%e5%be%81%e5%af%b9%e9%bd%90%e9%a2%84%e8%ae%ad%e7%bb%83feature-alignment-pre-training>#</a></h4><p><strong>训练策略</strong>：</p><ul><li>🔒 <strong>冻结</strong>：Vision Encoder + LLM</li><li>🔥 <strong>训练</strong>：仅 Projection Layer</li></ul><p><strong>数据</strong>：CC3M（300 万图像-标题对）</p><p><strong>目的</strong>：让 Projection Layer 学会将视觉特征映射到 LLM 能理解的空间</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=c1># 伪代码</span>
</span></span><span class=line><span class=cl><span class=k>for</span> <span class=n>image</span><span class=p>,</span> <span class=n>caption</span> <span class=ow>in</span> <span class=n>dataset</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 提取视觉特征（冻结）</span>
</span></span><span class=line><span class=cl>    <span class=n>vision_features</span> <span class=o>=</span> <span class=n>vision_encoder</span><span class=p>(</span><span class=n>image</span><span class=p>)</span>  <span class=c1># [B, 576, 1024]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 投影到 LLM 空间（训练）</span>
</span></span><span class=line><span class=cl>    <span class=n>visual_tokens</span> <span class=o>=</span> <span class=n>projection_layer</span><span class=p>(</span><span class=n>vision_features</span><span class=p>)</span>  <span class=c1># [B, 576, 4096]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 拼接文本 Token（冻结）</span>
</span></span><span class=line><span class=cl>    <span class=n>text_tokens</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>tokenize</span><span class=p>(</span><span class=n>caption</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>combined_tokens</span> <span class=o>=</span> <span class=n>concat</span><span class=p>([</span><span class=n>visual_tokens</span><span class=p>,</span> <span class=n>text_tokens</span><span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 4. 语言建模损失（仅反向传播到 Projection Layer）</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span> <span class=o>=</span> <span class=n>llm</span><span class=o>.</span><span class=n>forward</span><span class=p>(</span><span class=n>combined_tokens</span><span class=p>,</span> <span class=n>labels</span><span class=o>=</span><span class=n>caption</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>loss</span><span class=o>.</span><span class=n>backward</span><span class=p>()</span>  <span class=c1># 只更新 Projection Layer 的参数</span></span></span></code></pre></div><h4 id=阶段二视觉指令微调visual-instruction-tuning>阶段二：视觉指令微调（Visual Instruction Tuning）<a class=anchor href=#%e9%98%b6%e6%ae%b5%e4%ba%8c%e8%a7%86%e8%a7%89%e6%8c%87%e4%bb%a4%e5%be%ae%e8%b0%83visual-instruction-tuning>#</a></h4><p><strong>训练策略</strong>：</p><ul><li>🔒 <strong>冻结</strong>：Vision Encoder</li><li>🔥 <strong>训练</strong>：Projection Layer + LLM</li></ul><p><strong>数据</strong>：高质量视觉指令数据（如 LLaVA-Instruct-150K）</p><p><strong>示例数据</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-json data-lang=json><span class=line><span class=cl><span class=p>{</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;image&#34;</span><span class=p>:</span> <span class=s2>&#34;beach.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=nt>&#34;conversations&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;human&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;这张图片中发生了什么？&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;assistant&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=nt>&#34;content&#34;</span><span class=p>:</span> <span class=s2>&#34;这张图片展示了一个美丽的海滩日落场景。天空呈现出橙色和紫色的渐变，海浪轻柔地拍打着沙滩。远处可以看到几只海鸥在飞翔。整体氛围宁静而祥和。&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl><span class=p>}</span></span></span></code></pre></div><p><strong>目的</strong>：</p><ul><li>提升多模态推理能力</li><li>学会遵循视觉相关的指令</li><li>生成更详细、准确的描述</li></ul><h3 id=54-其他连接器方案perceiver-resampler-flamingoidefics>5.4 其他连接器方案：Perceiver Resampler (Flamingo/IDEFICS)<a class=anchor href=#54-%e5%85%b6%e4%bb%96%e8%bf%9e%e6%8e%a5%e5%99%a8%e6%96%b9%e6%a1%88perceiver-resampler-flamingoidefics>#</a></h3><p>LLaVA 使用简单的 MLP，但有些模型使用更复杂的连接器。</p><p><strong>Perceiver Resampler</strong>（Flamingo 架构）：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>class</span> <span class=nc>PerceiverResampler</span><span class=p>(</span><span class=n>nn</span><span class=o>.</span><span class=n>Module</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>    使用交叉注意力压缩视觉 Token
</span></span></span><span class=line><span class=cl><span class=s2>    &#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>num_queries</span><span class=o>=</span><span class=mi>64</span><span class=p>,</span> <span class=n>vision_dim</span><span class=o>=</span><span class=mi>1024</span><span class=p>,</span> <span class=n>llm_dim</span><span class=o>=</span><span class=mi>4096</span><span class=p>,</span> <span class=n>depth</span><span class=o>=</span><span class=mi>6</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>super</span><span class=p>()</span><span class=o>.</span><span class=fm>__init__</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=c1># 可学习的 Query Token</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>queries</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Parameter</span><span class=p>(</span><span class=n>torch</span><span class=o>.</span><span class=n>randn</span><span class=p>(</span><span class=n>num_queries</span><span class=p>,</span> <span class=n>llm_dim</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 多层交叉注意力</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>layers</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>ModuleList</span><span class=p>([</span>
</span></span><span class=line><span class=cl>            <span class=n>nn</span><span class=o>.</span><span class=n>MultiheadAttention</span><span class=p>(</span><span class=n>llm_dim</span><span class=p>,</span> <span class=n>num_heads</span><span class=o>=</span><span class=mi>16</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>_</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=n>depth</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=p>])</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>forward</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>vision_features</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=c1># vision_features: [B, 576, 1024]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 先投影到 LLM 维度</span>
</span></span><span class=line><span class=cl>        <span class=n>vision_features</span> <span class=o>=</span> <span class=n>nn</span><span class=o>.</span><span class=n>Linear</span><span class=p>(</span><span class=mi>1024</span><span class=p>,</span> <span class=mi>4096</span><span class=p>)(</span><span class=n>vision_features</span><span class=p>)</span>  <span class=c1># [B, 576, 4096]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. 使用固定数量的 Queries 提取信息</span>
</span></span><span class=line><span class=cl>        <span class=n>B</span> <span class=o>=</span> <span class=n>vision_features</span><span class=o>.</span><span class=n>size</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>queries</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>queries</span><span class=o>.</span><span class=n>unsqueeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span><span class=o>.</span><span class=n>expand</span><span class=p>(</span><span class=n>B</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=o>-</span><span class=mi>1</span><span class=p>)</span>  <span class=c1># [B, 64, 4096]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. 多层交叉注意力</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>layer</span> <span class=ow>in</span> <span class=bp>self</span><span class=o>.</span><span class=n>layers</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>queries</span><span class=p>,</span> <span class=n>_</span> <span class=o>=</span> <span class=n>layer</span><span class=p>(</span>
</span></span><span class=line><span class=cl>                <span class=n>query</span><span class=o>=</span><span class=n>queries</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>        <span class=c1># [64, B, 4096]</span>
</span></span><span class=line><span class=cl>                <span class=n>key</span><span class=o>=</span><span class=n>vision_features</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>),</span>  <span class=c1># [576, B, 4096]</span>
</span></span><span class=line><span class=cl>                <span class=n>value</span><span class=o>=</span><span class=n>vision_features</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>queries</span> <span class=o>=</span> <span class=n>queries</span><span class=o>.</span><span class=n>transpose</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=mi>1</span><span class=p>)</span>         <span class=c1># [B, 64, 4096]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 输出: [B, 64, 4096] (从 576 压缩到 64 个 Token!)</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>queries</span></span></span></code></pre></div><p><strong>对比</strong>：</p><table><thead><tr><th>方案</th><th>输出 Token 数</th><th>复杂度</th><th>代表模型</th></tr></thead><tbody><tr><td><strong>MLP (LLaVA)</strong></td><td>576</td><td>低</td><td>LLaVA, Qwen-VL</td></tr><tr><td><strong>Perceiver Resampler</strong></td><td>64</td><td>中</td><td>Flamingo, IDEFICS</td></tr><tr><td><strong>Q-Former (BLIP-2)</strong></td><td>32</td><td>高</td><td>BLIP-2, InstructBLIP</td></tr></tbody></table><p><strong>权衡</strong>：</p><ul><li><strong>更多 Token</strong>：保留更多视觉细节，但增加 LLM 计算量</li><li><strong>更少 Token</strong>：计算高效，但可能丢失细节</li></ul><hr><h2 id=六视频理解video-as-frames>六、视频理解：Video as Frames<a class=anchor href=#%e5%85%ad%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3video-as-frames>#</a></h2><blockquote class=book-hint><p><strong>核心定位</strong>：理解多模态模型如何处理视频 - 最常用的方法是将视频视为一系列静态图像。</p></blockquote><h3 id=61-视频的本质时序图像序列>6.1 视频的本质：时序图像序列<a class=anchor href=#61-%e8%a7%86%e9%a2%91%e7%9a%84%e6%9c%ac%e8%b4%a8%e6%97%b6%e5%ba%8f%e5%9b%be%e5%83%8f%e5%ba%8f%e5%88%97>#</a></h3><p><strong>核心思想</strong>：视频 = 连续的图像帧 + 时间维度</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>视频文件 (30 FPS, 10秒)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>300 个图像帧
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>抽帧策略 (降低计算成本)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>选择关键帧 (例如: 每秒 1 帧)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>10 个图像 Token 序列
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>输入到多模态模型</span></span></code></pre></div><h3 id=62-视频抽帧策略>6.2 视频抽帧策略<a class=anchor href=#62-%e8%a7%86%e9%a2%91%e6%8a%bd%e5%b8%a7%e7%ad%96%e7%95%a5>#</a></h3><p><strong>常见策略</strong>：</p><ol><li><p><strong>均匀抽帧（Uniform Sampling）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>uniform_sample_frames</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;均匀抽取 N 帧&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>total_frames</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_COUNT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算采样间隔</span>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>total_frames</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_frames</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>frames</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>cap</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_POS_FRAMES</span><span class=p>,</span> <span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>frames</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>frames</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=c1># 10秒视频(300帧) → 抽取 8 帧 → 每 37 帧抽一次</span>
</span></span><span class=line><span class=cl><span class=n>frames</span> <span class=o>=</span> <span class=n>uniform_sample_frames</span><span class=p>(</span><span class=s2>&#34;video.mp4&#34;</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span></span></span></code></pre></div></li><li><p><strong>FPS 固定抽帧（Fixed FPS）</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=k>def</span> <span class=nf>sample_by_fps</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>target_fps</span><span class=o>=</span><span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;按固定 FPS 抽帧（例如每秒 1 帧）&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>original_fps</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FPS</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 计算每隔多少帧抽一次</span>
</span></span><span class=line><span class=cl>    <span class=n>frame_interval</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>original_fps</span> <span class=o>/</span> <span class=n>target_fps</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>frames</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=n>frame_idx</span> <span class=o>=</span> <span class=mi>0</span>
</span></span><span class=line><span class=cl>    <span class=k>while</span> <span class=kc>True</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=ow>not</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>break</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>frame_idx</span> <span class=o>%</span> <span class=n>frame_interval</span> <span class=o>==</span> <span class=mi>0</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=n>frames</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>frame</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>frame_idx</span> <span class=o>+=</span> <span class=mi>1</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>frames</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=c1># 30 FPS 视频 → 每 30 帧抽一次 → 1 FPS</span>
</span></span><span class=line><span class=cl><span class=n>frames</span> <span class=o>=</span> <span class=n>sample_by_fps</span><span class=p>(</span><span class=s2>&#34;video.mp4&#34;</span><span class=p>,</span> <span class=n>target_fps</span><span class=o>=</span><span class=mi>1</span><span class=p>)</span></span></span></code></pre></div></li><li><p><strong>关键帧检测（Keyframe Detection）</strong></p><ul><li>基于场景变化检测（Scene Change Detection）</li><li>检测帧间差异，保留变化显著的帧</li><li>更智能，但计算成本更高</li></ul></li></ol><h3 id=63-视频-token-化两种范式>6.3 视频 Token 化：两种范式<a class=anchor href=#63-%e8%a7%86%e9%a2%91-token-%e5%8c%96%e4%b8%a4%e7%a7%8d%e8%8c%83%e5%bc%8f>#</a></h3><h4 id=范式-1连接器方案llava-video>范式 1：连接器方案（LLaVA-Video）<a class=anchor href=#%e8%8c%83%e5%bc%8f-1%e8%bf%9e%e6%8e%a5%e5%99%a8%e6%96%b9%e6%a1%88llava-video>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌──────────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                    LLaVA-Video 架构                       │
</span></span><span class=line><span class=cl>└──────────────────────────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>视频输入 (10秒, 30 FPS)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>抽取 8 帧 (Uniform Sampling)
</span></span><span class=line><span class=cl>    ↓
</span></span><span class=line><span class=cl>┌───────┬───────┬───────┬─────┬───────┐
</span></span><span class=line><span class=cl>│ Frame │ Frame │ Frame │ ... │ Frame │
</span></span><span class=line><span class=cl>│   1   │   2   │   3   │     │   8   │
</span></span><span class=line><span class=cl>└───┬───┴───┬───┴───┬───┴─────┴───┬───┘
</span></span><span class=line><span class=cl>    │       │       │             │
</span></span><span class=line><span class=cl>    ▼       ▼       ▼             ▼
</span></span><span class=line><span class=cl>┌────────────────────────────────────┐
</span></span><span class=line><span class=cl>│    Vision Encoder (CLIP ViT)      │
</span></span><span class=line><span class=cl>│    每帧 → [576, 1024]              │
</span></span><span class=line><span class=cl>└────────────┬───────────────────────┘
</span></span><span class=line><span class=cl>             ▼
</span></span><span class=line><span class=cl>    8 × [576, 1024] = [4608, 1024]
</span></span><span class=line><span class=cl>             ↓
</span></span><span class=line><span class=cl>┌────────────────────────────────────┐
</span></span><span class=line><span class=cl>│    Projection Layer                │
</span></span><span class=line><span class=cl>│    [4608, 1024] → [4608, 4096]     │
</span></span><span class=line><span class=cl>└────────────┬───────────────────────┘
</span></span><span class=line><span class=cl>             ▼
</span></span><span class=line><span class=cl>┌────────────────────────────────────┐
</span></span><span class=line><span class=cl>│    LLM (处理 4608 个视觉 Token)    │
</span></span><span class=line><span class=cl>│    + 文本 Token                     │
</span></span><span class=line><span class=cl>│    → 生成视频描述                   │
</span></span><span class=line><span class=cl>└────────────────────────────────────┘</span></span></code></pre></div><p><strong>关键点</strong>：</p><ul><li>每帧独立编码（无时序建模）</li><li>拼接所有帧的 Token（线性增长）</li><li>依赖 LLM 的自注意力学习时序关系</li></ul><h4 id=范式-2原生统一方案gpt-4o>范式 2：原生统一方案（GPT-4o）<a class=anchor href=#%e8%8c%83%e5%bc%8f-2%e5%8e%9f%e7%94%9f%e7%bb%9f%e4%b8%80%e6%96%b9%e6%a1%88gpt-4o>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>视频 → VQ-VAE 编码器（3D 卷积）→ 时空离散 Token
</span></span><span class=line><span class=cl>                ↓
</span></span><span class=line><span class=cl>    直接输入统一 Transformer
</span></span><span class=line><span class=cl>    （视觉 Token 本身包含时间信息）</span></span></code></pre></div><h3 id=64-实战使用-llava-video-理解视频>6.4 实战：使用 LLaVA-Video 理解视频<a class=anchor href=#64-%e5%ae%9e%e6%88%98%e4%bd%bf%e7%94%a8-llava-video-%e7%90%86%e8%a7%a3%e8%a7%86%e9%a2%91>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>使用 Video-LLaVA 进行视频问答
</span></span></span><span class=line><span class=cl><span class=s2>需要: pip install transformers accelerate opencv-python
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>cv2</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>VideoLlavaForConditionalGeneration</span><span class=p>,</span> <span class=n>AutoProcessor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>load_video_frames</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;从视频中均匀抽取 N 帧&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>cap</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>VideoCapture</span><span class=p>(</span><span class=n>video_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>total_frames</span> <span class=o>=</span> <span class=nb>int</span><span class=p>(</span><span class=n>cap</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_FRAME_COUNT</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>indices</span> <span class=o>=</span> <span class=n>np</span><span class=o>.</span><span class=n>linspace</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=n>total_frames</span><span class=o>-</span><span class=mi>1</span><span class=p>,</span> <span class=n>num_frames</span><span class=p>,</span> <span class=n>dtype</span><span class=o>=</span><span class=nb>int</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>frames</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>idx</span> <span class=ow>in</span> <span class=n>indices</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>cap</span><span class=o>.</span><span class=n>set</span><span class=p>(</span><span class=n>cv2</span><span class=o>.</span><span class=n>CAP_PROP_POS_FRAMES</span><span class=p>,</span> <span class=n>idx</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>ret</span><span class=p>,</span> <span class=n>frame</span> <span class=o>=</span> <span class=n>cap</span><span class=o>.</span><span class=n>read</span><span class=p>()</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=n>ret</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=c1># OpenCV 读取的是 BGR，转为 RGB</span>
</span></span><span class=line><span class=cl>            <span class=n>frame</span> <span class=o>=</span> <span class=n>cv2</span><span class=o>.</span><span class=n>cvtColor</span><span class=p>(</span><span class=n>frame</span><span class=p>,</span> <span class=n>cv2</span><span class=o>.</span><span class=n>COLOR_BGR2RGB</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>frames</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Image</span><span class=o>.</span><span class=n>fromarray</span><span class=p>(</span><span class=n>frame</span><span class=p>))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>cap</span><span class=o>.</span><span class=n>release</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>frames</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 加载模型</span>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;LanguageBind/Video-LLaVA-7B&#34;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>VideoLlavaForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 加载视频并抽帧</span>
</span></span><span class=line><span class=cl><span class=n>video_path</span> <span class=o>=</span> <span class=s2>&#34;cooking.mp4&#34;</span>
</span></span><span class=line><span class=cl><span class=n>frames</span> <span class=o>=</span> <span class=n>load_video_frames</span><span class=p>(</span><span class=n>video_path</span><span class=p>,</span> <span class=n>num_frames</span><span class=o>=</span><span class=mi>8</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;抽取了 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=n>frames</span><span class=p>)</span><span class=si>}</span><span class=s2> 帧&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 准备问题</span>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;USER: &lt;video&gt;</span><span class=se>\n</span><span class=s2>Describe what&#39;s happening in this video.</span><span class=se>\n</span><span class=s2>ASSISTANT:&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 处理输入</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>images</span><span class=o>=</span><span class=n>frames</span><span class=p>,</span>  <span class=c1># Video-LLaVA 使用 images 参数处理视频帧</span>
</span></span><span class=line><span class=cl>    <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span>
</span></span><span class=line><span class=cl><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 生成回答</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=o>**</span><span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>150</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>do_sample</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 6. 解码输出</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>answer</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;ASSISTANT:&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>视频: </span><span class=si>{</span><span class=n>video_path</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;问题: Describe what&#39;s happening in this video.&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;回答: </span><span class=si>{</span><span class=n>answer</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预期输出示例:</span>
</span></span><span class=line><span class=cl><span class=c1># &#34;This video shows a person cooking in a kitchen. They start by chopping vegetables,</span>
</span></span><span class=line><span class=cl><span class=c1>#  then heat oil in a pan, add the vegetables, and stir-fry them. The person appears</span>
</span></span><span class=line><span class=cl><span class=c1>#  to be preparing a healthy meal.&#34;</span></span></span></code></pre></div><h3 id=65-视频理解的挑战与优化>6.5 视频理解的挑战与优化<a class=anchor href=#65-%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3%e7%9a%84%e6%8c%91%e6%88%98%e4%b8%8e%e4%bc%98%e5%8c%96>#</a></h3><p><strong>挑战 1：Token 数量爆炸</strong></p><ul><li>问题：8 帧 × 576 Token/帧 = 4608 Token（接近某些模型的上下文限制）</li><li>解决方案：<ul><li>使用 Perceiver Resampler 压缩（576 → 64 Token/帧）</li><li>减少抽帧数量（牺牲时序细节）</li></ul></li></ul><p><strong>挑战 2：缺乏真正的时序建模</strong></p><ul><li>问题：独立编码每帧，无法捕捉连续动作</li><li>解决方案：<ul><li>使用 3D 卷积（C3D、I3D）</li><li>时序 Transformer（TimeSformer）</li><li>原生多模态模型（GPT-4o）</li></ul></li></ul><p><strong>挑战 3：长视频处理</strong></p><ul><li>问题：10 分钟视频抽帧后仍有数百帧</li><li>解决方案：<ul><li>分段处理（每 30 秒一段）</li><li>层次化采样（先粗采样定位关键片段，再细采样）</li><li>使用长上下文模型（Gemini 1.5：1M Token）</li></ul></li></ul><h3 id=66-视频理解的应用场景>6.6 视频理解的应用场景<a class=anchor href=#66-%e8%a7%86%e9%a2%91%e7%90%86%e8%a7%a3%e7%9a%84%e5%ba%94%e7%94%a8%e5%9c%ba%e6%99%af>#</a></h3><ol><li><p><strong>视频摘要生成</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;Summarize the main events in this video in 3 sentences.&#34;</span></span></span></code></pre></div></li><li><p><strong>时间戳定位</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;At what timestamp does the person start cooking? Answer in format MM:SS.&#34;</span></span></span></code></pre></div></li><li><p><strong>动作识别</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;What actions does the person perform in this video? List them step by step.&#34;</span></span></span></code></pre></div></li><li><p><strong>视频问答</strong></p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;How many people appear in this video?&#34;</span></span></span></code></pre></div></li></ol><hr><h2 id=七实战多模态理解应用>七、实战：多模态理解应用<a class=anchor href=#%e4%b8%83%e5%ae%9e%e6%88%98%e5%a4%9a%e6%a8%a1%e6%80%81%e7%90%86%e8%a7%a3%e5%ba%94%e7%94%a8>#</a></h2><h3 id=71-使用开源模型llava-图像问答>7.1 使用开源模型：LLaVA 图像问答<a class=anchor href=#71-%e4%bd%bf%e7%94%a8%e5%bc%80%e6%ba%90%e6%a8%a1%e5%9e%8bllava-%e5%9b%be%e5%83%8f%e9%97%ae%e7%ad%94>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>使用 Hugging Face 的 LLaVA-1.5-7B 进行图像理解
</span></span></span><span class=line><span class=cl><span class=s2>需要: pip install transformers accelerate pillow
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>AutoProcessor</span><span class=p>,</span> <span class=n>LlavaForConditionalGeneration</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>requests</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 1. 加载模型和处理器</span>
</span></span><span class=line><span class=cl><span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;llava-hf/llava-1.5-7b-hf&#34;</span>
</span></span><span class=line><span class=cl><span class=n>model</span> <span class=o>=</span> <span class=n>LlavaForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span>
</span></span><span class=line><span class=cl>    <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>  <span class=c1># 自动分配 GPU/CPU</span>
</span></span><span class=line><span class=cl><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 2. 准备图像和问题</span>
</span></span><span class=line><span class=cl><span class=n>url</span> <span class=o>=</span> <span class=s2>&#34;https://www.ilankelman.org/stopsigns/australia.jpg&#34;</span>
</span></span><span class=line><span class=cl><span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>requests</span><span class=o>.</span><span class=n>get</span><span class=p>(</span><span class=n>url</span><span class=p>,</span> <span class=n>stream</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>raw</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>prompt</span> <span class=o>=</span> <span class=s2>&#34;USER: &lt;image&gt;</span><span class=se>\n</span><span class=s2>What&#39;s the content of this image?</span><span class=se>\n</span><span class=s2>ASSISTANT:&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 3. 处理输入</span>
</span></span><span class=line><span class=cl><span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span> <span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 4. 生成回答</span>
</span></span><span class=line><span class=cl><span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>    <span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=o>**</span><span class=n>inputs</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>100</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>do_sample</span><span class=o>=</span><span class=kc>False</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 5. 解码输出</span>
</span></span><span class=line><span class=cl><span class=n>output</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=n>answer</span> <span class=o>=</span> <span class=n>output</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;ASSISTANT:&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;图像:&#34;</span><span class=p>,</span> <span class=n>url</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;问题:&#34;</span><span class=p>,</span> <span class=s2>&#34;What&#39;s the content of this image?&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl><span class=nb>print</span><span class=p>(</span><span class=s2>&#34;回答:&#34;</span><span class=p>,</span> <span class=n>answer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 预期输出:</span>
</span></span><span class=line><span class=cl><span class=c1># &#34;This image shows a red stop sign at a street intersection in Australia.</span>
</span></span><span class=line><span class=cl><span class=c1>#  The sign features white text in English and additional text in Chinese characters.&#34;</span></span></span></code></pre></div><h3 id=72-实战构建本地图文检索引擎>7.2 实战：构建本地图文检索引擎<a class=anchor href=#72-%e5%ae%9e%e6%88%98%e6%9e%84%e5%bb%ba%e6%9c%ac%e5%9c%b0%e5%9b%be%e6%96%87%e6%a3%80%e7%b4%a2%e5%bc%95%e6%93%8e>#</a></h3><p>使用 CLIP 构建一个简单的图片搜索引擎。</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=kn>import</span> <span class=nn>os</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>glob</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>CLIPProcessor</span><span class=p>,</span> <span class=n>CLIPModel</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>numpy</span> <span class=k>as</span> <span class=nn>np</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>class</span> <span class=nc>ImageSearchEngine</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;基于 CLIP 的图文检索引擎&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=fm>__init__</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>model_id</span><span class=o>=</span><span class=s2>&#34;openai/clip-vit-base-patch32&#34;</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>device</span> <span class=o>=</span> <span class=s2>&#34;cuda&#34;</span> <span class=k>if</span> <span class=n>torch</span><span class=o>.</span><span class=n>cuda</span><span class=o>.</span><span class=n>is_available</span><span class=p>()</span> <span class=k>else</span> <span class=s2>&#34;cpu&#34;</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;使用设备: </span><span class=si>{</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 加载 CLIP 模型</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>model</span> <span class=o>=</span> <span class=n>CLIPModel</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>processor</span> <span class=o>=</span> <span class=n>CLIPProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 索引数据</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>image_features</span> <span class=o>=</span> <span class=kc>None</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>index_images</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>image_dir</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;为指定目录下的所有图片建立特征索引&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 收集图片路径</span>
</span></span><span class=line><span class=cl>        <span class=n>extensions</span> <span class=o>=</span> <span class=p>[</span><span class=s1>&#39;*.jpg&#39;</span><span class=p>,</span> <span class=s1>&#39;*.jpeg&#39;</span><span class=p>,</span> <span class=s1>&#39;*.png&#39;</span><span class=p>,</span> <span class=s1>&#39;*.webp&#39;</span><span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>ext</span> <span class=ow>in</span> <span class=n>extensions</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=o>.</span><span class=n>extend</span><span class=p>(</span><span class=n>glob</span><span class=o>.</span><span class=n>glob</span><span class=p>(</span><span class=n>os</span><span class=o>.</span><span class=n>path</span><span class=o>.</span><span class=n>join</span><span class=p>(</span><span class=n>image_dir</span><span class=p>,</span> <span class=n>ext</span><span class=p>)))</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;找到 </span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>)</span><span class=si>}</span><span class=s2> 张图片，开始建立索引...&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. 批量提取特征</span>
</span></span><span class=line><span class=cl>        <span class=n>all_features</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=n>batch_size</span> <span class=o>=</span> <span class=mi>32</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span> <span class=ow>in</span> <span class=nb>range</span><span class=p>(</span><span class=mi>0</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>),</span> <span class=n>batch_size</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>batch_paths</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>[</span><span class=n>i</span><span class=p>:</span><span class=n>i</span><span class=o>+</span><span class=n>batch_size</span><span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=n>images</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 加载图片</span>
</span></span><span class=line><span class=cl>            <span class=k>for</span> <span class=n>path</span> <span class=ow>in</span> <span class=n>batch_paths</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>try</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=n>images</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>path</span><span class=p>)</span><span class=o>.</span><span class=n>convert</span><span class=p>(</span><span class=s2>&#34;RGB&#34;</span><span class=p>))</span>
</span></span><span class=line><span class=cl>                <span class=k>except</span> <span class=ne>Exception</span> <span class=k>as</span> <span class=n>e</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                    <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;读取失败 </span><span class=si>{</span><span class=n>path</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>e</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                    <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=k>if</span> <span class=ow>not</span> <span class=n>images</span><span class=p>:</span>
</span></span><span class=line><span class=cl>                <span class=k>continue</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=c1># 提取特征</span>
</span></span><span class=line><span class=cl>            <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>                <span class=n>inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=p>(</span><span class=n>images</span><span class=o>=</span><span class=n>images</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                       <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>get_image_features</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=c1># 归一化（用于余弦相似度）</span>
</span></span><span class=line><span class=cl>                <span class=n>features</span> <span class=o>=</span> <span class=n>features</span> <span class=o>/</span> <span class=n>features</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>                <span class=n>all_features</span><span class=o>.</span><span class=n>append</span><span class=p>(</span><span class=n>features</span><span class=o>.</span><span class=n>cpu</span><span class=p>())</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;已索引: </span><span class=si>{</span><span class=nb>min</span><span class=p>(</span><span class=n>i</span><span class=o>+</span><span class=n>batch_size</span><span class=p>,</span> <span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>))</span><span class=si>}</span><span class=s2>/</span><span class=si>{</span><span class=nb>len</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>)</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. 合并所有特征</span>
</span></span><span class=line><span class=cl>        <span class=bp>self</span><span class=o>.</span><span class=n>image_features</span> <span class=o>=</span> <span class=n>torch</span><span class=o>.</span><span class=n>cat</span><span class=p>(</span><span class=n>all_features</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;索引完成!&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>def</span> <span class=nf>search</span><span class=p>(</span><span class=bp>self</span><span class=p>,</span> <span class=n>query_text</span><span class=p>,</span> <span class=n>top_k</span><span class=o>=</span><span class=mi>5</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;&#34;&#34;使用文本搜索图片&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>        <span class=k>if</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_features</span> <span class=ow>is</span> <span class=kc>None</span><span class=p>:</span>
</span></span><span class=line><span class=cl>            <span class=k>raise</span> <span class=ne>ValueError</span><span class=p>(</span><span class=s2>&#34;请先调用 index_images() 建立索引&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 1. 编码查询文本</span>
</span></span><span class=line><span class=cl>        <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>no_grad</span><span class=p>():</span>
</span></span><span class=line><span class=cl>            <span class=n>inputs</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=p>[</span><span class=n>query_text</span><span class=p>],</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                                   <span class=n>padding</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=bp>self</span><span class=o>.</span><span class=n>device</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>text_features</span> <span class=o>=</span> <span class=bp>self</span><span class=o>.</span><span class=n>model</span><span class=o>.</span><span class=n>get_text_features</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>)</span>
</span></span><span class=line><span class=cl>            <span class=n>text_features</span> <span class=o>=</span> <span class=n>text_features</span> <span class=o>/</span> <span class=n>text_features</span><span class=o>.</span><span class=n>norm</span><span class=p>(</span><span class=n>p</span><span class=o>=</span><span class=mi>2</span><span class=p>,</span> <span class=n>dim</span><span class=o>=-</span><span class=mi>1</span><span class=p>,</span> <span class=n>keepdim</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 2. 计算相似度（余弦相似度）</span>
</span></span><span class=line><span class=cl>        <span class=c1># [1, D] @ [N, D]^T = [1, N]</span>
</span></span><span class=line><span class=cl>        <span class=n>similarities</span> <span class=o>=</span> <span class=p>(</span><span class=n>text_features</span><span class=o>.</span><span class=n>cpu</span><span class=p>()</span> <span class=o>@</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_features</span><span class=o>.</span><span class=n>T</span><span class=p>)</span><span class=o>.</span><span class=n>squeeze</span><span class=p>(</span><span class=mi>0</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=c1># 3. 获取 Top-K</span>
</span></span><span class=line><span class=cl>        <span class=n>values</span><span class=p>,</span> <span class=n>indices</span> <span class=o>=</span> <span class=n>similarities</span><span class=o>.</span><span class=n>topk</span><span class=p>(</span><span class=n>top_k</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=p>[]</span>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>val</span><span class=p>,</span> <span class=n>idx</span> <span class=ow>in</span> <span class=nb>zip</span><span class=p>(</span><span class=n>values</span><span class=p>,</span> <span class=n>indices</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=n>results</span><span class=o>.</span><span class=n>append</span><span class=p>({</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;path&#39;</span><span class=p>:</span> <span class=bp>self</span><span class=o>.</span><span class=n>image_paths</span><span class=p>[</span><span class=n>idx</span><span class=p>],</span>
</span></span><span class=line><span class=cl>                <span class=s1>&#39;score&#39;</span><span class=p>:</span> <span class=n>val</span><span class=o>.</span><span class=n>item</span><span class=p>()</span>
</span></span><span class=line><span class=cl>            <span class=p>})</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>results</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 创建搜索引擎并建立索引</span>
</span></span><span class=line><span class=cl>    <span class=n>engine</span> <span class=o>=</span> <span class=n>ImageSearchEngine</span><span class=p>()</span>
</span></span><span class=line><span class=cl>    <span class=n>engine</span><span class=o>.</span><span class=n>index_images</span><span class=p>(</span><span class=s2>&#34;./my_photos&#34;</span><span class=p>)</span>  <span class=c1># 替换为你的图片文件夹</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. 搜索</span>
</span></span><span class=line><span class=cl>    <span class=n>queries</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;a dog playing in the park&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;sunset at the beach&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;a person reading a book&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>query</span> <span class=ow>in</span> <span class=n>queries</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>查询: &#39;</span><span class=si>{</span><span class=n>query</span><span class=si>}</span><span class=s2>&#39;&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>results</span> <span class=o>=</span> <span class=n>engine</span><span class=o>.</span><span class=n>search</span><span class=p>(</span><span class=n>query</span><span class=p>,</span> <span class=n>top_k</span><span class=o>=</span><span class=mi>3</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>result</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>results</span><span class=p>,</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>            <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;  </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>. </span><span class=si>{</span><span class=n>result</span><span class=p>[</span><span class=s1>&#39;path&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2> (相似度: </span><span class=si>{</span><span class=n>result</span><span class=p>[</span><span class=s1>&#39;score&#39;</span><span class=p>]</span><span class=si>:</span><span class=s2>.4f</span><span class=si>}</span><span class=s2>)&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>输出示例</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>找到 1523 张图片，开始建立索引...
</span></span><span class=line><span class=cl>已索引: 32/1523
</span></span><span class=line><span class=cl>已索引: 64/1523
</span></span><span class=line><span class=cl>...
</span></span><span class=line><span class=cl>索引完成!
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>查询: &#39;a dog playing in the park&#39;
</span></span><span class=line><span class=cl>  1. ./my_photos/IMG_2023.jpg (相似度: 0.8752)
</span></span><span class=line><span class=cl>  2. ./my_photos/IMG_1845.jpg (相似度: 0.8231)
</span></span><span class=line><span class=cl>  3. ./my_photos/IMG_2091.jpg (相似度: 0.7963)</span></span></code></pre></div><h3 id=73-实战使用-gpt-4v-进行高级视觉理解>7.3 实战：使用 GPT-4V 进行高级视觉理解<a class=anchor href=#73-%e5%ae%9e%e6%88%98%e4%bd%bf%e7%94%a8-gpt-4v-%e8%bf%9b%e8%a1%8c%e9%ab%98%e7%ba%a7%e8%a7%86%e8%a7%89%e7%90%86%e8%a7%a3>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>调用 GPT-4V API 进行图像理解
</span></span></span><span class=line><span class=cl><span class=s2>需要: pip install openai
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>base64</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;your-api-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;将图片编码为 base64&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s2>&#34;rb&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>image_file</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=k>return</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>image_file</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>analyze_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=s2>&#34;&#34;&#34;使用 GPT-4V 分析图像&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>base64_image</span> <span class=o>=</span> <span class=n>encode_image</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>  <span class=c1># 或 &#34;gpt-4-turbo&#34;</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[</span>
</span></span><span class=line><span class=cl>            <span class=p>{</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span>
</span></span><span class=line><span class=cl>                    <span class=p>},</span>
</span></span><span class=line><span class=cl>                    <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                            <span class=s2>&#34;detail&#34;</span><span class=p>:</span> <span class=s2>&#34;high&#34;</span>  <span class=c1># 高分辨率模式</span>
</span></span><span class=line><span class=cl>                        <span class=p>}</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>]</span>
</span></span><span class=line><span class=cl>            <span class=p>}</span>
</span></span><span class=line><span class=cl>        <span class=p>],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>500</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># 使用示例</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=c1># 1. 图像描述</span>
</span></span><span class=line><span class=cl>    <span class=n>description</span> <span class=o>=</span> <span class=n>analyze_image</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;chart.png&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;详细描述这张图表，包括类型、趋势和关键数据点&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;图表分析:&#34;</span><span class=p>,</span> <span class=n>description</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 2. OCR + 结构化输出</span>
</span></span><span class=line><span class=cl>    <span class=n>ocr_result</span> <span class=o>=</span> <span class=n>analyze_image</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;receipt.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;提取这张收据中的所有信息，以 JSON 格式输出，包括：商家名称、日期、商品列表、总金额&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;收据信息:&#34;</span><span class=p>,</span> <span class=n>ocr_result</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=c1># 3. 视觉推理</span>
</span></span><span class=line><span class=cl>    <span class=n>reasoning</span> <span class=o>=</span> <span class=n>analyze_image</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;scene.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=s2>&#34;这张图片中有哪些潜在的安全隐患？请列举并解释&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;安全分析:&#34;</span><span class=p>,</span> <span class=n>reasoning</span><span class=p>)</span></span></span></code></pre></div><hr><h2 id=八当前视角connector-vs-native-multimodal>八、当前视角：Connector vs Native Multimodal<a class=anchor href=#%e5%85%ab%e5%bd%93%e5%89%8d%e8%a7%86%e8%a7%92connector-vs-native-multimodal>#</a></h2><blockquote class=book-hint><p><strong>核心定位</strong>：深入理解两种多模态架构范式的本质区别 - Connector（连接器）是"外挂眼睛"，Native（原生）是"全身神经系统"。</p></blockquote><h3 id=81-架构范式对比眼睛-vs-神经系统>8.1 架构范式对比：眼睛 vs 神经系统<a class=anchor href=#81-%e6%9e%b6%e6%9e%84%e8%8c%83%e5%bc%8f%e5%af%b9%e6%af%94%e7%9c%bc%e7%9d%9b-vs-%e7%a5%9e%e7%bb%8f%e7%b3%bb%e7%bb%9f>#</a></h3><h4 id=connector-方案llava外挂的眼睛>Connector 方案（LLaVA）：外挂的"眼睛"<a class=anchor href=#connector-%e6%96%b9%e6%a1%88llava%e5%a4%96%e6%8c%82%e7%9a%84%e7%9c%bc%e7%9d%9b>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌──────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│              Connector 架构 (LLaVA)                   │
</span></span><span class=line><span class=cl>└──────────────────────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                  ┌─────────────┐
</span></span><span class=line><span class=cl>                  │   大脑      │
</span></span><span class=line><span class=cl>                  │   (LLM)     │  ← 只懂&#34;语言&#34;
</span></span><span class=line><span class=cl>                  └──────┬──────┘
</span></span><span class=line><span class=cl>                         ↑
</span></span><span class=line><span class=cl>                      投影层
</span></span><span class=line><span class=cl>                    (翻译器)
</span></span><span class=line><span class=cl>                         ↑
</span></span><span class=line><span class=cl>                  ┌──────────────┐
</span></span><span class=line><span class=cl>                  │   眼睛       │
</span></span><span class=line><span class=cl>                  │ (CLIP ViT)   │  ← 只懂&#34;视觉&#34;
</span></span><span class=line><span class=cl>                  └──────┬───────┘
</span></span><span class=line><span class=cl>                         ↑
</span></span><span class=line><span class=cl>                     🖼️ 图像
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>本质：两个独立训练的系统，通过&#34;翻译层&#34;勉强沟通
</span></span><span class=line><span class=cl>类比：给只会中文的人配一个英语翻译</span></span></code></pre></div><p><strong>工作流程</strong>：</p><ol><li><p><strong>视觉编码器</strong>（CLIP ViT）：独立预训练，冻结参数</p><ul><li>训练数据：4亿图文对（CLIP 数据集）</li><li>目标：图文对比学习</li><li>输出：1024 维视觉特征</li></ul></li><li><p><strong>投影层</strong>（Projection）：桥接层，唯一可训练</p><ul><li>作用：将 1024 维视觉特征"伪装"成 4096 维文本 Token</li><li>训练数据：少量（30万-150万）图文对</li><li>挑战：必须在有限数据下完成"翻译"任务</li></ul></li><li><p><strong>语言模型</strong>（LLM）：独立预训练，微调</p><ul><li>训练数据：数万亿 Token 的纯文本</li><li>目标：语言建模</li><li>问题：从未在预训练中"见过"真实图像</li></ul></li></ol><h4 id=native-方案gpt-4o原生的神经系统>Native 方案（GPT-4o）：原生的"神经系统"<a class=anchor href=#native-%e6%96%b9%e6%a1%88gpt-4o%e5%8e%9f%e7%94%9f%e7%9a%84%e7%a5%9e%e7%bb%8f%e7%b3%bb%e7%bb%9f>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌──────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│              Native 架构 (GPT-4o)                     │
</span></span><span class=line><span class=cl>└──────────────────────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>                  ┌─────────────────┐
</span></span><span class=line><span class=cl>                  │   统一大脑      │
</span></span><span class=line><span class=cl>                  │  (Transformer)  │
</span></span><span class=line><span class=cl>                  │                 │
</span></span><span class=line><span class=cl>                  │  从出生就同时  │
</span></span><span class=line><span class=cl>                  │  &#34;看&#34;&#34;听&#34;&#34;说&#34; │
</span></span><span class=line><span class=cl>                  └────────┬────────┘
</span></span><span class=line><span class=cl>                           ↑
</span></span><span class=line><span class=cl>                    统一 Token 流
</span></span><span class=line><span class=cl>                           ↑
</span></span><span class=line><span class=cl>        ┌──────────────────┼──────────────────┐
</span></span><span class=line><span class=cl>        │                  │                  │
</span></span><span class=line><span class=cl>     🖼️ 图像            📝 文本            🔊 音频
</span></span><span class=line><span class=cl>    (VQ-VAE)         (BPE)            (Codec)
</span></span><span class=line><span class=cl>        │                  │                  │
</span></span><span class=line><span class=cl>        └──────────────────┴──────────────────┘
</span></span><span class=line><span class=cl>              所有模态共享同一词汇表
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>本质：从零开始，用多模态数据联合训练的单一系统
</span></span><span class=line><span class=cl>类比：从小在双语环境长大的人，天生就会中英文</span></span></code></pre></div><p><strong>工作流程</strong>：</p><ol><li><p><strong>统一 Token 化</strong>：所有模态转为离散 Token</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>文本: &#34;猫&#34; → Token ID 1024
</span></span><span class=line><span class=cl>图像: 🐱  → Token ID 256142
</span></span><span class=line><span class=cl>音频: 喵  → Token ID 264523</span></span></code></pre></div></li><li><p><strong>统一 Transformer</strong>：单一模型处理所有 Token</p><ul><li>训练数据：混合数据（文本 + 图像 + 音频 + &mldr;）</li><li>训练目标：统一的 Next Token Prediction</li><li>优势：每层都能学习跨模态交互</li></ul></li><li><p><strong>无需桥接层</strong>：所有模态天生在同一空间</p><ul><li>无信息瓶颈</li><li>无需"翻译"</li><li>自然支持模态混合</li></ul></li></ol><h3 id=82-核心差异深入技术对比>8.2 核心差异：深入技术对比<a class=anchor href=#82-%e6%a0%b8%e5%bf%83%e5%b7%ae%e5%bc%82%e6%b7%b1%e5%85%a5%e6%8a%80%e6%9c%af%e5%af%b9%e6%af%94>#</a></h3><table><thead><tr><th>维度</th><th>Connector (LLaVA)</th><th>Native (GPT-4o)</th></tr></thead><tbody><tr><td><strong>训练范式</strong></td><td>🔧 <strong>组装式</strong>：先单模态 → 后拼接</td><td>🌱 <strong>原生式</strong>：从零多模态联合训练</td></tr><tr><td><strong>Token 空间</strong></td><td>🔀 <strong>分离后对齐</strong>：<br>- CLIP: $\mathbb{R}^{1024}$<br>- LLM: $\mathbb{R}^{4096}$<br>- 投影层强行对齐</td><td>✨ <strong>天然统一</strong>：<br>- 所有模态共享同一词汇表<br>- [0, 300k) 包含文本/图像/音频</td></tr><tr><td><strong>信息流动</strong></td><td>🚧 <strong>单向受限</strong>：<br>视觉 → 投影层 → LLM<br>投影层是瓶颈（576 Token）</td><td>🌊 <strong>全向流动</strong>：<br>任意模态可在任意层交互<br>无瓶颈</td></tr><tr><td><strong>细粒度交互</strong></td><td>❌ <strong>浅层交互</strong>：<br>- 只有 LLM 的自注意力能跨模态<br>- 视觉编码器完全不知道文本</td><td>✅ <strong>深层融合</strong>：<br>- 每层 Transformer 都跨模态<br>- 图像、文本、音频互相"理解"</td></tr><tr><td><strong>长上下文</strong></td><td>📏 <strong>受限</strong>：<br>- 8K Token（LLaMA-7B）<br>- 视觉 Token 占大头（576×N 帧）</td><td>🚀 <strong>超长</strong>：<br>- 128K+ (GPT-4o)<br>- 1M Token (Gemini 1.5)</td></tr><tr><td><strong>模态数量</strong></td><td>🔢 <strong>受限</strong>：<br>- 通常只支持文本+图像<br>- 添加新模态需要新的编码器+投影层</td><td>∞ <strong>无限扩展</strong>：<br>- 文本、图像、音频、视频统一<br>- 添加新模态只需扩展词汇表</td></tr><tr><td><strong>训练成本</strong></td><td>💰 <strong>低</strong>：<br>- 100万美元级别<br>- 只训练投影层+微调 LLM</td><td>💸 <strong>极高</strong>：<br>- 数亿美元级别<br>- 从零训练整个模型</td></tr><tr><td><strong>推理效率</strong></td><td>⚡ <strong>高</strong>：<br>- 7B-13B 参数<br>- 可本地部署</td><td>🐢 <strong>低</strong>：<br>- 数百 B 参数（推测）<br>- 只能 API 调用</td></tr></tbody></table><h3 id=83-能力对比实际场景测试>8.3 能力对比：实际场景测试<a class=anchor href=#83-%e8%83%bd%e5%8a%9b%e5%af%b9%e6%af%94%e5%ae%9e%e9%99%85%e5%9c%ba%e6%99%af%e6%b5%8b%e8%af%95>#</a></h3><h4 id=场景-1细粒度视觉推理>场景 1：细粒度视觉推理<a class=anchor href=#%e5%9c%ba%e6%99%af-1%e7%bb%86%e7%b2%92%e5%ba%a6%e8%a7%86%e8%a7%89%e6%8e%a8%e7%90%86>#</a></h4><p><strong>任务</strong>：图中左下角的咖啡杯是什么颜色？</p><p><strong>Connector（LLaVA）表现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>问：图中左下角的咖啡杯是什么颜色？
</span></span><span class=line><span class=cl>答：图片中有一个咖啡杯，它是白色的。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>问题：无法精确定位&#34;左下角&#34;，因为：
</span></span><span class=line><span class=cl>- CLIP ViT 只输出全局特征（576 个 patch）
</span></span><span class=line><span class=cl>- 投影层压缩后，空间信息进一步损失
</span></span><span class=line><span class=cl>- LLM 难以理解精确的空间位置</span></span></code></pre></div><p><strong>Native（GPT-4o）表现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>问：图中左下角的咖啡杯是什么颜色？
</span></span><span class=line><span class=cl>答：左下角的咖啡杯是深蓝色，杯身上有白色的品牌logo。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>优势：
</span></span><span class=line><span class=cl>- 原生视觉编码保留更多空间信息
</span></span><span class=line><span class=cl>- 统一 Transformer 能在多层细化空间理解
</span></span><span class=line><span class=cl>- 无信息瓶颈</span></span></code></pre></div><h4 id=场景-2跨模态推理>场景 2：跨模态推理<a class=anchor href=#%e5%9c%ba%e6%99%af-2%e8%b7%a8%e6%a8%a1%e6%80%81%e6%8e%a8%e7%90%86>#</a></h4><p><strong>任务</strong>：看图说话，并解释为什么这张图令人感动。</p><p><strong>Connector（LLaVA）表现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>答：图片显示了一位母亲抱着她的孩子。这可能令人感动，
</span></span><span class=line><span class=cl>    因为它展示了母爱。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>特点：
</span></span><span class=line><span class=cl>- 描述准确但浅层
</span></span><span class=line><span class=cl>- 缺乏情感细节（表情、姿态、背景）
</span></span><span class=line><span class=cl>- 推理链较短</span></span></code></pre></div><p><strong>Native（GPT-4o）表现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>答：图片中，一位母亲正紧紧拥抱着她的孩子，两人都闭着眼睛，
</span></span><span class=line><span class=cl>    脸上洋溢着幸福的微笑。阳光从窗户洒进来，温暖地照在她们
</span></span><span class=line><span class=cl>    身上。这张图令人感动，因为：
</span></span><span class=line><span class=cl>    1. 肢体语言：紧密的拥抱传递出深深的爱
</span></span><span class=line><span class=cl>    2. 面部表情：满足且安心的微笑
</span></span><span class=line><span class=cl>    3. 光线氛围：暖色调烘托出温馨感
</span></span><span class=line><span class=cl>    这种母子间的纯粹情感连接触动人心。
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>优势：
</span></span><span class=line><span class=cl>- 多层次细节观察
</span></span><span class=line><span class=cl>- 视觉-情感-语言深度融合
</span></span><span class=line><span class=cl>- 推理链更长更连贯</span></span></code></pre></div><h4 id=场景-3视频音频理解>场景 3：视频+音频理解<a class=anchor href=#%e5%9c%ba%e6%99%af-3%e8%a7%86%e9%a2%91%e9%9f%b3%e9%a2%91%e7%90%86%e8%a7%a3>#</a></h4><p><strong>任务</strong>：分析这段钢琴演奏视频，评价演奏者的技巧。</p><p><strong>Connector（LLaVA-Video）表现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>答：无法完成任务
</span></span><span class=line><span class=cl>原因：
</span></span><span class=line><span class=cl>- 需要单独的音频编码器（增加复杂度）
</span></span><span class=line><span class=cl>- 视频帧和音频 Token 如何同步？
</span></span><span class=line><span class=cl>- 投影层如何处理三模态（视频+音频+文本）？</span></span></code></pre></div><p><strong>Native（GPT-4o）表现</strong>：</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>输入：[视频帧 Token] + [音频 Token] + [文本 Token]
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>答：演奏者展现了出色的技巧：
</span></span><span class=line><span class=cl>    - 视觉观察：手指动作流畅，踏板使用精准
</span></span><span class=line><span class=cl>    - 听觉分析：音色饱满，节奏稳定，强弱对比明显
</span></span><span class=line><span class=cl>    - 综合评价：这是一场高水平的演出
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>优势：
</span></span><span class=line><span class=cl>- Any-to-Any 原生支持
</span></span><span class=line><span class=cl>- 统一 Token 空间无需复杂工程</span></span></code></pre></div><h3 id=84-类比理解两种架构的本质>8.4 类比理解：两种架构的本质<a class=anchor href=#84-%e7%b1%bb%e6%af%94%e7%90%86%e8%a7%a3%e4%b8%a4%e7%a7%8d%e6%9e%b6%e6%9e%84%e7%9a%84%e6%9c%ac%e8%b4%a8>#</a></h3><h4 id=connector拼接汽车>Connector：拼接汽车<a class=anchor href=#connector%e6%8b%bc%e6%8e%a5%e6%b1%bd%e8%bd%a6>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌─────────┐    ┌──────────┐    ┌─────────┐
</span></span><span class=line><span class=cl>│ 自行车  │ → │  改装套件 │ → │ 电动车  │
</span></span><span class=line><span class=cl>│ 引擎    │    │ (投影层)  │    │ (能跑)  │
</span></span><span class=line><span class=cl>└─────────┘    └──────────┘    └─────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>优点：
</span></span><span class=line><span class=cl>✅ 便宜：利用现成部件
</span></span><span class=line><span class=cl>✅ 快速：组装即可上路
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>缺点：
</span></span><span class=line><span class=cl>❌ 性能受限：引擎和电池不匹配
</span></span><span class=line><span class=cl>❌ 效率低：能量在转换中损失
</span></span><span class=line><span class=cl>❌ 扩展难：加装音响系统很麻烦</span></span></code></pre></div><h4 id=native原生电动车>Native：原生电动车<a class=anchor href=#native%e5%8e%9f%e7%94%9f%e7%94%b5%e5%8a%a8%e8%bd%a6>#</a></h4><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌─────────────────────────────────────┐
</span></span><span class=line><span class=cl>│        特斯拉 (Tesla)                │
</span></span><span class=line><span class=cl>│  - 电池、引擎、控制系统一体化设计    │
</span></span><span class=line><span class=cl>│  - 从零开始为电动优化                │
</span></span><span class=line><span class=cl>│  - 软硬件深度集成                    │
</span></span><span class=line><span class=cl>└─────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>优点：
</span></span><span class=line><span class=cl>✅ 性能强：专为目标设计
</span></span><span class=line><span class=cl>✅ 效率高：无能量转换损失
</span></span><span class=line><span class=cl>✅ 扩展易：添加功能只需软件升级
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>缺点：
</span></span><span class=line><span class=cl>❌ 昂贵：研发成本数十亿美元
</span></span><span class=line><span class=cl>❌ 耗时：需要多年迭代</span></span></code></pre></div><h3 id=85-未来趋势预测>8.5 未来趋势预测<a class=anchor href=#85-%e6%9c%aa%e6%9d%a5%e8%b6%8b%e5%8a%bf%e9%a2%84%e6%b5%8b>#</a></h3><p><strong>短期（1-2年）</strong>：Connector 仍是主流</p><ul><li>✅ 开源社区持续优化 LLaVA 类模型</li><li>✅ Qwen-VL、InternVL 等国产方案成熟</li><li>✅ 企业优先选择成本低、易部署的方案</li></ul><p><strong>中期（2-3年）</strong>：Native 开始普及</p><ul><li>🚀 新一代闭源模型进一步提升能力</li><li>🚀 开源社区尝试小规模 Native 模型（7B-13B）</li><li>🚀 Omni 模型成为高端应用标配</li></ul><p><strong>长期（3年以上）</strong>：Native 完全主导</p><ul><li>🌟 训练成本降低（更高效的算法）</li><li>🌟 开源 Native 模型性能追上 Connector</li><li>🌟 Connector 方案逐渐被淘汰（就像单模态模型淘汰传统 CV/NLP pipeline）</li></ul><h3 id=86-选型建议最新版>8.6 选型建议（最新版）<a class=anchor href=#86-%e9%80%89%e5%9e%8b%e5%bb%ba%e8%ae%ae%e6%9c%80%e6%96%b0%e7%89%88>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>┌──────────────────────────────────────────────────────┐
</span></span><span class=line><span class=cl>│                    决策树                             │
</span></span><span class=line><span class=cl>└──────────────────────────────────────────────────────┘
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>你的预算是否 &gt; $10万/年？
</span></span><span class=line><span class=cl>    │
</span></span><span class=line><span class=cl>    ├─ 否 → 用 Connector (LLaVA, Qwen-VL)
</span></span><span class=line><span class=cl>    │       - 开源免费
</span></span><span class=line><span class=cl>    │       - 可本地部署
</span></span><span class=line><span class=cl>    │       - 适合：研究、原型、中小企业
</span></span><span class=line><span class=cl>    │
</span></span><span class=line><span class=cl>    └─ 是 → 你需要顶级性能吗？
</span></span><span class=line><span class=cl>            │
</span></span><span class=line><span class=cl>            ├─ 是 → Native (GPT-4o, Claude 3.5)
</span></span><span class=line><span class=cl>            │       - API 调用
</span></span><span class=line><span class=cl>            │       - 适合：高价值应用（医疗、金融）
</span></span><span class=line><span class=cl>            │
</span></span><span class=line><span class=cl>            └─ 否 → 混合方案
</span></span><span class=line><span class=cl>                    - 简单任务：Connector (自部署)
</span></span><span class=line><span class=cl>                    - 复杂任务：Native (API)
</span></span><span class=line><span class=cl>                    - 适合：成本敏感的生产环境</span></span></code></pre></div><p><strong>具体场景推荐</strong>：</p><table><thead><tr><th>场景</th><th>推荐方案</th><th>理由</th></tr></thead><tbody><tr><td><strong>学术研究</strong></td><td>LLaVA-1.5-7B</td><td>开源、可复现、社区活跃</td></tr><tr><td><strong>产品原型</strong></td><td>Qwen-VL-Chat</td><td>中文友好、部署简单</td></tr><tr><td><strong>内容审核</strong></td><td>Connector 自部署</td><td>隐私保护、低延迟</td></tr><tr><td><strong>医疗诊断</strong></td><td>GPT-4o / Claude 3.5</td><td>最高精度、可解释性强</td></tr><tr><td><strong>长视频分析</strong></td><td>Gemini 1.5 Pro</td><td>1M Token 上下文</td></tr><tr><td><strong>实时语音交互</strong></td><td>GPT-4o</td><td>Any-to-Any 原生支持</td></tr></tbody></table><h3 id=87-实战对比测试两种架构>8.7 实战：对比测试两种架构<a class=anchor href=#87-%e5%ae%9e%e6%88%98%e5%af%b9%e6%af%94%e6%b5%8b%e8%af%95%e4%b8%a4%e7%a7%8d%e6%9e%b6%e6%9e%84>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-python data-lang=python><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;
</span></span></span><span class=line><span class=cl><span class=s2>对比 Connector (LLaVA) 和 Native (GPT-4o) 在同一任务上的表现
</span></span></span><span class=line><span class=cl><span class=s2>&#34;&#34;&#34;</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>transformers</span> <span class=kn>import</span> <span class=n>LlavaForConditionalGeneration</span><span class=p>,</span> <span class=n>AutoProcessor</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>openai</span> <span class=kn>import</span> <span class=n>OpenAI</span>
</span></span><span class=line><span class=cl><span class=kn>from</span> <span class=nn>PIL</span> <span class=kn>import</span> <span class=n>Image</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>base64</span>
</span></span><span class=line><span class=cl><span class=kn>import</span> <span class=nn>torch</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ========== Connector 方案 (LLaVA) ==========</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_connector</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>model_id</span> <span class=o>=</span> <span class=s2>&#34;llava-hf/llava-1.5-7b-hf&#34;</span>
</span></span><span class=line><span class=cl>    <span class=n>model</span> <span class=o>=</span> <span class=n>LlavaForConditionalGeneration</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model_id</span><span class=p>,</span> <span class=n>torch_dtype</span><span class=o>=</span><span class=n>torch</span><span class=o>.</span><span class=n>float16</span><span class=p>,</span> <span class=n>device_map</span><span class=o>=</span><span class=s2>&#34;auto&#34;</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>processor</span> <span class=o>=</span> <span class=n>AutoProcessor</span><span class=o>.</span><span class=n>from_pretrained</span><span class=p>(</span><span class=n>model_id</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>image</span> <span class=o>=</span> <span class=n>Image</span><span class=o>.</span><span class=n>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=n>prompt</span> <span class=o>=</span> <span class=sa>f</span><span class=s2>&#34;USER: &lt;image&gt;</span><span class=se>\n</span><span class=si>{</span><span class=n>question</span><span class=si>}</span><span class=se>\n</span><span class=s2>ASSISTANT:&#34;</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>inputs</span> <span class=o>=</span> <span class=n>processor</span><span class=p>(</span><span class=n>text</span><span class=o>=</span><span class=n>prompt</span><span class=p>,</span> <span class=n>images</span><span class=o>=</span><span class=n>image</span><span class=p>,</span> <span class=n>return_tensors</span><span class=o>=</span><span class=s2>&#34;pt&#34;</span><span class=p>)</span><span class=o>.</span><span class=n>to</span><span class=p>(</span><span class=s2>&#34;cuda&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=n>torch</span><span class=o>.</span><span class=n>inference_mode</span><span class=p>():</span>
</span></span><span class=line><span class=cl>        <span class=n>generated_ids</span> <span class=o>=</span> <span class=n>model</span><span class=o>.</span><span class=n>generate</span><span class=p>(</span><span class=o>**</span><span class=n>inputs</span><span class=p>,</span> <span class=n>max_new_tokens</span><span class=o>=</span><span class=mi>200</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>output</span> <span class=o>=</span> <span class=n>processor</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=n>generated_ids</span><span class=p>[</span><span class=mi>0</span><span class=p>],</span> <span class=n>skip_special_tokens</span><span class=o>=</span><span class=kc>True</span><span class=p>)</span>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>output</span><span class=o>.</span><span class=n>split</span><span class=p>(</span><span class=s2>&#34;ASSISTANT:&#34;</span><span class=p>)[</span><span class=o>-</span><span class=mi>1</span><span class=p>]</span><span class=o>.</span><span class=n>strip</span><span class=p>()</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ========== Native 方案 (GPT-4o) ==========</span>
</span></span><span class=line><span class=cl><span class=k>def</span> <span class=nf>test_native</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=n>question</span><span class=p>):</span>
</span></span><span class=line><span class=cl>    <span class=n>client</span> <span class=o>=</span> <span class=n>OpenAI</span><span class=p>(</span><span class=n>api_key</span><span class=o>=</span><span class=s2>&#34;your-api-key&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>with</span> <span class=nb>open</span><span class=p>(</span><span class=n>image_path</span><span class=p>,</span> <span class=s2>&#34;rb&#34;</span><span class=p>)</span> <span class=k>as</span> <span class=n>f</span><span class=p>:</span>
</span></span><span class=line><span class=cl>        <span class=n>base64_image</span> <span class=o>=</span> <span class=n>base64</span><span class=o>.</span><span class=n>b64encode</span><span class=p>(</span><span class=n>f</span><span class=o>.</span><span class=n>read</span><span class=p>())</span><span class=o>.</span><span class=n>decode</span><span class=p>(</span><span class=s1>&#39;utf-8&#39;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=n>response</span> <span class=o>=</span> <span class=n>client</span><span class=o>.</span><span class=n>chat</span><span class=o>.</span><span class=n>completions</span><span class=o>.</span><span class=n>create</span><span class=p>(</span>
</span></span><span class=line><span class=cl>        <span class=n>model</span><span class=o>=</span><span class=s2>&#34;gpt-4o&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>        <span class=n>messages</span><span class=o>=</span><span class=p>[{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;role&#34;</span><span class=p>:</span> <span class=s2>&#34;user&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;content&#34;</span><span class=p>:</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span><span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;text&#34;</span><span class=p>,</span> <span class=s2>&#34;text&#34;</span><span class=p>:</span> <span class=n>question</span><span class=p>},</span>
</span></span><span class=line><span class=cl>                <span class=p>{</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;type&#34;</span><span class=p>:</span> <span class=s2>&#34;image_url&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                    <span class=s2>&#34;image_url&#34;</span><span class=p>:</span> <span class=p>{</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;url&#34;</span><span class=p>:</span> <span class=sa>f</span><span class=s2>&#34;data:image/jpeg;base64,</span><span class=si>{</span><span class=n>base64_image</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>                        <span class=s2>&#34;detail&#34;</span><span class=p>:</span> <span class=s2>&#34;high&#34;</span>
</span></span><span class=line><span class=cl>                    <span class=p>}</span>
</span></span><span class=line><span class=cl>                <span class=p>}</span>
</span></span><span class=line><span class=cl>            <span class=p>]</span>
</span></span><span class=line><span class=cl>        <span class=p>}],</span>
</span></span><span class=line><span class=cl>        <span class=n>max_tokens</span><span class=o>=</span><span class=mi>200</span>
</span></span><span class=line><span class=cl>    <span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>return</span> <span class=n>response</span><span class=o>.</span><span class=n>choices</span><span class=p>[</span><span class=mi>0</span><span class=p>]</span><span class=o>.</span><span class=n>message</span><span class=o>.</span><span class=n>content</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># ========== 对比测试 ==========</span>
</span></span><span class=line><span class=cl><span class=k>if</span> <span class=vm>__name__</span> <span class=o>==</span> <span class=s2>&#34;__main__&#34;</span><span class=p>:</span>
</span></span><span class=line><span class=cl>    <span class=n>test_cases</span> <span class=o>=</span> <span class=p>[</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=s2>&#34;complex_scene.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=s2>&#34;请详细描述图片右上角的物体，并解释它为什么重要。&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=s2>&#34;chart.png&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=s2>&#34;分析这张图表的趋势，并给出投资建议。&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>},</span>
</span></span><span class=line><span class=cl>        <span class=p>{</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;image&#34;</span><span class=p>:</span> <span class=s2>&#34;medical_scan.jpg&#34;</span><span class=p>,</span>
</span></span><span class=line><span class=cl>            <span class=s2>&#34;question&#34;</span><span class=p>:</span> <span class=s2>&#34;识别图中的异常区域，并评估严重程度（仅供参考）。&#34;</span>
</span></span><span class=line><span class=cl>        <span class=p>}</span>
</span></span><span class=line><span class=cl>    <span class=p>]</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>    <span class=k>for</span> <span class=n>i</span><span class=p>,</span> <span class=n>test</span> <span class=ow>in</span> <span class=nb>enumerate</span><span class=p>(</span><span class=n>test_cases</span><span class=p>,</span> <span class=mi>1</span><span class=p>):</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;测试 </span><span class=si>{</span><span class=n>i</span><span class=si>}</span><span class=s2>: </span><span class=si>{</span><span class=n>test</span><span class=p>[</span><span class=s1>&#39;question&#39;</span><span class=p>]</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=s2>&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>[Connector - LLaVA]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>connector_answer</span> <span class=o>=</span> <span class=n>test_connector</span><span class=p>(</span><span class=n>test</span><span class=p>[</span><span class=s1>&#39;image&#39;</span><span class=p>],</span> <span class=n>test</span><span class=p>[</span><span class=s1>&#39;question&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>connector_answer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=s2>&#34;</span><span class=se>\n</span><span class=s2>[Native - GPT-4o]&#34;</span><span class=p>)</span>
</span></span><span class=line><span class=cl>        <span class=n>native_answer</span> <span class=o>=</span> <span class=n>test_native</span><span class=p>(</span><span class=n>test</span><span class=p>[</span><span class=s1>&#39;image&#39;</span><span class=p>],</span> <span class=n>test</span><span class=p>[</span><span class=s1>&#39;question&#39;</span><span class=p>])</span>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=n>native_answer</span><span class=p>)</span>
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl>        <span class=nb>print</span><span class=p>(</span><span class=sa>f</span><span class=s2>&#34;</span><span class=se>\n</span><span class=si>{</span><span class=s1>&#39;=&#39;</span><span class=o>*</span><span class=mi>60</span><span class=si>}</span><span class=se>\n</span><span class=s2>&#34;</span><span class=p>)</span></span></span></code></pre></div><p><strong>预期观察</strong>：</p><ul><li><strong>细节丰富度</strong>：Native > Connector</li><li><strong>推理深度</strong>：Native > Connector</li><li><strong>空间理解</strong>：Native > Connector</li><li><strong>响应速度</strong>：Connector > Native（本地部署）</li><li><strong>成本</strong>：Connector &lt; Native</li></ul><hr><h2 id=九总结与展望>九、总结与展望<a class=anchor href=#%e4%b9%9d%e6%80%bb%e7%bb%93%e4%b8%8e%e5%b1%95%e6%9c%9b>#</a></h2><h3 id=91-核心知识点回顾>9.1 核心知识点回顾<a class=anchor href=#91-%e6%a0%b8%e5%bf%83%e7%9f%a5%e8%af%86%e7%82%b9%e5%9b%9e%e9%a1%be>#</a></h3><table><thead><tr><th>技术</th><th>核心思想</th><th>关键创新</th></tr></thead><tbody><tr><td><strong>ViT</strong></td><td>图像分块 → Transformer</td><td>证明 Transformer 可处理视觉</td></tr><tr><td><strong>CLIP</strong></td><td>对比学习对齐图文</td><td>零样本能力，跨模态检索</td></tr><tr><td><strong>LLaVA</strong></td><td>投影层连接视觉和语言</td><td>简单高效，易于训练</td></tr><tr><td><strong>Native Multimodal</strong></td><td>统一 Token 空间</td><td>更强交互，更长上下文</td></tr></tbody></table><h3 id=92-多模态技术演进路线>9.2 多模态技术演进路线<a class=anchor href=#92-%e5%a4%9a%e6%a8%a1%e6%80%81%e6%8a%80%e6%9c%af%e6%bc%94%e8%bf%9b%e8%b7%af%e7%ba%bf>#</a></h3><div class=highlight><pre tabindex=0 class=chroma><code class=language-fallback data-lang=fallback><span class=line><span class=cl>2017: Transformer 诞生（纯文本）
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>2020: ViT 证明 Transformer 可处理图像
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>2021: CLIP 实现图文对齐（对比学习）
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>2023: LLaVA 连接 LLM 和视觉（投影层方案）
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>SOTA: GPT-4V/Gemini 原生多模态（端到端训练）
</span></span><span class=line><span class=cl>  ↓
</span></span><span class=line><span class=cl>当前: Omni 模型成标配（图文音视频统一）</span></span></code></pre></div><h3 id=93-未来趋势>9.3 未来趋势<a class=anchor href=#93-%e6%9c%aa%e6%9d%a5%e8%b6%8b%e5%8a%bf>#</a></h3><ol><li><p><strong>Any-to-Any 模型</strong></p><ul><li>输入：图/文/音/视频</li><li>输出：图/文/音/视频</li><li>代表：GPT-4o（实时语音对话 + 视觉）</li></ul></li><li><p><strong>具身智能（Embodied AI）</strong></p><ul><li>多模态 + 机器人控制</li><li>感知（视觉）+ 理解（语言）+ 行动（控制）</li><li>代表：RT-2、PaLM-E</li></ul></li><li><p><strong>更长上下文</strong></p><ul><li>处理完整电影、长文档</li><li>Gemini 1.5：1M Token（约 1 小时视频）</li></ul></li><li><p><strong>更高效的训练</strong></p><ul><li>小模型 + 大数据 > 大模型 + 小数据</li><li>LoRA、QLoRA 等高效微调技术</li></ul></li></ol><h3 id=94-学习资源>9.4 学习资源<a class=anchor href=#94-%e5%ad%a6%e4%b9%a0%e8%b5%84%e6%ba%90>#</a></h3><p><strong>论文</strong>：</p><ul><li>ViT: <a href=https://arxiv.org/abs/2010.11929>An Image is Worth 16x16 Words</a></li><li>CLIP: <a href=https://arxiv.org/abs/2103.00020>Learning Transferable Visual Models</a></li><li>LLaVA: <a href=https://arxiv.org/abs/2304.08485>Visual Instruction Tuning</a></li><li>GPT-4o: <a href=https://openai.com/index/hello-gpt-4o/>Omni Technical Report</a></li></ul><p><strong>代码</strong>：</p><ul><li>LLaVA: <a href=https://github.com/haotian-liu/LLaVA>https://github.com/haotian-liu/LLaVA</a></li><li>CLIP: <a href=https://github.com/openai/CLIP>https://github.com/openai/CLIP</a></li><li>Video-LLaVA: <a href=https://github.com/PKU-YuanGroup/Video-LLaVA>https://github.com/PKU-YuanGroup/Video-LLaVA</a></li></ul><p><strong>实践建议</strong>：</p><ol><li>先用 CLIP 熟悉图文对齐</li><li>尝试部署 LLaVA-1.5-7B（本地 GPU）</li><li>使用 GPT-4o/Gemini API 体验原生多模态</li><li>尝试处理简单视频（抽帧方案）</li></ol><hr><blockquote class=book-hint><p><strong>下一步</strong>：详见 [Part 6 第4章] 多模态模型评估，学习如何评估多模态模型的能力。</p></blockquote></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第3章 智能体（Agent）核心机制</span>
</a></span><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/ class="flex align-center"><span>第1章 Hugging Face生态全景</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#目录>目录</a></li><li><a href=#一多模态的直觉理解图像作为外语>一、多模态的直觉理解：图像作为"外语"</a><ul><li><a href=#11-token-space-alignment为什么图像可以被视为外语>1.1 Token Space Alignment：为什么图像可以被视为"外语"</a></li><li><a href=#12-数学本质余弦相似度>1.2 数学本质：余弦相似度</a></li></ul></li><li><a href=#二统一-token-化omni-模型的基石>二、统一 Token 化：Omni 模型的基石</a><ul><li><a href=#21-从连续到离散为什么需要-token-化>2.1 从连续到离散：为什么需要 Token 化</a></li><li><a href=#22-视觉-token-化vq-vaevector-quantized-variational-autoencoder>2.2 视觉 Token 化：VQ-VAE（Vector Quantized Variational AutoEncoder）</a><ul><li><a href=#221-vq-vae-核心原理>2.2.1 VQ-VAE 核心原理</a></li><li><a href=#222-codebook-的工作机制>2.2.2 Codebook 的工作机制</a></li><li><a href=#223-视觉-token-化的直观理解>2.2.3 视觉 Token 化的直观理解</a></li></ul></li><li><a href=#23-音频-token-化audio-codec>2.3 音频 Token 化：Audio Codec</a><ul><li><a href=#231-常用音频-codec>2.3.1 常用音频 Codec</a></li><li><a href=#232-音频-token-化示例代码>2.3.2 音频 Token 化示例代码</a></li></ul></li><li><a href=#24-统一-token-空间omni-模型的实现>2.4 统一 Token 空间：Omni 模型的实现</a></li><li><a href=#25-实战构建简易的视觉-token-化器>2.5 实战：构建简易的视觉 Token 化器</a></li></ul></li><li><a href=#三视觉编码器vision-transformer-vit>三、视觉编码器：Vision Transformer (ViT)</a><ul><li><a href=#31-核心思想图像是-1616-的单词>3.1 核心思想：图像是 16×16 的单词</a></li><li><a href=#32-vit-代码实现>3.2 ViT 代码实现</a></li></ul></li><li><a href=#四图文对齐clip>四、图文对齐：CLIP</a><ul><li><a href=#41-核心机制对比学习contrastive-learning>4.1 核心机制：对比学习（Contrastive Learning）</a></li><li><a href=#42-clip-的实际使用>4.2 CLIP 的实际使用</a></li><li><a href=#43-clip-的应用场景>4.3 CLIP 的应用场景</a></li></ul></li><li><a href=#五多模态大模型架构llava>五、多模态大模型架构：LLaVA</a><ul><li><a href=#51-架构设计三个组件>5.1 架构设计：三个组件</a></li><li><a href=#52-projection-layertoken-space-alignment-的实现>5.2 Projection Layer：Token Space Alignment 的实现</a></li><li><a href=#53-llava-的两阶段训练>5.3 LLaVA 的两阶段训练</a><ul><li><a href=#阶段一特征对齐预训练feature-alignment-pre-training>阶段一：特征对齐预训练（Feature Alignment Pre-training）</a></li><li><a href=#阶段二视觉指令微调visual-instruction-tuning>阶段二：视觉指令微调（Visual Instruction Tuning）</a></li></ul></li><li><a href=#54-其他连接器方案perceiver-resampler-flamingoidefics>5.4 其他连接器方案：Perceiver Resampler (Flamingo/IDEFICS)</a></li></ul></li><li><a href=#六视频理解video-as-frames>六、视频理解：Video as Frames</a><ul><li><a href=#61-视频的本质时序图像序列>6.1 视频的本质：时序图像序列</a></li><li><a href=#62-视频抽帧策略>6.2 视频抽帧策略</a></li><li><a href=#63-视频-token-化两种范式>6.3 视频 Token 化：两种范式</a><ul><li><a href=#范式-1连接器方案llava-video>范式 1：连接器方案（LLaVA-Video）</a></li><li><a href=#范式-2原生统一方案gpt-4o>范式 2：原生统一方案（GPT-4o）</a></li></ul></li><li><a href=#64-实战使用-llava-video-理解视频>6.4 实战：使用 LLaVA-Video 理解视频</a></li><li><a href=#65-视频理解的挑战与优化>6.5 视频理解的挑战与优化</a></li><li><a href=#66-视频理解的应用场景>6.6 视频理解的应用场景</a></li></ul></li><li><a href=#七实战多模态理解应用>七、实战：多模态理解应用</a><ul><li><a href=#71-使用开源模型llava-图像问答>7.1 使用开源模型：LLaVA 图像问答</a></li><li><a href=#72-实战构建本地图文检索引擎>7.2 实战：构建本地图文检索引擎</a></li><li><a href=#73-实战使用-gpt-4v-进行高级视觉理解>7.3 实战：使用 GPT-4V 进行高级视觉理解</a></li></ul></li><li><a href=#八当前视角connector-vs-native-multimodal>八、当前视角：Connector vs Native Multimodal</a><ul><li><a href=#81-架构范式对比眼睛-vs-神经系统>8.1 架构范式对比：眼睛 vs 神经系统</a><ul><li><a href=#connector-方案llava外挂的眼睛>Connector 方案（LLaVA）：外挂的"眼睛"</a></li><li><a href=#native-方案gpt-4o原生的神经系统>Native 方案（GPT-4o）：原生的"神经系统"</a></li></ul></li><li><a href=#82-核心差异深入技术对比>8.2 核心差异：深入技术对比</a></li><li><a href=#83-能力对比实际场景测试>8.3 能力对比：实际场景测试</a><ul><li><a href=#场景-1细粒度视觉推理>场景 1：细粒度视觉推理</a></li><li><a href=#场景-2跨模态推理>场景 2：跨模态推理</a></li><li><a href=#场景-3视频音频理解>场景 3：视频+音频理解</a></li></ul></li><li><a href=#84-类比理解两种架构的本质>8.4 类比理解：两种架构的本质</a><ul><li><a href=#connector拼接汽车>Connector：拼接汽车</a></li><li><a href=#native原生电动车>Native：原生电动车</a></li></ul></li><li><a href=#85-未来趋势预测>8.5 未来趋势预测</a></li><li><a href=#86-选型建议最新版>8.6 选型建议（最新版）</a></li><li><a href=#87-实战对比测试两种架构>8.7 实战：对比测试两种架构</a></li></ul></li><li><a href=#九总结与展望>九、总结与展望</a><ul><li><a href=#91-核心知识点回顾>9.1 核心知识点回顾</a></li><li><a href=#92-多模态技术演进路线>9.2 多模态技术演进路线</a></li><li><a href=#93-未来趋势>9.3 未来趋势</a></li><li><a href=#94-学习资源>9.4 学习资源</a></li></ul></li></ul></nav></div></aside></main></body></html>