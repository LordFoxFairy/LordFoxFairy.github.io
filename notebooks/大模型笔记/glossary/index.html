<!doctype html><html lang=zh-cn dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=description content="GLOSSARY 术语表# 大语言模型技术索引 (2025年版)
本术语表包含大语言模型领域的核心概念、前沿技术与工程实践术语。每个术语提供精炼定义及章节交叉引用。
A# AdaLoRA (Adaptive LoRA)# 自适应秩分配的LoRA变体，根据重要性动态调整不同层的秩参数，提升参数效率。 → 详见 [Part 3 Ch 2: 微调你的专属模型]
Agent (智能体)# 能够感知环境、自主决策并执行行动以完成目标的LLM系统，通常结合ReAct模式与工具调用能力。 → 详见 [Part 4 Ch 3: 智能体核心机制]
Alignment (对齐)# 使模型输出符合人类价值观和意图的过程，核心技术包括RLHF、DPO等。 → 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]
Attention (注意力机制)# Transformer的核心组件，通过Query-Key-Value机制动态加权聚合信息，实现上下文理解。 → 详见 [Part 2 Ch 1: Transformer核心揭秘]
B# BERT (Bidirectional Encoder Representations from Transformers)# 基于Transformer编码器的双向预训练模型，擅长理解任务如文本分类、命名实体识别。 → 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 2: 模型家族谱系]
"><meta name=theme-color media="(prefers-color-scheme: light)" content="#ffffff"><meta name=theme-color media="(prefers-color-scheme: dark)" content="#343a40"><meta name=color-scheme content="light dark"><meta property="og:url" content="https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/"><meta property="og:site_name" content="LordFoxFairy的笔记本"><meta property="og:title" content="GLOSSARY"><meta property="og:description" content="GLOSSARY 术语表# 大语言模型技术索引 (2025年版)
本术语表包含大语言模型领域的核心概念、前沿技术与工程实践术语。每个术语提供精炼定义及章节交叉引用。
A# AdaLoRA (Adaptive LoRA)# 自适应秩分配的LoRA变体，根据重要性动态调整不同层的秩参数，提升参数效率。 → 详见 [Part 3 Ch 2: 微调你的专属模型]
Agent (智能体)# 能够感知环境、自主决策并执行行动以完成目标的LLM系统，通常结合ReAct模式与工具调用能力。 → 详见 [Part 4 Ch 3: 智能体核心机制]
Alignment (对齐)# 使模型输出符合人类价值观和意图的过程，核心技术包括RLHF、DPO等。 → 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]
Attention (注意力机制)# Transformer的核心组件，通过Query-Key-Value机制动态加权聚合信息，实现上下文理解。 → 详见 [Part 2 Ch 1: Transformer核心揭秘]
B# BERT (Bidirectional Encoder Representations from Transformers)# 基于Transformer编码器的双向预训练模型，擅长理解任务如文本分类、命名实体识别。 → 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 2: 模型家族谱系]"><meta property="og:locale" content="zh_cn"><meta property="og:type" content="article"><meta property="article:section" content="notebooks"><meta itemprop=name content="GLOSSARY"><meta itemprop=description content="GLOSSARY 术语表# 大语言模型技术索引 (2025年版)
本术语表包含大语言模型领域的核心概念、前沿技术与工程实践术语。每个术语提供精炼定义及章节交叉引用。
A# AdaLoRA (Adaptive LoRA)# 自适应秩分配的LoRA变体，根据重要性动态调整不同层的秩参数，提升参数效率。 → 详见 [Part 3 Ch 2: 微调你的专属模型]
Agent (智能体)# 能够感知环境、自主决策并执行行动以完成目标的LLM系统，通常结合ReAct模式与工具调用能力。 → 详见 [Part 4 Ch 3: 智能体核心机制]
Alignment (对齐)# 使模型输出符合人类价值观和意图的过程，核心技术包括RLHF、DPO等。 → 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]
Attention (注意力机制)# Transformer的核心组件，通过Query-Key-Value机制动态加权聚合信息，实现上下文理解。 → 详见 [Part 2 Ch 1: Transformer核心揭秘]
B# BERT (Bidirectional Encoder Representations from Transformers)# 基于Transformer编码器的双向预训练模型，擅长理解任务如文本分类、命名实体识别。 → 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 2: 模型家族谱系]"><meta itemprop=wordCount content="954"><title>GLOSSARY | LordFoxFairy的笔记本</title><link rel=icon href=/favicon.png><link rel=manifest href=/manifest.json><link rel=canonical href=https://LordFoxFairy.github.io/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/><link rel=stylesheet href=/book.min.6970156cec683193d93c9c4edaf0d56574e4361df2e0c1be4f697ae81c3ba55f.css integrity="sha256-aXAVbOxoMZPZPJxO2vDVZXTkNh3y4MG+T2l66Bw7pV8=" crossorigin=anonymous><script defer src=/fuse.min.js></script><script defer src=/en.search.min.a7a11a812549b6c20d4eeaf4a5a8317847527505f7a0ad3e6824fb320b3128a8.js integrity="sha256-p6EagSVJtsINTur0pagxeEdSdQX3oK0+aCT7MgsxKKg=" crossorigin=anonymous></script></head><body dir=ltr class="book-kind-page book-type-notebooks"><input type=checkbox class="hidden toggle" id=menu-control>
<input type=checkbox class="hidden toggle" id=toc-control><main class="container flex"><aside class=book-menu><div class=book-menu-content><nav><h2 class=book-brand><a class="flex align-center" href=/><span>LordFoxFairy的笔记本</span></a></h2><div class="book-search hidden"><input id=book-search-input type=text placeholder=Search aria-label=Search maxlength=64 data-hotkeys=s/><div class="book-search-spinner hidden"></div><ul id=book-search-results></ul></div><script>document.querySelector(".book-search").classList.remove("hidden")</script><ul><li><input type=checkbox id=section-8410cdd8ef137d6cb143c08e6db6ba10 class=toggle>
<label for=section-8410cdd8ef137d6cb143c08e6db6ba10 class=flex><a role=button>LangChain笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87-%E5%9F%BA%E7%A1%80%E8%AE%A4%E7%9F%A5/>第一篇 基础认知</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87-%E5%BF%AB%E9%80%9F%E4%B8%8A%E6%89%8B%E5%AE%9E%E6%88%98/>第二篇 快速上手实战</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87-langgraph-%E6%B7%B1%E5%85%A5/>第三篇 LangGraph 深入</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87langchain%E7%AF%87/>第四篇 RAG基础篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87-rag%E5%9F%BA%E7%A1%80%E7%AF%87llamaindex%E7%AF%87/>第四篇 RAG基础篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87langchain%E7%AF%87/>第五篇 RAG高级篇(LangChain篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87-rag%E9%AB%98%E7%BA%A7%E7%AF%87llamaindex%E7%AF%87/>第五篇 RAG高级篇(LlamaIndex篇)</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87-%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86%E4%B8%8E%E6%95%B0%E6%8D%AE%E6%B8%85%E6%B4%97/>第六篇 文档处理与数据清洗</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87-deep-agents/>第七篇 Deep Agents</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87-middleware-%E5%B7%A5%E7%A8%8B%E5%8C%96/>第八篇 Middleware 工程化</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B9%9D%E7%AF%87-agent-%E6%9E%B6%E6%9E%84%E8%AE%BE%E8%AE%A1/>第九篇 Agent 架构设计</a></li><li><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%8D%81%E7%AF%87-%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5%E4%B8%8E%E7%9B%91%E6%8E%A7%E8%AF%84%E4%BC%B0/>第十篇 生产实践与监控评估</a></li><li><input type=checkbox id=section-a3e9b1811e5a21dbfddb0753f565cedb class=toggle>
<label for=section-a3e9b1811e5a21dbfddb0753f565cedb class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><input type=checkbox id=section-9a64553a000534ad3c81a611c6c29ec2 class=toggle>
<label for=section-9a64553a000534ad3c81a611c6c29ec2 class=flex><a role=button>code</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-6fad2589acfdd5d6a1fb55beb392fb77 class=toggle>
<label for=section-6fad2589acfdd5d6a1fb55beb392fb77 class=flex><a href=/notebooks/langchain%E7%AC%94%E8%AE%B0/code/fasta2a/>fasta2a</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li></ul></li></ul></li><li><input type=checkbox id=section-ce33306d44f9ed4d296b9a79329bed1c class=toggle>
<label for=section-ce33306d44f9ed4d296b9a79329bed1c class=flex><a role=button>图像算法笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E7%AF%87_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第一篇 机器学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E7%AF%87_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第二篇 深度学习基础</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E7%AF%87_%E8%AE%A1%E7%AE%97%E6%9C%BA%E8%A7%86%E8%A7%89%E6%A0%B8%E5%BF%83%E6%8A%80%E6%9C%AF/>第三篇 计算机视觉核心技术</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E7%AF%87_%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%8Eyolo%E7%B3%BB%E5%88%97/>第四篇 目标检测与YOLO系列</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E7%AF%87_%E5%9B%BE%E5%83%8F%E5%88%86%E5%89%B2/>第五篇 图像分割</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E7%AF%87_%E7%94%9F%E6%88%90%E6%A8%A1%E5%9E%8B/>第六篇 生成模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E7%AF%87_%E8%A7%86%E8%A7%89%E5%A4%A7%E6%A8%A1%E5%9E%8B/>第七篇 视觉大模型</a></li><li><a href=/notebooks/%E5%9B%BE%E5%83%8F%E7%AE%97%E6%B3%95%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AB%E7%AF%87_%E7%94%9F%E4%BA%A7%E5%AE%9E%E8%B7%B5/>第八篇 生产实践</a></li></ul></li><li><input type=checkbox id=section-77f5db9e44a9af6dab4403b49a65334f class=toggle checked>
<label for=section-77f5db9e44a9af6dab4403b49a65334f class=flex><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/>大模型笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><input type=checkbox id=section-db59738de306cbbe384ad7fbd5cf11b5 class=toggle>
<label for=section-db59738de306cbbe384ad7fbd5cf11b5 class=flex><a role=button>第一部分：大语言模型基础</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC1%E7%AB%A0_%E5%88%9D%E8%AF%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B/>第1章 初识大语言模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC2%E7%AB%A0_%E4%B8%8E%E6%A8%A1%E5%9E%8B%E5%AF%B9%E8%AF%9D%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第2章 与模型对话：提示工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/%E7%AC%AC3%E7%AB%A0_%E8%AF%AD%E8%A8%80%E7%9A%84%E5%9F%BA%E7%9F%B3%E5%88%86%E8%AF%8D%E4%B8%8E%E5%B5%8C%E5%85%A5/>第3章 语言的基石：分词与嵌入</a></li></ul></li><li><input type=checkbox id=section-30b17899e420f6a53aa6e578440dd132 class=toggle>
<label for=section-30b17899e420f6a53aa6e578440dd132 class=flex><a role=button>第二部分：Transformer架构揭秘</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC1%E7%AB%A0_transformer%E6%A0%B8%E5%BF%83%E6%8F%AD%E7%A7%98/>第1章 Transformer核心揭秘</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC2%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%B6%E6%97%8F%E8%B0%B1%E7%B3%BB%E4%BB%8E%E7%BC%96%E7%A0%81%E5%99%A8%E5%88%B0%E8%A7%A3%E7%A0%81%E5%99%A8/>第2章 模型家族谱系：从编码器到解码器</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86transformer%E6%9E%B6%E6%9E%84%E6%8F%AD%E7%A7%98/%E7%AC%AC3%E7%AB%A0_%E9%A2%84%E8%AE%AD%E7%BB%83%E7%9A%84%E5%A5%A5%E7%A7%98%E4%BB%8E%E6%95%B0%E6%8D%AE%E5%88%B0%E6%99%BA%E8%83%BD/>第3章 预训练的奥秘：从数据到智能</a></li></ul></li><li><input type=checkbox id=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=toggle>
<label for=section-da88ac5e3d01ea6f4b2996cb87ecf19f class=flex><a role=button>第三部分：数据工程与定制化</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC1%E7%AB%A0_%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E5%9F%BA%E7%A1%80/>第1章 数据工程基础</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC2%E7%AB%A0_%E5%BE%AE%E8%B0%83%E4%BD%A0%E7%9A%84%E4%B8%93%E5%B1%9E%E6%A8%A1%E5%9E%8B/>第2章 微调你的专属模型</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC3%E7%AB%A0_%E4%B8%8E%E4%BA%BA%E7%B1%BB%E5%AF%B9%E9%BD%90%E5%81%8F%E5%A5%BD%E4%BC%98%E5%8C%96/>第3章 与人类对齐：偏好优化</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%89%E9%83%A8%E5%88%86%E6%95%B0%E6%8D%AE%E5%B7%A5%E7%A8%8B%E4%B8%8E%E5%AE%9A%E5%88%B6%E5%8C%96/%E7%AC%AC4%E7%AB%A0_%E5%88%9B%E5%BB%BA%E6%9B%B4%E4%BC%98%E7%9A%84%E5%B5%8C%E5%85%A5%E6%A8%A1%E5%9E%8B/>第4章 创建更优的嵌入模型</a></li></ul></li><li><input type=checkbox id=section-81f0a7a10bc544ea0e1fd883e2a436eb class=toggle>
<label for=section-81f0a7a10bc544ea0e1fd883e2a436eb class=flex><a role=button>第四部分：大模型应用开发</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC1%E7%AB%A0_%E6%8F%90%E7%A4%BA%E5%B7%A5%E7%A8%8B%E4%B8%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0/>第1章 提示工程与上下文学习</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC2%E7%AB%A0_%E6%A3%80%E7%B4%A2%E5%A2%9E%E5%BC%BA%E7%94%9F%E6%88%90rag%E5%8E%9F%E7%90%86/>第2章 检索增强生成（RAG）原理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC3%E7%AB%A0_%E6%99%BA%E8%83%BD%E4%BD%93agent%E6%A0%B8%E5%BF%83%E6%9C%BA%E5%88%B6/>第3章 智能体（Agent）核心机制</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%9B%9B%E9%83%A8%E5%88%86%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%BA%94%E7%94%A8%E5%BC%80%E5%8F%91/%E7%AC%AC4%E7%AB%A0_%E5%A4%9A%E6%A8%A1%E6%80%81%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%8E%9F%E7%90%86/>第4章 多模态大模型原理</a></li></ul></li><li><input type=checkbox id=section-0509decfe880d3d2074947902aea8022 class=toggle>
<label for=section-0509decfe880d3d2074947902aea8022 class=flex><a role=button>第五部分：工程实战工具栈</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC1%E7%AB%A0_hugging_face%E7%94%9F%E6%80%81%E5%85%A8%E6%99%AF/>第1章 Hugging Face生态全景</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC2%E7%AB%A0_llama-factory%E5%BE%AE%E8%B0%83%E5%B7%A5%E5%8E%82/>第2章 LLaMA-Factory微调工厂</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC3%E7%AB%A0_trl%E4%B8%8E%E5%BC%BA%E5%8C%96%E5%AD%A6%E4%B9%A0%E5%AE%9E%E6%88%98/>第3章 TRL与强化学习实战</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC4%E7%AB%A0_deepspeed%E5%88%86%E5%B8%83%E5%BC%8F%E8%AE%AD%E7%BB%83/>第4章 DeepSpeed分布式训练</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%BA%94%E9%83%A8%E5%88%86%E5%B7%A5%E7%A8%8B%E5%AE%9E%E6%88%98%E5%B7%A5%E5%85%B7%E6%A0%88/%E7%AC%AC5%E7%AB%A0_%E7%AB%AF%E5%88%B0%E7%AB%AFllm%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98/>第5章 端到端LLM项目实战</a></li></ul></li><li><input type=checkbox id=section-dc465ed94a0f7fb78440cab8a8a2a28b class=toggle>
<label for=section-dc465ed94a0f7fb78440cab8a8a2a28b class=flex><a role=button>第六部分：生产部署与评估</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC1%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%8E%8B%E7%BC%A9%E4%B8%8E%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F/>第1章 模型压缩与推理加速</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC2%E7%AB%A0_vllm%E9%AB%98%E6%80%A7%E8%83%BD%E6%8E%A8%E7%90%86/>第2章 vLLM高性能推理</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E5%85%AD%E9%83%A8%E5%88%86%E7%94%9F%E4%BA%A7%E9%83%A8%E7%BD%B2%E4%B8%8E%E8%AF%84%E4%BC%B0/%E7%AC%AC3%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%BD%93%E7%B3%BB/>第3章 模型评估体系</a></li></ul></li><li><input type=checkbox id=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=toggle>
<label for=section-54ec04ac2cdda7238de2ed38f0bcb7b1 class=flex><a role=button>第七部分：高级技术专题</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC1%E7%AB%A0_%E9%95%BF%E4%B8%8A%E4%B8%8B%E6%96%87%E6%8A%80%E6%9C%AF/>第1章 长上下文技术</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC2%E7%AB%A0_%E6%96%B0%E5%9E%8B%E6%9E%B6%E6%9E%84%E6%8E%A2%E7%B4%A2/>第2章 新型架构探索</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC3%E7%AB%A0_%E6%8E%A8%E7%90%86%E5%8A%A0%E9%80%9F%E9%BB%91%E7%A7%91%E6%8A%80/>第3章 推理加速黑科技</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC4%E7%AB%A0_%E6%8E%A8%E7%90%86%E6%A8%A1%E5%9E%8B%E4%B8%93%E9%A2%98/>第4章 推理模型专题</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/>第5章 模型安全与可解释性</a></li></ul></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/glossary/ class=active>GLOSSARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/>ROADMAP</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/summary/>SUMMARY</a></li><li><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E5%AE%8C%E7%BB%93%E6%8A%A5%E5%91%8A/>完结报告</a></li></ul></li><li><input type=checkbox id=section-7177254393287994b491879262a62a06 class=toggle>
<label for=section-7177254393287994b491879262a62a06 class=flex><a role=button>实践笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/2.-%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3-fastapi/>深入理解 FastAPI</a></li><li><a href=/notebooks/%E5%AE%9E%E8%B7%B5%E7%AC%94%E8%AE%B0/4.-agent%E6%9C%80%E4%BD%B3%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/>Agent最佳设计模式</a></li></ul></li><li><input type=checkbox id=section-0172eb8516eeb7b4e657f3949a135c25 class=toggle>
<label for=section-0172eb8516eeb7b4e657f3949a135c25 class=flex><a role=button>机器学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC01%E7%AB%A0_%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E6%A6%82%E8%A7%88/>第01章 机器学习概览</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC02%E7%AB%A0_%E7%9F%A9%E9%98%B5%E8%BF%90%E7%AE%97%E4%B8%8E%E5%BE%AE%E7%A7%AF%E5%88%86/>第02章 矩阵运算与微积分</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC03%E7%AB%A0_svd%E4%B8%8E%E7%9F%A9%E9%98%B5%E5%88%86%E8%A7%A3/>第03章 SVD与矩阵分解</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC04%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%88%86%E5%B8%83_%E6%8C%87%E6%95%B0%E6%97%8F%E4%B8%8E%E5%85%B1%E8%BD%AD%E5%85%88%E9%AA%8C/>第04章 概率分布 指数族与共轭先验</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC05%E7%AB%A0_%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/>第05章 线性回归</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC06%E7%AB%A0_%E6%84%9F%E7%9F%A5%E6%9C%BA/>第06章 感知机</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC07%E7%AB%A0_%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BAsvm/>第07章 支持向量机(SVM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC08%E7%AB%A0_%E6%A0%B8%E6%96%B9%E6%B3%95/>第08章 核方法</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC09%E7%AB%A0_%E5%86%B3%E7%AD%96%E6%A0%91%E4%B8%8E%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0/>第09章 决策树与集成学习</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC10%E7%AB%A0_%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E4%B8%8E%E6%9C%80%E5%A4%A7%E7%86%B5%E6%A8%A1%E5%9E%8B/>第10章 逻辑回归与最大熵模型</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC11%E7%AB%A0_%E5%B9%BF%E4%B9%89%E7%BA%BF%E6%80%A7%E6%A8%A1%E5%9E%8Bglm/>第11章 广义线性模型(GLM)</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC13%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E8%A1%A8%E7%A4%BA/>第13章 概率图模型 表示</a></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC14%E7%AB%A0_%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E6%8E%A8%E6%96%AD/>第14章 概率图模型 推断</a></li><li><input type=checkbox id=section-b17efd79c46843a887113a063f929150 class=toggle>
<label for=section-b17efd79c46843a887113a063f929150 class=flex><a role=button>assets</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul></ul></li><li><a href=/notebooks/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/skills/>skills</a></li></ul></li><li><input type=checkbox id=section-29762f225235d2ac19b613cc28b093c8 class=toggle>
<label for=section-29762f225235d2ac19b613cc28b093c8 class=flex><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/>深度学习笔记</a>
<img src=/icons/chevron-right.svg class=book-icon alt=Expand></label><ul><li><a href=/notebooks/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%AC%AC1%E7%AB%A0_%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%9F%BA%E7%A1%80/>第1章 深度学习基础</a></li></ul></li></ul></nav><script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script></div></aside><div class=book-page><header class="book-header hidden"><div class="flex align-center justify-between"><label for=menu-control><img src=/icons/menu.svg class=book-icon alt=Menu></label><h3>GLOSSARY</h3><label for=toc-control><img src=/icons/toc.svg class=book-icon alt="Table of Contents"></label></div><aside class=hidden><nav id=TableOfContents><ul><li><a href=#a>A</a><ul><li><a href=#adalora-adaptive-lora>AdaLoRA (Adaptive LoRA)</a></li><li><a href=#agent-智能体>Agent (智能体)</a></li><li><a href=#alignment-对齐>Alignment (对齐)</a></li><li><a href=#attention-注意力机制>Attention (注意力机制)</a></li></ul></li><li><a href=#b>B</a><ul><li><a href=#bert-bidirectional-encoder-representations-from-transformers>BERT (Bidirectional Encoder Representations from Transformers)</a></li><li><a href=#bpe-byte-pair-encoding>BPE (Byte Pair Encoding)</a></li></ul></li><li><a href=#c>C</a><ul><li><a href=#chain-of-thought-cot--思维链>Chain-of-Thought (CoT / 思维链)</a></li><li><a href=#chunking-文档分块>Chunking (文档分块)</a></li><li><a href=#cold-start-冷启动>Cold Start (冷启动)</a></li><li><a href=#context-window-上下文窗口>Context Window (上下文窗口)</a></li><li><a href=#continuous-batching-连续批处理>Continuous Batching (连续批处理)</a></li></ul></li><li><a href=#d>D</a><ul><li><a href=#deepseek-r1>DeepSeek-R1</a></li><li><a href=#deepspeed>DeepSpeed</a></li><li><a href=#dora-weight-decomposed-low-rank-adaptation>DoRA (Weight-Decomposed Low-Rank Adaptation)</a></li><li><a href=#dpo-direct-preference-optimization>DPO (Direct Preference Optimization)</a></li></ul></li><li><a href=#e>E</a><ul><li><a href=#embedding-嵌入>Embedding (嵌入)</a></li><li><a href=#encoder-decoder>Encoder-Decoder</a></li></ul></li><li><a href=#f>F</a><ul><li><a href=#few-shot-learning-少样本学习>Few-shot Learning (少样本学习)</a></li><li><a href=#flashattention>FlashAttention</a></li><li><a href=#function-calling-函数调用>Function Calling (函数调用)</a></li></ul></li><li><a href=#g>G</a><ul><li><a href=#gpt-generative-pre-trained-transformer>GPT (Generative Pre-trained Transformer)</a></li><li><a href=#graphrag>GraphRAG</a></li><li><a href=#grokking-顿悟>Grokking (顿悟)</a></li><li><a href=#grpo-group-relative-policy-optimization>GRPO (Group Relative Policy Optimization)</a></li></ul></li><li><a href=#h>H</a><ul><li><a href=#hallucination-幻觉>Hallucination (幻觉)</a></li></ul></li><li><a href=#i>I</a><ul><li><a href=#in-context-learning-icl--上下文学习>In-Context Learning (ICL / 上下文学习)</a></li><li><a href=#instruction-tuning-指令微调>Instruction Tuning (指令微调)</a></li></ul></li><li><a href=#k>K</a><ul><li><a href=#kv-cache-键值缓存>KV Cache (键值缓存)</a></li></ul></li><li><a href=#l>L</a><ul><li><a href=#langchain>LangChain</a></li><li><a href=#langgraph>LangGraph</a></li><li><a href=#lawglm>LawGLM</a></li><li><a href=#llama-factory>LLaMA-Factory</a></li><li><a href=#lora-low-rank-adaptation>LoRA (Low-Rank Adaptation)</a></li></ul></li><li><a href=#m>M</a><ul><li><a href=#mamba>Mamba</a></li><li><a href=#matryoshka-embedding-俄罗斯套娃嵌入>Matryoshka Embedding (俄罗斯套娃嵌入)</a></li><li><a href=#mcp-model-context-protocol>MCP (Model Context Protocol)</a></li><li><a href=#minhash-lsh-局部敏感哈希>MinHash LSH (局部敏感哈希)</a></li><li><a href=#moe-mixture-of-experts--专家混合>MoE (Mixture of Experts / 专家混合)</a></li></ul></li><li><a href=#p>P</a><ul><li><a href=#pagedattention>PagedAttention</a></li><li><a href=#peft-parameter-efficient-fine-tuning--参数高效微调>PEFT (Parameter-Efficient Fine-Tuning / 参数高效微调)</a></li><li><a href=#ppo-proximal-policy-optimization>PPO (Proximal Policy Optimization)</a></li><li><a href=#prompt-engineering-提示工程>Prompt Engineering (提示工程)</a></li></ul></li><li><a href=#q>Q</a><ul><li><a href=#qlora-quantized-lora>QLoRA (Quantized LoRA)</a></li><li><a href=#quantization-量化>Quantization (量化)</a></li></ul></li><li><a href=#r>R</a><ul><li><a href=#rag-retrieval-augmented-generation--检索增强生成>RAG (Retrieval-Augmented Generation / 检索增强生成)</a></li><li><a href=#react-reasoning-and-acting>ReAct (Reasoning and Acting)</a></li><li><a href=#reranking-重排序>Reranking (重排序)</a></li><li><a href=#rlhf-reinforcement-learning-from-human-feedback--基于人类反馈的强化学习>RLHF (Reinforcement Learning from Human Feedback / 基于人类反馈的强化学习)</a></li><li><a href=#rope-rotary-position-embedding--旋转位置编码>RoPE (Rotary Position Embedding / 旋转位置编码)</a></li></ul></li><li><a href=#s>S</a><ul><li><a href=#scaling-laws-缩放定律>Scaling Laws (缩放定律)</a></li><li><a href=#self-attention-自注意力>Self-Attention (自注意力)</a></li><li><a href=#setfit-sentence-transformer-fine-tuning>SetFit (Sentence Transformer Fine-Tuning)</a></li><li><a href=#sft-supervised-fine-tuning--监督式微调>SFT (Supervised Fine-Tuning / 监督式微调)</a></li><li><a href=#simpo-simple-preference-optimization>SimPO (Simple Preference Optimization)</a></li><li><a href=#speculative-decoding-推测解码>Speculative Decoding (推测解码)</a></li><li><a href=#swiglu-swish-gated-linear-unit>SwiGLU (Swish-Gated Linear Unit)</a></li><li><a href=#synthetic-data-合成数据>Synthetic Data (合成数据)</a></li></ul></li><li><a href=#t>T</a><ul><li><a href=#temperature-温度参数>Temperature (温度参数)</a></li><li><a href=#tokenizer-分词器>Tokenizer (分词器)</a></li><li><a href=#top-p-sampling-核采样>Top-p Sampling (核采样)</a></li><li><a href=#transformer>Transformer</a></li><li><a href=#trl-transformer-reinforcement-learning>TRL (Transformer Reinforcement Learning)</a></li></ul></li><li><a href=#v>V</a><ul><li><a href=#vllm>vLLM</a></li><li><a href=#vera-vector-based-random-matrix-adaptation>VeRA (Vector-based Random Matrix Adaptation)</a></li></ul></li><li><a href=#z>Z</a><ul><li><a href=#zero-zero-redundancy-optimizer>ZeRO (Zero Redundancy Optimizer)</a></li><li><a href=#zero-shot-learning-零样本学习>Zero-shot Learning (零样本学习)</a></li></ul></li><li><a href=#交叉索引>交叉索引</a><ul><li><a href=#按技术领域分类>按技术领域分类</a></li></ul></li><li><a href=#参考文献>参考文献</a></li></ul></nav></aside></header><article class="markdown book-article"><h1 id=glossary-术语表>GLOSSARY 术语表<a class=anchor href=#glossary-%e6%9c%af%e8%af%ad%e8%a1%a8>#</a></h1><blockquote class=book-hint><p><strong>大语言模型技术索引 (2025年版)</strong></p><p>本术语表包含大语言模型领域的核心概念、前沿技术与工程实践术语。每个术语提供精炼定义及章节交叉引用。</p></blockquote><hr><h2 id=a>A<a class=anchor href=#a>#</a></h2><h3 id=adalora-adaptive-lora>AdaLoRA (Adaptive LoRA)<a class=anchor href=#adalora-adaptive-lora>#</a></h3><p>自适应秩分配的LoRA变体，根据重要性动态调整不同层的秩参数，提升参数效率。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><h3 id=agent-智能体>Agent (智能体)<a class=anchor href=#agent-%e6%99%ba%e8%83%bd%e4%bd%93>#</a></h3><p>能够感知环境、自主决策并执行行动以完成目标的LLM系统，通常结合ReAct模式与工具调用能力。
→ 详见 [Part 4 Ch 3: 智能体核心机制]</p><h3 id=alignment-对齐>Alignment (对齐)<a class=anchor href=#alignment-%e5%af%b9%e9%bd%90>#</a></h3><p>使模型输出符合人类价值观和意图的过程，核心技术包括RLHF、DPO等。
→ 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]</p><h3 id=attention-注意力机制>Attention (注意力机制)<a class=anchor href=#attention-%e6%b3%a8%e6%84%8f%e5%8a%9b%e6%9c%ba%e5%88%b6>#</a></h3><p>Transformer的核心组件，通过Query-Key-Value机制动态加权聚合信息，实现上下文理解。
→ 详见 [Part 2 Ch 1: Transformer核心揭秘]</p><hr><h2 id=b>B<a class=anchor href=#b>#</a></h2><h3 id=bert-bidirectional-encoder-representations-from-transformers>BERT (Bidirectional Encoder Representations from Transformers)<a class=anchor href=#bert-bidirectional-encoder-representations-from-transformers>#</a></h3><p>基于Transformer编码器的双向预训练模型，擅长理解任务如文本分类、命名实体识别。
→ 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 2: 模型家族谱系]</p><h3 id=bpe-byte-pair-encoding>BPE (Byte Pair Encoding)<a class=anchor href=#bpe-byte-pair-encoding>#</a></h3><p>子词分词算法，通过迭代合并高频字符对构建词表，平衡词表大小与分词粒度。
→ 详见 [Part 1 Ch 3: 语言的基石：分词与嵌入]</p><hr><h2 id=c>C<a class=anchor href=#c>#</a></h2><h3 id=chain-of-thought-cot--思维链>Chain-of-Thought (CoT / 思维链)<a class=anchor href=#chain-of-thought-cot--%e6%80%9d%e7%bb%b4%e9%93%be>#</a></h3><p>通过在Prompt中要求模型"逐步思考"输出推理过程，显著提升复杂推理任务准确率的技术。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础] / [Part 7 Ch 3: 推理时计算增强]</p><h3 id=chunking-文档分块>Chunking (文档分块)<a class=anchor href=#chunking-%e6%96%87%e6%a1%a3%e5%88%86%e5%9d%97>#</a></h3><p>RAG系统中将长文档切分为语义连贯的片段的技术，影响检索精度与生成质量。
→ 详见 [Part 4 Ch 2: 检索增强生成（RAG）原理]</p><h3 id=cold-start-冷启动>Cold Start (冷启动)<a class=anchor href=#cold-start-%e5%86%b7%e5%90%af%e5%8a%a8>#</a></h3><p>数据工程中缺乏初始训练数据的场景，常通过Synthetic Data或Self-Instruct缓解。
→ 详见 [Part 3 Ch 1: 数据工程基础]</p><h3 id=context-window-上下文窗口>Context Window (上下文窗口)<a class=anchor href=#context-window-%e4%b8%8a%e4%b8%8b%e6%96%87%e7%aa%97%e5%8f%a3>#</a></h3><p>模型一次能处理的最大Token数量，2025年前沿模型已达128K~200K tokens。
→ 详见 [Part 7 Ch 1: 长上下文技术]</p><h3 id=continuous-batching-连续批处理>Continuous Batching (连续批处理)<a class=anchor href=#continuous-batching-%e8%bf%9e%e7%bb%ad%e6%89%b9%e5%a4%84%e7%90%86>#</a></h3><p>vLLM核心技术，动态管理不同长度的推理请求，避免传统静态批处理的等待浪费。
→ 详见 [Part 6 Ch 2: vLLM高性能推理]</p><hr><h2 id=d>D<a class=anchor href=#d>#</a></h2><h3 id=deepseek-r1>DeepSeek-R1<a class=anchor href=#deepseek-r1>#</a></h3><p>2025年前沿推理模型，通过强化学习训练推理时计算能力，在数学/代码任务中表现出色。
→ 详见 [Part 7 Ch 4: 推理模型专题]</p><h3 id=deepspeed>DeepSpeed<a class=anchor href=#deepspeed>#</a></h3><p>微软开源的分布式训练框架，支持ZeRO优化、流水线并行、混合精度训练等大模型训练技术。
→ 详见 [Part 5 Ch 4: DeepSpeed分布式训练]</p><h3 id=dora-weight-decomposed-low-rank-adaptation>DoRA (Weight-Decomposed Low-Rank Adaptation)<a class=anchor href=#dora-weight-decomposed-low-rank-adaptation>#</a></h3><p>将权重分解为幅度(Magnitude)和方向(Direction)的LoRA变体，提升微调性能与稳定性。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><h3 id=dpo-direct-preference-optimization>DPO (Direct Preference Optimization)<a class=anchor href=#dpo-direct-preference-optimization>#</a></h3><p>无需RL训练器的偏好优化算法，直接从偏好数据中优化模型，相比RLHF更简单高效。
→ 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]</p><hr><h2 id=e>E<a class=anchor href=#e>#</a></h2><h3 id=embedding-嵌入>Embedding (嵌入)<a class=anchor href=#embedding-%e5%b5%8c%e5%85%a5>#</a></h3><p>将离散的Token/文本映射到连续向量空间的表示，是语义理解与RAG的基础。
→ 详见 [Part 1 Ch 3: 语言的基石：分词与嵌入] / [Part 3 Ch 4: 创建更优的嵌入模型]</p><h3 id=encoder-decoder>Encoder-Decoder<a class=anchor href=#encoder-decoder>#</a></h3><p>Transformer的完整架构，编码器双向理解输入，解码器自回归生成输出，适用于翻译任务。
→ 详见 [Part 2 Ch 2: 模型家族谱系：从编码器到解码器]</p><hr><h2 id=f>F<a class=anchor href=#f>#</a></h2><h3 id=few-shot-learning-少样本学习>Few-shot Learning (少样本学习)<a class=anchor href=#few-shot-learning-%e5%b0%91%e6%a0%b7%e6%9c%ac%e5%ad%a6%e4%b9%a0>#</a></h3><p>通过在Prompt中提供少量示例让模型学会新任务，无需梯度更新，是ICL的核心应用。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础]</p><h3 id=flashattention>FlashAttention<a class=anchor href=#flashattention>#</a></h3><p>高效Attention实现，通过IO-aware算法和Tiling优化显存访问，加速训练与推理2-4倍。
→ 详见 [Part 2 Ch 1: Transformer核心揭秘] / [Part 6 Ch 1: 模型压缩与推理加速]</p><h3 id=function-calling-函数调用>Function Calling (函数调用)<a class=anchor href=#function-calling-%e5%87%bd%e6%95%b0%e8%b0%83%e7%94%a8>#</a></h3><p>模型根据用户意图自动调用外部工具/API的能力，是构建Agent系统的核心机制。
→ 详见 [Part 4 Ch 3: 智能体核心机制]</p><hr><h2 id=g>G<a class=anchor href=#g>#</a></h2><h3 id=gpt-generative-pre-trained-transformer>GPT (Generative Pre-trained Transformer)<a class=anchor href=#gpt-generative-pre-trained-transformer>#</a></h3><p>基于Transformer解码器的自回归生成模型，通过预测下一个Token训练，是ChatGPT的基础架构。
→ 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 2: 模型家族谱系]</p><h3 id=graphrag>GraphRAG<a class=anchor href=#graphrag>#</a></h3><p>微软提出的高级RAG架构，通过知识图谱建模文档关系，提升复杂推理与多跳问答能力。
→ 详见 [Part 4 Ch 2: 检索增强生成（RAG）原理]</p><h3 id=grokking-顿悟>Grokking (顿悟)<a class=anchor href=#grokking-%e9%a1%bf%e6%82%9f>#</a></h3><p>训练过程中模型突然从记忆转向泛化的现象，通常在过拟合后继续训练才出现。
→ 详见 [Part 2 Ch 3: 预训练的奥秘：从数据到智能]</p><h3 id=grpo-group-relative-policy-optimization>GRPO (Group Relative Policy Optimization)<a class=anchor href=#grpo-group-relative-policy-optimization>#</a></h3><p>分组相对策略优化，DeepSeek-R1等推理模型使用的强化学习算法，改进传统PPO。
→ 详见 [Part 7 Ch 4: 推理模型专题]</p><hr><h2 id=h>H<a class=anchor href=#h>#</a></h2><h3 id=hallucination-幻觉>Hallucination (幻觉)<a class=anchor href=#hallucination-%e5%b9%bb%e8%a7%89>#</a></h3><p>模型生成看似合理但实际错误或无根据的内容，RAG与外部验证是主要缓解手段。
→ 详见 [Part 4 Ch 2: 检索增强生成（RAG）原理] / [Part 7 Ch 5: 模型安全与可解释性]</p><hr><h2 id=i>I<a class=anchor href=#i>#</a></h2><h3 id=in-context-learning-icl--上下文学习>In-Context Learning (ICL / 上下文学习)<a class=anchor href=#in-context-learning-icl--%e4%b8%8a%e4%b8%8b%e6%96%87%e5%ad%a6%e4%b9%a0>#</a></h3><p>模型通过Prompt中的示例学会新任务而无需梯度更新，是大模型的涌现能力。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础]</p><h3 id=instruction-tuning-指令微调>Instruction Tuning (指令微调)<a class=anchor href=#instruction-tuning-%e6%8c%87%e4%bb%a4%e5%be%ae%e8%b0%83>#</a></h3><p>在多样化指令数据上微调模型，使其能准确理解并遵循人类指令，是SFT的核心。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><hr><h2 id=k>K<a class=anchor href=#k>#</a></h2><h3 id=kv-cache-键值缓存>KV Cache (键值缓存)<a class=anchor href=#kv-cache-%e9%94%ae%e5%80%bc%e7%bc%93%e5%ad%98>#</a></h3><p>自回归生成中缓存历史Token的Key和Value张量，避免重复计算，PagedAttention优化其管理。
→ 详见 [Part 6 Ch 2: vLLM高性能推理]</p><hr><h2 id=l>L<a class=anchor href=#l>#</a></h2><h3 id=langchain>LangChain<a class=anchor href=#langchain>#</a></h3><p>开源LLM应用开发框架，提供链式调用、Agent、RAG等组件，简化应用构建。
→ 详见 [Part 5 Ch 5: 端到端LLM项目实战]</p><h3 id=langgraph>LangGraph<a class=anchor href=#langgraph>#</a></h3><p>LangChain团队推出的多Agent编排框架，基于有向图建模Agent工作流。
→ 详见 [Part 4 Ch 3: 智能体核心机制]</p><h3 id=lawglm>LawGLM<a class=anchor href=#lawglm>#</a></h3><p>面向法律领域的垂直大模型，通过领域预训练与微调实现专业法律问答与文书生成。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><h3 id=llama-factory>LLaMA-Factory<a class=anchor href=#llama-factory>#</a></h3><p>一站式大模型微调工具，集成LoRA/QLoRA/全量微调，支持WebUI配置，降低微调门槛。
→ 详见 [Part 5 Ch 2: LLaMA-Factory微调工厂]</p><h3 id=lora-low-rank-adaptation>LoRA (Low-Rank Adaptation)<a class=anchor href=#lora-low-rank-adaptation>#</a></h3><p>参数高效微调(PEFT)的代表方法，通过低秩分解冻结原模型权重，仅训练小规模适配器。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><hr><h2 id=m>M<a class=anchor href=#m>#</a></h2><h3 id=mamba>Mamba<a class=anchor href=#mamba>#</a></h3><p>基于状态空间模型(SSM)的新型架构，线性时间复杂度替代Attention，适合超长序列建模。
→ 详见 [Part 7 Ch 2: 新型架构探索]</p><h3 id=matryoshka-embedding-俄罗斯套娃嵌入>Matryoshka Embedding (俄罗斯套娃嵌入)<a class=anchor href=#matryoshka-embedding-%e4%bf%84%e7%bd%97%e6%96%af%e5%a5%97%e5%a8%83%e5%b5%8c%e5%85%a5>#</a></h3><p>支持灵活维度的嵌入模型，可在推理时截断向量维度以平衡精度与效率。
→ 详见 [Part 3 Ch 4: 创建更优的嵌入模型]</p><h3 id=mcp-model-context-protocol>MCP (Model Context Protocol)<a class=anchor href=#mcp-model-context-protocol>#</a></h3><p>Anthropic提出的标准化协议，定义LLM与外部工具/数据源交互接口，增强互操作性。
→ 详见 [Part 4 Ch 3: 智能体核心机制]</p><h3 id=minhash-lsh-局部敏感哈希>MinHash LSH (局部敏感哈希)<a class=anchor href=#minhash-lsh-%e5%b1%80%e9%83%a8%e6%95%8f%e6%84%9f%e5%93%88%e5%b8%8c>#</a></h3><p>高效近似最近邻搜索算法，在大规模文档去重与相似度检索中广泛应用。
→ 详见 [Part 3 Ch 1: 数据工程基础] / [Part 7 Ch 6: 大规模预训练数据工程]</p><h3 id=moe-mixture-of-experts--专家混合>MoE (Mixture of Experts / 专家混合)<a class=anchor href=#moe-mixture-of-experts--%e4%b8%93%e5%ae%b6%e6%b7%b7%e5%90%88>#</a></h3><p>模型架构变体，每次只激活部分专家子网络，在保持性能的同时大幅减少计算量。
→ 详见 [Part 2 Ch 2: 模型家族谱系] / [Part 6 Ch 1: 模型压缩与推理加速]</p><hr><h2 id=p>P<a class=anchor href=#p>#</a></h2><h3 id=pagedattention>PagedAttention<a class=anchor href=#pagedattention>#</a></h3><p>vLLM核心技术，借鉴虚拟内存思想，将KV Cache分块管理，解决内存碎片与利用率问题。
→ 详见 [Part 6 Ch 2: vLLM高性能推理]</p><h3 id=peft-parameter-efficient-fine-tuning--参数高效微调>PEFT (Parameter-Efficient Fine-Tuning / 参数高效微调)<a class=anchor href=#peft-parameter-efficient-fine-tuning--%e5%8f%82%e6%95%b0%e9%ab%98%e6%95%88%e5%be%ae%e8%b0%83>#</a></h3><p>只更新少量参数实现模型适配的方法集合，包括LoRA、Adapter、Prefix-Tuning等。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><h3 id=ppo-proximal-policy-optimization>PPO (Proximal Policy Optimization)<a class=anchor href=#ppo-proximal-policy-optimization>#</a></h3><p>RLHF训练中使用的强化学习算法，通过限制策略更新步长保证训练稳定性。
→ 详见 [Part 3 Ch 3: 与人类对齐：偏好优化] / [Part 5 Ch 3: TRL与强化学习实战]</p><h3 id=prompt-engineering-提示工程>Prompt Engineering (提示工程)<a class=anchor href=#prompt-engineering-%e6%8f%90%e7%a4%ba%e5%b7%a5%e7%a8%8b>#</a></h3><p>设计优化Prompt以引导模型输出的技术，包括Few-shot、CoT、ReAct等模式。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础]</p><hr><h2 id=q>Q<a class=anchor href=#q>#</a></h2><h3 id=qlora-quantized-lora>QLoRA (Quantized LoRA)<a class=anchor href=#qlora-quantized-lora>#</a></h3><p>结合4-bit量化与LoRA的微调方法，在单张消费级GPU上微调65B模型。
→ 详见 [Part 3 Ch 2: 微调你的专属模型] / [Part 5 Ch 2: LLaMA-Factory微调工厂]</p><h3 id=quantization-量化>Quantization (量化)<a class=anchor href=#quantization-%e9%87%8f%e5%8c%96>#</a></h3><p>降低模型权重/激活精度(如FP16→INT8)以减少显存占用与计算量，关键技术是量化感知训练。
→ 详见 [Part 6 Ch 1: 模型压缩与推理加速]</p><hr><h2 id=r>R<a class=anchor href=#r>#</a></h2><h3 id=rag-retrieval-augmented-generation--检索增强生成>RAG (Retrieval-Augmented Generation / 检索增强生成)<a class=anchor href=#rag-retrieval-augmented-generation--%e6%a3%80%e7%b4%a2%e5%a2%9e%e5%bc%ba%e7%94%9f%e6%88%90>#</a></h3><p>结合外部知识库检索与LLM生成的架构，缓解幻觉、知识过时问题。
→ 详见 [Part 4 Ch 2: 检索增强生成（RAG）原理]</p><h3 id=react-reasoning-and-acting>ReAct (Reasoning and Acting)<a class=anchor href=#react-reasoning-and-acting>#</a></h3><p>结合推理(Thought)与行动(Action)的Prompt模式，是Agent系统的核心范式。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础] / [Part 4 Ch 3: 智能体核心机制]</p><h3 id=reranking-重排序>Reranking (重排序)<a class=anchor href=#reranking-%e9%87%8d%e6%8e%92%e5%ba%8f>#</a></h3><p>RAG中对初步检索结果进行精排的步骤，使用Cross-Encoder等模型提升Top-K精度。
→ 详见 [Part 4 Ch 2: 检索增强生成（RAG）原理]</p><h3 id=rlhf-reinforcement-learning-from-human-feedback--基于人类反馈的强化学习>RLHF (Reinforcement Learning from Human Feedback / 基于人类反馈的强化学习)<a class=anchor href=#rlhf-reinforcement-learning-from-human-feedback--%e5%9f%ba%e4%ba%8e%e4%ba%ba%e7%b1%bb%e5%8f%8d%e9%a6%88%e7%9a%84%e5%bc%ba%e5%8c%96%e5%ad%a6%e4%b9%a0>#</a></h3><p>通过奖励模型(Reward Model)与PPO训练使模型对齐人类偏好，是ChatGPT的关键技术。
→ 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]</p><h3 id=rope-rotary-position-embedding--旋转位置编码>RoPE (Rotary Position Embedding / 旋转位置编码)<a class=anchor href=#rope-rotary-position-embedding--%e6%97%8b%e8%bd%ac%e4%bd%8d%e7%bd%ae%e7%bc%96%e7%a0%81>#</a></h3><p>相对位置编码方法，通过复数旋转矩阵注入位置信息，支持长度外推，是LLaMA架构标配。
→ 详见 [Part 2 Ch 1: Transformer核心揭秘] / [Part 7 Ch 1: 长上下文技术]</p><hr><h2 id=s>S<a class=anchor href=#s>#</a></h2><h3 id=scaling-laws-缩放定律>Scaling Laws (缩放定律)<a class=anchor href=#scaling-laws-%e7%bc%a9%e6%94%be%e5%ae%9a%e5%be%8b>#</a></h3><p>描述模型性能与参数量、数据量、计算量之间幂律关系的经验规律，指导大模型训练资源配置。
→ 详见 [Part 2 Ch 3: 预训练的奥秘：从数据到智能]</p><h3 id=self-attention-自注意力>Self-Attention (自注意力)<a class=anchor href=#self-attention-%e8%87%aa%e6%b3%a8%e6%84%8f%e5%8a%9b>#</a></h3><p>Transformer核心机制，计算序列内每个Token与其他Token的关联权重，实现全局依赖建模。
→ 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 1: Transformer核心揭秘]</p><h3 id=setfit-sentence-transformer-fine-tuning>SetFit (Sentence Transformer Fine-Tuning)<a class=anchor href=#setfit-sentence-transformer-fine-tuning>#</a></h3><p>少样本文本分类框架，先用对比学习微调Sentence-Transformer，再训练轻量分类头。
→ 详见 [Part 4 Ch 1: 语义理解应用：文本分类与聚类]</p><h3 id=sft-supervised-fine-tuning--监督式微调>SFT (Supervised Fine-Tuning / 监督式微调)<a class=anchor href=#sft-supervised-fine-tuning--%e7%9b%91%e7%9d%a3%e5%bc%8f%e5%be%ae%e8%b0%83>#</a></h3><p>在标注数据上通过最大似然训练微调模型，是RLHF流程的第一阶段。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><h3 id=simpo-simple-preference-optimization>SimPO (Simple Preference Optimization)<a class=anchor href=#simpo-simple-preference-optimization>#</a></h3><p>简化版偏好优化算法，直接优化模型输出概率而不引入参考模型，相比DPO更高效。
→ 详见 [Part 3 Ch 3: 与人类对齐：偏好优化]</p><h3 id=speculative-decoding-推测解码>Speculative Decoding (推测解码)<a class=anchor href=#speculative-decoding-%e6%8e%a8%e6%b5%8b%e8%a7%a3%e7%a0%81>#</a></h3><p>用小模型快速生成候选Token序列，大模型并行验证，加速自回归生成2-3倍。
→ 详见 [Part 6 Ch 1: 模型压缩与推理加速] / [Part 6 Ch 2: vLLM高性能推理]</p><h3 id=swiglu-swish-gated-linear-unit>SwiGLU (Swish-Gated Linear Unit)<a class=anchor href=#swiglu-swish-gated-linear-unit>#</a></h3><p>改进的FFN激活函数，结合Swish激活与门控机制，是LLaMA/PaLM等模型的标准选择。
→ 详见 [Part 2 Ch 1: Transformer核心揭秘]</p><h3 id=synthetic-data-合成数据>Synthetic Data (合成数据)<a class=anchor href=#synthetic-data-%e5%90%88%e6%88%90%e6%95%b0%e6%8d%ae>#</a></h3><p>使用大模型生成的训练数据，通过Self-Instruct、Evol-Instruct等方法缓解数据稀缺。
→ 详见 [Part 3 Ch 1: 数据工程基础] / [Part 7 Ch 6: 大规模预训练数据工程]</p><hr><h2 id=t>T<a class=anchor href=#t>#</a></h2><h3 id=temperature-温度参数>Temperature (温度参数)<a class=anchor href=#temperature-%e6%b8%a9%e5%ba%a6%e5%8f%82%e6%95%b0>#</a></h3><p>控制模型输出随机性的采样参数，T=0确定性输出，T>1增加创造性。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础]</p><h3 id=tokenizer-分词器>Tokenizer (分词器)<a class=anchor href=#tokenizer-%e5%88%86%e8%af%8d%e5%99%a8>#</a></h3><p>将文本切分为Token序列的工具，常用算法包括BPE、WordPiece、SentencePiece。
→ 详见 [Part 1 Ch 3: 语言的基石：分词与嵌入]</p><h3 id=top-p-sampling-核采样>Top-p Sampling (核采样)<a class=anchor href=#top-p-sampling-%e6%a0%b8%e9%87%87%e6%a0%b7>#</a></h3><p>动态截断低概率Token的采样策略，只从累积概率达到p的最小集合中采样。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础]</p><h3 id=transformer>Transformer<a class=anchor href=#transformer>#</a></h3><p>基于Self-Attention的深度学习架构，彻底改变NLP领域，是现代大语言模型的基础。
→ 详见 [Part 1 Ch 1: 初识大语言模型] / [Part 2 Ch 1: Transformer核心揭秘]</p><h3 id=trl-transformer-reinforcement-learning>TRL (Transformer Reinforcement Learning)<a class=anchor href=#trl-transformer-reinforcement-learning>#</a></h3><p>Hugging Face推出的强化学习训练库，简化RLHF/DPO实现，与PEFT、Accelerate深度集成。
→ 详见 [Part 5 Ch 3: TRL与强化学习实战]</p><hr><h2 id=v>V<a class=anchor href=#v>#</a></h2><h3 id=vllm>vLLM<a class=anchor href=#vllm>#</a></h3><p>高性能LLM推理引擎，通过PagedAttention与Continuous Batching实现24倍吞吐量提升。
→ 详见 [Part 6 Ch 2: vLLM高性能推理]</p><h3 id=vera-vector-based-random-matrix-adaptation>VeRA (Vector-based Random Matrix Adaptation)<a class=anchor href=#vera-vector-based-random-matrix-adaptation>#</a></h3><p>使用共享随机矩阵+可训练缩放向量的PEFT方法，相比LoRA参数量更少。
→ 详见 [Part 3 Ch 2: 微调你的专属模型]</p><hr><h2 id=z>Z<a class=anchor href=#z>#</a></h2><h3 id=zero-zero-redundancy-optimizer>ZeRO (Zero Redundancy Optimizer)<a class=anchor href=#zero-zero-redundancy-optimizer>#</a></h3><p>DeepSpeed核心优化技术，通过分片优化器状态、梯度、参数实现显存高效分布式训练。
→ 详见 [Part 5 Ch 4: DeepSpeed分布式训练]</p><h3 id=zero-shot-learning-零样本学习>Zero-shot Learning (零样本学习)<a class=anchor href=#zero-shot-learning-%e9%9b%b6%e6%a0%b7%e6%9c%ac%e5%ad%a6%e4%b9%a0>#</a></h3><p>不提供任何示例直接让模型完成任务，依赖预训练期间学到的通用能力。
→ 详见 [Part 1 Ch 2: 与模型对话：提示工程基础]</p><hr><h2 id=交叉索引>交叉索引<a class=anchor href=#%e4%ba%a4%e5%8f%89%e7%b4%a2%e5%bc%95>#</a></h2><h3 id=按技术领域分类>按技术领域分类<a class=anchor href=#%e6%8c%89%e6%8a%80%e6%9c%af%e9%a2%86%e5%9f%9f%e5%88%86%e7%b1%bb>#</a></h3><p><strong>架构与原理</strong>:
Transformer | Self-Attention | Encoder-Decoder | MoE | Mamba</p><p><strong>训练与微调</strong>:
SFT | LoRA | QLoRA | DoRA | PEFT | AdaLoRA | Instruction Tuning</p><p><strong>对齐与优化</strong>:
RLHF | DPO | SimPO | PPO | Alignment</p><p><strong>推理与部署</strong>:
vLLM | PagedAttention | KV Cache | Speculative Decoding | Quantization | FlashAttention</p><p><strong>应用开发</strong>:
RAG | Agent | ReAct | Function Calling | Prompt Engineering | LangChain | LangGraph</p><p><strong>数据工程</strong>:
Synthetic Data | MinHash LSH | Cold Start | Chunking</p><p><strong>位置编码与长上下文</strong>:
RoPE | Context Window</p><p><strong>分布式训练</strong>:
DeepSpeed | ZeRO</p><hr><h2 id=参考文献>参考文献<a class=anchor href=#%e5%8f%82%e8%80%83%e6%96%87%e7%8c%ae>#</a></h2><p>本术语表基于2025年前沿研究与工程实践整理，具体技术细节与实现请参阅对应章节。</p><p><strong>版本</strong>: v1.0 (2025-01)
<strong>维护</strong>: 随书籍章节更新同步更新</p><hr><p><strong>使用建议</strong>:</p><ul><li>初学者: 按字母顺序浏览，结合章节交叉引用建立知识体系</li><li>实践者: 作为快速查询手册，定位具体技术的章节位置</li><li>研究者: 追踪术语演进脉络，理解技术发展趋势</li></ul></article><div style="margin-top:2rem;border-top:1px solid #e5e7eb;padding-top:1rem;font-size:.85rem;color:#6b7280;text-align:center">[统计组件仅在生产环境显示]</div><div class=giscus style=margin-top:2rem></div><script src=https://giscus.app/client.js data-repo=LordFoxFairy/LordFoxFairy.github.io data-repo-id=R_kgDOQ-JRGA data-category=Announcements data-category-id=DIC_kwDOQ-JRGM4C1PDC data-mapping=pathname data-strict=0 data-reactions-enabled=1 data-emit-metadata=0 data-input-position=bottom data-theme=preferred_color_scheme data-lang=zh-CN data-loading=lazy crossorigin=anonymous async></script><footer class=book-footer><div class="flex flex-wrap justify-between"><div></div><div></div></div><div class="flex flex-wrap justify-between"><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/%E7%AC%AC%E4%B8%83%E9%83%A8%E5%88%86%E9%AB%98%E7%BA%A7%E6%8A%80%E6%9C%AF%E4%B8%93%E9%A2%98/%E7%AC%AC5%E7%AB%A0_%E6%A8%A1%E5%9E%8B%E5%AE%89%E5%85%A8%E4%B8%8E%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7/ class="flex align-center"><img src=/icons/backward.svg class=book-icon alt=Backward>
<span>第5章 模型安全与可解释性</span>
</a></span><span><a href=/notebooks/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%AC%94%E8%AE%B0/roadmap/ class="flex align-center"><span>ROADMAP</span>
<img src=/icons/forward.svg class=book-icon alt=Forward></a></span></div><div class=book-comments></div><script>(function(){document.querySelectorAll("pre:has(code)").forEach(e=>{e.addEventListener("click",e.focus),e.addEventListener("copy",function(t){if(t.preventDefault(),navigator.clipboard){const t=window.getSelection().toString()||e.textContent;navigator.clipboard.writeText(t)}})})})()</script></footer><label for=menu-control class="hidden book-menu-overlay"></label></div><aside class=book-toc><div class=book-toc-content><nav id=TableOfContents><ul><li><a href=#a>A</a><ul><li><a href=#adalora-adaptive-lora>AdaLoRA (Adaptive LoRA)</a></li><li><a href=#agent-智能体>Agent (智能体)</a></li><li><a href=#alignment-对齐>Alignment (对齐)</a></li><li><a href=#attention-注意力机制>Attention (注意力机制)</a></li></ul></li><li><a href=#b>B</a><ul><li><a href=#bert-bidirectional-encoder-representations-from-transformers>BERT (Bidirectional Encoder Representations from Transformers)</a></li><li><a href=#bpe-byte-pair-encoding>BPE (Byte Pair Encoding)</a></li></ul></li><li><a href=#c>C</a><ul><li><a href=#chain-of-thought-cot--思维链>Chain-of-Thought (CoT / 思维链)</a></li><li><a href=#chunking-文档分块>Chunking (文档分块)</a></li><li><a href=#cold-start-冷启动>Cold Start (冷启动)</a></li><li><a href=#context-window-上下文窗口>Context Window (上下文窗口)</a></li><li><a href=#continuous-batching-连续批处理>Continuous Batching (连续批处理)</a></li></ul></li><li><a href=#d>D</a><ul><li><a href=#deepseek-r1>DeepSeek-R1</a></li><li><a href=#deepspeed>DeepSpeed</a></li><li><a href=#dora-weight-decomposed-low-rank-adaptation>DoRA (Weight-Decomposed Low-Rank Adaptation)</a></li><li><a href=#dpo-direct-preference-optimization>DPO (Direct Preference Optimization)</a></li></ul></li><li><a href=#e>E</a><ul><li><a href=#embedding-嵌入>Embedding (嵌入)</a></li><li><a href=#encoder-decoder>Encoder-Decoder</a></li></ul></li><li><a href=#f>F</a><ul><li><a href=#few-shot-learning-少样本学习>Few-shot Learning (少样本学习)</a></li><li><a href=#flashattention>FlashAttention</a></li><li><a href=#function-calling-函数调用>Function Calling (函数调用)</a></li></ul></li><li><a href=#g>G</a><ul><li><a href=#gpt-generative-pre-trained-transformer>GPT (Generative Pre-trained Transformer)</a></li><li><a href=#graphrag>GraphRAG</a></li><li><a href=#grokking-顿悟>Grokking (顿悟)</a></li><li><a href=#grpo-group-relative-policy-optimization>GRPO (Group Relative Policy Optimization)</a></li></ul></li><li><a href=#h>H</a><ul><li><a href=#hallucination-幻觉>Hallucination (幻觉)</a></li></ul></li><li><a href=#i>I</a><ul><li><a href=#in-context-learning-icl--上下文学习>In-Context Learning (ICL / 上下文学习)</a></li><li><a href=#instruction-tuning-指令微调>Instruction Tuning (指令微调)</a></li></ul></li><li><a href=#k>K</a><ul><li><a href=#kv-cache-键值缓存>KV Cache (键值缓存)</a></li></ul></li><li><a href=#l>L</a><ul><li><a href=#langchain>LangChain</a></li><li><a href=#langgraph>LangGraph</a></li><li><a href=#lawglm>LawGLM</a></li><li><a href=#llama-factory>LLaMA-Factory</a></li><li><a href=#lora-low-rank-adaptation>LoRA (Low-Rank Adaptation)</a></li></ul></li><li><a href=#m>M</a><ul><li><a href=#mamba>Mamba</a></li><li><a href=#matryoshka-embedding-俄罗斯套娃嵌入>Matryoshka Embedding (俄罗斯套娃嵌入)</a></li><li><a href=#mcp-model-context-protocol>MCP (Model Context Protocol)</a></li><li><a href=#minhash-lsh-局部敏感哈希>MinHash LSH (局部敏感哈希)</a></li><li><a href=#moe-mixture-of-experts--专家混合>MoE (Mixture of Experts / 专家混合)</a></li></ul></li><li><a href=#p>P</a><ul><li><a href=#pagedattention>PagedAttention</a></li><li><a href=#peft-parameter-efficient-fine-tuning--参数高效微调>PEFT (Parameter-Efficient Fine-Tuning / 参数高效微调)</a></li><li><a href=#ppo-proximal-policy-optimization>PPO (Proximal Policy Optimization)</a></li><li><a href=#prompt-engineering-提示工程>Prompt Engineering (提示工程)</a></li></ul></li><li><a href=#q>Q</a><ul><li><a href=#qlora-quantized-lora>QLoRA (Quantized LoRA)</a></li><li><a href=#quantization-量化>Quantization (量化)</a></li></ul></li><li><a href=#r>R</a><ul><li><a href=#rag-retrieval-augmented-generation--检索增强生成>RAG (Retrieval-Augmented Generation / 检索增强生成)</a></li><li><a href=#react-reasoning-and-acting>ReAct (Reasoning and Acting)</a></li><li><a href=#reranking-重排序>Reranking (重排序)</a></li><li><a href=#rlhf-reinforcement-learning-from-human-feedback--基于人类反馈的强化学习>RLHF (Reinforcement Learning from Human Feedback / 基于人类反馈的强化学习)</a></li><li><a href=#rope-rotary-position-embedding--旋转位置编码>RoPE (Rotary Position Embedding / 旋转位置编码)</a></li></ul></li><li><a href=#s>S</a><ul><li><a href=#scaling-laws-缩放定律>Scaling Laws (缩放定律)</a></li><li><a href=#self-attention-自注意力>Self-Attention (自注意力)</a></li><li><a href=#setfit-sentence-transformer-fine-tuning>SetFit (Sentence Transformer Fine-Tuning)</a></li><li><a href=#sft-supervised-fine-tuning--监督式微调>SFT (Supervised Fine-Tuning / 监督式微调)</a></li><li><a href=#simpo-simple-preference-optimization>SimPO (Simple Preference Optimization)</a></li><li><a href=#speculative-decoding-推测解码>Speculative Decoding (推测解码)</a></li><li><a href=#swiglu-swish-gated-linear-unit>SwiGLU (Swish-Gated Linear Unit)</a></li><li><a href=#synthetic-data-合成数据>Synthetic Data (合成数据)</a></li></ul></li><li><a href=#t>T</a><ul><li><a href=#temperature-温度参数>Temperature (温度参数)</a></li><li><a href=#tokenizer-分词器>Tokenizer (分词器)</a></li><li><a href=#top-p-sampling-核采样>Top-p Sampling (核采样)</a></li><li><a href=#transformer>Transformer</a></li><li><a href=#trl-transformer-reinforcement-learning>TRL (Transformer Reinforcement Learning)</a></li></ul></li><li><a href=#v>V</a><ul><li><a href=#vllm>vLLM</a></li><li><a href=#vera-vector-based-random-matrix-adaptation>VeRA (Vector-based Random Matrix Adaptation)</a></li></ul></li><li><a href=#z>Z</a><ul><li><a href=#zero-zero-redundancy-optimizer>ZeRO (Zero Redundancy Optimizer)</a></li><li><a href=#zero-shot-learning-零样本学习>Zero-shot Learning (零样本学习)</a></li></ul></li><li><a href=#交叉索引>交叉索引</a><ul><li><a href=#按技术领域分类>按技术领域分类</a></li></ul></li><li><a href=#参考文献>参考文献</a></li></ul></nav></div></aside></main></body></html>